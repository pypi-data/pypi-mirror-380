# ----------------------------------------------------------------------------
#
#  Welcome to Baml! To use this generated code, please run the following:
#
#  $ pip install baml
#
# ----------------------------------------------------------------------------

# This file was generated by BAML: please do not edit it. Instead, edit the
# BAML files and re-generate this code using: baml-cli generate
# baml-cli is available with the baml package.

_file_map = {

    "baml_src/main.baml": "// Test literal types in BAML\n\nclass StringLiterals {\n  status \"active\" | \"inactive\" | \"pending\"\n  environment \"dev\" | \"staging\" | \"prod\"\n  method \"GET\" | \"POST\" | \"PUT\" | \"DELETE\"\n}\n\nclass IntegerLiterals {\n  priority 1 | 2 | 3 | 4 | 5\n  httpStatus 200 | 201 | 400 | 404 | 500\n  maxRetries 0 | 1 | 3 | 5\n}\n\nclass BooleanLiterals {\n  alwaysTrue true\n  alwaysFalse false\n  eitherBool true | false\n}\n\nclass MixedLiterals {\n  id int\n  type \"user\" | \"admin\" | \"guest\"\n  level 1 | 2 | 3\n  isActive true | false\n  apiVersion \"v1\" | \"v2\" | \"v3\"\n}\n\nclass ComplexLiterals {\n  state \"draft\" | \"published\" | \"archived\" | \"deleted\"\n  retryCount 0 | 1 | 2 | 3 | 5 | 8 | 13  // Fibonacci sequence\n  response \"success\" | \"error\" | \"timeout\"\n  flags (true | false)[]\n  codes (200 | 404 | 500)[]\n}\n\nfunction TestStringLiterals(input: string) -> StringLiterals {\n  client \"openai/gpt-4o-mini\"\n  prompt #\"\n    Return a StringLiterals object with:\n    - status: \"active\"\n    - environment: \"prod\"\n    - method: \"POST\"\n    \n    {{ ctx.output_format }}\n    \n    Input: {{ input }}\n  \"#\n}\n\nfunction TestIntegerLiterals(input: string) -> IntegerLiterals {\n  client \"openai/gpt-4o-mini\"\n  prompt #\"\n    Return an IntegerLiterals object with:\n    - priority: 3\n    - httpStatus: 201\n    - maxRetries: 3\n    \n    {{ ctx.output_format }}\n    \n    Input: {{ input }}\n  \"#\n}\n\nfunction TestBooleanLiterals(input: string) -> BooleanLiterals {\n  client \"openai/gpt-4o-mini\"\n  prompt #\"\n    Return a BooleanLiterals object with:\n    - alwaysTrue: true\n    - alwaysFalse: false\n    - eitherBool: true\n    \n    {{ ctx.output_format }}\n    \n    Input: {{ input }}\n  \"#\n}\n\nfunction TestMixedLiterals(input: string) -> MixedLiterals {\n  client \"openai/gpt-4o-mini\"\n  prompt #\"\n    Return a MixedLiterals object with:\n    - id: 12345\n    - type: \"admin\"\n    - level: 2\n    - isActive: true\n    - apiVersion: \"v2\"\n    \n    {{ ctx.output_format }}\n    \n    Input: {{ input }}\n  \"#\n}\n\nfunction TestComplexLiterals(input: string) -> ComplexLiterals {\n  client \"openai/gpt-4o-mini\"\n  prompt #\"\n    Return a ComplexLiterals object with:\n    - state: \"published\"\n    - retryCount: 5\n    - response: \"success\"\n    - flags: [true, false, true]\n    - codes: [200, 404, 200]\n    \n    {{ ctx.output_format }}\n    \n    Input: {{ input }}\n  \"#\n}",
}

def get_baml_files():
    return _file_map