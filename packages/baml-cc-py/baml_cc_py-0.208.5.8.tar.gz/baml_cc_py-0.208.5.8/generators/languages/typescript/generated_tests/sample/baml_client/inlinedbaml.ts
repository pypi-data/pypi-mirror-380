/*************************************************************************************************

Welcome to Baml! To use this generated code, please run one of the following:

$ npm install @boundaryml/baml
$ yarn add @boundaryml/baml
$ pnpm add @boundaryml/baml

*************************************************************************************************/

// This file was generated by BAML: please do not edit it. Instead, edit the
// BAML files and re-generate this code using: baml-cli generate
// You can install baml-cli with:
//  $ npm install @boundaryml/baml
//
/* eslint-disable */
// tslint:disable
// @ts-nocheck
// biome-ignore format: autogenerated code

const fileMap = {
  
  "baml_src/main.baml": "class Example {\n    type \"example_1\" @stream.not_null\n    a int @check(a_is_positive, {{this > 0}})\n    b string\n\n    // This doesn't work :(\n    // @@stream.with_state\n}\n\nclass Example2 {\n    type \"example_2\" @stream.not_null\n    item Example\n    element string\n    element2 string\n}\n\nclient<llm> Thinking {\n    provider \"anthropic\"\n    options {\n        model \"claude-sonnet-4-20250514\"\n        thinking {\n            type enabled\n            budget_tokens 1024\n        }\n        max_tokens 2048\n    }\n}\n\nfunction Foo(x: int) -> Example2 | Example {\n    client Thinking\n    prompt #\"\n        Fill out this data model with some examples.\n\n        {{ ctx.output_format }}\n\n        use {{ x }} somewhere in the data model\n    \"#\n}\n\n// use flipped unions to ensure order doesn't matter for code-gen\nfunction Bar(x: int) -> Example | Example2 {\n    client \"openai/gpt-4o-mini\"\n    prompt #\"\n        Fill out this data model with some examples.\n\n        {{ ctx.output_format }}\n\n        use {{ x }} somewhere in the data model\n    \"#\n}\n\ntest FooTest {\n    functions [Foo]\n    args {\n        x 1\n    }\n}\n",
}
export const getBamlFiles = () => {
    return fileMap;
}