# ----------------------------------------------------------------------------
#
#  Welcome to Baml! To use this generated code, please run the following:
#
#  $ pip install baml
#
# ----------------------------------------------------------------------------

# This file was generated by BAML: please do not edit it. Instead, edit the
# BAML files and re-generate this code using: baml-cli generate
# baml-cli is available with the baml package.

_file_map = {

    "baml_src/main.baml": "enum TestEnum {\n  Angry @alias(\"k1\") @description(#\"\n    User is angry\n  \"#)\n  Happy @alias(\"k2\") @description(#\"\n    User is happy\n  \"#)\n  // tests whether k1 doesnt incorrectly get matched with k11\n  Sad @alias(\"k3\") @description(#\"\n    User is sad\n  \"#)\n  Confused @description(\n    User is confused\n  )\n  Excited @alias(\"k5\") @description(\n    User is excited\n  )\n  Exclamation @alias(\"k6\") // only alias\n  \n  Bored @alias(\"k7\") @description(#\"\n    User is bored\n    With a long description\n  \"#)\n   \n  @@alias(\"Category\")\n}\n\nfunction FnTestAliasedEnumOutput(input: string) -> TestEnum {\n  client \"openai/gpt-4o-mini\"\n  prompt #\"\n    Classify the user input into the following category\n      \n    {{ ctx.output_format }}\n\n    {{ _.role('user') }}\n    {{input}}\n\n    {{ _.role('assistant') }}\n    Category ID:\n  \"#\n}\n\nfunction ConsumeTestEnum(input: TestEnum) -> TestEnum {\n  client \"openai/gpt-4o-mini\"\n  prompt #\"\n    Return back to me verbatim:\n    \n    {{ input }}\n  \"#\n}\n\ntest FnTestAliasedEnumOutput {\n  functions [FnTestAliasedEnumOutput]\n  args {\n    input \"mehhhhh\"\n  }\n}",
}

def get_baml_files():
    return _file_map