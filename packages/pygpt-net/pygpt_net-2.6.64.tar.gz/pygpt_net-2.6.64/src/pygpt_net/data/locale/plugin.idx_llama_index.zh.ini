[LOCALE]
append_meta.description = 如果启用，将把LlamaIndex的元数据附加到额外上下文中
append_meta.label = 将元数据追加到上下文中
ask_llama_first.description = 如果启用，将首先询问LlamaIndex，并将回答作为在prompt中使用的额外知识。禁用时，只在需要时才询问LlamaIndex。INFO：在自主模式（通过插件）中禁用！
ask_llama_first.label = 首先询问LlamaIndex
idx.description = 查询附加上下文时要使用的索引。您可以同时使用多个索引。
idx.label = 要使用的索引
max_question_chars.description = 查询LlamaIndex时问题中的最大字符数，0 = 无限制。
max_question_chars.label = 问题中的最大字符数
model_prepare_question.description = 用于在询问LlamaIndex之前准备问题的模型，默认为：gpt-3.5-turbo
model_prepare_question.label = 准备问题的模型
model_query.description = 用于查询LlamaIndex的模型，默认为：gpt-3.5-turbo。
model_query.label = 模型
plugin.description = 将LlamaIndex（文件聊天）存储集成到任何聊天中，并提供来自文件和数据库中上下文历史的额外上下文知识
plugin.name = 文件聊天（LlamaIndex，内联）
prepare_question.description = 如果启用，在询问LlamaIndex之前，将准备问题以创建最佳查询。
prepare_question.label = 在首次询问LlamaIndex之前自动准备问题
prepare_question_max_tokens.description = 在询问LlamaIndex之前准备问题时输出中的最大令牌数。
prepare_question_max_tokens.label = 准备问题的最大输出令牌数
prompt.description = 用于指导如何使用LlamaIndex提供的额外数据的提示。
prompt.label = 提示
syntax_prepare_question.description = 准备问题的系统提示。
syntax_prepare_question.label = 准备问题的提示
