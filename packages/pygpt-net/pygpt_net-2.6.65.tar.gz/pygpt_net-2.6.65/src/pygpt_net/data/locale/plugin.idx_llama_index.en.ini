[LOCALE]
append_meta.description = If enabled, metadata from LlamaIndex will be appended to the additional context
append_meta.label = Append metadata to context
ask_llama_first.description = When enabled, LlamaIndex will be asked first, and the response will be used as additional knowledge in the prompt. When disabled, LlamaIndex will be asked only when needed. INFO: Disabled in autonomous mode (via plugin)!
ask_llama_first.label = Ask LlamaIndex first
idx.description = Indexes to use when querying for additional context. You can use more than one index at once.
idx.label = Indexes to use
max_question_chars.description = Maximum characters in a question when querying LlamaIndex, 0 = no limit.
max_question_chars.label = Maximum characters in question
model_prepare_question.description = Model used to prepare a question before asking LlamaIndex, default: gpt-3.5-turbo
model_prepare_question.label = Model for question preparation
model_query.description = Model used for querying LlamaIndex, default: gpt-3.5-turbo.
model_query.label = Model
plugin.description = Integrates LlamaIndex (Chat with files) storage in any chat and provides additional knowledge into context (from files and from context history in the database)
plugin.name = Chat with files (LlamaIndex, inline)
prepare_question.description = When enabled, the question will be prepared before asking LlamaIndex to create the best query.
prepare_question.label = Auto-prepare question before asking LlamaIndex first
prepare_question_max_tokens.description = Maximum tokens in output when preparing a question before asking LlamaIndex.
prepare_question_max_tokens.label = Maximum output tokens for question preparation
prompt.description = Prompt used to instruct how to use additional data provided from LlamaIndex.
prompt.label = Prompt
syntax_prepare_question.description = System prompt for question preparation.
syntax_prepare_question.label = Prompt for question preparation
