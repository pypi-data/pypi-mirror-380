[
  {
    "name": "engineer_response_formatter",
    "content": "**Code Explanation:**\n\nThis code implements the third step of our cosmic reionization project. It extracts observational constraints on the ionization fraction from Table 5.1 of the reference paper, sets up a Bayesian inference framework, and defines priors for model parameters. The code includes:\n\n1. A function to extract and process the observational data\n2. A likelihood function for comparing model predictions to observations\n3. Prior definitions for all model parameters\n4. Functions to calculate the CMB optical depth as an additional constraint\n5. Visualization of the observational constraints and prior distributions\n\n**Python Code:**\n\n```python\n# filename: codebase/bayesian_framework.py\nimport numpy as np\nimport matplotlib.pyplot as plt\nimport pandas as pd\nfrom scipy.stats import norm, uniform, truncnorm\nfrom scipy.integrate import simps\nimport os\nfrom codebase.cosmic_reionization_model import (\n    solve_QHII, H, sigma_T, c, n_H_0, X_p, year_in_s, Mpc_to_cm\n)\n\n# Create data directory if it doesn't exist\ndatabase_path = \"data/\"\nif not os.path.exists(database_path):\n    os.makedirs(database_path)\n\n# Set matplotlib parameters to avoid LaTeX rendering\nplt.rcParams['text.usetex'] = False\n\n\ndef extract_observational_data():\n    \"\"\"\n    Extract observational constraints on the ionization fraction from Table 5.1\n    of the reference paper and other sources.\n    \n    Returns:\n    --------\n    dict\n        Dictionary containing observational data with keys:\n        - 'z': redshift values\n        - 'Q_HII': ionization fraction values\n        - 'Q_HII_lower': lower bounds on ionization fraction\n        - 'Q_HII_upper': upper bounds on ionization fraction\n        - 'method': measurement method\n    \"\"\"\n    # Data from Table 5.1 of the reference paper\n    # Format: redshift, Q_HII, lower_error, upper_error, method\n    table_data = [\n        # Dark pixel covering fraction\n        [5.9, 0.91, 0.02, 0.03, \"Dark pixel\"],\n        # Lyman-alpha emission fraction\n        [7, 0.66, 0.09, 0.09, \"Lyman-alpha emission\"],\n        [7.5, 0.46, 0.12, 0.12, \"Lyman-alpha emission\"],\n        # Lyman-alpha + Lyman-beta dark fraction\n        [6, 0.87, 0.08, 0.05, \"Lyman-alpha + beta dark fraction\"],\n        [6.2, 0.79, 0.08, 0.08, \"Lyman-alpha + beta dark fraction\"],\n        [6.4, 0.69, 0.08, 0.08, \"Lyman-alpha + beta dark fraction\"],\n        [6.6, 0.52, 0.08, 0.08, \"Lyman-alpha + beta dark fraction\"],\n        [6.8, 0.35, 0.08, 0.08, \"Lyman-alpha + beta dark fraction\"],\n        # QSO damping wings\n        [7.09, 0.48, 0.26, 0.26, \"QSO damping wings\"],\n        [7.54, 0.4, 0.23, 0.23, \"QSO damping wings\"],\n        [7.0, 0.7, 0.2, 0.2, \"QSO damping wings\"],\n        # Lyman-alpha dark fraction\n        [5.6, 0.94, 0.06, 0.06, \"Lyman-alpha dark fraction\"],\n        [5.8, 0.88, 0.05, 0.05, \"Lyman-alpha dark fraction\"],\n        [6.0, 0.85, 0.05, 0.05, \"Lyman-alpha dark fraction\"],\n        [6.2, 0.71, 0.06, 0.06, \"Lyman-alpha dark fraction\"],\n        [6.4, 0.59, 0.06, 0.06, \"Lyman-alpha dark fraction\"],\n        [6.6, 0.44, 0.06, 0.06, \"Lyman-alpha dark fraction\"]\n    ]\n    \n    # Convert to numpy arrays\n    data = np.array(table_data)\n    z = data[:, 0]\n    Q_HII = data[:, 1]\n    Q_HII_lower = Q_HII - data[:, 2]  # Lower bound\n    Q_HII_upper = Q_HII + data[:, 3]  # Upper bound\n    method = data[:, 4]\n    \n    # Ensure bounds are within [0, 1]\n    Q_HII_lower = np.clip(Q_HII_lower, 0, 1)\n    Q_HII_upper = np.clip(Q_HII_upper, 0, 1)\n    \n    # Create a dictionary with the data\n    obs_data = {\n        'z': z,\n        'Q_HII': Q_HII,\n        'Q_HII_lower': Q_HII_lower,\n        'Q_HII_upper': Q_HII_upper,\n        'method': method\n    }\n    \n    # Additional constraint: CMB optical depth from Planck 2018\n    # tau_e = 0.054 \u00b1 0.007\n    obs_data['tau_e'] = 0.054\n    obs_data['tau_e_error'] = 0.007\n    \n    return obs_data\n\n\ndef calculate_tau_e(z_array, Q_HII_array, z_max=30.0):\n    \"\"\"\n    Calculate the CMB optical depth to electron scattering.\n    \n    Parameters:\n    -----------\n    z_array : array-like\n        Redshift array\n    Q_HII_array : array-like\n        Ionization fraction array\n    z_max : float, optional\n        Maximum redshift to consider\n        \n    Returns:\n    --------\n    float\n        CMB optical depth\n    \"\"\"\n    # Ensure z_array is in ascending order for integration\n    if z_array[0] > z_array[-1]:\n        z_array = z_array[::-1]\n        Q_HII_array = Q_HII_array[::-1]\n    \n    # Extend arrays to z_max if needed\n    if z_array[-1] < z_max:\n        z_extended = np.append(z_array, z_max)\n        # Assume Q_HII = 0 at z_max\n        Q_HII_extended = np.append(Q_HII_array, 0.0)\n    else:\n        z_extended = z_array\n        Q_HII_extended = Q_HII_array\n    \n    # Calculate the integrand: n_e(z) * sigma_T * c * dt/dz\n    integrand = np.zeros_like(z_extended)\n    \n    for i, z in enumerate(z_extended):\n        # Electron number density: n_e(z) = n_H(z) * Q_HII(z) * (1 + Y_p/(4*X_p))\n        # n_H(z) = n_H_0 * (1+z)^3\n        n_e = n_H_0 * (1 + z)**3 * Q_HII_extended[i] * (1 + 0.25/0.75)  # Assuming Y_p=0.25, X_p=0.75\n        \n        # dt/dz = -1/[H(z)*(1+z)]\n        dt_dz = -1.0 / (H(z) * (1 + z) * 1.0e5 / Mpc_to_cm)  # Convert H(z) from km/s/Mpc to 1/s\n        \n        integrand[i] = n_e * sigma_T * c * dt_dz\n    \n    # Integrate using Simpson's rule\n    tau_e = simps(integrand, z_extended)\n    \n    return tau_e\n\n\ndef log_likelihood(params, obs_data, z_range=(20.0, 5.0), QHII_init=1e-4, include_tau_e=True):\n    \"\"\"\n    Calculate the log-likelihood of the model parameters given the observational data.\n    \n    Parameters:\n    -----------\n    params : tuple\n        Model parameters (f0, alpha, beta, C0, gamma, xi0, M_h)\n    obs_data : dict\n        Dictionary containing observational data\n    z_range : tuple, optional\n        Redshift range for model calculation\n    QHII_init : float, optional\n        Initial ionization fraction\n    include_tau_e : bool, optional\n        Whether to include CMB optical depth constraint\n        \n    Returns:\n    --------\n    float\n        Log-likelihood value\n    \"\"\"\n    # Unpack parameters\n    f0, alpha, beta, C0, gamma, xi0, M_h = params\n    \n    # Solve the model\n    try:\n        z_model, Q_HII_model = solve_QHII(z_range, params, QHII_init)\n    except Exception as e:\n        print(\"Error in model solution: \" + str(e))\n        return -np.inf\n    \n    # Initialize log-likelihood\n    log_like = 0.0\n    \n    # Contribution from ionization fraction measurements\n    for i, z_obs in enumerate(obs_data['z']):\n        # Find the model value at the observed redshift\n        idx = np.argmin(np.abs(z_model - z_obs))\n        Q_HII_pred = Q_HII_model[idx]\n        \n        # Observed value and uncertainty\n        Q_HII_obs = obs_data['Q_HII'][i]\n        \n        # Use asymmetric errors if available\n        Q_HII_lower = obs_data['Q_HII_lower'][i]\n        Q_HII_upper = obs_data['Q_HII_upper'][i]\n        \n        # Calculate sigma based on which side of the observation the prediction falls\n        if Q_HII_pred <= Q_HII_obs:\n            sigma = Q_HII_obs - Q_HII_lower\n        else:\n            sigma = Q_HII_upper - Q_HII_obs\n        \n        # Avoid division by zero\n        if sigma <= 0:\n            sigma = 0.1  # Default uncertainty\n        \n        # Add to log-likelihood (assuming Gaussian errors)\n        log_like += -0.5 * ((Q_HII_pred - Q_HII_obs) / sigma)**2\n    \n    # Contribution from CMB optical depth if included\n    if include_tau_e and 'tau_e' in obs_data and 'tau_e_error' in obs_data:\n        tau_e_obs = obs_data['tau_e']\n        tau_e_error = obs_data['tau_e_error']\n        \n        # Calculate model prediction for tau_e\n        tau_e_pred = calculate_tau_e(z_model, Q_HII_model)\n        \n        # Add to log-likelihood\n        log_like += -0.5 * ((tau_e_pred - tau_e_obs) / tau_e_error)**2\n    \n    return log_like\n\n\ndef log_prior(params):\n    \"\"\"\n    Calculate the log-prior probability of the model parameters.\n    \n    Parameters:\n    -----------\n    params : tuple\n        Model parameters (f0, alpha, beta, C0, gamma, xi0, M_h)\n        \n    Returns:\n    --------\n    float\n        Log-prior value\n    \"\"\"\n    f0, alpha, beta, C0, gamma, xi0, M_h = params\n    \n    # Prior ranges based on physical plausibility and literature\n    # f0: escape fraction normalization [0, 1]\n    if not 0 <= f0 <= 1:\n        return -np.inf\n    \n    # alpha: redshift dependence of escape fraction [-2, 5]\n    if not -2 <= alpha <= 5:\n        return -np.inf\n    \n    # beta: halo mass dependence of escape fraction [-2, 2]\n    if not -2 <= beta <= 2:\n        return -np.inf\n    \n    # C0: clumping factor normalization [1, 20]\n    if not 1 <= C0 <= 20:\n        return -np.inf\n    \n    # gamma: redshift dependence of clumping factor [0, 3]\n    if not 0 <= gamma <= 3:\n        return -np.inf\n    \n    # xi0: ionizing photon production efficiency [1e24, 1e26]\n    if not 1e24 <= xi0 <= 1e26:\n        return -np.inf\n    \n    # M_h: characteristic halo mass [1e9, 1e12]\n    if not 1e9 <= M_h <= 1e12:\n        return -np.inf\n    \n    # If all parameters are within their prior ranges, return 0 (log(1))\n    return 0.0\n\n\ndef log_posterior(params, obs_data, z_range=(20.0, 5.0), QHII_init=1e-4, include_tau_e=True):\n    \"\"\"\n    Calculate the log-posterior probability of the model parameters.\n    \n    Parameters:\n    -----------\n    params : tuple\n        Model parameters (f0, alpha, beta, C0, gamma, xi0, M_h)\n    obs_data : dict\n        Dictionary containing observational data\n    z_range : tuple, optional\n        Redshift range for model calculation\n    QHII_init : float, optional\n        Initial ionization fraction\n    include_tau_e : bool, optional\n        Whether to include CMB optical depth constraint\n        \n    Returns:\n    --------\n    float\n        Log-posterior value\n    \"\"\"\n    # Calculate log-prior\n    lp = log_prior(params)\n    \n    # If parameters are outside prior range, return -inf\n    if not np.isfinite(lp):\n        return -np.inf\n    \n    # Calculate log-likelihood\n    ll = log_likelihood(params, obs_data, z_range, QHII_init, include_tau_e)\n    \n    # Return log-posterior (log-prior + log-likelihood)\n    return lp + ll\n\n\ndef visualize_observational_constraints(obs_data):\n    \"\"\"\n    Visualize the observational constraints on the ionization fraction.\n    \n    Parameters:\n    -----------\n    obs_data : dict\n        Dictionary containing observational data\n    \n    Returns:\n    --------\n    str\n        Filename of the saved plot\n    \"\"\"\n    # Create figure\n    fig, ax = plt.subplots(figsize=(10, 6), dpi=300)\n    \n    # Get unique measurement methods\n    methods = np.unique(obs_data['method'])\n    \n    # Define colors and markers for different methods\n    colors = ['blue', 'red', 'green', 'purple', 'orange']\n    markers = ['o', 's', '^', 'D', 'v']\n    \n    # Plot data points with error bars for each method\n    for i, method in enumerate(methods):\n        # Find indices for this method\n        idx = np.where(obs_data['method'] == method)[0]\n        \n        # Plot data points with error bars\n        ax.errorbar(\n            obs_data['z'][idx],\n            obs_data['Q_HII'][idx],\n            yerr=[\n                obs_data['Q_HII'][idx] - obs_data['Q_HII_lower'][idx],\n                obs_data['Q_HII_upper'][idx] - obs_data['Q_HII'][idx]\n            ],\n            fmt=markers[i % len(markers)],\n            color=colors[i % len(colors)],\n            label=method,\n            capsize=4,\n            markersize=8,\n            elinewidth=2\n        )\n    \n    # Set axis labels and title\n    ax.set_xlabel('Redshift (z)')\n    ax.set_ylabel('Ionization Fraction (Q_HII)')\n    ax.set_title('Observational Constraints on Ionization Fraction')\n    \n    # Set axis limits\n    ax.set_xlim(5, 8)\n    ax.set_ylim(0, \n```",
    "timestamp": "2025-07-28 18:49:53",
    "cost": {
      "Agent": [
        "engineer_response_formatter"
      ],
      "Model": [
        "o3-mini-2025-01-31"
      ],
      "Cost": [
        0.023749000000000003
      ],
      "Prompt Tokens": [
        4110
      ],
      "Completion Tokens": [
        4370
      ],
      "Total Tokens": [
        8480
      ]
    }
  },
  {
    "name": "executor",
    "content": "execution results:\nExecution output: \n  File \u001b[35m\"/home/tda/PABLO/AstroPilot/examples/reionization_project/experiment_generation_output/control/codebase/bayesian_framework.py\"\u001b[0m, line \u001b[35m355\u001b[0m\n    ax.set_ylim\u001b[1;31m(\u001b[0m0, \n               \u001b[1;31m^\u001b[0m\n\u001b[1;35mSyntaxError\u001b[0m: \u001b[35m'(' was never closed\u001b[0m\n",
    "timestamp": "2025-07-28 18:49:53",
    "cost": {
      "Agent": [],
      "Model": [],
      "Cost": [],
      "Prompt Tokens": [],
      "Completion Tokens": [],
      "Total Tokens": []
    }
  }
]