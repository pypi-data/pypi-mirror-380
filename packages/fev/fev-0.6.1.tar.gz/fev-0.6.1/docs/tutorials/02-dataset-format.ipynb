{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This notebook answers the following questions:\n",
    "1. What dataset format does `fev` expect?\n",
    "2. How is this format different from other popular time series data formats?\n",
    "3. How to convert my dataset into a format expected by `fev`?\n",
    "\n",
    "For information on how to convert a `datasets.Dataset` into other popular time series data formats see notebook [04-models.ipynb](./04-models.ipynb)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import warnings\n",
    "import datasets\n",
    "\n",
    "warnings.simplefilter(\"ignore\")\n",
    "datasets.disable_progress_bars()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## What dataset format does `fev` expect?\n",
    "We store time series datasets using the Hugging Face `datasets` library.\n",
    "\n",
    "We assume that all time series datasets obey the following schema:\n",
    "- each dataset entry (=row) represents a single (univariate/multivariate) time series\n",
    "- each entry contains\n",
    "    - 1/ a field of type `Sequence(timestamp)` that contains the **timestamps** of observations\n",
    "    - 2/ at least one field of type `Sequence(float)` that can be used as the **target** time series\n",
    "    - 3/ a field of type `string` that contains the **unique ID** of each time series\n",
    "- all fields of type `Sequence` have the same length\n",
    "\n",
    "A few notes about the above schema:\n",
    "- The ID, timestamp and target fields can have arbitrary names. These names can be specified when creating an `fev.Task` object.\n",
    "- In addition to the required fields above, the dataset can contain arbitrary other fields such as \n",
    "    - extra dynamic columns of type `Sequence`\n",
    "    - static features of type `Value` or `Image`\n",
    "- The dataset itself contains no information about the forecasting task. For example, the dataset does not say which dynamic columns should be used as the target column or exogenous features, or which columns are known only in the past. Such design makes it easy to re-use the same dataset across multiple different tasks without data duplication.\n",
    "\n",
    "Here is an example of such dataset taken from https://huggingface.co/datasets/autogluon/chronos_datasets."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Dataset({\n",
       "    features: ['id', 'timestamp', 'target', 'city', 'station', 'measurement'],\n",
       "    num_rows: 270\n",
       "})"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "ds = datasets.load_dataset(\"autogluon/chronos_datasets\", \"monash_kdd_cup_2018\", split=\"train\")\n",
    "ds.set_format(\"numpy\")\n",
    "ds"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Each entry corresponds to a single time series"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'id': np.str_('T000000'),\n",
       " 'timestamp': array(['2017-01-01T14:00:00.000', '2017-01-01T15:00:00.000',\n",
       "        '2017-01-01T16:00:00.000', ..., '2018-03-31T13:00:00.000',\n",
       "        '2018-03-31T14:00:00.000', '2018-03-31T15:00:00.000'],\n",
       "       dtype='datetime64[ms]'),\n",
       " 'target': array([453., 417., 395., ..., 132., 158., 118.], dtype=float32),\n",
       " 'city': np.str_('Beijing'),\n",
       " 'station': np.str_('aotizhongxin_aq'),\n",
       " 'measurement': np.str_('PM2.5')}"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "ds[0]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The `datasets` library conveniently stores metadata about the different features of the dataset."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'id': Value(dtype='string', id=None),\n",
       " 'timestamp': Sequence(feature=Value(dtype='timestamp[ms]', id=None), length=-1, id=None),\n",
       " 'target': Sequence(feature=Value(dtype='float64', id=None), length=-1, id=None),\n",
       " 'city': Value(dtype='string', id=None),\n",
       " 'station': Value(dtype='string', id=None),\n",
       " 'measurement': Value(dtype='string', id=None)}"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "ds.features"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## What are the advantages of the \"fev format\" compared to other common formats?\n",
    "We find the above dataset format (\"fev format\") more convenient and practical compared to other popular formats for storing time series data.\n",
    "\n",
    "**Long-format data frame** is quite common for storing data, is human readable and widely used by practitioners.\n",
    "\n",
    "|   item_id | timestamp   |   scaled_price |   promotion_email |   promotion_homepage |   unit_sales |   product_code | product_category   | product_subcategory   |   location_code |\n",
    "|----------:|:------------|---------------:|------------------:|---------------------:|-------------:|---------------:|:-------------------|:----------------------|----------------:|\n",
    "|  1062_101 | 2018-01-01  |       0.87913  |                 0 |                    0 |          636 |           1062 | Beverages          | Fruit Juice Mango     |             101 |\n",
    "|  1062_101 | 2018-01-08  |       0.994517 |                 0 |                    0 |          123 |           1062 | Beverages          | Fruit Juice Mango     |             101 |\n",
    "|  1062_101 | 2018-01-15  |       1.00551  |                 0 |                    0 |          391 |           1062 | Beverages          | Fruit Juice Mango     |             101 |\n",
    "|  1062_101 | 2018-01-22  |       1        |                 0 |                    0 |          339 |           1062 | Beverages          | Fruit Juice Mango     |             101 |\n",
    "|  ... | ...  |       ... |                 ... |                    ... |          ... |           ... | ...          | ...     |             ... |\n",
    "\n",
    "The long-format data frame has two main limitations compared to the \"fev format\".\n",
    "- Static features either need to be unnecessarily duplicated for each row, or need to be stored in a separate file.\n",
    "    - This becomes especially problematic if static features contain information such as images or text documents.\n",
    "- Dealing with large datasets is challenging.\n",
    "    - Obtaining individual time series requires an expensive `groupby` operation.\n",
    "    - When sharding, we need custom logic to ensure that rows corresponding to the same `item_id` are kept in the same shard.\n",
    "    - We either constantly need to ensure that the rows are ordered chronologically, or need to sort the rows each time the data is used.\n",
    "\n",
    "In contrast, the \"fev format\" can easily distinguish between static & dynamic features using the `datasets.Features` metadata. Since one time series corresponds to a single row, it has no problems with sharding.\n",
    "\n",
    "**GluonTS format** is another popular choice for storing time series data (e.g., used in [LOTSA](https://huggingface.co/datasets/Salesforce/lotsa_data)).\n",
    "\n",
    "Each entry is encoded as a dictionary with a pre-defined schema shared across all datasets\n",
    "\n",
    "```json\n",
    "{\n",
    "    \"start\": \"2024-01-01\", \n",
    "    \"freq\": \"1D\", \n",
    "    \"target\": [0.5, 1.2, ...], \n",
    "    \"feat_dynamic_real\": [[...]], \n",
    "    \"past_feat_dynamic_real\": [[...]], \n",
    "    \"feat_static_cat\": [...], \n",
    "    \"feat_static_real\": [...], \n",
    "    ...,\n",
    "}\n",
    "```\n",
    "This format is efficient and can be immediately consumed by some ML models. However, it also has some drawbacks compared to the \"fev format\".\n",
    "- It hard-codes the forecasting task definition into the dataset (i.e., which columns are used as target, which columns are known in the future vs. only in the past). This often leads to data duplication.\n",
    "    - For example, consider a dataset that contains energy demand & weather time series for some region. If you want to evaluate a model in 3 settings (weather forecast is available for the future; weather is known only in the past; weather is ignored, only historic demand is available), you will need to create 3 copies of the dataset.\n",
    "- It only supports numeric data, so it's not future-proof.\n",
    "    - Incorporating multimodal data such images or text into time series forecasting tasks [is becoming popular](https://arxiv.org/abs/2410.18959). The GluonTS format cannot natively handle that.\n",
    "- It relies on pandas `freq` aliases staying consistent over time - which is something that we [cannot take for granted](https://pandas.pydata.org/docs/whatsnew/v2.2.0.html#deprecate-aliases-m-q-y-etc-in-favour-of-me-qe-ye-etc-for-offsets).\n",
    "\n",
    "The \"fev format\" does not hard-code the task properties, natively deals with multimodal data and is not tied to the pandas versions."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## How to convert my dataset into a format expected by `fev`?\n",
    "If your dataset is stored in a long-format data frame, you can convert into an fev-compatible `datasets.Dataset` object using a helper function"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import fev.utils"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>item_id</th>\n",
       "      <th>timestamp</th>\n",
       "      <th>scaled_price</th>\n",
       "      <th>promotion_email</th>\n",
       "      <th>promotion_homepage</th>\n",
       "      <th>unit_sales</th>\n",
       "      <th>product_code</th>\n",
       "      <th>product_category</th>\n",
       "      <th>product_subcategory</th>\n",
       "      <th>location_code</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1062_101</td>\n",
       "      <td>2018-01-01</td>\n",
       "      <td>0.879130</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>636.0</td>\n",
       "      <td>1062</td>\n",
       "      <td>Beverages</td>\n",
       "      <td>Fruit Juice Mango</td>\n",
       "      <td>101</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1062_101</td>\n",
       "      <td>2018-01-08</td>\n",
       "      <td>0.994517</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>123.0</td>\n",
       "      <td>1062</td>\n",
       "      <td>Beverages</td>\n",
       "      <td>Fruit Juice Mango</td>\n",
       "      <td>101</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>1062_101</td>\n",
       "      <td>2018-01-15</td>\n",
       "      <td>1.005513</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>391.0</td>\n",
       "      <td>1062</td>\n",
       "      <td>Beverages</td>\n",
       "      <td>Fruit Juice Mango</td>\n",
       "      <td>101</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>1062_101</td>\n",
       "      <td>2018-01-22</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>339.0</td>\n",
       "      <td>1062</td>\n",
       "      <td>Beverages</td>\n",
       "      <td>Fruit Juice Mango</td>\n",
       "      <td>101</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>1062_101</td>\n",
       "      <td>2018-01-29</td>\n",
       "      <td>0.883309</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>661.0</td>\n",
       "      <td>1062</td>\n",
       "      <td>Beverages</td>\n",
       "      <td>Fruit Juice Mango</td>\n",
       "      <td>101</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "    item_id   timestamp  scaled_price  promotion_email  promotion_homepage  \\\n",
       "0  1062_101  2018-01-01      0.879130              0.0                 0.0   \n",
       "1  1062_101  2018-01-08      0.994517              0.0                 0.0   \n",
       "2  1062_101  2018-01-15      1.005513              0.0                 0.0   \n",
       "3  1062_101  2018-01-22      1.000000              0.0                 0.0   \n",
       "4  1062_101  2018-01-29      0.883309              0.0                 0.0   \n",
       "\n",
       "   unit_sales  product_code product_category product_subcategory  \\\n",
       "0       636.0          1062        Beverages   Fruit Juice Mango   \n",
       "1       123.0          1062        Beverages   Fruit Juice Mango   \n",
       "2       391.0          1062        Beverages   Fruit Juice Mango   \n",
       "3       339.0          1062        Beverages   Fruit Juice Mango   \n",
       "4       661.0          1062        Beverages   Fruit Juice Mango   \n",
       "\n",
       "   location_code  \n",
       "0            101  \n",
       "1            101  \n",
       "2            101  \n",
       "3            101  \n",
       "4            101  "
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df = pd.read_csv(\"https://autogluon.s3.us-west-2.amazonaws.com/datasets/timeseries/grocery_sales/merged.csv\")\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'item_id': Value(dtype='string', id=None),\n",
       " 'product_code': Value(dtype='int64', id=None),\n",
       " 'product_category': Value(dtype='string', id=None),\n",
       " 'product_subcategory': Value(dtype='string', id=None),\n",
       " 'location_code': Value(dtype='int64', id=None),\n",
       " 'timestamp': Sequence(feature=Value(dtype='timestamp[us]', id=None), length=-1, id=None),\n",
       " 'scaled_price': Sequence(feature=Value(dtype='float64', id=None), length=-1, id=None),\n",
       " 'promotion_email': Sequence(feature=Value(dtype='float64', id=None), length=-1, id=None),\n",
       " 'promotion_homepage': Sequence(feature=Value(dtype='float64', id=None), length=-1, id=None),\n",
       " 'unit_sales': Sequence(feature=Value(dtype='float64', id=None), length=-1, id=None)}"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "ds = fev.utils.convert_long_df_to_hf_dataset(df, id_column=\"item_id\", static_columns=[\"product_code\", \"product_category\", \"product_subcategory\", \"location_code\"])\n",
    "ds.features"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'item_id': np.str_('1062_101'),\n",
       " 'product_code': np.int64(1062),\n",
       " 'product_category': np.str_('Beverages'),\n",
       " 'product_subcategory': np.str_('Fruit Juice Mango'),\n",
       " 'location_code': np.int64(101),\n",
       " 'timestamp': array(['2018-01-01T00:00:00.000000', '2018-01-08T00:00:00.000000',\n",
       "        '2018-01-15T00:00:00.000000', '2018-01-22T00:00:00.000000',\n",
       "        '2018-01-29T00:00:00.000000', '2018-02-05T00:00:00.000000',\n",
       "        '2018-02-12T00:00:00.000000', '2018-02-19T00:00:00.000000',\n",
       "        '2018-02-26T00:00:00.000000', '2018-03-05T00:00:00.000000',\n",
       "        '2018-03-12T00:00:00.000000', '2018-03-19T00:00:00.000000',\n",
       "        '2018-03-26T00:00:00.000000', '2018-04-02T00:00:00.000000',\n",
       "        '2018-04-09T00:00:00.000000', '2018-04-16T00:00:00.000000',\n",
       "        '2018-04-23T00:00:00.000000', '2018-04-30T00:00:00.000000',\n",
       "        '2018-05-07T00:00:00.000000', '2018-05-14T00:00:00.000000',\n",
       "        '2018-05-21T00:00:00.000000', '2018-05-28T00:00:00.000000',\n",
       "        '2018-06-04T00:00:00.000000', '2018-06-11T00:00:00.000000',\n",
       "        '2018-06-18T00:00:00.000000', '2018-06-25T00:00:00.000000',\n",
       "        '2018-07-02T00:00:00.000000', '2018-07-09T00:00:00.000000',\n",
       "        '2018-07-16T00:00:00.000000', '2018-07-23T00:00:00.000000',\n",
       "        '2018-07-30T00:00:00.000000'], dtype='datetime64[us]'),\n",
       " 'scaled_price': array([0.8791298 , 0.99451727, 1.005513  , 1.        , 0.88330877,\n",
       "        0.8728938 , 0.8780195 , 0.8884807 , 0.9889777 , 1.0055426 ,\n",
       "        0.98920846, 1.0054836 , 1.        , 1.        , 1.011026  ,\n",
       "        0.9945471 , 0.99454623, 1.        , 0.99451727, 1.        ,\n",
       "        1.        , 0.9945471 , 1.011026  , 1.0054251 , 1.0054537 ,\n",
       "        1.        , 1.005513  , 1.        , 1.        , 1.0123464 ,\n",
       "        1.006248  ], dtype=float32),\n",
       " 'promotion_email': array([0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.],\n",
       "       dtype=float32),\n",
       " 'promotion_homepage': array([0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.],\n",
       "       dtype=float32),\n",
       " 'unit_sales': array([636., 123., 391., 339., 661., 513., 555., 485., 339., 230., 202.,\n",
       "        420., 418., 581., 472., 230., 176., 242., 270., 285., 258., 285.,\n",
       "        377., 339., 310., 231., 393., 447., 486., 284., 392.],\n",
       "       dtype=float32)}"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "ds.with_format(\"numpy\")[0]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "To verify that the dataset was converted correctly, use the `fev.utils.validate_time_series_dataset` method."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "fev.utils.validate_time_series_dataset(ds, id_column=\"item_id\", timestamp_column=\"timestamp\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "You can save the dataset to disk as a parquet file"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "# ds.to_parquet(DATASET_PATH)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Or directly push it to HF Hub"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "# ds.push_to_hub(repo_id=YOUR_REPO_ID, config_name=CONFIG_NAME)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "You can then use the path to your dataset when creating a `fev.Task`."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "fev",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
