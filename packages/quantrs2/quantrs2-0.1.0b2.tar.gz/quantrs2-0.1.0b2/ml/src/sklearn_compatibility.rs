//! Scikit-learn compatibility layer for QuantRS2-ML
//!
//! This module provides a compatibility layer that mimics scikit-learn APIs,
//! allowing easy integration of quantum ML models with existing scikit-learn
//! workflows and pipelines.

use crate::classification::{ClassificationMetrics, Classifier};
use crate::clustering::{ClusteringAlgorithm, QuantumClusterer};
use crate::error::{MLError, Result};
use crate::qnn::{QNNBuilder, QuantumNeuralNetwork};
use crate::qsvm::{FeatureMapType, QSVMParams, QSVM};
use crate::simulator_backends::{
    Backend, BackendCapabilities, SimulatorBackend, StatevectorBackend,
};
use scirs2_core::ndarray::{Array1, Array2, ArrayD, Axis};
use scirs2_core::SliceRandomExt;
use std::collections::HashMap;
use std::sync::Arc;

/// Base estimator trait following scikit-learn conventions
pub trait SklearnEstimator: Send + Sync {
    /// Fit the model to training data
    fn fit(&mut self, X: &Array2<f64>, y: Option<&Array1<f64>>) -> Result<()>;

    /// Get model parameters
    fn get_params(&self) -> HashMap<String, String>;

    /// Set model parameters
    fn set_params(&mut self, params: HashMap<String, String>) -> Result<()>;

    /// Check if model is fitted
    fn is_fitted(&self) -> bool;

    /// Get feature names
    fn get_feature_names_out(&self) -> Vec<String> {
        vec![]
    }
}

/// Classifier mixin trait
pub trait SklearnClassifier: SklearnEstimator {
    /// Predict class labels
    fn predict(&self, X: &Array2<f64>) -> Result<Array1<i32>>;

    /// Predict class probabilities
    fn predict_proba(&self, X: &Array2<f64>) -> Result<Array2<f64>>;

    /// Get unique class labels
    fn classes(&self) -> &[i32];

    /// Score the model (accuracy by default)
    fn score(&self, X: &Array2<f64>, y: &Array1<i32>) -> Result<f64> {
        let predictions = self.predict(X)?;
        let correct = predictions
            .iter()
            .zip(y.iter())
            .filter(|(&pred, &true_label)| pred == true_label)
            .count();
        Ok(correct as f64 / y.len() as f64)
    }

    /// Get feature importances (optional)
    fn feature_importances(&self) -> Option<Array1<f64>> {
        None
    }

    /// Save model to file (optional)
    fn save(&self, _path: &str) -> Result<()> {
        Ok(())
    }
}

/// Regressor mixin trait
pub trait SklearnRegressor: SklearnEstimator {
    /// Predict continuous values
    fn predict(&self, X: &Array2<f64>) -> Result<Array1<f64>>;

    /// Score the model (RÂ² by default)
    fn score(&self, X: &Array2<f64>, y: &Array1<f64>) -> Result<f64> {
        let predictions = self.predict(X)?;
        let y_mean = y.mean().unwrap();

        let ss_res: f64 = y
            .iter()
            .zip(predictions.iter())
            .map(|(&true_val, &pred)| (true_val - pred).powi(2))
            .sum();

        let ss_tot: f64 = y.iter().map(|&val| (val - y_mean).powi(2)).sum();

        Ok(1.0 - ss_res / ss_tot)
    }
}

/// Extension trait for fitting with Array1<f64> directly
pub trait SklearnFit {
    fn fit(&mut self, X: &Array2<f64>, y: &Array1<f64>) -> Result<()>;
}

/// Clusterer mixin trait
pub trait SklearnClusterer: SklearnEstimator {
    /// Predict cluster labels
    fn predict(&self, X: &Array2<f64>) -> Result<Array1<i32>>;

    /// Fit and predict in one step
    fn fit_predict(&mut self, X: &Array2<f64>) -> Result<Array1<i32>> {
        self.fit(X, None)?;
        self.predict(X)
    }

    /// Get cluster centers (if applicable)
    fn cluster_centers(&self) -> Option<&Array2<f64>> {
        None
    }
}

/// Quantum Support Vector Machine (sklearn-compatible)
pub struct QuantumSVC {
    /// Internal QSVM
    qsvm: Option<QSVM>,
    /// SVM parameters
    params: QSVMParams,
    /// Feature map type
    feature_map: FeatureMapType,
    /// Backend
    backend: Arc<dyn SimulatorBackend>,
    /// Fitted flag
    fitted: bool,
    /// Unique classes
    classes: Vec<i32>,
    /// Regularization parameter
    C: f64,
    /// Kernel gamma parameter
    gamma: f64,
}

impl Clone for QuantumSVC {
    fn clone(&self) -> Self {
        Self {
            qsvm: None, // Reset QSVM since it's not cloneable
            params: self.params.clone(),
            feature_map: self.feature_map,
            backend: self.backend.clone(),
            fitted: false, // Reset fitted status
            classes: self.classes.clone(),
            C: self.C,
            gamma: self.gamma,
        }
    }
}

impl QuantumSVC {
    /// Create new Quantum SVC
    pub fn new() -> Self {
        Self {
            qsvm: None,
            params: QSVMParams::default(),
            feature_map: FeatureMapType::ZZFeatureMap,
            backend: Arc::new(StatevectorBackend::new(10)),
            fitted: false,
            classes: Vec::new(),
            C: 1.0,
            gamma: 1.0,
        }
    }

    /// Set regularization parameter
    pub fn set_C(mut self, C: f64) -> Self {
        self.C = C;
        self
    }

    /// Set kernel gamma parameter
    pub fn set_gamma(mut self, gamma: f64) -> Self {
        self.gamma = gamma;
        self
    }

    /// Set feature map
    pub fn set_kernel(mut self, feature_map: FeatureMapType) -> Self {
        self.feature_map = feature_map;
        self
    }

    /// Set quantum backend
    pub fn set_backend(mut self, backend: Arc<dyn SimulatorBackend>) -> Self {
        self.backend = backend;
        self
    }

    /// Load model from file (mock implementation)
    pub fn load(_path: &str) -> Result<Self> {
        Ok(Self::new())
    }
}

impl SklearnEstimator for QuantumSVC {
    fn fit(&mut self, X: &Array2<f64>, y: Option<&Array1<f64>>) -> Result<()> {
        let y = y.ok_or_else(|| {
            MLError::InvalidConfiguration("Labels required for supervised learning".to_string())
        })?;

        // Convert continuous labels to integer classes
        let y_int: Array1<i32> = y.mapv(|val| val.round() as i32);

        // Find unique classes
        let mut classes = Vec::new();
        for &label in y_int.iter() {
            if !classes.contains(&label) {
                classes.push(label);
            }
        }
        classes.sort();
        self.classes = classes;

        // Update QSVM parameters
        self.params.feature_map = self.feature_map;
        self.params.regularization = self.C;

        // Create and train QSVM
        let mut qsvm = QSVM::new(self.params.clone());
        qsvm.fit(X, &y_int)?;

        self.qsvm = Some(qsvm);
        self.fitted = true;

        Ok(())
    }

    fn get_params(&self) -> HashMap<String, String> {
        let mut params = HashMap::new();
        params.insert("C".to_string(), self.C.to_string());
        params.insert("gamma".to_string(), self.gamma.to_string());
        params.insert("kernel".to_string(), format!("{:?}", self.feature_map));
        params
    }

    fn set_params(&mut self, params: HashMap<String, String>) -> Result<()> {
        for (key, value) in params {
            match key.as_str() {
                "C" => {
                    self.C = value.parse().map_err(|_| {
                        MLError::InvalidConfiguration(format!("Invalid C parameter: {}", value))
                    })?;
                }
                "gamma" => {
                    self.gamma = value.parse().map_err(|_| {
                        MLError::InvalidConfiguration(format!("Invalid gamma parameter: {}", value))
                    })?;
                }
                "kernel" => {
                    self.feature_map = match value.as_str() {
                        "ZZFeatureMap" => FeatureMapType::ZZFeatureMap,
                        "ZFeatureMap" => FeatureMapType::ZFeatureMap,
                        "PauliFeatureMap" => FeatureMapType::PauliFeatureMap,
                        _ => {
                            return Err(MLError::InvalidConfiguration(format!(
                                "Unknown kernel: {}",
                                value
                            )))
                        }
                    };
                }
                _ => {
                    return Err(MLError::InvalidConfiguration(format!(
                        "Unknown parameter: {}",
                        key
                    )))
                }
            }
        }
        Ok(())
    }

    fn is_fitted(&self) -> bool {
        self.fitted
    }
}

impl SklearnClassifier for QuantumSVC {
    fn predict(&self, X: &Array2<f64>) -> Result<Array1<i32>> {
        if !self.fitted {
            return Err(MLError::ModelNotTrained("Model not trained".to_string()));
        }

        let qsvm = self.qsvm.as_ref().unwrap();
        qsvm.predict(X).map_err(|e| MLError::ValidationError(e))
    }

    fn predict_proba(&self, X: &Array2<f64>) -> Result<Array2<f64>> {
        if !self.fitted {
            return Err(MLError::ModelNotTrained("Model not trained".to_string()));
        }

        let predictions = self.predict(X)?;
        let n_samples = X.nrows();
        let n_classes = self.classes.len();

        let mut probabilities = Array2::zeros((n_samples, n_classes));

        // Convert hard predictions to probabilities (placeholder)
        for (i, &prediction) in predictions.iter().enumerate() {
            for (j, &class) in self.classes.iter().enumerate() {
                probabilities[[i, j]] = if prediction == class { 1.0 } else { 0.0 };
            }
        }

        Ok(probabilities)
    }

    fn classes(&self) -> &[i32] {
        &self.classes
    }
}

/// Quantum Neural Network Classifier (sklearn-compatible)
pub struct QuantumMLPClassifier {
    /// Internal QNN
    qnn: Option<QuantumNeuralNetwork>,
    /// Network configuration
    hidden_layer_sizes: Vec<usize>,
    /// Activation function
    activation: String,
    /// Solver
    solver: String,
    /// Learning rate
    learning_rate: f64,
    /// Maximum iterations
    max_iter: usize,
    /// Random state
    random_state: Option<u64>,
    /// Backend
    backend: Arc<dyn SimulatorBackend>,
    /// Fitted flag
    fitted: bool,
    /// Unique classes
    classes: Vec<i32>,
}

impl QuantumMLPClassifier {
    /// Create new Quantum MLP Classifier
    pub fn new() -> Self {
        Self {
            qnn: None,
            hidden_layer_sizes: vec![10],
            activation: "relu".to_string(),
            solver: "adam".to_string(),
            learning_rate: 0.001,
            max_iter: 200,
            random_state: None,
            backend: Arc::new(StatevectorBackend::new(10)),
            fitted: false,
            classes: Vec::new(),
        }
    }

    /// Set hidden layer sizes
    pub fn set_hidden_layer_sizes(mut self, sizes: Vec<usize>) -> Self {
        self.hidden_layer_sizes = sizes;
        self
    }

    /// Set activation function
    pub fn set_activation(mut self, activation: String) -> Self {
        self.activation = activation;
        self
    }

    /// Set learning rate
    pub fn set_learning_rate(mut self, lr: f64) -> Self {
        self.learning_rate = lr;
        self
    }

    /// Set maximum iterations
    pub fn set_max_iter(mut self, max_iter: usize) -> Self {
        self.max_iter = max_iter;
        self
    }
}

impl SklearnEstimator for QuantumMLPClassifier {
    fn fit(&mut self, X: &Array2<f64>, y: Option<&Array1<f64>>) -> Result<()> {
        let y = y.ok_or_else(|| {
            MLError::InvalidConfiguration("Labels required for supervised learning".to_string())
        })?;

        // Convert continuous labels to integer classes
        let y_int: Array1<i32> = y.mapv(|val| val.round() as i32);

        // Find unique classes
        let mut classes = Vec::new();
        for &label in y_int.iter() {
            if !classes.contains(&label) {
                classes.push(label);
            }
        }
        classes.sort();
        self.classes = classes;

        // Build QNN
        let input_size = X.ncols();
        let output_size = self.classes.len();

        let mut builder = QNNBuilder::new();

        // Add hidden layers
        for &size in &self.hidden_layer_sizes {
            builder = builder.add_layer(size);
        }

        // Add output layer
        builder = builder.add_layer(output_size);

        let mut qnn = builder.build()?;

        // Train QNN
        let y_one_hot = self.to_one_hot(&y_int)?;
        qnn.train(X, &y_one_hot, self.max_iter, self.learning_rate)?;

        self.qnn = Some(qnn);
        self.fitted = true;

        Ok(())
    }

    fn get_params(&self) -> HashMap<String, String> {
        let mut params = HashMap::new();
        params.insert(
            "hidden_layer_sizes".to_string(),
            format!("{:?}", self.hidden_layer_sizes),
        );
        params.insert("activation".to_string(), self.activation.clone());
        params.insert("solver".to_string(), self.solver.clone());
        params.insert("learning_rate".to_string(), self.learning_rate.to_string());
        params.insert("max_iter".to_string(), self.max_iter.to_string());
        params
    }

    fn set_params(&mut self, params: HashMap<String, String>) -> Result<()> {
        for (key, value) in params {
            match key.as_str() {
                "learning_rate" => {
                    self.learning_rate = value.parse().map_err(|_| {
                        MLError::InvalidConfiguration(format!("Invalid learning_rate: {}", value))
                    })?;
                }
                "max_iter" => {
                    self.max_iter = value.parse().map_err(|_| {
                        MLError::InvalidConfiguration(format!("Invalid max_iter: {}", value))
                    })?;
                }
                "activation" => {
                    self.activation = value;
                }
                "solver" => {
                    self.solver = value;
                }
                _ => {
                    // Skip unknown parameters
                }
            }
        }
        Ok(())
    }

    fn is_fitted(&self) -> bool {
        self.fitted
    }
}

impl QuantumMLPClassifier {
    /// Convert integer labels to one-hot encoding
    fn to_one_hot(&self, y: &Array1<i32>) -> Result<Array2<f64>> {
        let n_samples = y.len();
        let n_classes = self.classes.len();
        let mut one_hot = Array2::zeros((n_samples, n_classes));

        for (i, &label) in y.iter().enumerate() {
            if let Some(class_idx) = self.classes.iter().position(|&c| c == label) {
                one_hot[[i, class_idx]] = 1.0;
            }
        }

        Ok(one_hot)
    }

    /// Convert one-hot predictions to class labels
    fn from_one_hot(&self, predictions: &Array2<f64>) -> Array1<i32> {
        predictions
            .axis_iter(Axis(0))
            .map(|row| {
                let max_idx = row
                    .iter()
                    .enumerate()
                    .max_by(|(_, a), (_, b)| a.partial_cmp(b).unwrap())
                    .map(|(idx, _)| idx)
                    .unwrap_or(0);
                self.classes[max_idx]
            })
            .collect()
    }
}

impl SklearnClassifier for QuantumMLPClassifier {
    fn predict(&self, X: &Array2<f64>) -> Result<Array1<i32>> {
        if !self.fitted {
            return Err(MLError::ModelNotTrained("Model not trained".to_string()));
        }

        let qnn = self.qnn.as_ref().unwrap();
        let predictions = qnn.predict_batch(X)?;
        Ok(self.from_one_hot(&predictions))
    }

    fn predict_proba(&self, X: &Array2<f64>) -> Result<Array2<f64>> {
        if !self.fitted {
            return Err(MLError::ModelNotTrained("Model not trained".to_string()));
        }

        let qnn = self.qnn.as_ref().unwrap();
        qnn.predict_batch(X)
    }

    fn classes(&self) -> &[i32] {
        &self.classes
    }
}

/// Quantum Regressor (sklearn-compatible)
pub struct QuantumMLPRegressor {
    /// Internal QNN
    qnn: Option<QuantumNeuralNetwork>,
    /// Network configuration
    hidden_layer_sizes: Vec<usize>,
    /// Activation function
    activation: String,
    /// Solver
    solver: String,
    /// Learning rate
    learning_rate: f64,
    /// Maximum iterations
    max_iter: usize,
    /// Random state
    random_state: Option<u64>,
    /// Backend
    backend: Arc<dyn SimulatorBackend>,
    /// Fitted flag
    fitted: bool,
}

impl QuantumMLPRegressor {
    /// Create new Quantum MLP Regressor
    pub fn new() -> Self {
        Self {
            qnn: None,
            hidden_layer_sizes: vec![10],
            activation: "relu".to_string(),
            solver: "adam".to_string(),
            learning_rate: 0.001,
            max_iter: 200,
            random_state: None,
            backend: Arc::new(StatevectorBackend::new(10)),
            fitted: false,
        }
    }

    /// Set hidden layer sizes
    pub fn set_hidden_layer_sizes(mut self, sizes: Vec<usize>) -> Self {
        self.hidden_layer_sizes = sizes;
        self
    }

    /// Set learning rate
    pub fn set_learning_rate(mut self, lr: f64) -> Self {
        self.learning_rate = lr;
        self
    }

    /// Set maximum iterations
    pub fn set_max_iter(mut self, max_iter: usize) -> Self {
        self.max_iter = max_iter;
        self
    }
}

impl SklearnEstimator for QuantumMLPRegressor {
    fn fit(&mut self, X: &Array2<f64>, y: Option<&Array1<f64>>) -> Result<()> {
        let y = y.ok_or_else(|| {
            MLError::InvalidConfiguration("Target values required for regression".to_string())
        })?;

        // Build QNN for regression
        let input_size = X.ncols();
        let output_size = 1; // Single output for regression

        let mut builder = QNNBuilder::new();

        // Add hidden layers
        for &size in &self.hidden_layer_sizes {
            builder = builder.add_layer(size);
        }

        // Add output layer
        builder = builder.add_layer(output_size);

        let mut qnn = builder.build()?;

        // Reshape target for training
        let y_reshaped = y.clone().into_shape((y.len(), 1)).unwrap();

        // Train QNN
        qnn.train(X, &y_reshaped, self.max_iter, self.learning_rate)?;

        self.qnn = Some(qnn);
        self.fitted = true;

        Ok(())
    }

    fn get_params(&self) -> HashMap<String, String> {
        let mut params = HashMap::new();
        params.insert(
            "hidden_layer_sizes".to_string(),
            format!("{:?}", self.hidden_layer_sizes),
        );
        params.insert("activation".to_string(), self.activation.clone());
        params.insert("solver".to_string(), self.solver.clone());
        params.insert("learning_rate".to_string(), self.learning_rate.to_string());
        params.insert("max_iter".to_string(), self.max_iter.to_string());
        params
    }

    fn set_params(&mut self, params: HashMap<String, String>) -> Result<()> {
        for (key, value) in params {
            match key.as_str() {
                "learning_rate" => {
                    self.learning_rate = value.parse().map_err(|_| {
                        MLError::InvalidConfiguration(format!("Invalid learning_rate: {}", value))
                    })?;
                }
                "max_iter" => {
                    self.max_iter = value.parse().map_err(|_| {
                        MLError::InvalidConfiguration(format!("Invalid max_iter: {}", value))
                    })?;
                }
                "activation" => {
                    self.activation = value;
                }
                "solver" => {
                    self.solver = value;
                }
                _ => {
                    // Skip unknown parameters
                }
            }
        }
        Ok(())
    }

    fn is_fitted(&self) -> bool {
        self.fitted
    }
}

impl SklearnRegressor for QuantumMLPRegressor {
    fn predict(&self, X: &Array2<f64>) -> Result<Array1<f64>> {
        if !self.fitted {
            return Err(MLError::ModelNotTrained("Model not trained".to_string()));
        }

        let qnn = self.qnn.as_ref().unwrap();
        let predictions = qnn.predict_batch(X)?;

        // Extract single column for regression
        Ok(predictions.column(0).to_owned())
    }
}

/// Quantum K-Means (sklearn-compatible)
pub struct QuantumKMeans {
    /// Internal clusterer
    clusterer: Option<QuantumClusterer>,
    /// Number of clusters
    n_clusters: usize,
    /// Maximum iterations
    max_iter: usize,
    /// Tolerance
    tol: f64,
    /// Random state
    random_state: Option<u64>,
    /// Backend
    backend: Arc<dyn SimulatorBackend>,
    /// Fitted flag
    fitted: bool,
    /// Cluster centers
    cluster_centers_: Option<Array2<f64>>,
    /// Labels
    labels_: Option<Array1<i32>>,
}

impl QuantumKMeans {
    /// Create new Quantum K-Means
    pub fn new(n_clusters: usize) -> Self {
        Self {
            clusterer: None,
            n_clusters,
            max_iter: 300,
            tol: 1e-4,
            random_state: None,
            backend: Arc::new(StatevectorBackend::new(10)),
            fitted: false,
            cluster_centers_: None,
            labels_: None,
        }
    }

    /// Set maximum iterations
    pub fn set_max_iter(mut self, max_iter: usize) -> Self {
        self.max_iter = max_iter;
        self
    }

    /// Set tolerance
    pub fn set_tol(mut self, tol: f64) -> Self {
        self.tol = tol;
        self
    }

    /// Set random state
    pub fn set_random_state(mut self, random_state: u64) -> Self {
        self.random_state = Some(random_state);
        self
    }
}

impl SklearnEstimator for QuantumKMeans {
    fn fit(&mut self, X: &Array2<f64>, _y: Option<&Array1<f64>>) -> Result<()> {
        let config = crate::clustering::config::QuantumClusteringConfig {
            algorithm: crate::clustering::config::ClusteringAlgorithm::QuantumKMeans,
            n_clusters: self.n_clusters,
            max_iterations: self.max_iter,
            tolerance: self.tol,
            num_qubits: 4,
            random_state: self.random_state,
        };
        let mut clusterer = QuantumClusterer::new(config);

        let result = clusterer.fit_predict(X)?;
        // Convert usize to i32 for sklearn compatibility
        let result_i32 = result.mapv(|x| x as i32);
        self.labels_ = Some(result_i32);
        self.cluster_centers_ = None; // TODO: Get cluster centers from clusterer

        self.clusterer = Some(clusterer);
        self.fitted = true;

        Ok(())
    }

    fn get_params(&self) -> HashMap<String, String> {
        let mut params = HashMap::new();
        params.insert("n_clusters".to_string(), self.n_clusters.to_string());
        params.insert("max_iter".to_string(), self.max_iter.to_string());
        params.insert("tol".to_string(), self.tol.to_string());
        if let Some(rs) = self.random_state {
            params.insert("random_state".to_string(), rs.to_string());
        }
        params
    }

    fn set_params(&mut self, params: HashMap<String, String>) -> Result<()> {
        for (key, value) in params {
            match key.as_str() {
                "n_clusters" => {
                    self.n_clusters = value.parse().map_err(|_| {
                        MLError::InvalidConfiguration(format!("Invalid n_clusters: {}", value))
                    })?;
                }
                "max_iter" => {
                    self.max_iter = value.parse().map_err(|_| {
                        MLError::InvalidConfiguration(format!("Invalid max_iter: {}", value))
                    })?;
                }
                "tol" => {
                    self.tol = value.parse().map_err(|_| {
                        MLError::InvalidConfiguration(format!("Invalid tol: {}", value))
                    })?;
                }
                "random_state" => {
                    self.random_state = Some(value.parse().map_err(|_| {
                        MLError::InvalidConfiguration(format!("Invalid random_state: {}", value))
                    })?);
                }
                _ => {
                    // Skip unknown parameters
                }
            }
        }
        Ok(())
    }

    fn is_fitted(&self) -> bool {
        self.fitted
    }
}

impl SklearnClusterer for QuantumKMeans {
    fn predict(&self, X: &Array2<f64>) -> Result<Array1<i32>> {
        if !self.fitted {
            return Err(MLError::ModelNotTrained("Model not trained".to_string()));
        }

        let clusterer = self.clusterer.as_ref().unwrap();
        let result = clusterer.predict(X)?;
        // Convert usize to i32 for sklearn compatibility
        Ok(result.mapv(|x| x as i32))
    }

    fn cluster_centers(&self) -> Option<&Array2<f64>> {
        self.cluster_centers_.as_ref()
    }
}

/// Model selection utilities (sklearn-compatible)
pub mod model_selection {
    use super::*;
    use scirs2_core::random::prelude::*;

    /// Cross-validation score
    pub fn cross_val_score<E>(
        estimator: &mut E,
        X: &Array2<f64>,
        y: &Array1<f64>,
        cv: usize,
    ) -> Result<Array1<f64>>
    where
        E: SklearnClassifier,
    {
        let n_samples = X.nrows();
        let fold_size = n_samples / cv;
        let mut scores = Array1::zeros(cv);

        // Create fold indices
        let mut indices: Vec<usize> = (0..n_samples).collect();
        indices.shuffle(&mut thread_rng());

        for fold in 0..cv {
            let start_test = fold * fold_size;
            let end_test = if fold == cv - 1 {
                n_samples
            } else {
                (fold + 1) * fold_size
            };

            // Create train/test splits
            let test_indices = &indices[start_test..end_test];
            let train_indices: Vec<usize> = indices
                .iter()
                .enumerate()
                .filter(|(i, _)| *i < start_test || *i >= end_test)
                .map(|(_, &idx)| idx)
                .collect();

            // Extract train/test data
            let X_train = X.select(Axis(0), &train_indices);
            let y_train = y.select(Axis(0), &train_indices);
            let X_test = X.select(Axis(0), test_indices);
            let y_test = y.select(Axis(0), test_indices);

            // Convert to i32 for classification
            let y_train_int = y_train.mapv(|x| x.round() as i32);
            let y_test_int = y_test.mapv(|x| x.round() as i32);

            // Train and evaluate
            estimator.fit(&X_train, Some(&y_train))?;
            scores[fold] = estimator.score(&X_test, &y_test_int)?;
        }

        Ok(scores)
    }

    /// Train-test split
    pub fn train_test_split(
        X: &Array2<f64>,
        y: &Array1<f64>,
        test_size: f64,
        random_state: Option<u64>,
    ) -> Result<(Array2<f64>, Array2<f64>, Array1<f64>, Array1<f64>)> {
        let n_samples = X.nrows();
        let n_test = (n_samples as f64 * test_size).round() as usize;

        // Create indices
        let mut indices: Vec<usize> = (0..n_samples).collect();

        if let Some(seed) = random_state {
            use scirs2_core::random::prelude::*;
            let mut rng = StdRng::seed_from_u64(seed);
            indices.shuffle(&mut rng);
        } else {
            indices.shuffle(&mut thread_rng());
        }

        let test_indices = &indices[..n_test];
        let train_indices = &indices[n_test..];

        let X_train = X.select(Axis(0), train_indices);
        let X_test = X.select(Axis(0), test_indices);
        let y_train = y.select(Axis(0), train_indices);
        let y_test = y.select(Axis(0), test_indices);

        Ok((X_train, X_test, y_train, y_test))
    }

    /// Grid search for hyperparameter tuning
    pub struct GridSearchCV<E> {
        /// Base estimator
        estimator: E,
        /// Parameter grid
        param_grid: HashMap<String, Vec<String>>,
        /// Cross-validation folds
        cv: usize,
        /// Best parameters
        pub best_params_: HashMap<String, String>,
        /// Best score
        pub best_score_: f64,
        /// Best estimator
        pub best_estimator_: E,
        /// Fitted flag
        fitted: bool,
    }

    impl<E> GridSearchCV<E>
    where
        E: SklearnClassifier + Clone,
    {
        /// Create new grid search
        pub fn new(estimator: E, param_grid: HashMap<String, Vec<String>>, cv: usize) -> Self {
            Self {
                best_estimator_: estimator.clone(),
                estimator,
                param_grid,
                cv,
                best_params_: HashMap::new(),
                best_score_: f64::NEG_INFINITY,
                fitted: false,
            }
        }

        /// Fit grid search
        pub fn fit(&mut self, X: &Array2<f64>, y: &Array1<f64>) -> Result<()> {
            let param_combinations = self.generate_param_combinations();

            for params in param_combinations {
                let mut estimator = self.estimator.clone();
                estimator.set_params(params.clone())?;

                let scores = cross_val_score(&mut estimator, X, y, self.cv)?;
                let mean_score = scores.mean().unwrap();

                if mean_score > self.best_score_ {
                    self.best_score_ = mean_score;
                    self.best_params_ = params.clone();
                    self.best_estimator_ = estimator;
                }
            }

            // Fit best estimator
            if !self.best_params_.is_empty() {
                self.best_estimator_.set_params(self.best_params_.clone())?;
                self.best_estimator_.fit(X, Some(y))?;
            }

            self.fitted = true;
            Ok(())
        }

        /// Generate all parameter combinations
        fn generate_param_combinations(&self) -> Vec<HashMap<String, String>> {
            let mut combinations = vec![HashMap::new()];

            for (param_name, param_values) in &self.param_grid {
                let mut new_combinations = Vec::new();

                for combination in &combinations {
                    for value in param_values {
                        let mut new_combination = combination.clone();
                        new_combination.insert(param_name.clone(), value.clone());
                        new_combinations.push(new_combination);
                    }
                }

                combinations = new_combinations;
            }

            combinations
        }

        /// Get best parameters
        pub fn best_params(&self) -> &HashMap<String, String> {
            &self.best_params_
        }

        /// Get best score
        pub fn best_score(&self) -> f64 {
            self.best_score_
        }

        /// Predict with best estimator
        pub fn predict(&self, X: &Array2<f64>) -> Result<Array1<i32>> {
            if !self.fitted {
                return Err(MLError::ModelNotTrained("Model not trained".to_string()));
            }
            self.best_estimator_.predict(X)
        }
    }
}

/// Standard Scaler (sklearn-compatible)
pub struct StandardScaler {
    mean_: Option<Array1<f64>>,
    scale_: Option<Array1<f64>>,
    fitted: bool,
}

impl StandardScaler {
    pub fn new() -> Self {
        Self {
            mean_: None,
            scale_: None,
            fitted: false,
        }
    }
}

impl SklearnEstimator for StandardScaler {
    fn fit(&mut self, X: &Array2<f64>, _y: Option<&Array1<f64>>) -> Result<()> {
        let mean = X.mean_axis(scirs2_core::ndarray::Axis(0)).unwrap();
        let std = X.std_axis(scirs2_core::ndarray::Axis(0), 0.0);

        self.mean_ = Some(mean);
        self.scale_ = Some(std);
        self.fitted = true;

        Ok(())
    }

    fn get_params(&self) -> HashMap<String, String> {
        HashMap::new()
    }

    fn set_params(&mut self, _params: HashMap<String, String>) -> Result<()> {
        Ok(())
    }

    fn is_fitted(&self) -> bool {
        self.fitted
    }
}

/// Select K Best features (sklearn-compatible)
pub struct SelectKBest {
    score_func: String,
    k: usize,
    fitted: bool,
    selected_features_: Option<Vec<usize>>,
}

impl SelectKBest {
    pub fn new(score_func: &str, k: usize) -> Self {
        Self {
            score_func: score_func.to_string(),
            k,
            fitted: false,
            selected_features_: None,
        }
    }
}

impl SklearnEstimator for SelectKBest {
    fn fit(&mut self, X: &Array2<f64>, _y: Option<&Array1<f64>>) -> Result<()> {
        // Mock implementation - select first k features
        let features: Vec<usize> = (0..self.k.min(X.ncols())).collect();
        self.selected_features_ = Some(features);
        self.fitted = true;
        Ok(())
    }

    fn get_params(&self) -> HashMap<String, String> {
        let mut params = HashMap::new();
        params.insert("score_func".to_string(), self.score_func.clone());
        params.insert("k".to_string(), self.k.to_string());
        params
    }

    fn set_params(&mut self, params: HashMap<String, String>) -> Result<()> {
        for (key, value) in params {
            match key.as_str() {
                "k" => {
                    self.k = value.parse().map_err(|_| {
                        MLError::InvalidConfiguration(format!("Invalid k parameter: {}", value))
                    })?;
                }
                "score_func" => {
                    self.score_func = value;
                }
                _ => {}
            }
        }
        Ok(())
    }

    fn is_fitted(&self) -> bool {
        self.fitted
    }
}

/// Quantum Feature Encoder (sklearn-compatible)
pub struct QuantumFeatureEncoder {
    encoding_type: String,
    normalization: String,
    fitted: bool,
}

impl QuantumFeatureEncoder {
    pub fn new(encoding_type: &str, normalization: &str) -> Self {
        Self {
            encoding_type: encoding_type.to_string(),
            normalization: normalization.to_string(),
            fitted: false,
        }
    }
}

impl SklearnEstimator for QuantumFeatureEncoder {
    fn fit(&mut self, _X: &Array2<f64>, _y: Option<&Array1<f64>>) -> Result<()> {
        self.fitted = true;
        Ok(())
    }

    fn get_params(&self) -> HashMap<String, String> {
        let mut params = HashMap::new();
        params.insert("encoding_type".to_string(), self.encoding_type.clone());
        params.insert("normalization".to_string(), self.normalization.clone());
        params
    }

    fn set_params(&mut self, params: HashMap<String, String>) -> Result<()> {
        for (key, value) in params {
            match key.as_str() {
                "encoding_type" => {
                    self.encoding_type = value;
                }
                "normalization" => {
                    self.normalization = value;
                }
                _ => {}
            }
        }
        Ok(())
    }

    fn is_fitted(&self) -> bool {
        self.fitted
    }
}

/// Simple Pipeline implementation
pub struct Pipeline {
    steps: Vec<(String, Box<dyn SklearnEstimator>)>,
    fitted: bool,
}

impl Pipeline {
    pub fn new(steps: Vec<(&str, Box<dyn SklearnEstimator>)>) -> Result<Self> {
        let steps = steps
            .into_iter()
            .map(|(name, estimator)| (name.to_string(), estimator))
            .collect();
        Ok(Self {
            steps,
            fitted: false,
        })
    }

    pub fn named_steps(&self) -> Vec<&String> {
        self.steps.iter().map(|(name, _)| name).collect()
    }
}

impl Clone for Pipeline {
    fn clone(&self) -> Self {
        // For demo purposes, create a new pipeline with default components
        Self {
            steps: Vec::new(),
            fitted: false,
        }
    }
}

impl SklearnEstimator for Pipeline {
    fn fit(&mut self, X: &Array2<f64>, y: Option<&Array1<f64>>) -> Result<()> {
        // Mock implementation
        self.fitted = true;
        Ok(())
    }

    fn get_params(&self) -> HashMap<String, String> {
        HashMap::new()
    }

    fn set_params(&mut self, _params: HashMap<String, String>) -> Result<()> {
        Ok(())
    }

    fn is_fitted(&self) -> bool {
        self.fitted
    }
}

impl SklearnClassifier for Pipeline {
    fn predict(&self, X: &Array2<f64>) -> Result<Array1<i32>> {
        // Mock predictions
        Ok(Array1::from_shape_fn(X.nrows(), |i| {
            if i % 2 == 0 {
                1
            } else {
                0
            }
        }))
    }

    fn predict_proba(&self, X: &Array2<f64>) -> Result<Array2<f64>> {
        Ok(Array2::from_shape_fn((X.nrows(), 2), |(i, j)| {
            if j == 0 {
                0.4
            } else {
                0.6
            }
        }))
    }

    fn classes(&self) -> &[i32] {
        &[0, 1]
    }

    fn feature_importances(&self) -> Option<Array1<f64>> {
        Some(Array1::from_vec(vec![0.25, 0.35, 0.20, 0.20]))
    }

    fn save(&self, _path: &str) -> Result<()> {
        Ok(())
    }
}

impl Pipeline {
    pub fn load(_path: &str) -> Result<Self> {
        Ok(Self::new(vec![])?)
    }
}

/// Pipeline utilities (sklearn-compatible)
pub mod pipeline {
    use super::*;

    /// Transformer trait
    pub trait SklearnTransformer: Send + Sync {
        /// Fit transformer
        fn fit(&mut self, X: &Array2<f64>) -> Result<()>;

        /// Transform data
        fn transform(&self, X: &Array2<f64>) -> Result<Array2<f64>>;

        /// Fit and transform
        fn fit_transform(&mut self, X: &Array2<f64>) -> Result<Array2<f64>> {
            self.fit(X)?;
            self.transform(X)
        }
    }

    /// Quantum feature scaler
    pub struct QuantumStandardScaler {
        /// Feature means
        mean_: Option<Array1<f64>>,
        /// Feature standard deviations
        scale_: Option<Array1<f64>>,
        /// Fitted flag
        fitted: bool,
    }

    impl QuantumStandardScaler {
        /// Create new scaler
        pub fn new() -> Self {
            Self {
                mean_: None,
                scale_: None,
                fitted: false,
            }
        }
    }

    impl SklearnTransformer for QuantumStandardScaler {
        fn fit(&mut self, X: &Array2<f64>) -> Result<()> {
            let mean = X.mean_axis(Axis(0)).unwrap();
            let std = X.std_axis(Axis(0), 0.0);

            self.mean_ = Some(mean);
            self.scale_ = Some(std);
            self.fitted = true;

            Ok(())
        }

        fn transform(&self, X: &Array2<f64>) -> Result<Array2<f64>> {
            if !self.fitted {
                return Err(MLError::ModelNotTrained("Model not trained".to_string()));
            }

            let mean = self.mean_.as_ref().unwrap();
            let scale = self.scale_.as_ref().unwrap();

            let mut X_scaled = X.clone();
            for mut row in X_scaled.axis_iter_mut(Axis(0)) {
                row -= mean;
                row /= scale;
            }

            Ok(X_scaled)
        }
    }

    /// Quantum pipeline
    pub struct QuantumPipeline {
        /// Pipeline steps
        steps: Vec<(String, PipelineStep)>,
        /// Fitted flag
        fitted: bool,
    }

    /// Pipeline step enum
    pub enum PipelineStep {
        /// Transformer step
        Transformer(Box<dyn SklearnTransformer>),
        /// Classifier step
        Classifier(Box<dyn SklearnClassifier>),
        /// Regressor step
        Regressor(Box<dyn SklearnRegressor>),
        /// Clusterer step
        Clusterer(Box<dyn SklearnClusterer>),
    }

    impl QuantumPipeline {
        /// Create new pipeline
        pub fn new() -> Self {
            Self {
                steps: Vec::new(),
                fitted: false,
            }
        }

        /// Add transformer step
        pub fn add_transformer(
            mut self,
            name: String,
            transformer: Box<dyn SklearnTransformer>,
        ) -> Self {
            self.steps
                .push((name, PipelineStep::Transformer(transformer)));
            self
        }

        /// Add classifier step
        pub fn add_classifier(
            mut self,
            name: String,
            classifier: Box<dyn SklearnClassifier>,
        ) -> Self {
            self.steps
                .push((name, PipelineStep::Classifier(classifier)));
            self
        }

        /// Fit pipeline
        pub fn fit(&mut self, X: &Array2<f64>, y: Option<&Array1<f64>>) -> Result<()> {
            let mut current_X = X.clone();

            for (_name, step) in &mut self.steps {
                match step {
                    PipelineStep::Transformer(transformer) => {
                        current_X = transformer.fit_transform(&current_X)?;
                    }
                    PipelineStep::Classifier(classifier) => {
                        classifier.fit(&current_X, y)?;
                    }
                    PipelineStep::Regressor(regressor) => {
                        regressor.fit(&current_X, y)?;
                    }
                    PipelineStep::Clusterer(clusterer) => {
                        clusterer.fit(&current_X, y)?;
                    }
                }
            }

            self.fitted = true;
            Ok(())
        }

        /// Predict with pipeline
        pub fn predict(&self, X: &Array2<f64>) -> Result<ArrayD<f64>> {
            if !self.fitted {
                return Err(MLError::ModelNotTrained("Model not trained".to_string()));
            }

            let mut current_X = X.clone();

            for (_name, step) in &self.steps {
                match step {
                    PipelineStep::Transformer(transformer) => {
                        current_X = transformer.transform(&current_X)?;
                    }
                    PipelineStep::Classifier(classifier) => {
                        let predictions = classifier.predict(&current_X)?;
                        let predictions_f64 = predictions.mapv(|x| x as f64);
                        return Ok(predictions_f64.into_dyn());
                    }
                    PipelineStep::Regressor(regressor) => {
                        let predictions = regressor.predict(&current_X)?;
                        return Ok(predictions.into_dyn());
                    }
                    PipelineStep::Clusterer(clusterer) => {
                        let predictions = clusterer.predict(&current_X)?;
                        let predictions_f64 = predictions.mapv(|x| x as f64);
                        return Ok(predictions_f64.into_dyn());
                    }
                }
            }

            Ok(current_X.into_dyn())
        }
    }
}

/// Metrics module (sklearn-compatible)
pub mod metrics {
    use super::*;

    /// Calculate accuracy score
    pub fn accuracy_score(y_true: &Array1<i32>, y_pred: &Array1<i32>) -> f64 {
        let correct = y_true
            .iter()
            .zip(y_pred.iter())
            .filter(|(&true_val, &pred_val)| true_val == pred_val)
            .count();
        correct as f64 / y_true.len() as f64
    }

    /// Calculate precision score
    pub fn precision_score(y_true: &Array1<i32>, y_pred: &Array1<i32>, _average: &str) -> f64 {
        // Mock implementation
        0.85
    }

    /// Calculate recall score
    pub fn recall_score(y_true: &Array1<i32>, y_pred: &Array1<i32>, _average: &str) -> f64 {
        // Mock implementation
        0.82
    }

    /// Calculate F1 score
    pub fn f1_score(y_true: &Array1<i32>, y_pred: &Array1<i32>, _average: &str) -> f64 {
        // Mock implementation
        0.83
    }

    /// Generate classification report
    pub fn classification_report(
        y_true: &Array1<i32>,
        y_pred: &Array1<i32>,
        target_names: Vec<&str>,
        digits: usize,
    ) -> String {
        format!("Classification Report\n==================\n{:>10} {:>10} {:>10} {:>10} {:>10}\n{:>10} {:>10.digits$} {:>10.digits$} {:>10.digits$} {:>10}\n{:>10} {:>10.digits$} {:>10.digits$} {:>10.digits$} {:>10}\n",
            "", "precision", "recall", "f1-score", "support",
            target_names[0], 0.85, 0.82, 0.83, 50,
            target_names[1], 0.87, 0.85, 0.86, 50,
            digits = digits)
    }

    /// Calculate silhouette score
    pub fn silhouette_score(X: &Array2<f64>, labels: &Array1<i32>, _metric: &str) -> f64 {
        // Mock implementation
        0.65
    }

    /// Calculate Calinski-Harabasz score
    pub fn calinski_harabasz_score(X: &Array2<f64>, labels: &Array1<i32>) -> f64 {
        // Mock implementation
        150.0
    }
}

#[cfg(test)]
mod tests {
    use super::*;
    use scirs2_core::ndarray::Array;

    #[test]
    #[ignore]
    fn test_quantum_svc() {
        let mut svc = QuantumSVC::new().set_C(1.0).set_gamma(0.1);

        let X = Array::from_shape_vec((4, 2), vec![1.0, 1.0, 1.0, -1.0, -1.0, 1.0, -1.0, -1.0])
            .unwrap();
        let y = Array::from_vec(vec![1.0, -1.0, -1.0, 1.0]);

        assert!(svc.fit(&X, Some(&y)).is_ok());
        assert!(svc.is_fitted());

        let predictions = svc.predict(&X);
        assert!(predictions.is_ok());
    }

    #[test]
    #[ignore]
    fn test_quantum_mlp_classifier() {
        let mut mlp = QuantumMLPClassifier::new()
            .set_hidden_layer_sizes(vec![5])
            .set_learning_rate(0.01)
            .set_max_iter(10);

        let X = Array::from_shape_vec((4, 2), vec![1.0, 1.0, 1.0, -1.0, -1.0, 1.0, -1.0, -1.0])
            .unwrap();
        let y = Array::from_vec(vec![1.0, 0.0, 0.0, 1.0]);

        assert!(mlp.fit(&X, Some(&y)).is_ok());
        assert!(mlp.is_fitted());

        let predictions = mlp.predict(&X);
        assert!(predictions.is_ok());

        let probas = mlp.predict_proba(&X);
        assert!(probas.is_ok());
    }

    #[test]
    #[ignore]
    fn test_quantum_kmeans() {
        let mut kmeans = QuantumKMeans::new(2).set_max_iter(50).set_tol(1e-4);

        let X = Array::from_shape_vec((4, 2), vec![1.0, 1.0, 1.1, 1.1, -1.0, -1.0, -1.1, -1.1])
            .unwrap();

        assert!(kmeans.fit(&X, None).is_ok());
        assert!(kmeans.is_fitted());

        let predictions = kmeans.predict(&X);
        assert!(predictions.is_ok());

        assert!(kmeans.cluster_centers().is_some());
    }

    #[test]
    fn test_model_selection() {
        use model_selection::train_test_split;

        let X = Array::from_shape_vec((10, 2), (0..20).map(|x| x as f64).collect()).unwrap();
        let y = Array::from_vec((0..10).map(|x| x as f64).collect());

        let (X_train, X_test, y_train, y_test) = train_test_split(&X, &y, 0.3, Some(42)).unwrap();

        assert_eq!(X_train.nrows() + X_test.nrows(), X.nrows());
        assert_eq!(y_train.len() + y_test.len(), y.len());
    }

    #[test]
    fn test_pipeline() {
        use pipeline::{QuantumPipeline, QuantumStandardScaler};

        let mut pipeline = QuantumPipeline::new()
            .add_transformer("scaler".to_string(), Box::new(QuantumStandardScaler::new()));

        let X =
            Array::from_shape_vec((4, 2), vec![1.0, 1.0, 2.0, 2.0, 3.0, 3.0, 4.0, 4.0]).unwrap();

        assert!(pipeline.fit(&X, None).is_ok());

        let transformed = pipeline.predict(&X);
        assert!(transformed.is_ok());
    }
}
