@dlt.table(
    name="{{ full_table_name }}",
    comment="{{ comment }}",
    table_properties={{ properties | tojson }}
    {%- if spark_conf %},
    spark_conf={{ spark_conf | tojson }}
    {%- endif %}
    {%- if partitions %},
    partition_cols={{ partitions | tojson }}
    {%- endif %}
    {%- if cluster_by %},
    cluster_by={{ cluster_by | tojson }}
    {%- endif %}
    {%- if table_path %},
    path="{{ table_path }}"
    {%- endif %}
    {%- if schema %},
    schema="{{ schema }}"
    {%- endif %}
    {%- if row_filter %},
    row_filter="{{ row_filter }}"
    {%- endif %}
    {%- if temporary %},
    temporary={{ temporary | string | title }}
    {%- endif %}
    {%- if refresh_schedule %},
    refresh_schedule="{{ refresh_schedule }}"
    {%- endif %}
)
{% if expect_all %}
@dlt.expect_all({{ expect_all | tojson }})
{% endif %}
{% if expect_all_or_drop %}
@dlt.expect_all_or_drop({{ expect_all_or_drop | tojson }})
{% endif %}
{% if expect_all_or_fail %}
@dlt.expect_all_or_fail({{ expect_all_or_fail | tojson }})
{% endif %}
def {{ table_name }}():
    """{{ description }}"""
    # Materialized views use batch processing
    {% if sql_query %}
    df = spark.sql("""{{ sql_query }}""")
    {% else %}
    df = spark.read.table("{{ source_view }}")
    {% endif %}
    {% if add_operational_metadata %}
    
    # Add operational metadata columns
    {% for col_name, expression in metadata_columns.items()|sort %}
    df = df.withColumn('{{ col_name }}', {{ expression }})
    {% endfor %}
    {% endif %}
    
    return df 