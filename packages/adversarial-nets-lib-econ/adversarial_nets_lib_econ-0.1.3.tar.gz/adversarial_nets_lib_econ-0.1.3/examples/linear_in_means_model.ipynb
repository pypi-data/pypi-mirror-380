{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "0",
   "metadata": {},
   "source": [
    "## Linear-in-Means (2-parameter) model\n",
    "\n",
    "**Model.** We specialize the structural mapping to a linear-in-means form with **no self-loops** and **two parameters** $\\theta=(\\rho,\\beta)$:\n",
    "$$\n",
    "Y \\;=\\; (I - \\rho P)^{-1}\\,\\big(X\\beta + \\varepsilon\\big),\n",
    "$$\n",
    "where $P$ is a peer operator with zero diagonal (optionally row-normalized), $X\\in\\mathbb{R}^{n\\times 1}$ is a single covariate (scalar loading $\\beta$ keeps the model two-parameter), and $\\varepsilon$ is mean-zero noise with **fixed variance** (not estimated).\n",
    "\n",
    "**No self-loops.** We take\n",
    "$$\n",
    "P \\;=\\; A - \\mathrm{diag}(A),\n",
    "$$\n",
    "optionally followed by row (degree) normalization. Only $\\mathrm{diag}(P)=0$ is required.\n",
    "\n",
    "**Invertibility / stability.** We guard against singularity of $I-\\rho P$ by enforcing\n",
    "$$\n",
    "|\\rho| \\;<\\; \\frac{1}{\\lambda_{\\max}(P)}\\,,\n",
    "$$\n",
    "with $\\lambda_{\\max}(P)$ the spectral radius. (For row-normalized $P$, typically $\\lambda_{\\max}\\le 1$.)\n",
    "\n",
    "**Why “2-parameter”?** The noise scale (e.g. $\\varepsilon\\sim\\mathcal{N}(0,\\sigma^2 I)$) is **fixed** and not estimated, so the only free structural parameters are the peer effect $\\rho$ and the scalar loading $\\beta$.\n",
    "\n",
    "**Adversarial estimation hook.** The generator returns $Y'(\\rho,\\beta)$ for fixed $(X,P)$. Your adversarial loop (same subgraph sampler and discriminator) can keep using cross-entropy on real vs synthetic subgraphs as the outer loss while the optimizer searches over $(\\rho,\\beta)$.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1",
   "metadata": {},
   "source": [
    "## Imports"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2",
   "metadata": {},
   "outputs": [],
   "source": [
    "import warnings\n",
    "warnings.filterwarnings(\"ignore\", message=\"An issue occurred while importing 'torch-sparse'\")\n",
    "warnings.filterwarnings(\"ignore\", message=\"An issue occurred while importing 'torch-cluster'\")\n",
    "\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "from torch_geometric.nn import GCNConv, global_mean_pool\n",
    "import numpy as np\n",
    "import networkx as nx\n",
    "import matplotlib.pyplot as plt\n",
    "from tqdm import tqdm\n",
    "import random\n",
    "\n",
    "from adversarial_nets import (\n",
    "    AdversarialEstimator,\n",
    "    GraphDataset,\n",
    "    objective_function\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3",
   "metadata": {},
   "source": [
    "## Test dataset "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4",
   "metadata": {},
   "outputs": [],
   "source": [
    "N_NODES = 1000\n",
    "N_SAMPLES = 800\n",
    "RESOLUTION = 10\n",
    "TRUE_PARAMS = [0.5, 0.7]\n",
    "\n",
    "\n",
    "def create_test_graph_dataset(\n",
    "    num_nodes: int = 100,\n",
    "    true_a: float = 0.2,     # peer effect α; must satisfy |α| < 1/ρ(P)\n",
    "    true_b: float = 2.0,     # loading β on X_1\n",
    "    p: float = 0.01,\n",
    "    seed: int = 42,\n",
    "    noise_scale: float = 0.01,\n",
    "    row_normalize: bool = True,\n",
    ") -> GraphDataset:\n",
    "    \"\"\"Generate a test graph dataset for a linear-in-means model:\n",
    "       Y = (I - α P)^{-1}(β X_1 + ε)\n",
    "    \"\"\"\n",
    "    rng = np.random.default_rng(seed)\n",
    "\n",
    "    G = nx.erdos_renyi_graph(n=num_nodes, p=p, seed=seed)\n",
    "    A = nx.to_numpy_array(G, dtype=float)\n",
    "    np.fill_diagonal(A, 0.0)\n",
    "\n",
    "    if row_normalize:\n",
    "        deg = A.sum(axis=1, keepdims=True)\n",
    "        P = A / np.where(deg == 0.0, 1.0, deg)\n",
    "    else:\n",
    "        P = A\n",
    "\n",
    "    X = rng.normal(0.0, 1.0, size=(num_nodes, 1))\n",
    "    eps = rng.normal(0.0, noise_scale, size=num_nodes)\n",
    "\n",
    "    eigvals = np.linalg.eigvals(P) if P.size else np.array([0.0])\n",
    "    rad = float(np.max(np.abs(eigvals))) or 1.0\n",
    "    if not (abs(true_a) < 1.0 / rad):\n",
    "        raise ValueError(f\"|alpha| must be < 1/rho(P) ≈ {1.0/rad:.3f}, got {true_a}\")\n",
    "\n",
    "    I = np.eye(num_nodes)\n",
    "    rhs = true_b * X[:, 0] + eps\n",
    "    Y = np.linalg.solve(I - true_a * P, rhs).reshape(-1, 1)\n",
    "\n",
    "    N = list(range(num_nodes))\n",
    "    return GraphDataset(X=X, Y=Y, A=A, N=N)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5",
   "metadata": {},
   "source": [
    "## Structural model mapping"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6",
   "metadata": {},
   "outputs": [],
   "source": [
    "def linear_in_means_model(x, adjacency, y0, theta):\n",
    "    \"\"\"\n",
    "    Two-parameter linear-in-means generator (signature preserved).\n",
    "\n",
    "        Y = (I - alpha P)^{-1}(beta X_1 + eps)\n",
    "\n",
    "    alpha: peer-effect parameter\n",
    "    beta : scalar loading on the first covariate X_1\n",
    "    P    : row-normalized peer operator with no self-loops\n",
    "    eps  : mean-zero noise with FIXED variance\n",
    "\n",
    "    Returns\n",
    "    -------\n",
    "    y : (n, 1) ndarray\n",
    "    \"\"\"\n",
    "\n",
    "    if not hasattr(linear_in_means_model, \"_rng\"):\n",
    "        linear_in_means_model._rng = np.random.default_rng(0)\n",
    "    if not hasattr(linear_in_means_model, \"_noise\"):\n",
    "        linear_in_means_model._noise = {}\n",
    "\n",
    "    def _to_numpy(A):\n",
    "        if hasattr(A, \"toarray\"):\n",
    "            A = A.toarray()\n",
    "        else:\n",
    "            A = np.asarray(A)\n",
    "        return A.astype(float, copy=False)\n",
    "\n",
    "    def _build_peer_operator(A, row_normalize=True):\n",
    "        P = A.astype(float, copy=True)\n",
    "        np.fill_diagonal(P, 0.0)\n",
    "        if row_normalize:\n",
    "            deg = P.sum(axis=1, keepdims=True)\n",
    "            with np.errstate(divide=\"ignore\", invalid=\"ignore\"):\n",
    "                P = P / np.where(deg == 0.0, 1.0, deg)\n",
    "                P[~np.isfinite(P)] = 0.0\n",
    "        return P\n",
    "\n",
    "    X = _to_numpy(x)\n",
    "    A = _to_numpy(adjacency)\n",
    "    n = A.shape[0]\n",
    "\n",
    "    a, b = float(theta[0]), float(theta[1])\n",
    "    P = _build_peer_operator(A, row_normalize=True)\n",
    "\n",
    "    noise_scale = 0.01\n",
    "    noise_cache = linear_in_means_model._noise\n",
    "    if n not in noise_cache:\n",
    "        noise_cache[n] = linear_in_means_model._rng.normal(0.0, noise_scale, size=n)\n",
    "    eps = noise_cache[n]\n",
    "\n",
    "    x1 = X if X.ndim == 1 else X[:, 0]\n",
    "    rhs = b * x1 + eps\n",
    "\n",
    "    I = np.eye(n)\n",
    "    M = I - a * P\n",
    "    try:\n",
    "        y = np.linalg.solve(M, rhs)\n",
    "    except np.linalg.LinAlgError:\n",
    "        y = np.linalg.solve(M + 1e-8 * I, rhs)\n",
    "\n",
    "    return y.reshape(-1, 1)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7",
   "metadata": {},
   "source": [
    "## Discriminator model\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "from torch_geometric.nn import SGConv\n",
    "from torch_geometric.nn.aggr import AttentionalAggregation\n",
    "\n",
    "def discriminator_factory(input_dim, hidden_dim=16, num_classes=2,\n",
    "                          dropout_rate=0.1, K=1, add_self_loops=False):\n",
    "    class TinySGC(nn.Module):\n",
    "        def __init__(self, in_dim, hid_dim, num_cls):\n",
    "            super().__init__()\n",
    "            self.sgc = SGConv(in_channels=in_dim, out_channels=hid_dim,\n",
    "                              K=K, cached=False, add_self_loops=add_self_loops, bias=True)\n",
    "            self.pool = AttentionalAggregation(gate_nn=nn.Linear(hid_dim, 1, bias=False))\n",
    "  \n",
    "            self.head = nn.Linear(hid_dim, num_cls)\n",
    "\n",
    "        def forward(self, data):\n",
    "            x, edge_index, batch = data.x, data.edge_index, data.batch\n",
    "            h = self.sgc(x, edge_index)\n",
    "            h = F.dropout(h, p=dropout_rate, training=self.training)\n",
    "            g = self.pool(h, batch)          \n",
    "            return self.head(g)\n",
    "\n",
    "    return TinySGC(input_dim, hidden_dim, num_classes)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9",
   "metadata": {},
   "source": [
    "## Visualization utils "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "10",
   "metadata": {},
   "outputs": [],
   "source": [
    "def visualize_objective_surface(estimator, m, resolution, num_epochs, verbose=False):\n",
    "    a_range = np.linspace(-5, 5, resolution)\n",
    "    b_range = np.linspace(-5, 5, resolution)\n",
    "    A, B = np.meshgrid(a_range, b_range)\n",
    "\n",
    "    Z = np.zeros_like(A)\n",
    "\n",
    "    total_evals = resolution * resolution\n",
    "    with tqdm(total=total_evals, desc=\"Evaluating objective surface\") as pbar:\n",
    "        for i in range(resolution):\n",
    "            for j in range(resolution):\n",
    "                theta = [A[i, j], B[i, j]]\n",
    "                Z[i, j] = objective_function(\n",
    "                    theta,\n",
    "                    estimator.ground_truth_generator,\n",
    "                    estimator.synthetic_generator,\n",
    "                    discriminator_factory=estimator.discriminator_factory,\n",
    "                    num_epochs=num_epochs,\n",
    "                    m=m,\n",
    "                    verbose=verbose,\n",
    "                    num_runs=12,\n",
    "                    k_hops=1\n",
    "                )\n",
    "                pbar.update(1)\n",
    "\n",
    "    fig = plt.figure(figsize=(12, 5))\n",
    "\n",
    "    ax1 = fig.add_subplot(121, projection='3d')\n",
    "    surf = ax1.plot_surface(A, B, Z, cmap='viridis', alpha=0.8)\n",
    "    ax1.set_xlabel('Parameter a')\n",
    "    ax1.set_ylabel('Parameter b')\n",
    "    ax1.set_zlabel('Discriminator Accuracy')\n",
    "    ax1.set_title('Objective Function Surface')\n",
    "\n",
    "    true_a, true_b = TRUE_PARAMS[0], TRUE_PARAMS[1] \n",
    "    ax1.scatter([true_a], [true_b], [Z.min()], color='red', s=100, marker='*', label='True params')\n",
    "\n",
    "    ax2 = fig.add_subplot(122)\n",
    "    contour = ax2.contour(A, B, Z, levels=20, cmap='viridis')\n",
    "    ax2.clabel(contour, inline=True, fontsize=8)\n",
    "    ax2.scatter([true_a], [true_b], color='red', s=100, marker='*', label='True params')\n",
    "\n",
    "    if hasattr(estimator, 'estimated_params') and estimator.estimated_params is not None:\n",
    "        est_a, est_b = estimator.estimated_params\n",
    "        ax1.scatter([est_a], [est_b], [Z.min()], color='orange', s=100, marker='^', label='Estimated params')\n",
    "        ax2.scatter([est_a], [est_b], color='orange', s=100, marker='^', label='Estimated params')\n",
    "\n",
    "    ax2.set_xlabel('Parameter a')\n",
    "    ax2.set_ylabel('Parameter b')\n",
    "    ax2.set_title('Objective Function Contours')\n",
    "    ax2.legend()\n",
    "\n",
    "    plt.colorbar(surf, ax=ax1, shrink=0.5)\n",
    "    plt.tight_layout()\n",
    "    plt.show()\n",
    "\n",
    "    return Z, (A, B)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "11",
   "metadata": {},
   "source": [
    "## Generate dataset\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "12",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"Testing Adversarial Estimation for Linear-in-Means Model\")\n",
    "print(\"=\" * 60)\n",
    "print(\"\\n1. Generating test dataset...\")\n",
    "test_data = create_test_graph_dataset(num_nodes=N_NODES, true_a=TRUE_PARAMS[0], true_b=TRUE_PARAMS[1], p=0.05, noise_scale=0.001)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "13",
   "metadata": {},
   "source": [
    "## Create estimator\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "14",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"\\n2. Creating adversarial estimator...\")\n",
    "estimator = AdversarialEstimator(\n",
    "    ground_truth_data=test_data,\n",
    "    structural_model=linear_in_means_model,\n",
    "    initial_params=[0.0, 0.0],\n",
    "    bounds=[(0.0, 1.0), (0.0,1.0)],\n",
    "    discriminator_factory=discriminator_factory,\n",
    "    gp_params={\n",
    "        'initial_point_generator': 'sobol',\n",
    "        'n_initial_points': 100,\n",
    "        'noise': 0.0001,\n",
    "        'n_calls':150,\n",
    "        'acq_func': 'PI'\n",
    "    },\n",
    "    metric=\"neg_logloss\",\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "15",
   "metadata": {},
   "source": [
    "## Calibrate discriminator hyperparameters\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "16",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"\\n3. Calibrating discriminator hyperparameters...\")\n",
    "search_space = {\n",
    "    'discriminator_params': {\n",
    "        \"hidden_dim\":    lambda t: t.suggest_int(\"hidden_dim\",6, 12, step=1),\n",
    "        \"dropout_rate\":  lambda t: t.suggest_float(\"dropout_rate\", 0.0, 0.20, step=0.01)\n",
    "    },\n",
    "    'training_params': {\n",
    "        \"lr\":             lambda t: t.suggest_float(\"lr\", 1e-4, 1e-2, step=0.0001),\n",
    "        \"weight_decay\":   lambda t: t.suggest_float(\"weight_decay\", 0.0, 1e-2, step=0.005),\n",
    "        \"label_smoothing\":lambda t: t.suggest_float(\"label_smoothing\", 0.0, 1e-2, step=0.005),\n",
    "        \"batch_size\":     lambda t: t.suggest_categorical(\"batch_size\", [64, 128, 256]),\n",
    "        \"num_epochs\":     lambda t: t.suggest_int(\"num_epochs\", 7, 8),\n",
    "    }\n",
    "}\n",
    "\n",
    "optimizer_params = {'n_trials': 20}\n",
    "estimator.callibrate(search_space, optimizer_params, metric_name='ace', k=5, num_runs=5, k_hops=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "17",
   "metadata": {},
   "outputs": [],
   "source": [
    "estimator.calibration_study.best_params"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "18",
   "metadata": {},
   "outputs": [],
   "source": [
    "visualize_objective_surface(\n",
    "    resolution=25, \n",
    "    estimator=estimator, \n",
    "    num_epochs=estimator.calibration_study.best_params['num_epochs'], \n",
    "    m=N_SAMPLES\n",
    "    )\n",
    "\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "19",
   "metadata": {},
   "source": [
    "## Adversarial estimation\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "20",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"4. Running adversarial estimation...\")\n",
    "result = estimator.estimate(\n",
    "    m=N_SAMPLES,\n",
    "    verbose=True,\n",
    "    k_hops=1,\n",
    "    num_runs=5\n",
    ")\n",
    "\n",
    "estimated_params = result['x'] if isinstance(result, dict) else result.x\n",
    "estimator.estimated_params = estimated_params\n",
    "\n",
    "print(\"5. Results:\")\n",
    "print(f\"   - True parameters: alpha={TRUE_PARAMS[0]}, beta={TRUE_PARAMS[1]}\")\n",
    "print(f\"   - Estimated parameters: alpha={estimated_params[0]:.4f}, beta={estimated_params[1]:.4f}\")\n",
    "print(\n",
    "    f\"   - Estimation error: alpha_error={abs(estimated_params[0] - TRUE_PARAMS[0]):.4f}, \"\n",
    "    f\"beta_error={abs(estimated_params[1] - TRUE_PARAMS[1]):.4f}\"\n",
    ")\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.show()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
