"""
Configuration for all available models in LokisApi.
"""

# Gemini models configuration
GEMINI_MODELS = [
    {
        "id": "gemini-2.5-pro",
        "name": "Gemini 2.5 Pro",
        "category": "text",
        "provider": "Google",
        "rpm": 5,
        "tpm": 250_000,
        "rpd": 100,
        "deprecated": False,
        "supports_text": True,
        "supports_thinking": True,
        "supports_images": False,
    },
    {
        "id": "gemini-2.5-flash",
        "name": "Gemini 2.5 Flash",
        "category": "text",
        "provider": "Google",
        "rpm": 10,
        "tpm": 250_000,
        "rpd": 250,
        "deprecated": False,
        "supports_text": True,
        "supports_thinking": True,
        "supports_images": False,
    },
    {
        "id": "gemini-2.5-flash-lite",
        "name": "Gemini 2.5 Flash-Lite",
        "category": "text",
        "provider": "Google",
        "rpm": 15,
        "tpm": 250_000,
        "rpd": 1000,
        "deprecated": False,
        "supports_text": True,
        "supports_thinking": True,
        "supports_images": False,
    },
    {
        "id": "gemini-2.0-flash",
        "name": "Gemini 2.0 Flash",
        "category": "text",
        "provider": "Google",
        "rpm": 15,
        "tpm": 1_000_000,
        "rpd": 200,
        "deprecated": False,
        "supports_text": True,
        "supports_thinking": False,
        "supports_images": False,
    },
    {
        "id": "gemini-2.0-flash-lite",
        "name": "Gemini 2.0 Flash-Lite",
        "category": "text",
        "provider": "Google",
        "rpm": 30,
        "tpm": 1_000_000,
        "rpd": 200,
        "deprecated": False,
        "supports_text": True,
        "supports_thinking": False,
        "supports_images": False,
    },
    {
        "id": "gemini-1.5-flash",
        "name": "Gemini 1.5 Flash (Deprecated)",
        "category": "deprecated",
        "provider": "Google",
        "rpm": 15,
        "tpm": 250_000,
        "rpd": 50,
        "deprecated": True,
        "supports_text": True,
        "supports_thinking": False,
        "supports_images": False,
    },
    {
        "id": "gemini-1.5-flash-8b",
        "name": "Gemini 1.5 Flash-8B (Deprecated)",
        "category": "deprecated",
        "provider": "Google",
        "rpm": 15,
        "tpm": 250_000,
        "rpd": 50,
        "deprecated": True,
        "supports_text": True,
        "supports_thinking": False,
        "supports_images": False,
    },
    {
        "id": "gemini-1.5-pro",
        "name": "Gemini 1.5 Pro (Deprecated)",
        "category": "deprecated",
        "provider": "Google",
        "rpm": None,
        "tpm": None,
        "rpd": None,
        "deprecated": True,
        "supports_text": True,
        "supports_thinking": False,
        "supports_images": False,
    }
]

# OpenAI models configuration
OPENAI_MODELS = [
    {
        "id": "gpt-5",
        "name": "GPT-5",
        "provider": "OpenAI",
        "category": "chat",
        "rpm": 30,
        "tpm": 60_000,
        "rpd": 600,
        "deprecated": False,
        "supports_text": True,
        "supports_thinking": False,
        "supports_images": False,
    },
    {
        "id": "gpt-5-mini",
        "name": "GPT-5 Mini",
        "provider": "OpenAI",
        "category": "chat",
        "rpm": 50,
        "tpm": 100_000,
        "rpd": 1000,
        "deprecated": False,
        "supports_text": True,
        "supports_thinking": False,
        "supports_images": False,
    },
    {
        "id": "gpt-5-nano",
        "name": "GPT-5 Nano",
        "provider": "OpenAI",
        "category": "chat",
        "rpm": 80,
        "tpm": 150_000,
        "rpd": 1500,
        "deprecated": False,
        "supports_text": True,
        "supports_thinking": False,
        "supports_images": False,
    },
    {
        "id": "gpt-4.1",
        "name": "GPT-4.1",
        "provider": "OpenAI",
        "category": "chat",
        "rpm": 40,
        "tpm": 80_000,
        "rpd": 800,
        "deprecated": False,
        "supports_text": True,
        "supports_thinking": False,
        "supports_images": False,
    },
    {
        "id": "gpt-4.1-mini",
        "name": "GPT-4.1 Mini",
        "provider": "OpenAI",
        "category": "chat",
        "rpm": 60,
        "tpm": 100_000,
        "rpd": 1000,
        "deprecated": False,
        "supports_text": True,
        "supports_thinking": False,
        "supports_images": False,
    },
    {
        "id": "gpt-4.1-nano",
        "name": "GPT-4.1 Nano",
        "provider": "OpenAI",
        "category": "chat",
        "rpm": 80,
        "tpm": 130_000,
        "rpd": 1200,
        "deprecated": False,
        "supports_text": True,
        "supports_thinking": False,
        "supports_images": False,
    },
    {
        "id": "gpt-4-turbo",
        "name": "GPT-4 Turbo",
        "provider": "OpenAI",
        "category": "chat",
        "rpm": 50,
        "tpm": 100_000,
        "rpd": 1000,
        "deprecated": False,
        "supports_text": True,
        "supports_thinking": False,
        "supports_images": False,
    },
    {
        "id": "chatgpt-4o-latest",
        "name": "ChatGPT-4o Latest",
        "provider": "OpenAI",
        "category": "chat",
        "rpm": 60,
        "tpm": 120_000,
        "rpd": 1200,
        "deprecated": False,
        "supports_text": True,
        "supports_thinking": False,
        "supports_images": False,
    },
    {
        "id": "gpt-4o",
        "name": "GPT-4o",
        "provider": "OpenAI",
        "category": "chat",
        "rpm": 50,
        "tpm": 100_000,
        "rpd": 1000,
        "deprecated": False,
        "supports_text": True,
        "supports_thinking": False,
        "supports_images": False,
    },
    {
        "id": "gpt-4o-mini",
        "name": "GPT-4o Mini",
        "provider": "OpenAI",
        "category": "chat",
        "rpm": 80,
        "tpm": 150_000,
        "rpd": 1500,
        "deprecated": False,
        "supports_text": True,
        "supports_thinking": False,
        "supports_images": False,
    },
    {
        "id": "o3",
        "name": "O3",
        "provider": "OpenAI",
        "category": "chat",
        "rpm": 60,
        "tpm": 150_000,
        "rpd": 1500,
        "deprecated": False,
        "supports_text": True,
        "supports_thinking": False,
        "supports_images": False,
    },
    {
        "id": "o3-mini",
        "name": "O3 Mini",
        "provider": "OpenAI",
        "category": "chat",
        "rpm": 80,
        "tpm": 150_000,
        "rpd": 1500,
        "deprecated": False,
        "supports_text": True,
        "supports_thinking": False,
        "supports_images": False,
    },
    {
        "id": "gpt-3.5-turbo",
        "name": "GPT-3.5 Turbo",
        "provider": "OpenAI",
        "category": "chat",
        "rpm": 100,
        "tpm": 200_000,
        "rpd": 2000,
        "deprecated": False,
        "supports_text": True,
        "supports_thinking": False,
        "supports_images": False,
    },
    {
        "id": "dall-e-3",
        "name": "DALL-E 3",
        "provider": "OpenAI",
        "category": "image",
        "rpm": 25,
        "tpm": 50_000,
        "rpd": 500,
        "deprecated": False,
        "supports_text": False,
        "supports_thinking": False,
        "supports_images": True,
    },
]

# All models combined
ALL_MODELS = GEMINI_MODELS + OPENAI_MODELS

# Model mapping for OpenAI compatibility
OPENAI_MODEL_MAPPING = {
    "gpt-5": {"model": "gpt-4o", "max_tokens": 16384},
    "gpt-5-mini": {"model": "gpt-4o-mini", "max_tokens": 16384},
    "gpt-5-nano": {"model": "gpt-4o-mini", "max_tokens": 16384},
    "gpt-4.1": {"model": "gpt-4o", "max_tokens": 16384},
    "gpt-4.1-mini": {"model": "gpt-4o-mini", "max_tokens": 16384},
    "gpt-4.1-nano": {"model": "gpt-4o-mini", "max_tokens": 16384},
    "o3": {"model": "o1-preview", "max_tokens": 16384},
    "o3-mini": {"model": "o1-mini", "max_tokens": 16384},
}

# Models that support thinking
THINKING_MODELS = [model["id"] for model in ALL_MODELS if model.get("supports_thinking", False)]

# Models that support image generation/editing
IMAGE_MODELS = [model["id"] for model in ALL_MODELS if model.get("supports_images", False)]

# Models that support text generation
TEXT_MODELS = [model["id"] for model in ALL_MODELS if model.get("supports_text", False)]
