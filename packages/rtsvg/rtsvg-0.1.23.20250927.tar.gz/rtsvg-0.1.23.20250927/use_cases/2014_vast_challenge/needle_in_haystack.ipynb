{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import rtsvg\n",
    "rt = rtsvg.RACETrack()\n",
    "import time\n",
    "import csv\n",
    "import json\n",
    "import os\n",
    "from ollama import chat\n",
    "from ollama import ChatResponse\n",
    "from pydantic import BaseModel\n",
    "# model = 'deepseek-r1:32b'\n",
    "model = 'qwq' # 'llama3.2'\n",
    "def promptModel(prompt, context_window_size=8192):\n",
    "    response: ChatResponse = chat(model=model, messages=[{ 'role': 'user', 'content': prompt,},], options={'num_ctx': context_window_size})\n",
    "    return response['message']['content']\n",
    "_results_ = promptModel('What is 55*3?  Return a single number.') # force the model load\n",
    "import random\n",
    "import copy\n",
    "def randomizeOrder(_lines_):\n",
    "    _lines_ = copy.deepcopy(_lines_)\n",
    "    new_lines = []\n",
    "    while len(_lines_) > 0:\n",
    "        _index_ = random.randint(0, len(_lines_) - 1)\n",
    "        new_lines.append(_lines_.pop(_index_))\n",
    "    return new_lines\n",
    "social_media_lines = []\n",
    "_mc3_dir_ = '../../../data/2014_vast/MC3'\n",
    "_files_   = ['csv-1700-1830.csv','csv-1831-2000.csv','csv-2001-2131.csv']\n",
    "_dfs_     = []\n",
    "for _file_ in _files_:\n",
    "    _file_ = _mc3_dir_ + '/' + _file_\n",
    "    with open(_file_, encoding='iso-8859-1') as f:\n",
    "        _lines_ = f.readlines()\n",
    "        social_media_lines.extend(_lines_)\n",
    "    _header_, _for_df_ = None, {}\n",
    "    with open(_file_, 'r', encoding='iso-8859-1') as file:\n",
    "        csv_reader = csv.reader(file)\n",
    "        for row in csv_reader:\n",
    "            if _header_ is None:\n",
    "                _header_ = row\n",
    "                for _col_ in _header_: _for_df_[_col_] = []\n",
    "            else:\n",
    "                for _index_ in range(len(row)): \n",
    "                    _for_df_[_header_[_index_]].append(row[_index_])\n",
    "    _df_ = pd.DataFrame(_for_df_)\n",
    "    _df_['original_line'] = _lines_[1:]\n",
    "    _dfs_.append(_df_)\n",
    "\n",
    "df_social_media                 = pd.concat(_dfs_)\n",
    "df_social_media['newman_rally'] = df_social_media['message'].str.lower().str.contains('newman') & df_social_media['message'].str.lower().str.contains('rally')\n",
    "\n",
    "newman_lines, non_newman_lines = [], []\n",
    "for i in range(len(social_media_lines)):\n",
    "    if   'newman' in social_media_lines[i].lower() and 'rally' in social_media_lines[i].lower():  newman_lines    .append(social_media_lines[i])\n",
    "    elif 'newman' in social_media_lines[i].lower():                                               pass # just make sure that newman isn't in the dataset at all...\n",
    "    else:                                                                                         non_newman_lines.append(social_media_lines[i])\n",
    "print(f'{len(social_media_lines)=} {len(newman_lines)=} {len(non_newman_lines)=}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def createNeedlePrompt(wo_newman, w_newman):\n",
    "    _lines_  = []\n",
    "    _prompt_ = f'Which doctor spoke at the POK Rally?  Use the following social media JSON posts to answer the question.  Respond with their name in JSON format.  If there is no answer, respond with \"None\".\\n\\n'\n",
    "    for i in range(w_newman):\n",
    "        _df_   = None\n",
    "        while _df_ is None or len(_df_) == 0:\n",
    "            _line_ = random.choice(newman_lines)\n",
    "            _df_   = df_social_media[df_social_media['original_line'] == _line_].reset_index()\n",
    "        _lines_.append(str(json.dumps({'post':json.dumps(_df_.iloc[0]['message'])}))+'\\n')\n",
    "    for i in range(wo_newman):\n",
    "        _df_ = None\n",
    "        while _df_ is None or len(_df_) == 0:\n",
    "            _line_ = random.choice(non_newman_lines)\n",
    "            _df_   = df_social_media[df_social_media['original_line'] == _line_].reset_index()\n",
    "        _lines_.append(str(json.dumps({'post':json.dumps(_df_.iloc[0]['message'])}))+'\\n')\n",
    "    _lines_ = randomizeOrder(_lines_)\n",
    "    return _prompt_ + ''.join(_lines_)\n",
    "\n",
    "class RallySpeaker(BaseModel):\n",
    "    name: str\n",
    "\n",
    "_tuples_ = []\n",
    "for i in range(10, 1000, 100): # len(newman_lines)+len(non_newman_lines), 50):\n",
    "    for j in range(0, 2): # Inclusions of a Newman Line\n",
    "        for k in range(1): # Samples\n",
    "            _tuples_.append((i, j, k))\n",
    "len(_tuples_)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "_lu_ = {'time_taken':[], 'name':[], 'valid':[], 'wo_newman':[], 'w_newman':[], 'prompt':[], 'prompt_eval_count':[], 'eval_count':[], 'message_content':[], 'prompt_length':[]}\n",
    "for _index_ in range(len(_tuples_)):\n",
    "    i, j, k = _tuples_[_index_]\n",
    "    _prompt_ = createNeedlePrompt(i, j)\n",
    "    t0 = time.time()\n",
    "    response: ChatResponse = chat(model=model, messages=[{ 'role': 'user', 'content':  _prompt_,},], format=RallySpeaker.model_json_schema(),options={'num_ctx': 32768})\n",
    "    t1 = time.time()\n",
    "    rally_speaker = RallySpeaker.model_validate_json(response['message']['content'])\n",
    "    _lu_['time_taken'].append(t1 - t0)\n",
    "    _lu_['name'].append(rally_speaker.name)\n",
    "    _lu_['wo_newman'].append(i)\n",
    "    _lu_['w_newman'].append(j)\n",
    "    _lu_['prompt'].append(_prompt_)\n",
    "    _lu_['prompt_eval_count'].append(response.prompt_eval_count)\n",
    "    _lu_['eval_count'].append(response.eval_count)\n",
    "    _lu_['message_content'].append(response.message.content)\n",
    "    _lu_['prompt_length'].append(len(_prompt_))\n",
    "    if    j == 0: _lu_['valid'].append(rally_speaker.name.lower() == 'none')\n",
    "    else:         _lu_['valid'].append('newman' in rally_speaker.name.lower())\n",
    "    if _index_%50 == 0: print(f'{_index_}/{len(_tuples_)}',end='')\n",
    "    else:               print('.', end='')\n",
    "\n",
    "df_niah = pd.DataFrame(_lu_)\n",
    "params = {'df':df_niah, 'dot_size':'vary', 'max_dot_size':3.0, 'color_by':'valid'}\n",
    "rt.tile([rt.xy(x_field='prompt_eval_count', y_field='time_taken',        **params),\n",
    "         rt.xy(x_field='eval_count',        y_field='time_taken',        **params),\n",
    "         rt.xy(x_field='prompt_length',     y_field='time_taken',        **params),\n",
    "         rt.xy(x_field='prompt_length',     y_field='prompt_eval_count', **params)],spacer=10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# df_niah.to_parquet(_mc3_dir_ + '/20250305_1940_niah_deepseek_32b_context_window_issues.parquet')\n",
    "rt.smallMultiples(df=df_niah, sm_type='histogram', category_by='w_newman', sm_params={'bin_by':'name'}, color_by='valid', w=1536, h=512)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
