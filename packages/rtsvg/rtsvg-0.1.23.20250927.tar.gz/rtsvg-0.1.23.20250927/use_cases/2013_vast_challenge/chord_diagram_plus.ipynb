{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import polars as pl\n",
    "import numpy as np\n",
    "import networkx as nx\n",
    "from datetime import datetime, timedelta\n",
    "import sys\n",
    "sys.path.insert(1, '../../rtsvg')\n",
    "from rtsvg import *\n",
    "rt = RACETrack()\n",
    "_base_ = '../../../data/2013_vast_challenge/mc3_netflow/nf/'\n",
    "df_orig = pl.concat([pl.read_csv(_base_ + 'nf-chunk1.csv'), pl.read_csv(_base_ + 'nf-chunk2.csv'), pl.read_csv(_base_ + 'nf-chunk3.csv')])\n",
    "df_orig = df_orig.rename({'TimeSeconds':'secs',                  'parsedDate':'timestamp',                'dateTimeStr':'timestamp_str',\n",
    "                          'ipLayerProtocol':'pro_str',           'ipLayerProtocolCode':'pro',             'firstSeenSrcIp':'sip',\n",
    "                          'firstSeenDestIp':'dip',               'firstSeenSrcPort':'spt',                'firstSeenDestPort':'dpt',\n",
    "                          'moreFragments':'mfrag',               'contFragments':'cfrag',                 'durationSeconds':'dur',\n",
    "                          'firstSeenSrcPayloadBytes':'soct_pay', 'firstSeenDestPayloadBytes':'doct_pay',  'firstSeenSrcTotalBytes':'soct',\n",
    "                          'firstSeenDestTotalBytes':'doct',      'firstSeenSrcPacketCount':'spkt',        'firstSeenDestPacketCount':'dpkt',\n",
    "                          'recordForceOut':'out'})\n",
    "df_orig = rt.columnsAreTimestamps(df_orig, 'timestamp')\n",
    "df      = df_orig.sample(10_000)\n",
    "print(f'{len(df_orig)=} | {len(df)=}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#\n",
    "# detectDenialOfService() - detect simple denial of service\n",
    "# - From Claude (v3 Sonnet) with minor modifications on port names\n",
    "# - Doesn't appear to work correctly... believe the results were servers from the dataset\n",
    "#\n",
    "def detectDenialOfService(netflow_df):\n",
    "    # Group the data by source IP and a window of 1 minute\n",
    "    grouped = netflow_df.group_by([\n",
    "        \"sip\",\n",
    "        pl.col(\"timestamp\").dt.truncate(\"1m\").alias(\"time_window\")\n",
    "    ]).agg(\n",
    "        pl.col(\"spkt\").sum().alias(\"packet_count\"),\n",
    "        pl.col(\"soct\").sum().alias(\"total_bytes\")\n",
    "    )\n",
    "\n",
    "    # Filter groups with packet count or total bytes exceeding the threshold\n",
    "    potential_dos = grouped.filter(\n",
    "        (pl.col(\"packet_count\") > 1000) | (pl.col(\"total_bytes\") > 10_000_000)\n",
    "    )\n",
    "    return potential_dos\n",
    "\n",
    "#\n",
    "# detectDistributedDenialOfService() - detect simple denial of service\n",
    "# - From Claude (v3 Sonnet) with minor modifications on port names\n",
    "# - Doesn't appear to work correctly... thresholds are too high\n",
    "#\n",
    "def detectDistributedDenialOfService(netflow_df):\n",
    "    # Group the data by destination IP and a window of 1 minute\n",
    "    grouped = netflow_df.group_by([\n",
    "        \"dip\",\n",
    "        pl.col(\"timestamp\").dt.truncate(\"1m\").alias(\"time_window\")\n",
    "    ]).agg(\n",
    "        pl.col(\"spkt\").sum().alias(\"packet_count\"),\n",
    "        pl.col(\"soct\").sum().alias(\"total_bytes\"),\n",
    "        pl.col(\"sip\").n_unique().alias(\"unique_src_ips\")\n",
    "    )\n",
    "\n",
    "    # Filter groups with packet count, total bytes, and unique source IPs exceeding the thresholds\n",
    "    potential_ddos = grouped.filter(\n",
    "        (pl.col(\"packet_count\")   > 10_000) &\n",
    "        (pl.col(\"total_bytes\")    > 100_000_000) &\n",
    "        (pl.col(\"unique_src_ips\") > 50)\n",
    "    )\n",
    "    return potential_ddos\n",
    "\n",
    "#\n",
    "# detectHorizontalPortScanning()\n",
    "# - From Claude (v3 Sonnet) with minor modifications on port names\n",
    "#\n",
    "def detectHorizontalPortScanning(netflow_df):\n",
    "    # Group the data by source IP, and a window of 5 minutes\n",
    "    grouped = netflow_df.group_by([\n",
    "        \"sip\",\n",
    "        pl.col(\"timestamp\").dt.truncate(\"5m\").alias(\"time_window\")\n",
    "    ]).agg(\n",
    "        pl.col(\"dip\").n_unique().alias(\"unique_dst_ips\")\n",
    "    )\n",
    "    # Filter groups with unique destination IPs exceeding the threshold (e.g., 10)\n",
    "    potential_scanners = grouped.filter(pl.col(\"unique_dst_ips\") > 5)\n",
    "    return potential_scanners\n",
    "\n",
    "#\n",
    "# detectVerticalPortScanning()\n",
    "# - From Claude (v3 Sonnet) with minor modifications on port names\n",
    "#\n",
    "def detectVerticalPortScanning(netflow_df):\n",
    "    # Group the data by source IP, destination IP, and a window of 5 minutes\n",
    "    grouped = netflow_df.group_by([\n",
    "        \"sip\",\n",
    "        \"dip\",\n",
    "        pl.col(\"timestamp\").dt.truncate(\"5m\").alias(\"time_window\")\n",
    "    ]).agg(\n",
    "        pl.col(\"dpt\").n_unique().alias(\"unique_ports\")\n",
    "    )\n",
    "\n",
    "    # Filter groups with unique ports exceeding the threshold (e.g., 10)\n",
    "    potential_scanners = grouped.filter(pl.col(\"unique_ports\") > 10)\n",
    "    return potential_scanners\n",
    "\n",
    "# Print the potential scanners\n",
    "scans_svgs, entities_of_interest, widget_id_lu = [], {}, {}\n",
    "vscans      = detectVerticalPortScanning(df)\n",
    "for i in range(len(vscans)):\n",
    "    sip, dip, t, up = vscans[i][\"sip\"][0], vscans[i][\"dip\"][0], vscans[i][\"time_window\"][0], vscans[i][\"unique_ports\"][0]\n",
    "    df_sub = df.filter(pl.col(\"sip\") == sip).filter(pl.col(\"timestamp\").is_between(t - timedelta(minutes=30), t + timedelta(minutes=30)))\n",
    "    parent_lu, parent_set = {}, set()\n",
    "    for i in range(len(df_sub)):\n",
    "        sip, dip, dpt = df_sub[\"sip\"][i], df_sub[\"dip\"][i], df_sub[\"dpt\"][i]\n",
    "        parent_lu[f'{dip}|{dpt}'] = dip\n",
    "        parent_set.add(dip)\n",
    "        parent_lu[sip] = '.'.join(sip.split('.')[:3])\n",
    "    cd  = rt.chordDiagram(df_sub, [('sip', ('dip','dpt'))], parent_lu=parent_lu, draw_labels=True, label_style='circular', label_only=set([sip]), w=300, h=300, x_ins=32, y_ins=32, draw_border=False)\n",
    "    wid = cd.widgetId()\n",
    "    entities_of_interest[wid] = set([sip]) | parent_set\n",
    "    widget_id_lu[wid] = cd\n",
    "    scans_svgs.append(cd)\n",
    "hscans      = detectHorizontalPortScanning(df)\n",
    "for i in range(len(hscans)):\n",
    "    sip, t, uips = hscans[i][\"sip\"][0], hscans[i][\"time_window\"][0], hscans[i][\"unique_dst_ips\"][0]\n",
    "    df_sub = df.filter(pl.col(\"sip\") == sip).filter(pl.col(\"timestamp\").is_between(t - timedelta(minutes=30), t + timedelta(minutes=30)))\n",
    "    cd  = rt.chordDiagram(df_sub, [('sip', 'dip',)], draw_labels=True, label_style='radial', w=256, h=256, x_ins=48, y_ins=48,draw_border=False)\n",
    "    wid = cd.widgetId()\n",
    "    entities_of_interest[wid] = set(df_sub['sip'])\n",
    "    widget_id_lu[wid] = cd\n",
    "    scans_svgs.append(cd)\n",
    "rt.table(scans_svgs, per_row=8)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "all_entities_of_interest = set()\n",
    "for wid in widget_id_lu:\n",
    "    all_entities_of_interest = all_entities_of_interest | entities_of_interest[wid]\n",
    "# make the networkx graph for how to position each chord diagram\n",
    "fms, tos = [], []\n",
    "for wid in widget_id_lu:\n",
    "    for ent in entities_of_interest[wid]:\n",
    "        for wid2 in widget_id_lu:\n",
    "            if ent in entities_of_interest[wid2]:\n",
    "                fms.append(wid)\n",
    "                tos.append(wid2)\n",
    "df_comp = pd.DataFrame({'fm':fms,'to':tos})\n",
    "g_nx    = rt.createNetworkXGraph(df_comp, [('fm', 'to')])\n",
    "pos     = nx.spring_layout(g_nx)\n",
    "rt.linkNode(df_comp, [('fm','to')], link_shape='curve', link_color=\"#a0a0a0\", pos=pos)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from math import floor\n",
    "# findMiddlePointIndex() -- find the closest middle point balancing out x & y\n",
    "def findMiddlePointIndex(pts):\n",
    "    cxs = []\n",
    "    for i in range(len(pts)):\n",
    "        cxs.append((pts[i][0], i))\n",
    "    cxs.sort()\n",
    "    m   = floor(len(cxs)/2)\n",
    "    cys = []\n",
    "    m_i_lt = cxs[m-1][1]\n",
    "    m_i    = cxs[m][1]\n",
    "    m_i_gt = cxs[m+1][1]\n",
    "    cys.append((pts[m_i_lt][1], m_i_lt))\n",
    "    cys.append((pts[m_i]   [1], m_i))\n",
    "    cys.append((pts[m_i_gt][1], m_i_gt))\n",
    "    cys.sort()\n",
    "    return cys[1][1]\n",
    "\n",
    "# Crunch the circles\n",
    "circles, min_r, wid_to_circle_i = [], None, {}\n",
    "for wid in widget_id_lu:\n",
    "    r  = widget_id_lu[wid].r\n",
    "    min_r = r if min_r is None else min(min_r,r)\n",
    "    xy = pos[wid]\n",
    "    circles.append((xy[0], xy[1], r, wid))\n",
    "    wid_to_circle_i[wid] = len(circles)-1\n",
    "placement = rt.crunchCircles(circles, 2*min_r)\n",
    "inter_circle_d = 2*min_r\n",
    "\n",
    "# at this point, just make the canvas big enough to hold everything\n",
    "xmin,ymin,xmax,ymax,rmax = None, None, None, None, None\n",
    "for i in range(len(placement)):\n",
    "    x, y, r, wid = placement[i]\n",
    "    xmin = x if xmin is None else min(xmin,x-r)\n",
    "    ymin = y if ymin is None else min(ymin,y-r)\n",
    "    xmax = x if xmax is None else max(xmax,x+r)\n",
    "    ymax = y if ymax is None else max(ymax,y+r)\n",
    "    rmax = r if rmax is None else max(rmax,r)\n",
    "canvas_w, canvas_h = xmax - xmin, ymax-ymin\n",
    "xT = lambda x: (x-xmin)/(xmax-xmin)*(canvas_w-2*rmax)+rmax\n",
    "yT = lambda y: (canvas_h)-((y-ymin)/(ymax-ymin)*(canvas_h-2*rmax)+rmax) # inverted y axis (to match network x positioning)\n",
    "wid_placement = {}\n",
    "svg_canvas = [f'<svg width=\"{1024}\" height=\"{1024}\" x=\"0\" y=\"0\" viewBox=\"0 0 {canvas_w} {canvas_h}\" xmlns=\"http://www.w3.org/2000/svg\">']\n",
    "circles_t  = [] # transformed circles\n",
    "for i in range(len(placement)):\n",
    "    wx, wy, r, wid = placement[i]\n",
    "    sx,sy     = xT(wx), yT(wy)\n",
    "    circles_t.append((sx, sy, r, wid))\n",
    "    cd        = widget_id_lu[wid]\n",
    "    cd_w,cd_h = cd.w, cd.h\n",
    "    cd_svg    = cd._repr_svg_()\n",
    "    svg_canvas.append(f'<svg x=\"{sx-cd_w/2}\" y=\"{sy-cd_h/2}\" width=\"{cd_w}\" height=\"{cd_h}\">')\n",
    "    wid_placement[wid] = (sx-cd_w/2,sy-cd_h/2)\n",
    "    svg_canvas.append(cd_svg)\n",
    "    svg_canvas.append('</svg>')\n",
    "\n",
    "for _entity_ in list(all_entities_of_interest)[:3]: # truncate for testing\n",
    "    pts = []\n",
    "    for wid in entities_of_interest:\n",
    "        if _entity_ in entities_of_interest[wid]:\n",
    "            sx,sy = wid_placement[wid]\n",
    "            eps   = widget_id_lu[wid].entityPositions(_entity_)\n",
    "            ap    = eps[0].attachmentPointVecs()[0]\n",
    "            pts.append((sx+ap[0],sy+ap[1],wid_to_circle_i[wid]))\n",
    "    if len(pts) > 1:\n",
    "        if len(pts) > 2:\n",
    "            i = findMiddlePointIndex(pts)\n",
    "            entry_pt = pts[i]\n",
    "            exit_pts = pts[:i] + pts[i+1:]\n",
    "        else:\n",
    "            entry_pt = pts[0]\n",
    "            exit_pts = pts[1:]\n",
    "        _doesnt_work_ = '''    \n",
    "        _paths_, _merge_info_ = rt.circularPathRouter(entry_pt, exit_pts, circles_t)\n",
    "        for _path_ in _paths_:\n",
    "            d = f'M {_path_[0][0]} {_path_[0][1]}'\n",
    "            for i in range(1,len(_path_)):\n",
    "                d += f' L {_path_[i][0]} {_path_[i][1]}'\n",
    "            svg_canvas.append(f'<path d=\"{d}\" stroke=\"{rt.co_mgr.getColor(_entity_)}\" stroke-width=\"1.2\" fill=\"none\"/>')\n",
    "        '''\n",
    "svg_canvas.append('</svg>')\n",
    "# rt.svgObject(''.join(svg_canvas))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "svg_canvas = [f'<svg width=\"{1024}\" height=\"{1024}\" x=\"0\" y=\"0\" viewBox=\"0 0 {canvas_w} {canvas_h}\" xmlns=\"http://www.w3.org/2000/svg\">']\n",
    "for _circle_ in circles_t:\n",
    "    sx,sy, r, wid = _circle_\n",
    "    svg_canvas.append(f'<circle cx=\"{sx}\" cy=\"{sy}\" r=\"{r}\" stroke=\"black\" stroke-width=\"1.2\" fill=\"none\"/>')\n",
    "\n",
    "for i in range(len(placement)):\n",
    "    wx, wy, r, wid = placement[i]\n",
    "    sx,sy     = xT(wx), yT(wy)\n",
    "    circles_t.append((sx, sy, r, wid))\n",
    "    cd        = widget_id_lu[wid]\n",
    "    cd_w,cd_h = cd.w, cd.h\n",
    "    cd_svg    = cd._repr_svg_()\n",
    "    svg_canvas.append(f'<svg x=\"{sx-cd_w/2}\" y=\"{sy-cd_h/2}\" width=\"{cd_w}\" height=\"{cd_h}\">')\n",
    "    wid_placement[wid] = (sx-cd_w/2,sy-cd_h/2)\n",
    "    svg_canvas.append(cd_svg)\n",
    "    svg_canvas.append('</svg>')\n",
    "\n",
    "for _entity_ in list(all_entities_of_interest): # truncate for testing\n",
    "    pts, pts_actual = [], []\n",
    "    _entity_co_ = rt.co_mgr.getColor(_entity_)\n",
    "    for wid in entities_of_interest:\n",
    "        if _entity_ in entities_of_interest[wid]:\n",
    "            sx,sy = wid_placement[wid]\n",
    "            eps   = widget_id_lu[wid].entityPositions(_entity_)\n",
    "            ap    = eps[0].attachmentPointVecs()[0]\n",
    "            pts_actual.append((sx+ap[0],sy+ap[1],wid_to_circle_i[wid]))\n",
    "            pts.append((sx+ap[0]+ap[2]*20,\n",
    "                        sy+ap[1]+ap[3]*20,\n",
    "                        wid_to_circle_i[wid]))\n",
    "    if len(pts) > 1:\n",
    "        if len(pts) > 2:\n",
    "            i = findMiddlePointIndex(pts)\n",
    "            entry_pt        = pts[i]\n",
    "            entry_pt_actual = pts_actual[i]\n",
    "            exit_pts        = pts[:i] + pts[i+1:]\n",
    "            exit_pts_actual = pts_actual[:i] + pts_actual[i+1:]\n",
    "        else:\n",
    "            entry_pt        = pts[0]\n",
    "            entry_pt_actual = pts_actual[0]\n",
    "            exit_pts        = pts[1:]\n",
    "            exit_pts_actual = pts_actual[1:]\n",
    "\n",
    "        #svg_canvas.append(f'<circle cx=\"{entry_pt[0]}\" cy=\"{entry_pt[1]}\" r=\"{10}\" stroke=\"red\" stroke-width=\"1.2\" fill=\"none\"/>')\n",
    "        svg_canvas.append(f'<line x1=\"{entry_pt_actual[0]}\" y1=\"{entry_pt_actual[1]}\" x2=\"{entry_pt[0]}\" y2=\"{entry_pt[1]}\" stroke=\"{_entity_co_}\" stroke-width=\"1.2\"/>')\n",
    "\n",
    "        for i in range(len(exit_pts)):\n",
    "            pt = exit_pts[i]\n",
    "            pt_actual = exit_pts_actual[i]\n",
    "            #svg_canvas.append(f'<circle cx=\"{pt[0]}\" cy=\"{pt[1]}\" r=\"{5}\" stroke=\"black\" stroke-width=\"1.2\" fill=\"none\"/>')\n",
    "            svg_canvas.append(f'<line x1=\"{pt_actual[0]}\" y1=\"{pt_actual[1]}\" x2=\"{pt[0]}\" y2=\"{pt[1]}\" stroke=\"{_entity_co_}\" stroke-width=\"1.2\"/>')\n",
    "        \n",
    "        _paths_, _merge_info_ = rt.circularPathRouter(entry_pt, exit_pts, circles_t)\n",
    "        for _path_ in _paths_:\n",
    "            d = f'M {_path_[0][0]} {_path_[0][1]}'\n",
    "            for i in range(1,len(_path_)):\n",
    "                d += f' L {_path_[i][0]} {_path_[i][1]}'\n",
    "            svg_canvas.append(f'<path d=\"{d}\" stroke=\"{_entity_co_}\" stroke-width=\"2.6\" fill=\"none\"/>')\n",
    "\n",
    "svg_canvas.append('</svg>')\n",
    "rt.svgObject(''.join(svg_canvas))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "len(all_entities_of_interest)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
