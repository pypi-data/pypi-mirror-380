# OASIS-SDK

## 1. Concept

OASIS-LLM-PROXY-CLIENTëŠ” OpenAIì™€ Azure OpenAIë¥¼ **í†µí•©ëœ ë‹¨ì¼ í´ë¼ì´ì–¸íŠ¸**ë¡œ ì œê³µí•˜ëŠ” Python ë¼ì´ë¸ŒëŸ¬ë¦¬ì…ë‹ˆë‹¤. ê³µì‹ SDK ë° LangChainì„ ì–‡ê²Œ wrappingí•˜ì—¬ ì‚¬ë‚´ ê·œì¹™ì— ë§ëŠ” í•„ë“œ ì…ë ¥ê³¼ í”„ë¡ì‹œ ì„œë²„ë¥¼ í†µí•œ í‚¤ ì£¼ì…ì„ ì§€ì›í•©ë‹ˆë‹¤.

**ì£¼ìš” íŠ¹ì§•:**

- ğŸ”„ **í†µí•© í´ë¼ì´ì–¸íŠ¸**: í•˜ë‚˜ì˜ `OasisOpenAI` í´ë¼ì´ì–¸íŠ¸ë¡œ OpenAIì™€ Azure OpenAI ëª¨ë‘ ì‚¬ìš©
- ğŸ¯ **ìë™ í”„ë¡œë°”ì´ë” ì„ íƒ**: ëª¨ë¸ IDë§Œìœ¼ë¡œ ì ì ˆí•œ í”„ë¡œë°”ì´ë” ìë™ ì„ íƒ
- ğŸ”— **ì™„ì „í•œ í˜¸í™˜ì„±**: ì›ë³¸ ë¼ì´ë¸ŒëŸ¬ë¦¬ì˜ ëª¨ë“  ê¸°ëŠ¥ì„ ê·¸ëŒ€ë¡œ ì‚¬ìš© ê°€ëŠ¥
- ğŸ›¡ï¸ **í†µí•© ì¸ì¦**: í”„ë¡ì‹œ ì„œë²„ë¥¼ í†µí•œ ì•ˆì „í•œ í‚¤ ê´€ë¦¬

## 2. Usage

### 2.1 ì„¤ì¹˜

```bash
pip install oasis-sdk
```

### 2.2 í™˜ê²½ ì„¤ì •

í”„ë¡ì‹œ ì„œë²„ URLì„ í™˜ê²½ë³€ìˆ˜ë¡œ ì„¤ì •í•  ìˆ˜ ìˆìŠµë‹ˆë‹¤

- ê¸°ë³¸ê°’ì€ ì´ë¯¸ ì„¤ì •ë˜ì–´ìˆìŒ

```bash
export OASIS_PROXY_URL="https://your-proxy-server.com"
```

ë˜ëŠ” í´ë¼ì´ì–¸íŠ¸ ìƒì„±ì‹œ ì§ì ‘ ì§€ì •:

```python
client = OasisOpenAI(
    proxy_url="https://your-proxy-server.com",
    # ... ê¸°íƒ€ ë§¤ê°œë³€ìˆ˜
)
```

### 2.3 ì‚¬ìš© ì˜ˆì‹œ

**client parameters**

[required]

- account_id: ê³„ì • ID
- user_uuid: ì‚¬ìš©ì UUID
- workspace_uuid: ì›Œí¬ìŠ¤í˜ì´ìŠ¤ UUID
- tenant_uuid: í…Œë„ŒíŠ¸ UUID
- plugin_name: í˜¸ì¶œí•œ ì‹œìŠ¤í…œ ëª… (ex: chatbot, mcp1, rag-mcp ë“±)

[optional]

- proxy_url: LLM í”„ë¡ì‹œ ì„œë²„ URL (í™˜ê²½ë³€ìˆ˜ `OASIS_PROXY_URL`ì—ì„œ ìë™ ë¡œë“œ)
- user_ip: ì‚¬ìš©ì IP (ê¸°ë³¸ê°’: 127.0.0.1)

[auto]

- root_id: í´ë¼ì´ì–¸íŠ¸ ìƒì„±ì‹œ ë°œê¸‰
- req_id: ìš”ì²­ì‹œë§ˆë‹¤ ë°œê¸‰

ğŸ“ **ì£¼ì˜**

- 1ë²ˆì˜ ì—°ì†ì ì¸ ìˆ˜í–‰ì—ì„œ root_idëŠ” ê³ ì •ë˜ì–´ì•¼ í•¨
- ì—°ê³„ë˜ëŠ” ì‹œìŠ¤í…œì—ì„œëŠ” í´ë¼ì´ì–¸íŠ¸ ìƒì„±ì‹œ ì´ˆê¸° ë°œê¸‰ëœ root_idë¥¼ ì£¼ì…í•˜ì—¬ ì‚¬ìš©

#### 2.3.1 SDK (í†µí•©ëœ OpenAI í´ë¼ì´ì–¸íŠ¸)

**í†µí•©ëœ OpenAI/Azure SDK ë˜í¼**

> ğŸ“ **ì¤‘ìš”**: ì´ì œ OpenAIì™€ Azure OpenAI ëª¨ë‘ ë™ì¼í•œ `OasisOpenAI` í´ë¼ì´ì–¸íŠ¸ë¥¼ ì‚¬ìš©í•©ë‹ˆë‹¤. ëª¨ë¸ IDë§Œìœ¼ë¡œ ìë™ìœ¼ë¡œ ì ì ˆí•œ í”„ë¡œë°”ì´ë”ë¥¼ ì„ íƒí•©ë‹ˆë‹¤.

```python
import oasis
# ë˜ëŠ”
from oasis.sdk.openai import OasisOpenAI, OasisAsyncOpenAI

# ë™ê¸° í´ë¼ì´ì–¸íŠ¸
with OasisOpenAI(
    account_id="your_account_id",
    user_uuid="your_uuid",
    workspace_uuid="your_workspace_uuid",
    tenant_uuid="your_tenant_uuid",
    plugin_name="your_system"
) as client:
    print(f"Client base URL: {client.base_url}")

    # OpenAI ëª¨ë¸ ì‚¬ìš© ì˜ˆì‹œ
    openai_resp = client.chat.completions.create(
        model="your_openai_model_uuid",  # OpenAI ëª¨ë¸ UUID
        messages=[
            {"role": "system", "content": "You are a helpful assistant."},
            {"role": "user", "content": "What is the capital of France?"}
        ],
    )
    print("OpenAI Response:", openai_resp.choices[0].message.content)

    # Azure OpenAI ëª¨ë¸ ì‚¬ìš© ì˜ˆì‹œ (ë™ì¼í•œ í´ë¼ì´ì–¸íŠ¸ë¡œ!)
    azure_resp = client.chat.completions.create(
        model="your_azure_model_uuid",  # Azure deployment UUID
        messages=[
            {"role": "system", "content": "You are a helpful assistant."},
            {"role": "user", "content": "Hello from Azure!"}
        ],
        max_tokens=100,  # Azure ëª¨ë¸ ì‚¬ìš©ì‹œ í† í° ì œí•œ
    )
    print("Azure Response:", azure_resp.choices[0].message.content)

    # ìŠ¤íŠ¸ë¦¬ë° (OpenAI ëª¨ë¸)
    stream = client.chat.completions.create(
        model="your_openai_model_uuid",
        messages=[{"role": "user", "content": "Tell me a short story"}],
        stream=True,
    )
    print("OpenAI Stream:")
    for chunk in stream:
        if chunk.choices and chunk.choices[0].delta.content:
            print(chunk.choices[0].delta.content, end="", flush=True)
    print("\n")

    # ìŠ¤íŠ¸ë¦¬ë° (Azure ëª¨ë¸)
    azure_stream = client.chat.completions.create(
        model="your_azure_model_uuid",
        messages=[{"role": "user", "content": "Count to 3"}],
        max_tokens=50,
        stream=True,
    )
    print("Azure Stream:")
    for chunk in azure_stream:
        if chunk.choices and chunk.choices[0].delta.content:
            print(chunk.choices[0].delta.content, end="", flush=True)
    print("\n")

    # ì„ë² ë”© (ë™ì¼í•œ ëª¨ë¸ IDê°€ OpenAI/Azure ëª¨ë‘ ì§€ì›)
    embedding_resp = client.embeddings.create(
        model="your_embedding_uuid",  # ì„ë² ë”© ëª¨ë¸ UUID
        input=["This sentence will be embedded.", "Another test sentence."],
    )
    print(f"Embedding vector dimension: {len(embedding_resp.data[0].embedding)}")

# ë¹„ë™ê¸° í´ë¼ì´ì–¸íŠ¸ (ë™ì¼í•œ ë°©ì‹ìœ¼ë¡œ OpenAI/Azure ëª¨ë‘ ì§€ì›)
import asyncio

async def async_example():
    async with OasisAsyncOpenAI(
        account_id="your_account_id",
        user_uuid="your_uuid",
        workspace_uuid="your_workspace_uuid",
        tenant_uuid="your_tenant_uuid",
        plugin_name="your_system"
    ) as client:
        # ë¹„ë™ê¸° ì±„íŒ… ì™„ì„± (OpenAI)
        openai_resp = await client.chat.completions.create(
            model="model_uuid",
            messages=[{"role": "user", "content": "Hello OpenAI!"}],
        )
        print("Async OpenAI:", openai_resp.choices[0].message.content)

        # ë¹„ë™ê¸° ì±„íŒ… ì™„ì„± (Azure)
        azure_resp = await client.chat.completions.create(
            model="model_uuid",
            messages=[{"role": "user", "content": "Hello Azure!"}],
            max_tokens=50,
        )
        print("Async Azure:", azure_resp.choices[0].message.content)

        # ë¹„ë™ê¸° ìŠ¤íŠ¸ë¦¬ë°
        stream = await client.chat.completions.create(
            model="model_uuid",
            messages=[{"role": "user", "content": "Count to 5"}],
            stream=True,
        )
        print("Async Stream:")
        async for chunk in stream:
            if chunk.choices and chunk.choices[0].delta.content:
                print(chunk.choices[0].delta.content, end="", flush=True)
        print("\n")

        # ë¹„ë™ê¸° ì„ë² ë”©
        embedding_resp = await client.embeddings.create(
            model="your_model_uuid",
            input=["Async embedding test"],
        )
        print(f"Async embedding vector: {embedding_resp.data[0].embedding[:5]}...")

# ë¹„ë™ê¸° í•¨ìˆ˜ ì‹¤í–‰
asyncio.run(async_example())
```

#### 2.3.2 LangChain (í†µí•©ëœ OpenAI ë˜í¼)

> ğŸ“ **ì¤‘ìš”**: LangChainë„ í†µí•©ëœ `OasisChatOpenAI`ì™€ `OasisOpenAIEmbedding`ì„ ì‚¬ìš©í•©ë‹ˆë‹¤. ëª¨ë¸ IDë¡œ OpenAI/Azureë¥¼ ìë™ êµ¬ë¶„í•©ë‹ˆë‹¤.

```python
from oasis.langchain.openai import OasisChatOpenAI, OasisOpenAIEmbedding

# OpenAI ëª¨ë¸ì„ ì‚¬ìš©í•˜ëŠ” ì±„íŒ… ì˜ˆì‹œ
openai_llm = OasisChatOpenAI(
    account_id="your_account_id",
    user_uuid="your_uuid",
    workspace_uuid="your_workspace_uuid",
    tenant_uuid="your_tenant_uuid",
    model_name="model_uuid",  # OpenAI ëª¨ë¸ UUID
    plugin_name="langchain_openai_test"
)

# Azure ëª¨ë¸ì„ ì‚¬ìš©í•˜ëŠ” ì±„íŒ… ì˜ˆì‹œ (ë™ì¼í•œ í´ë˜ìŠ¤!)
azure_llm = OasisChatOpenAI(
    account_id="your_account_id",
    user_uuid="your_uuid",
    workspace_uuid="your_workspace_uuid",
    tenant_uuid="your_tenant_uuid",
    model_name="model_uuid",  # Azure deployment UUID
    plugin_name="langchain_azure_test"
)

try:
    # OpenAI ëª¨ë¸ í˜¸ì¶œ
    openai_resp = openai_llm.invoke("Hello from OpenAI via LangChain!")
    print("OpenAI Response:", openai_resp.content)

    # Azure ëª¨ë¸ í˜¸ì¶œ (ë™ì¼í•œ ì¸í„°í˜ì´ìŠ¤!)
    azure_resp = azure_llm.invoke("Hello from Azure via LangChain!")
    print("Azure Response:", azure_resp.content)

    # OpenAI ìŠ¤íŠ¸ë¦¬ë°
    print("OpenAI Stream:")
    for chunk in openai_llm.stream("Tell me a short story"):
        if chunk.content:
            print(chunk.content, end="", flush=True)
    print("\n")

    # Azure ìŠ¤íŠ¸ë¦¬ë°
    print("Azure Stream:")
    for chunk in azure_llm.stream("Count to 3"):
        if chunk.content:
            print(chunk.content, end="", flush=True)
    print("\n")

    # ë¹„ë™ê¸° í˜¸ì¶œ ì˜ˆì‹œ
    async def async_langchain_example():
        # ë¹„ë™ê¸° OpenAI í˜¸ì¶œ
        openai_async_resp = await openai_llm.ainvoke("Async OpenAI LangChain!")
        print("Async OpenAI:", openai_async_resp.content)

        # ë¹„ë™ê¸° Azure í˜¸ì¶œ
        azure_async_resp = await azure_llm.ainvoke("Async Azure LangChain!")
        print("Async Azure:", azure_async_resp.content)

        # ë¹„ë™ê¸° ìŠ¤íŠ¸ë¦¬ë°
        print("Async OpenAI Stream:")
        async for chunk in openai_llm.astream("Async streaming test"):
            if chunk.content:
                print(chunk.content, end="", flush=True)
        print("\n")

    # ë¹„ë™ê¸° í•¨ìˆ˜ ì‹¤í–‰
    import asyncio
    asyncio.run(async_langchain_example())

finally:
    # ë¦¬ì†ŒìŠ¤ ì •ë¦¬
    openai_llm.close()
    azure_llm.close()

# ì„ë² ë”© ì˜ˆì‹œ (OpenAI/Azure ëª¨ë‘ ë™ì¼í•œ í´ë˜ìŠ¤ ì‚¬ìš©)
openai_embedding = OasisOpenAIEmbedding(
    account_id="your_account_id",
    user_uuid="your_uuid",
    workspace_uuid="your_workspace_uuid",
    tenant_uuid="your_tenant_uuid",
    model_name="model_uuid",  # ì„ë² ë”© ëª¨ë¸ UUID (OpenAI/Azure ê³µí†µ)
    plugin_name="langchain_embedding_test"
)

try:
    # ë™ê¸° ì„ë² ë”© (ì—¬ëŸ¬ ë¬¸ì„œ)
    vectors = openai_embedding.embed_documents([
        "First document for embedding",
        "Second document for embedding",
        "Third document with different content"
    ])
    print(f"Embedded {len(vectors)} documents, vector dimension: {len(vectors[0])}")

    # ë™ê¸° ì„ë² ë”© (ë‹¨ì¼ ì¿¼ë¦¬)
    query_vector = openai_embedding.embed_query("What was the main topic?")
    print(f"Query vector dimension: {len(query_vector)}")

    # ë¹„ë™ê¸° ì„ë² ë”©
    async def async_embedding_example():
        async_vectors = await openai_embedding.aembed_documents([
            "Async embedding test document"
        ])
        print(f"Async embedded vector dimension: {len(async_vectors[0])}")

    asyncio.run(async_embedding_example())

finally:
    # ë¦¬ì†ŒìŠ¤ ì •ë¦¬
    await openai_embedding.aclose()
```

## 3. ëª¨ë²” ì‚¬ë¡€

### 3.1 ë¦¬ì†ŒìŠ¤ ê´€ë¦¬

**ê¶Œì¥: Context Manager ì‚¬ìš©**

```python
# ë™ê¸° í´ë¼ì´ì–¸íŠ¸
with OasisOpenAI(...) as client:
    # ì‘ì—… ìˆ˜í–‰
    resp = client.chat.completions.create(...)

# ë¹„ë™ê¸° í´ë¼ì´ì–¸íŠ¸
async with OasisAsyncOpenAI(...) as client:
    # ì‘ì—… ìˆ˜í–‰
    resp = await client.chat.completions.create(...)
```

**ìˆ˜ë™ ë¦¬ì†ŒìŠ¤ ê´€ë¦¬**

```python
# ë™ê¸°
client = OasisOpenAI(...)
try:
    # ì‘ì—… ìˆ˜í–‰
    resp = client.chat.completions.create(...)
finally:
    client.close()

# ë¹„ë™ê¸°
client = OasisAsyncOpenAI(...)
try:
    # ì‘ì—… ìˆ˜í–‰
    resp = await client.chat.completions.create(...)
finally:
    await client.aclose()
```

### 3.2 ìŠ¤íŠ¸ë¦¬ë° ì²˜ë¦¬

```python
# ë™ê¸° ìŠ¤íŠ¸ë¦¬ë°
with OasisOpenAI(...) as client:
    stream = client.chat.completions.create(
        model="model_id",
        messages=[...],
        stream=True
    )
    for chunk in stream:
        if chunk.choices and chunk.choices[0].delta.content:
            print(chunk.choices[0].delta.content, end="", flush=True)

# ë¹„ë™ê¸° ìŠ¤íŠ¸ë¦¬ë°
async with OasisAsyncOpenAI(...) as client:
    stream = await client.chat.completions.create(
        model="model_id",
        messages=[...],
        stream=True
    )
    async for chunk in stream:
        if chunk.choices and chunk.choices[0].delta.content:
            print(chunk.choices[0].delta.content, end="", flush=True)
```

### 3.3 ì—ëŸ¬ í•¸ë“¤ë§

```python
from oasis.sdk.openai import OasisOpenAI
from openai import OpenAIError

with OasisOpenAI(...) as client:
    try:
        resp = client.chat.completions.create(
            model="model_id",
            messages=[{"role": "user", "content": "Hello"}]
        )
    except OpenAIError as e:
        print(f"OpenAI API ì—ëŸ¬: {e}")
    except Exception as e:
        print(f"ê¸°íƒ€ ì—ëŸ¬: {e}")
```

## 4. ì˜ì¡´ì„±

- Python 3.11.x
- openai 1.97.0
- langchain-openai 0.3.28

## 5. í…ŒìŠ¤íŠ¸

```bash
# í…ŒìŠ¤íŠ¸ ì‹¤í–‰
python -m pytest tests/

# íŠ¹ì • í…ŒìŠ¤íŠ¸ë§Œ ì‹¤í–‰
python -m pytest tests/test_oasis_openai.py
python -m pytest tests/test_oasis_azure.py
python -m pytest tests/test_oasis_lc_openai.py
python -m pytest tests/test_oasis_lc_azure.py
```

**ë…¸íŠ¸ë¶ ì˜ˆì‹œ**

ì‹¤ì œ ì‚¬ìš© ì˜ˆì‹œëŠ” `tests/notebooks/` ë””ë ‰í† ë¦¬ì˜ Jupyter ë…¸íŠ¸ë¶ì„ ì°¸ê³ í•˜ì„¸ìš”:

- `openai.ipynb`: í†µí•© SDK ë˜í¼ë¥¼ ì‚¬ìš©í•œ OpenAI ëª¨ë¸ ì˜ˆì‹œ
- `azure.ipynb`: í†µí•© SDK ë˜í¼ë¥¼ ì‚¬ìš©í•œ Azure OpenAI ëª¨ë¸ ì˜ˆì‹œ
- `api.ipynb`: API ë ˆë²¨ ì‚¬ìš© ì˜ˆì‹œ
