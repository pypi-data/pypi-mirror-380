{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "df14d92a-e91e-42da-8d05-13cc974a605e",
   "metadata": {},
   "source": [
    "# OOI Sea Lion TensorFlow Lite Training Example\n",
    "\n",
    "Author: Ian Black\\\n",
    "Date: 2022-04-28\n",
    "\n",
    "If you are looking for an example on how to use a sealion model, you can find it [here](https://github.com/oceanobservatories/ooi-data-explorations/tree/master/python/examples/tensorflow).\n",
    "\n",
    "#### What is the goal of this example?\n",
    "The goal of this example is to show you how to perform transfer learning on a TensorFlow Lite object detection model. You will be using images from the [OOI CE07SHSM](https://oceanobservatories.org/site/ce07shsm/) buoy to develop a model that can detect a sea lion if a sea-lion is on the buoy. The dataset used to train and validate this model consists of images of sea lions captured on the buoy between 2018 and 2020.  \n",
    "\n",
    "#### What will the model run on?\n",
    "This example utilizes the efficientdet_lite0 model. TensorFlow Lite models are optimized to run on mobile and edge devices. However, training them requires a machine that does not have ARM architecture.\n",
    "\n",
    "#### Why might model creation and validation  fail at higher batch sizes?\n",
    "This may be a function of your system hardware and the size of the images used in the training data. The efficientdet lite0 model really prefers to have images with a size of 512x512 pixels. The images in the training dataset that come off the OOI buoy cameras have a size of 960x540 pixels and are resized in the model creation process, so running in large batch sizes may result in Out of Memory errors.\n",
    "***"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "204b79a9-3da9-4dc5-a26e-27e5dd109336",
   "metadata": {
    "tags": []
   },
   "source": [
    "## Downloading Data\n",
    "\n",
    "If you don't want to spend hours labeling data, you can download training, validation, and test data from [Kaggle](https://www.kaggle.com/datasets/blackia/ooi-sealions). There you will find folders that contain images and xml files in the Pascal VOC format. There are folders for training the model (658 images), validating the model (89 images), and testing the model (11 images). Simply download the data and extract it to a directory of choice. Once downloaded, make note of the data path in the User Defined Variables section."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "87e97c24-eaa4-4d13-9f84-d0566ad86773",
   "metadata": {},
   "source": [
    "## User Defined Variables\n",
    "\n",
    "You may need to change the following variables to match that of your own operating system."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "d7b3bb10-7ad3-4887-975e-9d7296dd2963",
   "metadata": {},
   "outputs": [],
   "source": [
    "training_data_location = 'C:/Users/Ian/Desktop/ooi-sealions/train'\n",
    "validation_data_location = 'C:/Users/Ian/Desktop/ooi-sealions/val'\n",
    "\n",
    "model_save_location = 'C:/Users/Ian/Desktop/ooi-sealions/models'\n",
    "model_save_name = 'ooi_sealions'"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "49900911-1491-4192-94eb-66f0edaeb150",
   "metadata": {},
   "source": [
    "## Imports\n",
    "\n",
    "If you don't already have numpy, tensorflow, tflite-model-maker, and tflite-support installed, you can install them with pip.\n",
    "\n",
    "```\n",
    "pip install numpy\n",
    "pip install tensorflow\n",
    "pip install tflite-model-maker\n",
    "pip install tflite-support\n",
    "```\n",
    "\n",
    "And if you have a GPU you can install the GPU version of tensorflow. Note, that this requires additional [GPU support](https://www.tensorflow.org/install/gpu) setup, which may take some time.\n",
    "\n",
    "```\n",
    "pip install tensorflow-gpu\n",
    "```"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "eb41837b-b85f-4fc4-8cd8-717ddaea5e8d",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import os\n",
    "\n",
    "import tensorflow as tf\n",
    "assert tf.__version__.startswith('2')\n",
    "tf.get_logger().setLevel('ERROR')\n",
    "\n",
    "from absl import logging\n",
    "logging.set_verbosity(logging.ERROR)\n",
    "\n",
    "from tflite_model_maker.config import ExportFormat, QuantizationConfig\n",
    "from tflite_model_maker import model_spec\n",
    "from tflite_model_maker import object_detector"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "39ccfc20-b894-4dcf-88fe-29a7a7adacc4",
   "metadata": {},
   "source": [
    "## Loading Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "7432022a-08a9-4317-aec5-4b5eef3298bb",
   "metadata": {},
   "outputs": [],
   "source": [
    "train_dir = os.path.normpath(training_data_location)\n",
    "val_dir = os.path.normpath(validation_data_location)\n",
    "labels = ['sealion']\n",
    "\n",
    "training_data = object_detector.DataLoader.from_pascal_voc(train_dir,train_dir,labels)\n",
    "validation_data = object_detector.DataLoader.from_pascal_voc(val_dir,val_dir,labels)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d1e990bc-a3cc-432c-b254-af8cfdc7b1ac",
   "metadata": {},
   "source": [
    "## Identifying the Model\n",
    "\n",
    "This example uses efficientdet_lite0. Transfer learning is performed using tflite-model-maker, enabling our recreation of the model to detect sealions."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "0b7b181a-39b8-4d42-b9bf-df7dbe225263",
   "metadata": {},
   "outputs": [],
   "source": [
    "tflite_model = 'efficientdet_lite0'  #You could do 0-4, but values greater than 0 require additional hardware.\n",
    "spec = model_spec.get(tflite_model)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "77170cc8-61ff-49f1-a0f7-9fd6164dc4f7",
   "metadata": {},
   "source": [
    "## Training the Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "cdc5733f-93cb-4abb-9431-9b89cdc45b5d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/10\n",
      "82/82 [==============================] - 40s 251ms/step - det_loss: 1.3438 - cls_loss: 0.7620 - box_loss: 0.0116 - reg_l2_loss: 0.0630 - loss: 1.4068 - learning_rate: 0.0090 - gradient_norm: 2.1388 - val_det_loss: 1.7132 - val_cls_loss: 1.1305 - val_box_loss: 0.0117 - val_reg_l2_loss: 0.0630 - val_loss: 1.7762\n",
      "Epoch 2/10\n",
      "82/82 [==============================] - 25s 309ms/step - det_loss: 0.8996 - cls_loss: 0.4464 - box_loss: 0.0091 - reg_l2_loss: 0.0631 - loss: 0.9626 - learning_rate: 0.0093 - gradient_norm: 3.0295 - val_det_loss: 1.1395 - val_cls_loss: 0.6732 - val_box_loss: 0.0093 - val_reg_l2_loss: 0.0631 - val_loss: 1.2027\n",
      "Epoch 3/10\n",
      "82/82 [==============================] - 26s 315ms/step - det_loss: 0.7804 - cls_loss: 0.3960 - box_loss: 0.0077 - reg_l2_loss: 0.0632 - loss: 0.8436 - learning_rate: 0.0082 - gradient_norm: 3.3169 - val_det_loss: 1.1855 - val_cls_loss: 0.7017 - val_box_loss: 0.0097 - val_reg_l2_loss: 0.0632 - val_loss: 1.2487\n",
      "Epoch 4/10\n",
      "82/82 [==============================] - 25s 310ms/step - det_loss: 0.7208 - cls_loss: 0.3778 - box_loss: 0.0069 - reg_l2_loss: 0.0633 - loss: 0.7841 - learning_rate: 0.0067 - gradient_norm: 3.3075 - val_det_loss: 0.8554 - val_cls_loss: 0.5027 - val_box_loss: 0.0071 - val_reg_l2_loss: 0.0633 - val_loss: 0.9187\n",
      "Epoch 5/10\n",
      "82/82 [==============================] - 30s 362ms/step - det_loss: 0.6718 - cls_loss: 0.3543 - box_loss: 0.0064 - reg_l2_loss: 0.0633 - loss: 0.7351 - learning_rate: 0.0050 - gradient_norm: 3.3361 - val_det_loss: 0.7567 - val_cls_loss: 0.4232 - val_box_loss: 0.0067 - val_reg_l2_loss: 0.0633 - val_loss: 0.8200\n",
      "Epoch 6/10\n",
      "82/82 [==============================] - 26s 318ms/step - det_loss: 0.6180 - cls_loss: 0.3321 - box_loss: 0.0057 - reg_l2_loss: 0.0634 - loss: 0.6814 - learning_rate: 0.0033 - gradient_norm: 3.3892 - val_det_loss: 0.7364 - val_cls_loss: 0.4262 - val_box_loss: 0.0062 - val_reg_l2_loss: 0.0634 - val_loss: 0.7998\n",
      "Epoch 7/10\n",
      "82/82 [==============================] - 26s 317ms/step - det_loss: 0.5994 - cls_loss: 0.3246 - box_loss: 0.0055 - reg_l2_loss: 0.0634 - loss: 0.6628 - learning_rate: 0.0018 - gradient_norm: 3.6262 - val_det_loss: 0.7578 - val_cls_loss: 0.4532 - val_box_loss: 0.0061 - val_reg_l2_loss: 0.0634 - val_loss: 0.8211\n",
      "Epoch 8/10\n",
      "82/82 [==============================] - 26s 312ms/step - det_loss: 0.5587 - cls_loss: 0.3074 - box_loss: 0.0050 - reg_l2_loss: 0.0634 - loss: 0.6221 - learning_rate: 6.9245e-04 - gradient_norm: 3.3428 - val_det_loss: 0.7206 - val_cls_loss: 0.4229 - val_box_loss: 0.0060 - val_reg_l2_loss: 0.0634 - val_loss: 0.7840\n",
      "Epoch 9/10\n",
      "82/82 [==============================] - 26s 322ms/step - det_loss: 0.5623 - cls_loss: 0.3072 - box_loss: 0.0051 - reg_l2_loss: 0.0634 - loss: 0.6257 - learning_rate: 1.0153e-04 - gradient_norm: 3.5329 - val_det_loss: 0.7077 - val_cls_loss: 0.4138 - val_box_loss: 0.0059 - val_reg_l2_loss: 0.0634 - val_loss: 0.7711\n",
      "Epoch 10/10\n",
      "82/82 [==============================] - 27s 334ms/step - det_loss: 0.5708 - cls_loss: 0.3113 - box_loss: 0.0052 - reg_l2_loss: 0.0634 - loss: 0.6342 - learning_rate: 1.0144e-04 - gradient_norm: 3.5116 - val_det_loss: 0.7049 - val_cls_loss: 0.4116 - val_box_loss: 0.0059 - val_reg_l2_loss: 0.0634 - val_loss: 0.7683\n"
     ]
    }
   ],
   "source": [
    "batch_size = 8\n",
    "epochs = 10\n",
    "\n",
    "model = object_detector.create(training_data, \n",
    "                               model_spec=spec, \n",
    "                               batch_size=batch_size, \n",
    "                               train_whole_model=True, \n",
    "                               epochs=epochs, \n",
    "                               validation_data=validation_data)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cb0fff3f-f362-4e22-bcfa-3be8b2d275ce",
   "metadata": {},
   "source": [
    "## Evaluating the Model\n",
    "\n",
    "TensorFlow Lite provides a handy function for evaluating a trained model. If we look at the output of the cell below, we can see that the AP (or Average Precision) is around 0.40. Not great, but we only trained for a few epochs."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "5a78bedc-de49-4c03-828b-3f858087f204",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "12/12 [==============================] - 5s 258ms/step\n",
      "\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "{'AP': 0.41080743,\n",
       " 'AP50': 0.8367011,\n",
       " 'AP75': 0.3563422,\n",
       " 'APs': -1.0,\n",
       " 'APm': 0.21739653,\n",
       " 'APl': 0.4192642,\n",
       " 'ARmax1': 0.27732557,\n",
       " 'ARmax10': 0.5604651,\n",
       " 'ARmax100': 0.5883721,\n",
       " 'ARs': -1.0,\n",
       " 'ARm': 0.41428572,\n",
       " 'ARl': 0.5957576,\n",
       " 'AP_/sealion': 0.41080743}"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.evaluate(validation_data,batch_size = batch_size)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d6d0e808-9364-4cee-af94-4e952edebed8",
   "metadata": {},
   "source": [
    "## Saving the Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "872f43ba-3b4e-4aa5-96d0-cae3e191fd02",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "89/89 [==============================] - 342s 4s/step\n",
      "\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "{'AP': 0.3876623,\n",
       " 'AP50': 0.8281781,\n",
       " 'AP75': 0.27713627,\n",
       " 'APs': -1.0,\n",
       " 'APm': 0.21022762,\n",
       " 'APl': 0.39606765,\n",
       " 'ARmax1': 0.2761628,\n",
       " 'ARmax10': 0.51337206,\n",
       " 'ARmax100': 0.53720933,\n",
       " 'ARs': -1.0,\n",
       " 'ARm': 0.31428573,\n",
       " 'ARl': 0.5466667,\n",
       " 'AP_/sealion': 0.3876623}"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "export_dir = os.path.normpath(model_save_location)\n",
    "tflite_filename = '.'.join((model_save_name,'tflite'))\n",
    "\n",
    "model.export(export_dir=export_dir, tflite_filename=tflite_filename)\n",
    "model.evaluate_tflite(os.path.join(export_dir,tflite_filename), validation_data)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1c603a29-f51c-4081-99f5-4931ceb95f59",
   "metadata": {},
   "source": [
    "## Check\n",
    "\n",
    "The next cell will check to see if the model was actually created."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "a56f2142-4667-4bc6-a614-03585bd03600",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Found model at C:\\Users\\Ian\\Desktop\\ooi-sealions\\models\\ooi_sealions.tflite.\n",
      "Congratulations on completing this example!\n"
     ]
    }
   ],
   "source": [
    "model_filepath = os.path.normpath(os.path.join(model_save_location,model_save_name+'.tflite'))\n",
    "if os.path.exists(model_filepath):\n",
    "    print(f\"Found model at {model_filepath}.\")\n",
    "    print(f\"Congratulations on completing this example!\")\n",
    "else:\n",
    "    raise OSError(f\"Unable to find model at {model_filepath}\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.12"
  },
  "widgets": {
   "application/vnd.jupyter.widget-state+json": {
    "state": {},
    "version_major": 2,
    "version_minor": 0
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
