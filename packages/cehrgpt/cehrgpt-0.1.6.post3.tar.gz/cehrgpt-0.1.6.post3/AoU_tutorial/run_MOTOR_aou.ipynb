{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import glob\n",
    "from pathlib import Path\n",
    "from tqdm import tqdm\n",
    "import pandas as pd\n",
    "bucket = os.getenv('WORKSPACE_BUCKET')\n",
    "bucket"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# MEDS ETL"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# !pip install meds_etl"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "folder = Path(\"allofus_omop_v8/allofus_omop_v8/visit_occurrence\")\n",
    "files = [p for p in folder.glob(\"*.parquet\")]  # only top-level files\n",
    "len(files)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "for src in tqdm(files):\n",
    "    df = pd.read_parquet(src)\n",
    "    df = df.rename(columns = {\"discharge_to_concept_id\": \"discharged_to_concept_id\"})\n",
    "    df.to_parquet(src)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "export OMOP_DIR=/home/jupyter/workspaces/ehrcancermodelevaluation/allofus_omop_v8/allofus_omop_v8\n",
    "export OMOP_MEDS=/home/jupyter/workspaces/ehrcancermodelevaluation/OMOP_MEDS\n",
    "\n",
    "meds_etl_omop $OMOP_DIR $OMOP_MEDS --num_proc 16"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Converting into meds_reader"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# !pip install meds_reader==0.1.13\n",
    "# !pip install femr-0.2.0-py3-none-any.whl\n",
    "# !pip install meds_evaluation-0.1.dev95+g841c87f-py3-none-any.whl"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "export OMOP_MEDS=/home/jupyter/workspaces/ehrcancermodelevaluation/OMOP_MEDS\n",
    "export OMOP_MEDS_READER=/home/jupyter/workspaces/ehrcancermodelevaluation/OMOP_MEDS_READER\n",
    "meds_reader_convert $OMOP_MEDS $OMOP_MEDS_READER --num_threads 16"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Preparing for training"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# prepare concept table in csv "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "files = glob.glob('allofus_omop_v8/concept/*.parquet')\n",
    "dfs = []\n",
    "for f in tqdm(files):\n",
    "    dfs.append(pd.read_parquet(f))\n",
    "concept = pd.concat(dfs)\n",
    "concept.to_csv('allofus_omop_v8/motor8192/CONCEPT.csv', index = False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "files = glob.glob('allofus_omop_v8/concept_relationship/*.parquet')\n",
    "dfs = []\n",
    "for f in tqdm(files):\n",
    "    dfs.append(pd.read_parquet(f))\n",
    "df = pd.concat(dfs)\n",
    "df.to_csv('allofus_omop_v8/motor8192/CONCEPT_RELATIONSHIP.csv', index = False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "files = glob.glob('allofus_omop_v8/concept_ancestor/*.parquet')\n",
    "dfs = []\n",
    "for f in tqdm(files):\n",
    "    dfs.append(pd.read_parquet(f))\n",
    "df = pd.concat(dfs)\n",
    "df.to_csv('allofus_omop_v8/motor8192/CONCEPT_ANCESTOR.csv', index = False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "files = glob.glob('allofus_omop_v8/allofus_omop_v8/patient_splits/*.parquet')\n",
    "patient_split = pd.concat([pd.read_parquet(f) for f in files], ignore_index=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [],
   "source": [
    "patient_split.columns = ['subject_id','split']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [],
   "source": [
    "patient_split.to_parquet('/home/jupyter/workspaces/ehrcancermodelevaluation/OMOP_MEDS_READER/metadata/subject_splits.parquet', index = False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# git clone https://github.com/ChaoPang/femr\n",
    "# femr/ pip install .\n",
    "# git checkout omop_meds_v3_tutorial"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "export PRETRAINING_DATA=/home/jupyter/workspaces/ehrcancermodelevaluation/allofus_omop_v8/motor8192\n",
    "export OMOP_MEDS_READER=/home/jupyter/workspaces/ehrcancermodelevaluation/OMOP_MEDS_READER\n",
    "export ATHENA_DATA=/home/jupyter/workspaces/ehrcancermodelevaluation/allofus_omop_v8/motor8192\n",
    "\n",
    "nohup python -u -m femr.omop_meds_tutorial.prepare_motor \\\n",
    "  --pretraining_data $PRETRAINING_DATA \\\n",
    "  --athena_path $ATHENA_DATA \\\n",
    "  --meds_reader $OMOP_MEDS_READER \\\n",
    "  --tokens_per_batch 8192 > nohup.out 2>&1 &"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Motor pretraining"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# There is one line of code we have to disable, which prevent from using multi gpus\n",
    "# processor.py at line 465, you need to remove that assertion \n",
    "# comment out \"assert len(batches)==1\" at line 465"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "export PRETRAINING_DATA=/home/jupyter/workspaces/ehrcancermodelevaluation/allofus_omop_v8/motor8192\n",
    "export OMOP_MEDS_READER=/home/jupyter/workspaces/ehrcancermodelevaluation/OMOP_MEDS_READER\n",
    "export ATHENA_DATA=/home/jupyter/workspaces/ehrcancermodelevaluation/allofus_omop_v8/motor8192\n",
    "export OUTPUT_DIR=/home/jupyter/workspaces/ehrcancermodelevaluation/aou_motor"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# memory error with the following command\n",
    "# nohup python -u -m femr.omop_meds_tutorial.pretrain_motor \\\n",
    "#   --pretraining_data $PRETRAINING_DATA \\\n",
    "#   --meds_reader $OMOP_MEDS_READER > motor_pretrain.out &\n",
    "\n",
    "nohup deepspeed --num_gpus=8 src/femr/omop_meds_tutorial/pretrain_motor.py --pretraining_data $PRETRAINING_DATA \\\n",
    "    --meds_reader $OMOP_MEDS_READER \\\n",
    "    --per_device_train_batch_size 1 \\\n",
    "    --per_device_eval_batch_size 1 \\\n",
    "    --learning_rate 1e-5\\\n",
    "    --output_dir $OUTPUT_DIR \\\n",
    "    --remove_unused_columns false \\\n",
    "    --weight_decay 0.1 \\\n",
    "    --adam_beta2 0.95 \\\n",
    "    --report_to tensorboard \\\n",
    "    --num_train_epochs 50 \\\n",
    "    --warmup_steps 500 \\\n",
    "    --logging_strategy epoch \\\n",
    "    --logging_steps 10 \\\n",
    "    --save_strategy epoch \\\n",
    "    --evaluation_strategy epoch \\\n",
    "    --dataloader_num_workers 12 \\\n",
    "    --save_total_limit 10 \\\n",
    "    --load_best_model_at_end \\\n",
    "    --metric_for_best_model eval_loss \\\n",
    "    --greater_is_better false \\\n",
    "    --deepspeed /home/jupyter/workspaces/ehrcancermodelevaluation/deepspeed.json \\\n",
    "    > motor_train_log.txt 2>&1 &"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Generate features"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# you need to make motor_model folder in aou_motor and copy neccessary files from aou_motor and motor8192\n",
    "# for example move trainer_state.json into motor_model\n",
    "# copy config.json and model.safetensors for checkpoint into motor_model\n",
    "# copy dictionary.msgpack from motor8192 tokenizer folder into motor_model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# src/femr/models/transformers.py, on line 489, femr autocasts data and model to bfloat16 in compute_features, this is not supported by V100. You can simply change it torch.float32, it should work. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "export PRETRAINING_DATA=/home/jupyter/workspaces/ehrcancermodelevaluation/aou_motor\n",
    "export OMOP_MEDS_READER=/home/jupyter/workspaces/ehrcancermodelevaluation/OMOP_MEDS_READER\n",
    "export COHORT_DIR=/home/jupyter/workspaces/ehrcancermodelevaluation/meds_data\n",
    "\n",
    "nohup python -u -m femr.omop_meds_tutorial.generate_motor_features \\\n",
    "  --pretraining_data $PRETRAINING_DATA \\\n",
    "  --meds_reader $OMOP_MEDS_READER \\\n",
    "  --cohort_dir $COHORT_DIR > motor_features.out 2>&1 &"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Femr baseline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [],
   "source": [
    "import glob\n",
    "files = glob.glob('allofus_omop_v8/patient_splits/*.parquet')\n",
    "patient_split = pd.concat([pd.read_parquet(f) for f in files], ignore_index=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "patient_split.columns = ['subject_id', 'split_name']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [],
   "source": [
    "patient_split.to_csv('OMOP_MEDS_READER/main_split.csv', index = False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "metadata": {},
   "outputs": [],
   "source": [
    "patient_split.to_csv('aou_motor/main_split.csv', index = False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ids_by_cancer_type = load_dict('ids_by_cancer_type')\n",
    "all_meds = pd.read_parquet('aou_motor/labels/meds_data.parquet')\n",
    "\n",
    "for cancer_type, ids in tqdm(ids_by_cancer_type.items()):\n",
    "    sub_meds = all_meds[all_meds['subject_id'].isin(ids)]\n",
    "    sub_meds.to_parquet(f'OMOP_MEDS_READER/labels/meds_{cancer_type}.parquet', index = False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#go to step 7 linear probing and generate 'aou_motor/features/meds_{cancer_type}_motor.pkl'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "export PRETRAINING_DATA=/home/jupyter/workspaces/ehrcancermodelevaluation/OMOP_MEDS_READER\n",
    "export OMOP_MEDS_READER=/home/jupyter/workspaces/ehrcancermodelevaluation/OMOP_MEDS_READER\n",
    "export COHORT_DIR=/home/jupyter/workspaces/ehrcancermodelevaluation/aou_motor/labels/meds_pancreas.parquet\n",
    "\n",
    "- featurizing\n",
    "python -u -m femr.omop_meds_tutorial.generate_tabular_features --pretraining_data $PRETRAINING_DATA --meds_reader $OMOP_MEDS_READER --cohort_dir $COHORT_DIR\n",
    "\n",
    "- baseline model training\n",
    "nohup python -u -m femr.omop_meds_tutorial.train_baseline --pretraining_data $PRETRAINING_DATA --meds_reader $OMOP_MEDS_READER --cohort_label meds_all &> meds_baseline2.out &"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# results are saved at OMOP_MEDS_READER/results "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Linear probing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "gs://fc-secure-29afd1b1-16e7-4b67-a9f2-ddd80f884e0d\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "from collections import Counter\n",
    "import os\n",
    "import numpy as np\n",
    "from tqdm import tqdm\n",
    "import pickle\n",
    "from sklearn.model_selection import StratifiedKFold\n",
    "from collections import Counter\n",
    "import gcsfs\n",
    "import matplotlib.pyplot as plt\n",
    "import matplotlib.patches as mpatches\n",
    "from scipy.stats import mannwhitneyu\n",
    "from pathlib import Path\n",
    "\n",
    "bucket = os.getenv(\"WORKSPACE_BUCKET\")\n",
    "print(bucket)\n",
    "\n",
    "def write_df_to_bucket(df, filename: str):\n",
    "    # save mt directly to bucket\n",
    "    df.to_csv(f\"{bucket}/data/{filename}.csv\", index = None)\n",
    "def read_df_from_bucket(filename: str):\n",
    "    # save mt directly to bucket\n",
    "    return pd.read_csv(f\"{bucket}/data/{filename}.csv\")\n",
    "\n",
    "fs = gcsfs.GCSFileSystem()\n",
    "def save_dict(data_dict, filename: str):\n",
    "    full_path = f\"{bucket}/data/{filename}.pickle\"\n",
    "    with fs.open(full_path, \"wb\") as h:\n",
    "        pickle.dump(data_dict, h)\n",
    "def load_dict(filename: str):\n",
    "    full_path = f\"{bucket}/data/{filename}.pickle\"\n",
    "    with fs.open(full_path, \"rb\") as h:\n",
    "        data_dict = pickle.load(h)\n",
    "    return data_dict"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "ids_by_cancer_type = load_dict('ids_by_cancer_type')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# all_meds = pd.read_parquet('aou_motor/labels/meds_data.parquet')\n",
    "all_meds = pd.read_parquet(f\"{bucket}/aou_motor/labels/meds_data.parquet\")\n",
    "all_meds.to_parquet('aou_motor/labels/meds_data.parquet', index = False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "metadata": {},
   "outputs": [],
   "source": [
    "patient_split_dict = dict(zip(patient_split['subject_id'], patient_split['split_name']))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "metadata": {},
   "outputs": [],
   "source": [
    "sub_meds = pd.read_parquet('aou_motor/labels/meds_all.parquet')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "metadata": {},
   "outputs": [],
   "source": [
    "sub_meds['split'] = sub_meds['subject_id'].map(patient_split_dict)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "for cancer_type, ids in tqdm(ids_by_cancer_type.items()):\n",
    "    sub_meds = all_meds[all_meds['subject_id'].isin(ids)]\n",
    "    sub_meds.to_parquet(f'aou_motor/labels/meds_{cancer_type}.parquet', index = False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "# with open('aou_motor/features/meds_data_motor.pkl', 'rb') as h:\n",
    "#     motor_fea = pickle.load(h)\n",
    "import gcsfs\n",
    "import pickle\n",
    "\n",
    "fs = gcsfs.GCSFileSystem()\n",
    "with fs.open(f'{bucket}/aou_motor/features/hide/meds_data_motor.pkl', 'rb') as h:\n",
    "    motor_fea = pickle.load(h)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "def filter_dict(data, selected_ids):\n",
    "    # data is your original dictionary with keys:\n",
    "    # \"subject_ids\", \"feature_times\", \"features\"\n",
    "    filtered = {\n",
    "        \"subject_ids\": [],\n",
    "        \"feature_times\": [],\n",
    "        \"features\": []\n",
    "    }\n",
    "\n",
    "    for sid, ftime, feat in tqdm(zip(data[\"subject_ids\"], data[\"feature_times\"], data[\"features\"]), total=len(data['subject_ids'])):\n",
    "        if sid in selected_ids:\n",
    "            filtered[\"subject_ids\"].append(sid)\n",
    "            filtered[\"feature_times\"].append(ftime)\n",
    "            filtered[\"features\"].append(feat)\n",
    "\n",
    "    return {\n",
    "        \"subject_ids\": np.array(filtered[\"subject_ids\"]),\n",
    "        \"feature_times\": np.array(filtered[\"feature_times\"]),\n",
    "        \"features\": np.array(filtered[\"features\"])\n",
    "    }"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "ctrl_ids = list(set(ids_by_cancer_type['crc']) & set(ids_by_cancer_type['lung']))\n",
    "# len(ctrl_ids)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 223402/223402 [18:13<00:00, 204.21it/s]\n"
     ]
    }
   ],
   "source": [
    "motor_fea_df = pd.DataFrame({'subject_ids':motor_fea['subject_ids'],\n",
    "                            'feature_times':motor_fea['feature_times'],\n",
    "                            'features':[np.array(x) for x in motor_fea['features']]})\n",
    "ctrl_fea_df = motor_fea_df[motor_fea_df['subject_ids'].isin(ctrl_ids)]\n",
    "ctrl_fea = ctrl_fea_df.to_dict(orient='list')\n",
    "ctrl_fea['features'] = np.stack(ctrl_fea['features'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "for cancer_type, ids in ids_by_cancer_type.items():\n",
    "    ids = list(set(ids) - set(ctrl_ids))\n",
    "    sub_fea = filter_dict(motor_fea, ids)\n",
    "    merged_fea = {\n",
    "    'subject_ids': np.concatenate([sub_fea['subject_ids'], ctrl_fea['subject_ids']]),\n",
    "    'feature_times': np.concatenate([sub_fea['feature_times'], ctrl_fea['feature_times']]),\n",
    "    'features': np.concatenate([sub_fea['features'], ctrl_fea['features']])}\n",
    "    print(cancer_type, len(merged_fea['subject_ids']))\n",
    "    with open(f'aou_motor/features/meds_{cancer_type}_motor.pkl', 'wb') as h:\n",
    "        pickle.dump(merged_fea, h)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "export PRETRAINING_DATA=/home/jupyter/workspaces/ehrcancermodelevaluation/aou_motor\n",
    "export OMOP_MEDS_READER=/home/jupyter/workspaces/ehrcancermodelevaluation/OMOP_MEDS_READER\n",
    "\n",
    "python -u -m femr.omop_meds_tutorial.finetune_motor   --pretraining_data $PRETRAINING_DATA   --meds_reader $OMOP_MEDS_READER --cohort_label meds_pancreas"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# saved in aou_motor/results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# save below in .txt and rename run_motor_lp.sh"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "export PRETRAINING_DATA=/home/jupyter/workspaces/ehrcancermodelevaluation/aou_motor\n",
    "export OMOP_MEDS_READER=/home/jupyter/workspaces/ehrcancermodelevaluation/OMOP_MEDS_READER\n",
    "\n",
    "cohorts=(\n",
    "    leukemia \n",
    "    urinary_tract_bladder\n",
    "    neuroendocrine\n",
    "    myelodysplastic_syndromes\n",
    "    cervical\n",
    "    soft_tissue_sarcoma\n",
    "    lymphoma_lymphoid\n",
    "    all\n",
    "    crc\n",
    "    kidney\n",
    "    lung\n",
    "    brain\n",
    "    skin\n",
    "    stomach\n",
    "    prostate\n",
    "    uterine_endometrial\n",
    "    liver\n",
    "    esophagus\n",
    "    ovarian\n",
    "    multiple_myeloma\n",
    "    breast\n",
    "    pancreas\n",
    "    head_and_neck\n",
    "    bone\n",
    "    testicular\n",
    "    eye_ocular\n",
    "    thyroid\n",
    ")\n",
    "\n",
    "for cohort in \"${cohorts[@]}\"; do\n",
    "    cohort_label=\"meds_${cohort}\"\n",
    "    echo \"Running fine-tuning for $cohort...\"\n",
    "    python -u -m femr.omop_meds_tutorial.finetune_motor \\\n",
    "        --pretraining_data $PRETRAINING_DATA \\\n",
    "        --meds_reader $OMOP_MEDS_READER \\\n",
    "        --cohort_label $cohort_label \\\n",
    "        &> \"finetune_${cohort}.out\" &\n",
    "done"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#bash run_motor_lp.sh"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# check if it is running\n",
    "# ps aux | grep finetune_motor"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.16"
  },
  "toc": {
   "base_numbering": 1,
   "nav_menu": {},
   "number_sections": true,
   "sideBar": true,
   "skip_h1_title": false,
   "title_cell": "Table of Contents",
   "title_sidebar": "Contents",
   "toc_cell": false,
   "toc_position": {},
   "toc_section_display": true,
   "toc_window_display": false
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
