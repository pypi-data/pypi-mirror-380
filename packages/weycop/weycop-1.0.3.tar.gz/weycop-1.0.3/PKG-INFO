Metadata-Version: 2.4
Name: weycop
Version: 1.0.3
Summary: Python client for WeyCP API - Advanced AI chat completions service
Home-page: https://github.com/weycop/weycop-python
Author: WeyCP Team
Author-email: apps@weycop.com
Project-URL: Bug Tracker, https://github.com/weycop/weycop-python/issues
Project-URL: Documentation, https://docs.weycop.com
Project-URL: Homepage, https://weycop.com
Keywords: weycop,ai,chat,completions,openai,llama,ollama,api
Classifier: Development Status :: 5 - Production/Stable
Classifier: Intended Audience :: Developers
Classifier: License :: OSI Approved :: MIT License
Classifier: Operating System :: OS Independent
Classifier: Programming Language :: Python :: 3
Classifier: Programming Language :: Python :: 3.8
Classifier: Programming Language :: Python :: 3.9
Classifier: Programming Language :: Python :: 3.10
Classifier: Programming Language :: Python :: 3.11
Classifier: Programming Language :: Python :: 3.12
Classifier: Topic :: Internet :: WWW/HTTP
Classifier: Topic :: Software Development :: Libraries :: Python Modules
Classifier: Topic :: Scientific/Engineering :: Artificial Intelligence
Requires-Python: >=3.8
Description-Content-Type: text/markdown
License-File: LICENSE
Requires-Dist: httpx>=0.24.0
Provides-Extra: dev
Requires-Dist: pytest>=7.0.0; extra == "dev"
Requires-Dist: pytest-asyncio>=0.21.0; extra == "dev"
Requires-Dist: pytest-httpx>=0.21.0; extra == "dev"
Requires-Dist: black>=22.0.0; extra == "dev"
Requires-Dist: flake8>=5.0.0; extra == "dev"
Requires-Dist: mypy>=1.0.0; extra == "dev"
Dynamic: author
Dynamic: author-email
Dynamic: classifier
Dynamic: description
Dynamic: description-content-type
Dynamic: home-page
Dynamic: keywords
Dynamic: license-file
Dynamic: project-url
Dynamic: provides-extra
Dynamic: requires-dist
Dynamic: requires-python
Dynamic: summary

# WeyCP Python Client

[![PyPI version](https://badge.fury.io/py/weycop.svg)](https://badge.fury.io/py/weycop)
[![Python 3.8+](https://img.shields.io/badge/python-3.8+-blue.svg)](https://www.python.org/downloads/)
[![License: MIT](https://img.shields.io/badge/License-MIT-yellow.svg)](https://opensource.org/licenses/MIT)

The official Python client for **WeyCP API** chat completions created by Weycop.

---

## üöÄ Features

* **Familiar API Interface** ‚Äì Easy-to-use chat completions API.
* **Sync & Async support** ‚Äì Use synchronous or asynchronous clients.
* **Built-in error handling** ‚Äì Comprehensive exception handling.
* **Usage tracking** ‚Äì Monitor token usage and costs.
* **Type hints** ‚Äì Full type annotation support.
* **High performance** ‚Äì Optimized for concurrent requests.

---

## üì¶ Installation

```bash
pip install weycop
```

---

## ‚ö° Quick Start

### Synchronous Client

```python
from weycop import WeycopClient

# Initialize client
client = WeycopClient(api_key="your-api-key")

# Simple chat
response = client.chat(
    message="Hello, how are you?",
    model="llama3.2:3b",
    system_prompt="You are a helpful assistant"
)
print(response)
```

### Asynchronous Client

```python
import asyncio
from weycop import AsyncWeycopClient

async def main():
    async with AsyncWeycopClient(api_key="your-api-key") as client:
        response = await client.chat(
            message="What is machine learning?",
            model="llama3.1:8b-8k"
        )
        print(response)

asyncio.run(main())
```

---

## üß† Supported Models

* `llama3.2:3b` ‚Äì Fast, lightweight model (~4 GB VRAM).
* `llama3.1:8b-8k` ‚Äì Advanced model with 8K context (~8.9 GB VRAM).

---

## üõ°Ô∏è Error Handling

```python
from weycop import WeycopClient, AuthenticationError, RateLimitError, APIError

client = WeycopClient(api_key="your-key")

try:
    response = client.chat("Hello", model="llama3.2:3b")
    print(response)
except AuthenticationError:
    print("Invalid API key")
except RateLimitError:
    print("Rate limit exceeded")
except APIError as e:
    print(f"API error: {e}")
```

---

## üîÑ Examples

### System Prompts

```python
from weycop import Message

completion = client.chat_completions_create(
    model="llama3.1:8b",
    messages=[
        Message("system", "You are a SQL expert. Only respond with SQL code."),
        Message("user", "Get all users created in the last 30 days")
    ]
)
```

### Multi-turn Conversation

```python
messages = [
    Message("system", "You are a helpful math tutor."),
    Message("user", "What is 15 + 27?"),
]

completion = client.chat_completions_create(model="llama3.2:3b", messages=messages)
assistant_response = completion.choices[0].message.content
messages.append(Message("assistant", assistant_response))

messages.append(Message("user", "Now multiply that by 3"))
completion = client.chat_completions_create(model="llama3.2:3b", messages=messages)
print(completion.choices[0].message.content)
```

### Context Management

```python
with WeycopClient(api_key="your-key") as client:
    response = client.chat("Hello!")
    print(response)
# Client is automatically closed
```

---

---

## Support

* Email: [apps@weycop.com](mailto:apps@weycop.com)

---

## üìú License

MIT License - see [LICENSE](LICENSE) file for details.
