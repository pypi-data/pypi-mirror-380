import os
os.environ.setdefault("SKRUB_RUST", "1")  # opt-in fastpath before any imports
import numpy as np
import pytest
import scipy.sparse as sp
from sklearn.feature_extraction.text import HashingVectorizer, TfidfTransformer

# Skip these tests if the Rust extension isn't importable
from stratum import _rust_backend as rb
pytestmark = pytest.mark.skipif(not rb.HAVE_RUST, reason="Rust backend not built")

def _mk_sklearn_tfidf(strings, analyzer, ngram_range, n_features):
    strings = [s if isinstance(s, str) else "" for s in strings]

    # Reference pipeline: HashingVectorizer + TfidfTransformer
    hv = HashingVectorizer (n_features=n_features, analyzer=analyzer,
        ngram_range=ngram_range, alternate_sign=False, lowercase=False, norm=None)
    X_tf = hv.transform(strings)
    tfidf = TfidfTransformer( norm="l2", use_idf=True,
        smooth_idf=True, sublinear_tf=False )
    X_tfidf = tfidf.fit_transform(X_tf)
    # Ensure float32 to match Rust path
    return X_tfidf.astype(np.float32)


def _build_rust_csr(strings, analyzer, ngram_range, n_features):
    # Rust expects a list[str]; replace None with ""
    strings = [s if isinstance(s, str) else "" for s in strings]
    data, indices, indptr, n_rows, n_cols, _idf = rb.hashing_tfidf_csr(
        strings, analyzer, int(ngram_range[0]), int(ngram_range[1]), int(n_features)
    )
    X = sp.csr_matrix((data, indices, indptr), shape=(n_rows, n_cols), dtype=np.float32)
    return X


def _assert_csr_invariants(X: sp.csr_matrix):
    assert sp.isspmatrix_csr(X)
    indptr = X.indptr
    indices = X.indices
    data = X.data
    # shape checks
    assert indptr.ndim == 1 and indices.ndim == 1 and data.ndim == 1
    assert indptr.size == X.shape[0] + 1, f"indptr size {indptr.size} vs rows+1 {X.shape[0] + 1}"
    assert indptr[0] == 0 and indptr[-1] == data.size, "CSR cumulative sizes inconsistent"
    # monotonic ptrs
    assert np.all(indptr[1:] >= indptr[:-1]), "indptr must be non-decreasing"
    # column bounds
    if data.size:
        cmin = indices.min()
        cmax = indices.max()
        assert 0 <= cmin and cmax < X.shape[1], "column index out of bounds"


def _assert_rows_close(A: sp.csr_matrix, B: sp.csr_matrix, atol=1e-5, rtol=1e-5):
    assert A.shape == B.shape
    # Compare row-by-row L2 norm of the difference.
    diff = (A - B).tocsr()
    # squared row norms of diff
    row_sumsq = np.array(diff.multiply(diff).sum(axis=1)).ravel()
    # we accept tiny floating noise
    assert np.allclose(row_sumsq, 0.0, atol=atol, rtol=rtol), f"Max row diff: {row_sumsq.max()}"


@pytest.mark.parametrize("analyzer", ["char", "char_wb"])
@pytest.mark.parametrize("ngram_range", [(2, 3), (3, 5)])
def test_hashing_tfidf_matches_sklearn(analyzer, ngram_range):
    n_features = 2**18  # small-ish table for tests
    strings = [
        "Foo bar baz",
        "bar   baz!!!",
        "",
        None,                   # will be treated as ""
        "lorem ipsum dolor sit amet",
        "BaZ foo BAR",          # case differences (we set lowercase=False in sklearn)
        "foo",
    ]

    X_rust = _build_rust_csr(strings, analyzer, ngram_range, n_features)
    _assert_csr_invariants(X_rust)
    X_ref = _mk_sklearn_tfidf(strings, analyzer, ngram_range, n_features)
    _assert_csr_invariants(X_ref)

    # Shapes must match
    assert X_rust.shape == X_ref.shape

    # Values should be close.
    # FIXME: enable after making the rust logic exactly as sklearn.
    #   The results mismatch due to different hash functions used.
    #_assert_rows_close(X_rust, X_ref, atol=1e-5, rtol=1e-5)


def test_empty_input_edge_cases():
    n_features = 2**15
    for strings in ([], [""], ["", ""], [None, None]):
        X = _build_rust_csr(strings, "char", (3, 5), n_features)
        _assert_csr_invariants(X)
        # For all-empty docs, the matrix can be all-zero.
        assert X.shape[0] == len(strings)
        # nnz must equal indptr[-1]
        assert X.nnz == X.indptr[-1]


def test_large_ngram_range_smoke():
    # Just ensure it runs and constructs a valid CSR (no OOB indices)
    n_features = 2**17
    strings = ["abcde", "xyz", "abcdefghij"]
    X = _build_rust_csr(strings, "char", (1, 8), n_features)
    _assert_csr_invariants(X)
