#!/usr/bin/env python3
"""
DataGuild Snowflake Connector - Basic Usage Example
===================================================

This example demonstrates how to use the DataGuild Snowflake Connector
for basic metadata extraction from a Snowflake database.

Prerequisites:
1. Install the package: pip install dataguild-snowflake-connector
2. Configure snowflake_config.yml with your Snowflake credentials
3. Ensure you have appropriate permissions on your Snowflake account

Usage:
    python basic_usage.py
"""

import asyncio
import logging
import sys
from pathlib import Path

# Configure logging
logging.basicConfig(
    level=logging.INFO,
    format='%(asctime)s - %(name)s - %(levelname)s - %(message)s'
)
logger = logging.getLogger(__name__)

try:
    from dataguild.source.snowflake.main import SnowflakeV2Source
    from dataguild.source.snowflake.config import SnowflakeV2Config
    from dataguild.api.common import PipelineContext
    from dataguild.utilities.performance_monitor import PerformanceMonitor
except ImportError as e:
    logger.error(f"Failed to import DataGuild modules: {e}")
    logger.error("Please install the package: pip install dataguild-snowflake-connector")
    sys.exit(1)


async def basic_metadata_extraction():
    """
    Basic metadata extraction example.
    """
    logger.info("üöÄ Starting DataGuild Snowflake Connector - Basic Usage")
    
    try:
        # Load configuration
        config_path = Path("snowflake_config.yml")
        if not config_path.exists():
            logger.error(f"Configuration file not found: {config_path}")
            logger.error("Please create snowflake_config.yml with your Snowflake credentials")
            return False
        
        config = SnowflakeV2Config.from_yaml(str(config_path))
        logger.info("‚úÖ Configuration loaded successfully")
        
        # Create pipeline context
        ctx = PipelineContext(pipeline_name="basic_metadata_extraction")
        logger.info("‚úÖ Pipeline context created")
        
        # Initialize performance monitor
        monitor = PerformanceMonitor()
        
        # Initialize source
        source = SnowflakeV2Source(ctx, config)
        logger.info("‚úÖ Snowflake source initialized")
        
        # Extract metadata
        logger.info("üîç Starting metadata extraction...")
        extracted_count = 0
        
        with monitor.timer("metadata_extraction"):
            async for work_unit in source.get_workunits():
                extracted_count += 1
                
                # Log basic information about each entity
                entity = work_unit.entity
                logger.info(f"üìä Extracted: {entity.name} (Type: {entity.type})")
                
                if hasattr(entity, 'description') and entity.description:
                    logger.info(f"   Description: {entity.description[:100]}...")
                
                # Log every 10 entities to avoid spam
                if extracted_count % 10 == 0:
                    logger.info(f"üìà Progress: {extracted_count} entities extracted")
        
        # Get performance metrics
        metrics = monitor.get_metrics("metadata_extraction")
        logger.info("üìä Extraction completed!")
        logger.info(f"   Total entities: {extracted_count}")
        logger.info(f"   Average time per entity: {metrics.get_average_time():.3f}s")
        logger.info(f"   Total extraction time: {metrics.total_time:.3f}s")
        
        return True
        
    except Exception as e:
        logger.error(f"‚ùå Extraction failed: {e}")
        logger.exception("Full error details:")
        return False


async def advanced_metadata_extraction():
    """
    Advanced metadata extraction with AI intelligence.
    """
    logger.info("ü§ñ Starting Advanced Metadata Extraction with AI Intelligence")
    
    try:
        from dataguild.ai.intelligent_extractor import DataGuildIntelligentExtractor
        from dataguild.ai.gemma_client import GemmaConfig
        
        # Load configuration
        config = SnowflakeV2Config.from_yaml("snowflake_config.yml")
        
        # Enable AI intelligence
        config.enable_ai_intelligence = True
        logger.info("‚úÖ AI intelligence enabled")
        
        # Create pipeline context
        ctx = PipelineContext(pipeline_name="ai_powered_extraction")
        
        # Initialize AI extractor (if API key is available)
        ai_extractor = None
        if hasattr(config, 'ai_api_key') and config.ai_api_key:
            ai_config = GemmaConfig(
                model_name="gemma-7b-it",
                api_key=config.ai_api_key,
                max_tokens=2048
            )
            ai_extractor = DataGuildIntelligentExtractor(ai_config)
            logger.info("‚úÖ AI extractor initialized")
        else:
            logger.warning("‚ö†Ô∏è  AI API key not configured, skipping AI features")
        
        # Initialize source
        source = SnowflakeV2Source(ctx, config)
        
        # Extract metadata with AI enhancement
        extracted_count = 0
        ai_enhanced_count = 0
        
        async for work_unit in source.get_workunits():
            extracted_count += 1
            
            # Basic extraction
            entity = work_unit.entity
            logger.info(f"üìä Extracted: {entity.name} (Type: {entity.type})")
            
            # AI enhancement (if available)
            if ai_extractor:
                try:
                    enhanced_metadata = await ai_extractor.enhance_metadata(work_unit)
                    ai_enhanced_count += 1
                    
                    if hasattr(enhanced_metadata.entity, 'ai_description'):
                        logger.info(f"ü§ñ AI Description: {enhanced_metadata.entity.ai_description[:100]}...")
                    
                    if hasattr(enhanced_metadata.entity, 'data_classification'):
                        logger.info(f"üè∑Ô∏è  Data Classification: {enhanced_metadata.entity.data_classification}")
                        
                except Exception as e:
                    logger.warning(f"‚ö†Ô∏è  AI enhancement failed for {entity.name}: {e}")
            
            # Limit for demo
            if extracted_count >= 20:
                logger.info("üõë Demo limit reached (20 entities)")
                break
        
        logger.info("üìä Advanced extraction completed!")
        logger.info(f"   Total entities: {extracted_count}")
        logger.info(f"   AI enhanced: {ai_enhanced_count}")
        
        return True
        
    except ImportError:
        logger.warning("‚ö†Ô∏è  AI modules not available, skipping advanced example")
        return True
    except Exception as e:
        logger.error(f"‚ùå Advanced extraction failed: {e}")
        logger.exception("Full error details:")
        return False


async def rest_api_integration_example():
    """
    Example of integrating with REST API for metadata emission.
    """
    logger.info("üåê Starting REST API Integration Example")
    
    try:
        from dataguild.emitter.dataguild_rest_emitter import DataGuildRestEmitter, DataGuildRestEmitterConfig
        from dataguild.emitter.mcp import MetadataChangeProposal, AspectType
        
        # Configure REST emitter
        rest_config = DataGuildRestEmitterConfig(
            server_url="https://api.dataguild.com",
            token="your-api-token",  # Replace with actual token
            batch_size=100,
            retry_max_times=3,
            timeout_sec=30.0
        )
        
        # Initialize emitter
        emitter = DataGuildRestEmitter(rest_config)
        logger.info("‚úÖ REST emitter configured")
        
        # Create sample metadata change proposal
        mcp = MetadataChangeProposal(
            entityType="dataset",
            changeType="UPSERT",
            entityUrn="urn:li:dataset:(snowflake,PROD_DB.PUBLIC.CUSTOMERS,PROD)",
            aspectName=AspectType.DATASET_PROPERTIES.value,
            aspect={
                "name": "CUSTOMERS",
                "description": "Customer data table with PII information",
                "customProperties": {
                    "owner": "data-team@company.com",
                    "pii": "true",
                    "retention_days": "2555",
                    "data_classification": "confidential"
                }
            }
        )
        
        logger.info("üì§ Sample MCP created")
        logger.info(f"   Entity: {mcp.entityUrn}")
        logger.info(f"   Aspect: {mcp.aspectName}")
        
        # Note: Actual emission would require valid API credentials
        logger.info("‚ÑπÔ∏è  To emit to REST API, configure valid credentials in rest_config")
        
        return True
        
    except Exception as e:
        logger.error(f"‚ùå REST API integration example failed: {e}")
        logger.exception("Full error details:")
        return False


async def main():
    """
    Main function to run all examples.
    """
    logger.info("=" * 60)
    logger.info("üöÄ DataGuild Snowflake Connector - Examples")
    logger.info("=" * 60)
    
    # Run basic extraction
    logger.info("\n" + "=" * 40)
    logger.info("üìä BASIC METADATA EXTRACTION")
    logger.info("=" * 40)
    
    basic_success = await basic_metadata_extraction()
    
    if basic_success:
        logger.info("‚úÖ Basic extraction completed successfully")
    else:
        logger.error("‚ùå Basic extraction failed")
        return False
    
    # Run advanced extraction
    logger.info("\n" + "=" * 40)
    logger.info("ü§ñ ADVANCED AI-POWERED EXTRACTION")
    logger.info("=" * 40)
    
    advanced_success = await advanced_metadata_extraction()
    
    if advanced_success:
        logger.info("‚úÖ Advanced extraction completed successfully")
    else:
        logger.warning("‚ö†Ô∏è  Advanced extraction had issues")
    
    # Run REST API integration example
    logger.info("\n" + "=" * 40)
    logger.info("üåê REST API INTEGRATION EXAMPLE")
    logger.info("=" * 40)
    
    rest_success = await rest_api_integration_example()
    
    if rest_success:
        logger.info("‚úÖ REST API integration example completed")
    else:
        logger.warning("‚ö†Ô∏è  REST API integration example had issues")
    
    # Summary
    logger.info("\n" + "=" * 60)
    logger.info("üìä SUMMARY")
    logger.info("=" * 60)
    logger.info(f"Basic Extraction: {'‚úÖ Success' if basic_success else '‚ùå Failed'}")
    logger.info(f"Advanced Extraction: {'‚úÖ Success' if advanced_success else '‚ö†Ô∏è  Issues'}")
    logger.info(f"REST API Example: {'‚úÖ Success' if rest_success else '‚ö†Ô∏è  Issues'}")
    
    if basic_success:
        logger.info("\nüéâ DataGuild Snowflake Connector is working correctly!")
        logger.info("üìö For more examples, visit: https://dataguild-snowflake.readthedocs.io")
        return True
    else:
        logger.error("\n‚ùå Please check your configuration and try again")
        return False


if __name__ == "__main__":
    # Run the examples
    success = asyncio.run(main())
    sys.exit(0 if success else 1)
