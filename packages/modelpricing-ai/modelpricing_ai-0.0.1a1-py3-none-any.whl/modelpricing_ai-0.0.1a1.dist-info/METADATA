Metadata-Version: 2.4
Name: modelpricing-ai
Version: 0.0.1a1
Summary: Python client for ModelPricing.ai cost estimates
Project-URL: Homepage, https://modelpricing.ai
Author: ModelPricing.ai
License: MIT
License-File: LICENSE
Classifier: Intended Audience :: Developers
Classifier: License :: OSI Approved :: MIT License
Classifier: Programming Language :: Python :: 3
Classifier: Programming Language :: Python :: 3 :: Only
Classifier: Programming Language :: Python :: 3.8
Classifier: Programming Language :: Python :: 3.9
Classifier: Programming Language :: Python :: 3.10
Classifier: Programming Language :: Python :: 3.11
Classifier: Programming Language :: Python :: 3.12
Classifier: Programming Language :: Python :: 3.13
Classifier: Topic :: Software Development :: Libraries :: Python Modules
Requires-Python: >=3.8
Requires-Dist: aiohttp>=3.9.0
Requires-Dist: pydantic>=2.3.0
Requires-Dist: requests>=2.31.0
Requires-Dist: tenacity>=8.0.0
Provides-Extra: dev
Requires-Dist: build>=1.2.1; extra == 'dev'
Requires-Dist: pytest-asyncio>=0.23; extra == 'dev'
Requires-Dist: pytest>=7.0; extra == 'dev'
Requires-Dist: twine>=5.0.0; extra == 'dev'
Description-Content-Type: text/markdown

# modelpricing-ai

Python client for the ModelPricing.ai API.

## Installation

```bash
pip install modelpricing-ai
```

## Usage (sync, typed)

```python
from modelpricing_ai import ModelPricingClient

client = ModelPricingClient(api_key="YOUR_API_KEY")

estimate = client.estimate(
    model="gpt-4o-mini",
    tokens_in=125000,
    tokens_out=42000,
    trace_id={"requestId": "abc-123"},
)
print(estimate.total)  # total USD cost
```

- Base URL: `https://api.modelpricing.ai`
- Auth: `Authorization: Bearer <API_KEY>`
- Endpoint: `POST /v1/estimate`
- Request body:

```json
{
    "metrics": { "tokensIn": 1000, "tokensOut": 2000 },
    "model": "<model-name>",
    "traceId": { "...": "..." }
}
```

### Error handling

- 401 Unauthorized: invalid or missing API key
- 422 Unprocessable Entity: validation error (e.g., invalid model or metrics)
- Other 4xx/5xx: raised as a generic server error

### Retry behavior

The client automatically retries on transient errors with exponential backoff:

- **Retries**: 5xx server errors and network/connection errors
- **No retry**: 4xx client errors (401, 404, 422)
- **Default**: 3 attempts with exponential backoff (1s, 2s, 4s, up to 10s max)

Configure retry behavior:

```python
# Customize max retries (default is 3)
client = ModelPricingClient(api_key="YOUR_API_KEY", max_retries=5)

# Disable retries
client = ModelPricingClient(api_key="YOUR_API_KEY", max_retries=1)
```

This handles transient infrastructure issues like Cloudflare errors, DNS failures, and temporary service disruptions.

## License

MIT

## Async usage (typed)

```python
import asyncio
from modelpricing_ai import AsyncModelPricingClient

async def main():
    client = AsyncModelPricingClient(api_key="YOUR_API_KEY")
    estimate = await client.estimate(
        model="gpt-4o-mini",
        tokens_in=125000,
        tokens_out=42000,
        trace_id={"requestId": "abc-123"},
    )
    print(estimate.total)  # total USD cost

asyncio.run(main())
```
