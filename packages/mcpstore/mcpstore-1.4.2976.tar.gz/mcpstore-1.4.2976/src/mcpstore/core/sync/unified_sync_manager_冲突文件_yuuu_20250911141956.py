"""
Unified MCP Configuration Synchronization Manager

Core design principles:
1. mcp.json is the single source of truth
2. All configuration changes go through mcp.json, automatically sync to global_agent_store
3. Agent operations only manage their own space + mcp.json, Store operations only manage mcp.json
4. Automatic sync mechanism handles mcp.json â†’ global_agent_store synchronization

Data space support:
- File monitoring based on orchestrator.mcp_config.json_path
- Support independent synchronization for different data spaces
"""

import asyncio
import logging
import os
import time
from pathlib import Path
from typing import Dict, Set, Optional, Any
from watchdog.observers import Observer
from watchdog.events import FileSystemEventHandler

logger = logging.getLogger(__name__)


class MCPFileHandler(FileSystemEventHandler):
    """MCP configuration file change handler"""
    
    def __init__(self, sync_manager):
        self.sync_manager = sync_manager
        self.mcp_filename = os.path.basename(sync_manager.mcp_json_path)
        
    def on_modified(self, event):
        """File modification event handling"""
        if event.is_directory:
            return

        # Only monitor target mcp.json file
        if os.path.basename(event.src_path) == self.mcp_filename:
            logger.debug(f"MCP config file modified: {event.src_path}")
            # Safely execute async method in correct event loop
            try:
                loop = asyncio.get_event_loop()
                if loop.is_running():
                    # If event loop is running, use call_soon_threadsafe
                    loop.call_soon_threadsafe(
                        lambda: asyncio.create_task(self.sync_manager.on_file_changed())
                    )
                else:
                    # å¦‚æœäº‹ä»¶å¾ªç¯æœªè¿è¡Œï¼Œç›´æ¥åˆ›å»ºä»»åŠ¡
                    asyncio.create_task(self.sync_manager.on_file_changed())
            except RuntimeError:
                # å¦‚æœæ²¡æœ‰äº‹ä»¶å¾ªç¯ï¼Œè®°å½•è­¦å‘Š
                logger.warning("No event loop available for file change notification")


class UnifiedMCPSyncManager:
    """ç»Ÿä¸€çš„MCPé…ç½®åŒæ­¥ç®¡ç†å™¨"""
    
    def __init__(self, orchestrator):
        """
        åˆå§‹åŒ–åŒæ­¥ç®¡ç†å™¨
        
        Args:
            orchestrator: MCPOrchestratorå®ä¾‹
        """
        self.orchestrator = orchestrator
        # ç¡®ä¿ä½¿ç”¨ç»å¯¹è·¯å¾„
        import os
        self.mcp_json_path = os.path.abspath(orchestrator.mcp_config.json_path)
        self.file_observer = None
        self.sync_lock = asyncio.Lock()
        self.debounce_delay = 1.0  # é˜²æŠ–å»¶è¿Ÿï¼ˆç§’ï¼‰
        self.sync_task = None
        self.last_change_time = None
        self.last_sync_time = None  # ğŸ”§ æ–°å¢ï¼šè®°å½•ä¸Šæ¬¡åŒæ­¥æ—¶é—´
        self.min_sync_interval = 5.0  # ğŸ”§ æ–°å¢ï¼šæœ€å°åŒæ­¥é—´éš”ï¼ˆç§’ï¼‰
        self.is_running = False
        
        logger.info(f"UnifiedMCPSyncManager initialized for: {self.mcp_json_path}")
        
    async def start(self):
        """å¯åŠ¨åŒæ­¥ç®¡ç†å™¨"""
        if self.is_running:
            logger.warning("Sync manager is already running")
            return
            
        try:
            logger.info("Starting unified MCP sync manager...")
            
            # å¯åŠ¨æ–‡ä»¶ç›‘å¬
            await self._start_file_watcher()

            # ğŸ”§ æ‰§è¡Œå¯åŠ¨æ—¶åŒæ­¥ï¼ˆå§‹ç»ˆå¯ç”¨ï¼‰
            logger.info("Executing initial sync from mcp.json")
            await self.sync_global_agent_store_from_mcp_json()

            self.is_running = True
            logger.info("Unified MCP sync manager started successfully")
            
        except Exception as e:
            logger.error(f"Failed to start sync manager: {e}")
            await self.stop()
            raise
            
    async def stop(self):
        """åœæ­¢åŒæ­¥ç®¡ç†å™¨"""
        if not self.is_running:
            return
            
        logger.info("Stopping unified MCP sync manager...")
        
        # åœæ­¢æ–‡ä»¶ç›‘å¬
        if self.file_observer:
            self.file_observer.stop()
            self.file_observer.join()
            self.file_observer = None
            
        # å–æ¶ˆå¾…æ‰§è¡Œçš„åŒæ­¥ä»»åŠ¡
        if self.sync_task and not self.sync_task.done():
            self.sync_task.cancel()
            
        self.is_running = False
        logger.info("Unified MCP sync manager stopped")
        
    async def _start_file_watcher(self):
        """å¯åŠ¨mcp.jsonæ–‡ä»¶ç›‘å¬"""
        try:
            # ç¡®ä¿mcp.jsonæ–‡ä»¶å­˜åœ¨
            if not os.path.exists(self.mcp_json_path):
                logger.warning(f"MCP config file not found: {self.mcp_json_path}")
                # åˆ›å»ºç©ºé…ç½®æ–‡ä»¶
                os.makedirs(os.path.dirname(self.mcp_json_path), exist_ok=True)
                with open(self.mcp_json_path, 'w', encoding='utf-8') as f:
                    import json
                    json.dump({"mcpServers": {}}, f, indent=2)
                logger.info(f"Created empty MCP config file: {self.mcp_json_path}")
            
            # åˆ›å»ºæ–‡ä»¶ç›‘å¬å™¨
            self.file_observer = Observer()
            handler = MCPFileHandler(self)
            
            # ç›‘å¬mcp.jsonæ‰€åœ¨ç›®å½•
            watch_dir = os.path.dirname(self.mcp_json_path)
            self.file_observer.schedule(handler, watch_dir, recursive=False)
            self.file_observer.start()
            
            logger.info(f"File watcher started for directory: {watch_dir}")
            
        except Exception as e:
            logger.error(f"Failed to start file watcher: {e}")
            raise
            
    async def on_file_changed(self):
        """æ–‡ä»¶å˜åŒ–å›è°ƒï¼ˆå¸¦é˜²æŠ–ï¼‰"""
        try:
            self.last_change_time = time.time()
            
            # å–æ¶ˆä¹‹å‰çš„åŒæ­¥ä»»åŠ¡
            if self.sync_task and not self.sync_task.done():
                self.sync_task.cancel()
                
            # å¯åŠ¨é˜²æŠ–åŒæ­¥
            self.sync_task = asyncio.create_task(self._debounced_sync())
            
        except Exception as e:
            logger.error(f"Error handling file change: {e}")
            
    async def _debounced_sync(self):
        """é˜²æŠ–åŒæ­¥"""
        try:
            await asyncio.sleep(self.debounce_delay)

            # æ£€æŸ¥æ˜¯å¦æœ‰æ–°çš„å˜åŒ–
            if self.last_change_time and time.time() - self.last_change_time >= self.debounce_delay:
                logger.info("Triggering auto-sync due to mcp.json changes")
                # ç»Ÿä¸€ä½¿ç”¨å…¨å±€åŒæ­¥æ–¹æ³•
                await self.sync_global_agent_store_from_mcp_json()
                
        except asyncio.CancelledError:
            logger.debug("Debounced sync cancelled")
        except Exception as e:
            logger.error(f"Error in debounced sync: {e}")
            
    async def sync_global_agent_store_from_mcp_json(self):
        """ä»mcp.jsonåŒæ­¥global_agent_storeï¼ˆæ ¸å¿ƒæ–¹æ³•ï¼‰"""
        async with self.sync_lock:
            try:
                # ğŸ”§ æ–°å¢ï¼šæ£€æŸ¥åŒæ­¥é¢‘ç‡ï¼Œé¿å…è¿‡åº¦åŒæ­¥
                import time
                current_time = time.time()

                if self.last_sync_time and (current_time - self.last_sync_time) < self.min_sync_interval:
                    logger.debug(f"Sync skipped due to frequency limit (last sync {current_time - self.last_sync_time:.1f}s ago)")
                    return {"skipped": True, "reason": "frequency_limit"}

                logger.info("Starting global_agent_store sync from mcp.json")

                # è¯»å–æœ€æ–°é…ç½®
                config = self.orchestrator.mcp_config.load_config()
                services = config.get("mcpServers", {})

                logger.debug(f"Found {len(services)} services in mcp.json")

                # æ‰§è¡ŒåŒæ­¥
                results = await self._sync_global_agent_store_services(services)

                # ğŸ”§ æ–°å¢ï¼šè®°å½•åŒæ­¥æ—¶é—´
                self.last_sync_time = current_time

                logger.info(f"Global agent store sync completed: {results}")
                return results

            except Exception as e:
                logger.error(f"Global agent store sync failed: {e}")
                raise
                
    async def _sync_global_agent_store_services(self, target_services: Dict[str, Any]) -> Dict[str, Any]:
        """åŒæ­¥global_agent_storeçš„æœåŠ¡"""
        try:
            global_agent_store_id = self.orchestrator.client_manager.global_agent_store_id

            # è·å–å½“å‰global_agent_storeçš„æœåŠ¡
            current_services = self._get_current_global_agent_store_services()
            
            # è®¡ç®—å·®å¼‚
            current_names = set(current_services.keys())
            target_names = set(target_services.keys())
            
            to_add = target_names - current_names
            to_remove = current_names - target_names
            to_update = target_names & current_names
            
            logger.debug(f"Sync plan: +{len(to_add)} -{len(to_remove)} ~{len(to_update)}")
            
            # æ‰§è¡ŒåŒæ­¥
            results = {
                "added": [],
                "removed": [],
                "updated": [],
                "failed": []
            }
            
            # 1. ç§»é™¤ä¸å†éœ€è¦çš„æœåŠ¡
            for service_name in to_remove:
                try:
                    success = await self._remove_service_from_global_agent_store(service_name)
                    if success:
                        results["removed"].append(service_name)
                        logger.debug(f"Removed service: {service_name}")
                    else:
                        results["failed"].append(f"remove:{service_name}")
                except Exception as e:
                    logger.error(f"Failed to remove service {service_name}: {e}")
                    results["failed"].append(f"remove:{service_name}:{e}")
            
            # 2. æ·»åŠ /æ›´æ–°æœåŠ¡ï¼ˆæ”¹è¿›é€»è¾‘ï¼šåªå¤„ç†çœŸæ­£éœ€è¦å˜æ›´çš„æœåŠ¡ï¼‰
            services_to_register = {}

            # å¤„ç†æ–°å¢æœåŠ¡
            for service_name in to_add:
                try:
                    success = await self._add_service_to_cache_mapping(
                        agent_id=global_agent_store_id,
                        service_name=service_name,
                        service_config=target_services[service_name]
                    )

                    if success:
                        services_to_register[service_name] = target_services[service_name]
                        results["added"].append(service_name)
                        logger.debug(f"Added new service to cache: {service_name}")
                    else:
                        results["failed"].append(f"add:{service_name}")

                except Exception as e:
                    logger.error(f"Failed to add service {service_name}: {e}")
                    results["failed"].append(f"add:{service_name}:{e}")

            # å¤„ç†æ›´æ–°æœåŠ¡ï¼ˆåªæœ‰é…ç½®çœŸæ­£å˜åŒ–æ—¶æ‰æ›´æ–°ï¼‰
            for service_name in to_update:
                try:
                    # æ£€æŸ¥é…ç½®æ˜¯å¦çœŸçš„æœ‰å˜åŒ–
                    current_config = current_services.get(service_name, {})
                    target_config = target_services[service_name]

                    if self._service_config_changed(current_config, target_config):
                        success = await self._add_service_to_cache_mapping(
                            agent_id=global_agent_store_id,
                            service_name=service_name,
                            service_config=target_config
                        )

                        if success:
                            services_to_register[service_name] = target_config
                            results["updated"].append(service_name)
                            logger.debug(f"Updated service in cache: {service_name}")
                        else:
                            results["failed"].append(f"update:{service_name}")
                    else:
                        logger.debug(f"Service {service_name} config unchanged, skipping update")

                except Exception as e:
                    logger.error(f"Failed to update service {service_name}: {e}")
                    results["failed"].append(f"update:{service_name}:{e}")

            # 3. æ‰¹é‡æ³¨å†Œåˆ°Registryï¼ˆåªæ³¨å†ŒçœŸæ­£éœ€è¦æ³¨å†Œçš„æœåŠ¡ï¼‰
            if services_to_register:
                logger.info(f"Registering {len(services_to_register)} services to Registry: {list(services_to_register.keys())}")
                await self._batch_register_to_registry(global_agent_store_id, services_to_register)
            else:
                logger.debug("No services need to be registered to Registry")

            # 4. ğŸ”§ æ–°å¢ï¼šè§¦å‘ç¼“å­˜åˆ°æ–‡ä»¶çš„å¼‚æ­¥æŒä¹…åŒ–
            if services_to_register:
                await self._trigger_cache_persistence()
            
            return results

        except Exception as e:
            logger.error(f"Error syncing main client services: {e}")
            raise

    def _get_current_global_agent_store_services(self) -> Dict[str, Any]:
        """è·å–å½“å‰global_agent_storeçš„æœåŠ¡é…ç½®"""
        try:
            # single-source: derive current services from registry cache only
            agent_id = self.orchestrator.client_manager.global_agent_store_id
            current_services = {}
            for service_name in self.orchestrator.registry.get_all_service_names(agent_id):
                config = self.orchestrator.mcp_config.get_service_config(service_name) or {}
                if config:
                    current_services[service_name] = config

            return current_services

        except Exception as e:
            logger.error(f"Error getting current main client services: {e}")
            return {}

    async def _remove_service_from_global_agent_store(self, service_name: str) -> bool:
        """ä»global_agent_storeç§»é™¤æœåŠ¡"""
        try:
            global_agent_store_id = self.orchestrator.client_manager.global_agent_store_id

            # æŸ¥æ‰¾åŒ…å«è¯¥æœåŠ¡çš„client_ids
            matching_clients = self.orchestrator.client_manager.find_clients_with_service(
                global_agent_store_id, service_name
            )

            # ç§»é™¤åŒ…å«è¯¥æœåŠ¡çš„clients
            for client_id in matching_clients:
                self.orchestrator.client_manager._remove_client_and_mapping(global_agent_store_id, client_id)
                logger.debug(f"Removed client {client_id} containing service {service_name}")

            # ä»Registryç§»é™¤
            if hasattr(self.orchestrator.registry, 'remove_service'):
                self.orchestrator.registry.remove_service(global_agent_store_id, service_name)

            return len(matching_clients) > 0

        except Exception as e:
            logger.error(f"Error removing service {service_name} from main client: {e}")
            return False

    async def _batch_register_to_registry(self, agent_id: str, services_to_register: Dict[str, Any]):
        """æ‰¹é‡æ³¨å†ŒæœåŠ¡åˆ°Registryï¼ˆæ”¹è¿›ç‰ˆï¼šé¿å…é‡å¤æ³¨å†Œï¼‰"""
        try:
            if not services_to_register:
                return

            logger.debug(f"Batch registering {len(services_to_register)} services to Registry")

            # single-source: register services_to_register directly if not present
            registered_count = 0
            skipped_count = 0

            for service_name, config in services_to_register.items():
                if self.orchestrator.registry.has_service(agent_id, service_name):
                    skipped_count += 1
                    continue
                try:
                    if hasattr(self.orchestrator, 'store') and self.orchestrator.store:
                        # Use existing add_service_async with explicit mcpServers shape
                        await self.orchestrator.store.for_store().add_service_async(
                            config={"mcpServers": {service_name: config}},
                            source="auto_startup"
                        )
                    else:
                        # Update mcp.json directly then let lifecycle initialize
                        current = self.orchestrator.mcp_config.load_config()
                        m = current.get("mcpServers", {})
                        m[service_name] = config
                        current["mcpServers"] = m
                        self.orchestrator.mcp_config.save_config(current)
                    registered_count += 1
                except Exception as e:
                    logger.error(f"Failed to register service {service_name}: {e}")

            logger.info(f"Batch registration completed: {registered_count} registered, {skipped_count} skipped")

        except Exception as e:
            logger.error(f"Error in batch register to registry: {e}")

    async def _add_service_to_cache_mapping(self, agent_id: str, service_name: str, service_config: Dict[str, Any]) -> bool:
        """
        å°†æœåŠ¡æ·»åŠ åˆ°ç¼“å­˜æ˜ å°„ï¼ˆRegistryä¸­çš„ä¸¤ä¸ªæ˜ å°„å­—æ®µï¼‰

        ç¼“å­˜æ˜ å°„æŒ‡çš„æ˜¯ï¼š
        - registry.agent_clients: Agent-Clientæ˜ å°„
        - registry.client_configs: Clienté…ç½®æ˜ å°„

        Args:
            agent_id: Agent ID
            service_name: æœåŠ¡åç§°
            service_config: æœåŠ¡é…ç½®

        Returns:
            æ˜¯å¦æˆåŠŸæ·»åŠ åˆ°ç¼“å­˜æ˜ å°„
        """
        try:
            # è·å–Registryå®ä¾‹
            registry = getattr(self.orchestrator, 'registry', None)
            if not registry:
                logger.error("Registry not available")
                return False

            # ğŸ”§ ä¿®å¤ï¼šæ£€æŸ¥æ˜¯å¦å·²å­˜åœ¨è¯¥æœåŠ¡çš„client_idï¼Œé¿å…é‡å¤ç”Ÿæˆ
            existing_client_id = self._find_existing_client_id_for_service(agent_id, service_name)

            if existing_client_id:
                # ä½¿ç”¨ç°æœ‰çš„client_idï¼Œåªæ›´æ–°é…ç½®
                client_id = existing_client_id
                logger.debug(f" ä½¿ç”¨ç°æœ‰client_id: {service_name} -> {client_id}")
            else:
                # ğŸ”§ ä½¿ç”¨ç»Ÿä¸€çš„ClientIDGeneratorç”Ÿæˆç¡®å®šæ€§client_id
                from mcpstore.core.utils.id_generator import ClientIDGenerator
                
                # UnifiedMCPSyncManagerä¸»è¦å¤„ç†Storeçº§åˆ«çš„æœåŠ¡ï¼Œæ‰€ä»¥ä½¿ç”¨global_agent_store_id
                global_agent_store_id = getattr(self.orchestrator.client_manager, 'global_agent_store_id', 'global_agent_store')
                
                client_id = ClientIDGenerator.generate_deterministic_id(
                    agent_id=agent_id,
                    service_name=service_name,
                    service_config=service_config,
                    global_agent_store_id=global_agent_store_id
                )
                logger.debug(f" ç”Ÿæˆæ–°client_id: {service_name} -> {client_id}")

            # æ›´æ–°ç¼“å­˜æ˜ å°„1ï¼šAgent-Clientæ˜ å°„
            if agent_id not in registry.agent_clients:
                registry.agent_clients[agent_id] = []
            if client_id not in registry.agent_clients[agent_id]:
                registry.agent_clients[agent_id].append(client_id)

            # æ›´æ–°ç¼“å­˜æ˜ å°„2ï¼šClienté…ç½®æ˜ å°„
            registry.client_configs[client_id] = {
                "mcpServers": {service_name: service_config}
            }

            logger.debug(f"ç¼“å­˜æ˜ å°„æ›´æ–°æˆåŠŸ: {service_name} -> {client_id}")
            logger.debug(f"   - agent_clients[{agent_id}] å·²æ›´æ–°")
            logger.debug(f"   - client_configs[{client_id}] å·²æ›´æ–°")
            return True

        except Exception as e:
            logger.error(f"Failed to add service to cache mapping: {e}")
            return False

    def _find_existing_client_id_for_service(self, agent_id: str, service_name: str) -> str:
        """
        æŸ¥æ‰¾æŒ‡å®šæœåŠ¡æ˜¯å¦å·²æœ‰å¯¹åº”çš„client_id

        Args:
            agent_id: Agent ID
            service_name: æœåŠ¡åç§°

        Returns:
            ç°æœ‰çš„client_idï¼Œå¦‚æœä¸å­˜åœ¨åˆ™è¿”å›None
        """
        try:
            registry = getattr(self.orchestrator, 'registry', None)
            if not registry:
                return None

            # è·å–è¯¥agentçš„æ‰€æœ‰client_id
            client_ids = registry.agent_clients.get(agent_id, [])

            # éå†æ¯ä¸ªclient_idï¼Œæ£€æŸ¥æ˜¯å¦åŒ…å«ç›®æ ‡æœåŠ¡
            for client_id in client_ids:
                client_config = registry.client_configs.get(client_id, {})
                if service_name in client_config.get("mcpServers", {}):
                    logger.debug(f"ğŸ” æ‰¾åˆ°ç°æœ‰client_id: {service_name} -> {client_id}")
                    return client_id

            return None

        except Exception as e:
            logger.error(f"Error finding existing client_id for service {service_name}: {e}")
            return None

    def _service_config_changed(self, current_config: Dict[str, Any], target_config: Dict[str, Any]) -> bool:
        """
        æ£€æŸ¥æœåŠ¡é…ç½®æ˜¯å¦å‘ç”Ÿå˜åŒ–

        Args:
            current_config: å½“å‰é…ç½®
            target_config: ç›®æ ‡é…ç½®

        Returns:
            é…ç½®æ˜¯å¦å‘ç”Ÿå˜åŒ–
        """
        try:
            # ç®€å•çš„å­—å…¸æ¯”è¾ƒï¼Œå¯ä»¥æ ¹æ®éœ€è¦æ‰©å±•
            import json
            current_str = json.dumps(current_config, sort_keys=True)
            target_str = json.dumps(target_config, sort_keys=True)
            changed = current_str != target_str

            if changed:
                logger.debug(f"Service config changed: {current_str} -> {target_str}")

            return changed

        except Exception as e:
            logger.error(f"Error comparing service configs: {e}")
            # å‡ºé”™æ—¶ä¿å®ˆå¤„ç†ï¼Œè®¤ä¸ºæœ‰å˜åŒ–
            return True

    async def _trigger_cache_persistence(self):
        """
        è§¦å‘ç¼“å­˜æ˜ å°„åˆ°æ–‡ä»¶çš„åŒæ­¥æœºåˆ¶

        æ³¨æ„ï¼šè¿™é‡Œè°ƒç”¨çš„æ˜¯åŒæ­¥æœºåˆ¶ï¼ˆsync_to_client_managerï¼‰ï¼Œ
        ä¸æ˜¯å¼‚æ­¥æŒä¹…åŒ–ï¼ˆ_persist_to_files_asyncï¼‰
        """
        try:
            # å•æºæ¨¡å¼ï¼šä¸å†å°†ç¼“å­˜æ˜ å°„åŒæ­¥åˆ°åˆ†ç‰‡æ–‡ä»¶
            logger.debug("Single-source mode: skip shard mapping sync (agent_clients/client_services)")
        except Exception as e:
            logger.error(f"Failed in shard sync skip path: {e}")

    async def manual_sync(self) -> Dict[str, Any]:
        """æ‰‹åŠ¨è§¦å‘åŒæ­¥ï¼ˆç”¨äºAPIè°ƒç”¨ï¼‰"""
        logger.info("Manual sync triggered")
        return await self.sync_global_agent_store_from_mcp_json()

    def get_sync_status(self) -> Dict[str, Any]:
        """è·å–åŒæ­¥çŠ¶æ€ä¿¡æ¯"""
        return {
            "is_running": self.is_running,
            "mcp_json_path": self.mcp_json_path,
            "last_change_time": self.last_change_time,
            "sync_lock_locked": self.sync_lock.locked(),
            "file_observer_running": self.file_observer is not None and self.file_observer.is_alive() if self.file_observer else False
        }

