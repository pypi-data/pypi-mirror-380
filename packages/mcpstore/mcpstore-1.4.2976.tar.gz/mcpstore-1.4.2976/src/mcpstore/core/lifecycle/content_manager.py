"""
æœåŠ¡å†…å®¹ç®¡ç†å™¨ - å®šæœŸæ›´æ–°å·¥å…·ã€èµ„æºå’Œæç¤ºè¯
è´Ÿè´£ç›‘æ§å’Œæ›´æ–°æœåŠ¡çš„æ‰€æœ‰å†…å®¹ï¼Œç¡®ä¿ç¼“å­˜ä¸å®é™…æœåŠ¡ä¿æŒåŒæ­¥
"""

import asyncio
import logging
from datetime import datetime, timedelta
from typing import Dict, Set, Optional, List, Any, Tuple
from dataclasses import dataclass
from fastmcp import Client

from mcpstore.core.configuration.config_processor import ConfigProcessor
from mcpstore.core.models.service import ServiceConnectionState

logger = logging.getLogger(__name__)


@dataclass
class ServiceContentSnapshot:
    """æœåŠ¡å†…å®¹å¿«ç…§"""
    service_name: str
    agent_id: str
    tools_count: int
    tools_hash: str  # å·¥å…·åˆ—è¡¨çš„å“ˆå¸Œå€¼ï¼Œç”¨äºå¿«é€Ÿæ¯”è¾ƒ
    resources_count: int = 0  # é¢„ç•™ï¼šèµ„æºæ•°é‡
    resources_hash: str = ""  # é¢„ç•™ï¼šèµ„æºå“ˆå¸Œ
    prompts_count: int = 0    # é¢„ç•™ï¼šæç¤ºè¯æ•°é‡
    prompts_hash: str = ""    # é¢„ç•™ï¼šæç¤ºè¯å“ˆå¸Œ
    last_updated: datetime = None
    
    def __post_init__(self):
        if self.last_updated is None:
            self.last_updated = datetime.now()


@dataclass
class ContentUpdateConfig:
    """å†…å®¹æ›´æ–°é…ç½®"""
    # æ›´æ–°é—´éš”
    tools_update_interval: float = 300.0      # å·¥å…·æ›´æ–°é—´éš”ï¼ˆ5åˆ†é’Ÿï¼‰
    resources_update_interval: float = 600.0  # èµ„æºæ›´æ–°é—´éš”ï¼ˆ10åˆ†é’Ÿï¼‰
    prompts_update_interval: float = 600.0    # æç¤ºè¯æ›´æ–°é—´éš”ï¼ˆ10åˆ†é’Ÿï¼‰
    
    # æ‰¹é‡å¤„ç†é…ç½®
    max_concurrent_updates: int = 3           # æœ€å¤§å¹¶å‘æ›´æ–°æ•°
    update_timeout: float = 30.0              # å•æ¬¡æ›´æ–°è¶…æ—¶ï¼ˆç§’ï¼‰
    
    # é”™è¯¯å¤„ç†
    max_consecutive_failures: int = 3         # æœ€å¤§è¿ç»­å¤±è´¥æ¬¡æ•°
    failure_backoff_multiplier: float = 2.0  # å¤±è´¥é€€é¿å€æ•°


class ServiceContentManager:
    """æœåŠ¡å†…å®¹ç®¡ç†å™¨"""
    
    def __init__(self, orchestrator):
        self.orchestrator = orchestrator
        self.registry = orchestrator.registry
        self.lifecycle_manager = orchestrator.lifecycle_manager
        self.config = ContentUpdateConfig()

        # å¯¹é½å…¨å±€ç›‘æ§é…ç½®çš„å·¥å…·æ›´æ–°æ—¶é—´é—´éš”ï¼ˆå¦‚é…ç½®å­˜åœ¨åˆ™è¦†ç›–é»˜è®¤å€¼ï¼‰
        try:
            timing_config = orchestrator.config.get("timing", {}) if isinstance(getattr(orchestrator, "config", None), dict) else {}
            interval = timing_config.get("tools_update_interval_seconds")
            if isinstance(interval, (int, float)) and interval > 0:
                self.config.tools_update_interval = float(interval)
                logger.info(f"ServiceContentManager tools_update_interval set to {self.config.tools_update_interval}s from orchestrator config")
        except Exception as e:
            logger.debug(f"Failed to read tools_update_interval from orchestrator config: {e}")

        # å†…å®¹å¿«ç…§ç¼“å­˜ï¼šagent_id -> service_name -> snapshot
        self.content_snapshots: Dict[str, Dict[str, ServiceContentSnapshot]] = {}

        # æ›´æ–°é˜Ÿåˆ—å’ŒçŠ¶æ€
        self.update_queue: Set[Tuple[str, str]] = set()  # (agent_id, service_name)
        self.updating_services: Set[Tuple[str, str]] = set()  # æ­£åœ¨æ›´æ–°çš„æœåŠ¡
        
        # å¤±è´¥ç»Ÿè®¡ï¼š(agent_id, service_name) -> consecutive_failures
        self.failure_counts: Dict[Tuple[str, str], int] = {}
        
        # å®šæ—¶ä»»åŠ¡
        self.content_update_task: Optional[asyncio.Task] = None
        self.is_running = False
        
        logger.info("ServiceContentManager initialized")
    
    async def start(self):
        """å¯åŠ¨å†…å®¹ç®¡ç†å™¨"""
        if self.is_running:
            logger.warning("ServiceContentManager is already running")
            return
        
        self.is_running = True
        self.content_update_task = asyncio.create_task(self._content_update_loop())
        logger.info("ServiceContentManager started")
    
    async def stop(self):
        """åœæ­¢å†…å®¹ç®¡ç†å™¨"""
        self.is_running = False
        if self.content_update_task and not self.content_update_task.done():
            self.content_update_task.cancel()
            try:
                # ğŸ”§ ä¿®å¤ï¼šæ£€æŸ¥å½“å‰äº‹ä»¶å¾ªç¯ï¼Œé¿å…å¾ªç¯å†²çª
                current_loop = asyncio.get_running_loop()
                task_loop = getattr(self.content_update_task, '_loop', None)

                if task_loop and task_loop != current_loop:
                    logger.warning("Task belongs to different event loop, skipping await")
                else:
                    # æ·»åŠ è¶…æ—¶ä¿æŠ¤ï¼Œé¿å…æ— é™ç­‰å¾…
                    await asyncio.wait_for(self.content_update_task, timeout=5.0)
            except asyncio.CancelledError:
                logger.debug("Content update task cancelled successfully")
            except asyncio.TimeoutError:
                logger.warning("Content update task cancellation timed out")
            except Exception as e:
                logger.warning(f"Error stopping content update task: {e}")

        # ğŸ”§ ä¿®å¤ï¼šæ¸…ç†ä»»åŠ¡å¼•ç”¨
        self.content_update_task = None
        logger.info("ServiceContentManager stopped")
    
    def add_service_for_monitoring(self, agent_id: str, service_name: str):
        """æ·»åŠ æœåŠ¡åˆ°å†…å®¹ç›‘æ§"""
        if agent_id not in self.content_snapshots:
            self.content_snapshots[agent_id] = {}
        
        # åˆ›å»ºåˆå§‹å¿«ç…§ï¼ˆå·¥å…·æ•°é‡ä¸º0ï¼Œç­‰å¾…é¦–æ¬¡æ›´æ–°ï¼‰
        self.content_snapshots[agent_id][service_name] = ServiceContentSnapshot(
            service_name=service_name,
            agent_id=agent_id,
            tools_count=0,
            tools_hash="",
            last_updated=datetime.now()
        )
        
        # æ·»åŠ åˆ°æ›´æ–°é˜Ÿåˆ—
        self.update_queue.add((agent_id, service_name))
        logger.info(f"Added service {service_name} to content monitoring (agent_id={agent_id})")
    
    def remove_service_from_monitoring(self, agent_id: str, service_name: str):
        """ä»å†…å®¹ç›‘æ§ä¸­ç§»é™¤æœåŠ¡"""
        if agent_id in self.content_snapshots:
            self.content_snapshots[agent_id].pop(service_name, None)
            if not self.content_snapshots[agent_id]:
                del self.content_snapshots[agent_id]
        
        self.update_queue.discard((agent_id, service_name))
        self.updating_services.discard((agent_id, service_name))
        self.failure_counts.pop((agent_id, service_name), None)
        
        logger.info(f"Removed service {service_name} from content monitoring (agent_id={agent_id})")
    
    async def force_update_service_content(self, agent_id: str, service_name: str) -> bool:
        """å¼ºåˆ¶æ›´æ–°æŒ‡å®šæœåŠ¡çš„å†…å®¹"""
        try:
            return await self._update_service_content(agent_id, service_name)
        except Exception as e:
            logger.error(f"Failed to force update content for {service_name}: {e}")
            return False
    
    def get_service_snapshot(self, agent_id: str, service_name: str) -> Optional[ServiceContentSnapshot]:
        """è·å–æœåŠ¡å†…å®¹å¿«ç…§"""
        return self.content_snapshots.get(agent_id, {}).get(service_name)
    
    async def _content_update_loop(self):
        """å†…å®¹æ›´æ–°ä¸»å¾ªç¯"""
        consecutive_failures = 0
        max_consecutive_failures = 5
        
        while self.is_running:
            try:
                await asyncio.sleep(30)  # æ¯30ç§’æ£€æŸ¥ä¸€æ¬¡
                await self._process_content_updates()
                consecutive_failures = 0
                
            except asyncio.CancelledError:
                logger.info("Content update loop cancelled")
                break
            except Exception as e:
                consecutive_failures += 1
                logger.error(f"Content update loop error (failure {consecutive_failures}/{max_consecutive_failures}): {e}")
                
                if consecutive_failures >= max_consecutive_failures:
                    logger.critical("Too many consecutive content update failures, stopping loop")
                    break
                
                # æŒ‡æ•°é€€é¿å»¶è¿Ÿ
                backoff_delay = min(60 * (2 ** consecutive_failures), 300)  # æœ€å¤§5åˆ†é’Ÿ
                await asyncio.sleep(backoff_delay)
    
    async def _process_content_updates(self):
        """å¤„ç†å†…å®¹æ›´æ–°é˜Ÿåˆ—"""
        if not self.update_queue:
            # æ£€æŸ¥æ˜¯å¦æœ‰æœåŠ¡éœ€è¦å®šæœŸæ›´æ–°
            await self._check_scheduled_updates()
            return
        
        # é™åˆ¶å¹¶å‘æ›´æ–°æ•°é‡
        available_slots = self.config.max_concurrent_updates - len(self.updating_services)
        if available_slots <= 0:
            return
        
        # è·å–å¾…æ›´æ–°çš„æœåŠ¡
        services_to_update = list(self.update_queue)[:available_slots]
        
        # å¹¶å‘æ›´æ–°
        update_tasks = []
        for agent_id, service_name in services_to_update:
            self.update_queue.discard((agent_id, service_name))
            self.updating_services.add((agent_id, service_name))
            
            task = asyncio.create_task(
                self._update_service_content_with_cleanup(agent_id, service_name)
            )
            update_tasks.append(task)
        
        if update_tasks:
            await asyncio.gather(*update_tasks, return_exceptions=True)
    
    async def _check_scheduled_updates(self):
        """æ£€æŸ¥éœ€è¦å®šæœŸæ›´æ–°çš„æœåŠ¡"""
        now = datetime.now()
        
        for agent_id, services in self.content_snapshots.items():
            for service_name, snapshot in services.items():
                # æ£€æŸ¥æœåŠ¡æ˜¯å¦å¥åº·
                service_state = self.lifecycle_manager.get_service_state(agent_id, service_name)
                if service_state not in [ServiceConnectionState.HEALTHY, ServiceConnectionState.WARNING]:
                    continue
                
                # æ£€æŸ¥æ˜¯å¦éœ€è¦æ›´æ–°å·¥å…·
                time_since_update = (now - snapshot.last_updated).total_seconds()
                if time_since_update >= self.config.tools_update_interval:
                    self.update_queue.add((agent_id, service_name))
                    logger.debug(f"Scheduled content update for {service_name} (last updated {time_since_update:.0f}s ago)")
    
    async def _update_service_content_with_cleanup(self, agent_id: str, service_name: str):
        """å¸¦æ¸…ç†çš„æœåŠ¡å†…å®¹æ›´æ–°"""
        try:
            success = await self._update_service_content(agent_id, service_name)
            if success:
                # é‡ç½®å¤±è´¥è®¡æ•°
                self.failure_counts.pop((agent_id, service_name), None)
            else:
                # å¢åŠ å¤±è´¥è®¡æ•°
                key = (agent_id, service_name)
                self.failure_counts[key] = self.failure_counts.get(key, 0) + 1
        finally:
            self.updating_services.discard((agent_id, service_name))
    
    async def _update_service_content(self, agent_id: str, service_name: str) -> bool:
        """æ›´æ–°æœåŠ¡å†…å®¹ï¼ˆå·¥å…·ã€èµ„æºã€æç¤ºè¯ï¼‰"""
        try:
            # è·å–æœåŠ¡é…ç½®
            service_config = self.orchestrator.mcp_config.get_service_config(service_name)
            if not service_config:
                logger.warning(f"No configuration found for service {service_name}")
                return False
            
            # åˆ›å»ºä¸´æ—¶å®¢æˆ·ç«¯
            user_config = {"mcpServers": {service_name: service_config}}
            fastmcp_config = ConfigProcessor.process_user_config_for_fastmcp(user_config)
            
            if service_name not in fastmcp_config.get("mcpServers", {}):
                logger.warning(f"Service {service_name} not found in processed config")
                return False
            
            client = Client(fastmcp_config)
            
            async with asyncio.timeout(self.config.update_timeout):
                async with client:
                    # è·å–å·¥å…·åˆ—è¡¨
                    tools = await client.list_tools()
                    tools_count = len(tools)
                    tools_hash = self._calculate_tools_hash(tools)
                    
                    # æ£€æŸ¥æ˜¯å¦æœ‰å˜åŒ–
                    current_snapshot = self.get_service_snapshot(agent_id, service_name)
                    if current_snapshot and current_snapshot.tools_hash == tools_hash:
                        # æ²¡æœ‰å˜åŒ–ï¼Œåªæ›´æ–°æ—¶é—´æˆ³
                        current_snapshot.last_updated = datetime.now()
                        logger.debug(f"No content changes detected for {service_name}")
                        return True
                    
                    # æœ‰å˜åŒ–ï¼Œæ›´æ–°ç¼“å­˜
                    await self._update_service_tools_cache(agent_id, service_name, tools)
                    
                    # æ›´æ–°å¿«ç…§
                    new_snapshot = ServiceContentSnapshot(
                        service_name=service_name,
                        agent_id=agent_id,
                        tools_count=tools_count,
                        tools_hash=tools_hash,
                        last_updated=datetime.now()
                    )
                    
                    if agent_id not in self.content_snapshots:
                        self.content_snapshots[agent_id] = {}
                    self.content_snapshots[agent_id][service_name] = new_snapshot
                    
                    logger.info(f"Updated content for {service_name}: {tools_count} tools")
                    return True
                    
        except asyncio.TimeoutError:
            logger.warning(f"Content update timeout for {service_name}")
            return False
        except Exception as e:
            logger.error(f"Failed to update content for {service_name}: {e}")
            return False
    
    def _calculate_tools_hash(self, tools: List[Any]) -> str:
        """è®¡ç®—å·¥å…·åˆ—è¡¨çš„å“ˆå¸Œå€¼"""
        import hashlib

        # æå–å…³é”®ä¿¡æ¯ç”¨äºå“ˆå¸Œè®¡ç®—
        tool_signatures = []
        for tool in tools:
            # å…¼å®¹å­—å…¸å’Œå¯¹è±¡ä¸¤ç§æ ¼å¼
            if hasattr(tool, 'get'):
                # å­—å…¸æ ¼å¼
                name = tool.get('name', '')
                description = tool.get('description', '')
            else:
                # å¯¹è±¡æ ¼å¼ï¼ˆå¦‚FastMCPçš„Toolå¯¹è±¡ï¼‰
                name = getattr(tool, 'name', '')
                description = getattr(tool, 'description', '')

            signature = f"{name}:{description}"
            tool_signatures.append(signature)

        # æ’åºç¡®ä¿ä¸€è‡´æ€§
        tool_signatures.sort()
        content = "|".join(tool_signatures)

        return hashlib.md5(content.encode()).hexdigest()
    
    async def _update_service_tools_cache(self, agent_id: str, service_name: str, tools: List[Any]):
        """æ›´æ–°æœåŠ¡å·¥å…·ç¼“å­˜"""
        if agent_id not in self.registry.tool_cache:
            self.registry.tool_cache[agent_id] = {}
        if agent_id not in self.registry.tool_to_session_map:
            self.registry.tool_to_session_map[agent_id] = {}

        # è·å–æœåŠ¡ä¼šè¯
        service_session = self.registry.sessions.get(agent_id, {}).get(service_name)
        if not service_session:
            logger.warning(f"No session found for service {service_name}")
            return

        # æ¸…ç†æ—§çš„å·¥å…·ç¼“å­˜ï¼ˆåªæ¸…ç†è¯¥æœåŠ¡çš„å·¥å…·ï¼‰
        tools_to_remove = []
        for tool_name, session in self.registry.tool_to_session_map[agent_id].items():
            if session == service_session:
                tools_to_remove.append(tool_name)

        for tool_name in tools_to_remove:
            self.registry.tool_cache[agent_id].pop(tool_name, None)
            self.registry.tool_to_session_map[agent_id].pop(tool_name, None)

        # æ·»åŠ æ–°çš„å·¥å…·ç¼“å­˜
        for tool in tools:
            # å…¼å®¹å­—å…¸å’Œå¯¹è±¡ä¸¤ç§æ ¼å¼
            if hasattr(tool, 'get'):
                # å­—å…¸æ ¼å¼
                tool_name = tool.get("name")
                tool_dict = tool
            else:
                # å¯¹è±¡æ ¼å¼ï¼ˆå¦‚FastMCPçš„Toolå¯¹è±¡ï¼‰
                tool_name = getattr(tool, 'name', None)
                # å°†å¯¹è±¡è½¬æ¢ä¸ºå­—å…¸æ ¼å¼å­˜å‚¨
                tool_dict = {
                    'name': getattr(tool, 'name', ''),
                    'description': getattr(tool, 'description', ''),
                    'inputSchema': getattr(tool, 'inputSchema', {})
                }

            if tool_name:
                self.registry.tool_cache[agent_id][tool_name] = tool_dict
                self.registry.tool_to_session_map[agent_id][tool_name] = service_session

        logger.debug(f"Updated tool cache for {service_name}: {len(tools)} tools")
