import asyncio
import httpx
import feedparser
from datetime import datetime
from typing import List, Dict
from mcp.server.fastmcp import FastMCP

# åˆ›å»º FastMCP å®ä¾‹
mcp = FastMCP("NewsServer")

class NewsFetcher:
    def __init__(self):
        self.client = None
        self.news_sources = {
            "tech": [
                "https://www.ithome.com/rss/",
            ],
            "general": [
                "http://www.people.com.cn/rss/politics.xml"
            ],
            "international": [
                "http://rss.cnn.com/rss/edition.rss",
                "https://feeds.bbci.co.uk/news/world/rss.xml"
            ]
        }

    async def initialize(self):
        """åˆå§‹åŒ–HTTPå®¢æˆ·ç«¯"""
        if self.client is None:
            self.client = httpx.AsyncClient(
                timeout=30.0,
                headers={
                    'User-Agent': 'Mozilla/5.0 (Windows NT 10.0; Win64; x64) AppleWebKit/537.36'
                }
            )
        return True

    async def fetch_hot_news(self, category: str = "general", limit: int = 20) -> List[Dict]:
        """è·å–çƒ­ç‚¹æ–°é—»"""
        await self.initialize()
        news_list = []
        sources = self.news_sources.get(category, self.news_sources["general"])
        
        # å¹¶å‘è·å–æ‰€æœ‰RSSæº
        tasks = [self._fetch_rss_feed(source) for source in sources[:3]]
        results = await asyncio.gather(*tasks, return_exceptions=True)
        
        for result in results:
            if isinstance(result, Exception):
                continue
            news_list.extend(result)

        # å»é‡å’Œæ’åº
        news_list = self._deduplicate_news(news_list)
        news_list.sort(key=lambda x: x.get('time', ''), reverse=True)
        return news_list[:limit]

    async def _fetch_rss_feed(self, rss_url: str) -> List[Dict]:
        """è·å–å•ä¸ªRSSæºçš„å†…å®¹"""
        try:
            response = await self.client.get(rss_url)
            feed = feedparser.parse(response.content)
            news_items = []
            
            for entry in feed.entries[:10]:  # æ¯ä¸ªæºæœ€å¤š10æ¡
                news_item = {
                    'title': entry.title,
                    'url': entry.link,
                    'source': feed.feed.get('title', 'æœªçŸ¥æ¥æº'),
                    'time': self._parse_time(entry.get('published', '')),
                    'summary': entry.get('summary', '')[:200]
                }
                news_items.append(news_item)
            return news_items
        except Exception as e:
            print(f"è·å–RSSæºå¤±è´¥ {rss_url}: {e}")
            return []

    async def search_news(self, keyword: str, limit: int = 10) -> List[Dict]:
        """æœç´¢æ–°é—»"""
        try:
            # å…ˆè·å–ä¸€äº›æ–°é—»ï¼Œç„¶åè¿‡æ»¤
            all_news = await self.fetch_hot_news("general", 50)
            filtered_news = [
                news for news in all_news
                if keyword.lower() in news['title'].lower()
            ]
            return filtered_news[:limit]
        except Exception as e:
            print(f"æœç´¢æ–°é—»å¤±è´¥: {e}")
            return []

    def _parse_time(self, time_str: str) -> str:
        """è§£ææ—¶é—´å­—ç¬¦ä¸²"""
        if not time_str:
            return datetime.now().strftime('%Y-%m-%d %H:%M:%S')
        
        time_formats = [
            '%a, %d %b %Y %H:%M:%S %Z',
            '%a, %d %b %Y %H:%M:%S %z',
            '%Y-%m-%dT%H:%M:%S%z',
            '%Y-%m-%d %H:%M:%S'
        ]
        
        for fmt in time_formats:
            try:
                dt = datetime.strptime(time_str, fmt)
                return dt.strftime('%Y-%m-%d %H:%M:%S')
            except ValueError:
                continue
        return datetime.now().strftime('%Y-%m-%d %H:%M:%S')

    def _deduplicate_news(self, news_list: List[Dict]) -> List[Dict]:
        """å»é‡æ–°é—»"""
        seen_titles = set()
        unique_news = []
        for news in news_list:
            title = news['title'].lower().strip()
            if title not in seen_titles:
                seen_titles.add(title)
                unique_news.append(news)
        return unique_news

    async def close(self):
        """å…³é—­å®¢æˆ·ç«¯"""
        if self.client:
            await self.client.aclose()
            self.client = None

# åˆ›å»ºå…¨å±€å®ä¾‹
news_fetcher = NewsFetcher()

def _format_news(news_list: list) -> str:
    """æ ¼å¼åŒ–æ–°é—»è¾“å‡º"""
    if not news_list:
        return "ğŸ“° æ²¡æœ‰æ‰¾åˆ°ç›¸å…³æ–°é—»"
    
    result = ["ğŸ“° æœ€æ–°æ–°é—»æ‘˜è¦:", ""]
    for i, news in enumerate(news_list, 1):
        result.append(f"{i}. **{news.get('title', 'æ— æ ‡é¢˜')}**")
        if news.get('source'):
            result.append(f"   ğŸ“ æ¥æº: {news['source']}")
        if news.get('time'):
            result.append(f"   â° æ—¶é—´: {news['time']}")
        if news.get('summary'):
            result.append(f"   ğŸ“ æ‘˜è¦: {news['summary']}")
        if news.get('url'):
            result.append(f"   ğŸ”— é“¾æ¥: {news['url']}")
        result.append("")
    
    return "\n".join(result)

@mcp.tool()
async def get_hot_news(category: str = "general", limit: int = 10) -> str:
    """è·å–çƒ­ç‚¹æ–°é—»
    
    Args:
        category: æ–°é—»åˆ†ç±» (general-ç»¼åˆ, tech-ç§‘æŠ€, international-å›½é™…)
        limit: è¿”å›æ–°é—»æ•°é‡ (1-20)
    """
    try:
        # å‚æ•°éªŒè¯
        if limit > 20:
            limit = 20
        if limit < 1:
            limit = 5
            
        valid_categories = ["general", "tech", "international"]
        if category not in valid_categories:
            category = "general"
            
        news_list = await news_fetcher.fetch_hot_news(category, limit)
        return _format_news(news_list)
    except Exception as e:
        return f"âŒ è·å–æ–°é—»å¤±è´¥: {str(e)}"

@mcp.tool()
async def search_news(keyword: str, limit: int = 10) -> str:
    """æœç´¢æ–°é—»
    
    Args:
        keyword: æœç´¢å…³é”®è¯
        limit: è¿”å›ç»“æœæ•°é‡ (1-10)
    """
    try:
        if limit > 10:
            limit = 10
        if limit < 1:
            limit = 5
            
        if not keyword or len(keyword.strip()) == 0:
            return "è¯·è¾“å…¥æœ‰æ•ˆçš„æœç´¢å…³é”®è¯"
            
        news_list = await news_fetcher.search_news(keyword.strip(), limit)
        return _format_news(news_list)
    except Exception as e:
        return f"âŒ æœç´¢æ–°é—»æ—¶å‡ºé”™: {str(e)}"

@mcp.tool()
async def list_news_categories() -> str:
    """åˆ—å‡ºå¯ç”¨çš„æ–°é—»åˆ†ç±»"""
    categories_info = """
ğŸ“Š å¯ç”¨çš„æ–°é—»åˆ†ç±»:

1. **general** - ç»¼åˆæ–°é—» (äººæ°‘ç½‘ç­‰)
2. **tech** - ç§‘æŠ€æ–°é—» (ITä¹‹å®¶ç­‰)  
3. **international** - å›½é™…æ–°é—» (CNNã€BBCç­‰)

ä½¿ç”¨ç¤ºä¾‹: get_hot_news(category="tech", limit=5)
"""
    return categories_info


# def main():
#     """ä¸»å…¥å£å‡½æ•° - è¿™æ˜¯æ‰“åŒ…çš„å…³é”®ï¼"""
#     print("ğŸš€ æ–°é—»MCPæœåŠ¡å™¨å¯åŠ¨ä¸­...")
#     print("ğŸ“‹ å¯ç”¨å·¥å…·:")
#     print("   - get_hot_news: è·å–çƒ­ç‚¹æ–°é—»")
#     print("   - search_news: æœç´¢æ–°é—»") 
#     print("   - list_news_categories: åˆ—å‡ºæ–°é—»åˆ†ç±»")
    
#     # ä½¿ç”¨stdioä¼ è¾“è¿è¡ŒMCPæœåŠ¡å™¨
#     mcp.run(transport="stdio")

if __name__ == "__main__":
    mcp.run(transport="stdio")


# # ç¡®ä¿è„šæœ¬å¯ä»¥ç›´æ¥è¿è¡Œ
# if __name__ == "__main__":
#     main()