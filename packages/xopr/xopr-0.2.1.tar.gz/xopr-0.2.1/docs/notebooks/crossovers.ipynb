{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "dd7e7209",
   "metadata": {},
   "source": [
    "---\n",
    "title: Crossover analysis\n",
    "description: Using xOPR to automatically find radar crossovers\n",
    "date: 2025-09-09\n",
    "---\n",
    "\n",
    "Radar sounder crossover analysis refers to finding crossing points between radar flight lines and analyzing differences between the radar data at the same point. Differences can arise from many factors. Often, crossing flight paths are at (nearly) perpendicular angles. Because the along-track and across-track beamwidth of most radar systems is very different, this different imaging geometry can lead to differences in the radar data. These differences are most pronouned over rough terrain, where off-nadir clutter may show up differently in coicident data collected along different angles. Temporal changes, changes in radar systems, and errors in picking the location of the surface or bed are other sources of differences in crossover analysis.\n",
    "\n",
    "In this notebook, we demonstratate how to automatically find and analyze radar crossovers. To do this, we will\n",
    "\n",
    "1. Find STAC items representing radar data within a geographic region.\n",
    "2. Use the STAC item geometry to identify points where the radar flight paths cross (crossover points).\n",
    "3. Selectively load layer information to make a map of the differences in WGS84 elevation between the bed picks at each crossover point. (This step is parallelized using Dask.)\n",
    "4. Interactively load and plot radar data round selected crossover points to see what's happening."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7bcc6a2e",
   "metadata": {},
   "outputs": [],
   "source": [
    "%load_ext autoreload\n",
    "%autoreload 2\n",
    "\n",
    "import numpy as np\n",
    "import xarray as xr\n",
    "import geoviews as gv\n",
    "import geoviews.feature as gf\n",
    "import cartopy.crs as ccrs\n",
    "import cartopy.io.shapereader as shapereader\n",
    "import matplotlib.pyplot as plt\n",
    "import shapely.geometry\n",
    "import scipy.constants\n",
    "import geopandas as gpd\n",
    "from tqdm import tqdm\n",
    "\n",
    "import requests\n",
    "import time\n",
    "\n",
    "import xopr\n",
    "\n",
    "import holoviews as hv\n",
    "import hvplot.xarray\n",
    "import hvplot.pandas\n",
    "hvplot.extension('bokeh')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e0e44ee5",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Useful background features for maps\n",
    "background_map = gf.ocean.opts(projection=ccrs.SouthPolarStereo(), scale='50m') * gf.coastline.opts(projection=ccrs.SouthPolarStereo(), scale='50m')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bd78bc99",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Establish an OPR session\n",
    "# You'll probably want to set a cache directory if you're running this locally to speed\n",
    "# up subsequent requests. You can do other things like customize the STAC API endpoint,\n",
    "# but you shouldn't need to do that for most use cases.\n",
    "opr = xopr.OPRConnection(cache_dir=\"/tmp\")\n",
    "\n",
    "# Or you can open a connection without a cache directory (for example, if you're parallelizing\n",
    "# this on a cloud cluster without persistent storage).\n",
    "#opr = xopr.OPRConnection()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "226145a0",
   "metadata": {},
   "source": [
    "### Step 1: Finding radar lines\n",
    "\n",
    "For this notebook, we'll experiment with finding data by geographic region. xOPR includes a helper module `xopr.geometry` with some useful utilities. You can call `xopr.geometry.get_antarctic_regions` to select one or more regions from the [MEaSUREs Antarctic Boundaries](https://nsidc.org/data/nsidc-0709/versions/2) dataset. Below, we plot all of the regions to give you some options for what to try. Mouse over each region to see its name."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3319c138",
   "metadata": {},
   "outputs": [],
   "source": [
    "regions_df = xopr.geometry.get_antarctic_regions(merge_regions=False).to_crs('EPSG:3031')\n",
    "regions_df.hvplot(frame_width=600, aspect='equal', hover_cols=['NAME'], c='TYPE')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bd7423a6",
   "metadata": {},
   "source": [
    "For our demonstration, we'll use David Glacier, but feel free to trade this out for other locations and experiment."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "252449c9",
   "metadata": {},
   "outputs": [],
   "source": [
    "region = xopr.geometry.get_antarctic_regions(name=\"David\", merge_regions=True, simplify_tolerance=100)\n",
    "region_projected = xopr.geometry.project_geojson(region, source_crs='EPSG:4326', target_crs=\"EPSG:3031\")\n",
    "\n",
    "region_hv = hv.Polygons([region_projected]).opts(\n",
    "    color='green',\n",
    "    line_color='black',\n",
    "    fill_alpha=0.5)\n",
    "\n",
    "(background_map * region_hv).opts(aspect='equal')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8be63534",
   "metadata": {},
   "outputs": [],
   "source": [
    "stac_items_df = opr.query_frames(geometry=region, date_range=\"2021-01-01T00:00:00Z/2025-06-01T00:00:00Z\") # Can also add a date range: date_range=\"2020-01-01T00:00:00Z/2024-01-01T00:00:00Z\"\n",
    "stac_items_df = stac_items_df.to_crs('EPSG:3031')\n",
    "\n",
    "print(f\"Found {len(stac_items_df)} frames across {stac_items_df['collection'].nunique()} collections:\")\n",
    "stac_items_df.groupby('collection').size()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9654220a",
   "metadata": {},
   "outputs": [],
   "source": [
    "flight_lines = stac_items_df.hvplot(by='collection')\n",
    "(background_map * region_hv * flight_lines).opts(frame_width=500, aspect='equal', active_tools=['pan', 'wheel_zoom'])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "dcd61b86",
   "metadata": {},
   "source": [
    "### Step 2: Identify crossover points\n",
    "\n",
    "xOPR includes a helper function to identify crossover points. Feel free to poke into the code and take a look. It takes advantage of GeoPandas's spatial join (`sjoin`) function, so it's actually quite concise.\n",
    "\n",
    "```{tip} Note about runtimes\n",
    "This notebook can take quite some time to run if you have a lot of crossover points. It's parallelized with dask, so exactly how long will depend on your setup and it should be relatively efficient. If you're here to learn the library and experiment, we recommend limiting your queries to 100 or so intersection points. Some ways that you can limit the number of intersection points include:\n",
    "- Choose a smaller geographic region or limit the date range of your query (above)\n",
    "- Filter the intersections dataframe by the crossing angle -- this will filter out nearly coincident lines which produce a lot of crossovers: `intersections = intersections[intersections['crossing_angle'] > 45]`\n",
    "- Just artificially limit the number of crossovers: `intersections = intersections.iloc[:100]`\n",
    "```"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2c6fa14b",
   "metadata": {},
   "outputs": [],
   "source": [
    "intersections = xopr.find_intersections(stac_items_df, calculate_crossing_angles=True)\n",
    "\n",
    "intersections = intersections[intersections['crossing_angle'] > 2] # Filter out nearly coincident crossings\n",
    "\n",
    "print(f\"Found {len(intersections)} crossover points between flight lines.\")\n",
    "(background_map * region_hv * flight_lines * intersections.hvplot(label='Intersection Points', c='crossing_angle')).opts(frame_width=500, aspect='equal', active_tools=['pan', 'wheel_zoom'])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "91aec159",
   "metadata": {},
   "source": [
    "Zoom in and check out the plot above. Every identified crossover point has a blue dot over it. The blue dots are shaded by the crossing angle. You'll see that nearly coincident lines will have a large number of low crossing angles wheras most other crossovers are at angles closer to 90 degrees.\n",
    "\n",
    "The cell below shows you what the result of `xopr.find_intersections()` looks like. It returns a GeoDataFrame where every column from the intersecting frames is preserved, with suffixes _1 and _2 to distinguish them."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "966ad78c",
   "metadata": {},
   "outputs": [],
   "source": [
    "intersections.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "101c983e",
   "metadata": {},
   "source": [
    "### Step 3: Load layer data and find the different in bed elevation\n",
    "\n",
    "Depending on how many intersection points you have, loading all of the layer data associated with each crossover may take quite some time. Luckily, this process can be parallelized fairly efficiently, so we'll use Dask to make this run a bit faster. Take a look at the \"Search and Scaling\" notebook for some tips on working with Dask.\n",
    "\n",
    "This is a good time to check that you have a reasonable number of intersection points if you've modified anything. We recommend starting with about 100 or fewer intersection points so that this won't take more than about 5 minutes to run."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "59c1a9ed",
   "metadata": {},
   "outputs": [],
   "source": [
    "import dask\n",
    "import dask.delayed as delayed\n",
    "from dask import compute\n",
    "from dask.distributed import LocalCluster\n",
    "\n",
    "client = LocalCluster().get_client()\n",
    "client"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d2c38687",
   "metadata": {},
   "source": [
    "By default, Dask will start a server at `http://127.0.0.1:8787/status`. If it can't use that port for some reason, the cell above should print out an alternative port. Visiting this status page is optional, but it will tell you about the progress of your job."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "94361c78",
   "metadata": {},
   "outputs": [],
   "source": [
    "@delayed\n",
    "def safe_get_layers_db(stac_item, opr=xopr.opr_access.OPRConnection()):\n",
    "    try:\n",
    "        retries = 1\n",
    "        backoff_time = 5\n",
    "        backoff_jitter = 30\n",
    "        while retries > 0:\n",
    "            try:\n",
    "                return opr.get_layers_db(stac_item)\n",
    "            except requests.exceptions.RequestException as e:\n",
    "                sleep_time = backoff_time + np.random.uniform(0, backoff_jitter)\n",
    "                print(f\"Request error fetching layers for {stac_item['id']}: {e}. Retrying in {sleep_time:.1f} seconds...\")\n",
    "                time.sleep(sleep_time)\n",
    "                retries -= 1\n",
    "                backoff_time *= 2  # Exponential backoff\n",
    "    except Exception as e:\n",
    "        print(f\"Error fetching layers for {stac_item['id']}: {e}\")\n",
    "        return None\n",
    "\n",
    "def get_basal_layer_wgs84(stac_item, preloaded_layer=None, opr=xopr.opr_access.OPRConnection()):\n",
    "    if (preloaded_layer is None) or len(preloaded_layer) < 2:\n",
    "        layers = opr.get_layers_files(stac_item)\n",
    "    else:\n",
    "        layers = preloaded_layer\n",
    "    \n",
    "    basal_layer = layers[2]\n",
    "    surface_layer = layers[1]\n",
    "\n",
    "    surface_wgs84 = layers[1]['elev'] - (layers[1]['twtt'] * (scipy.constants.c / 2))\n",
    "    delta_twtt = basal_layer['twtt'] - surface_layer['twtt']\n",
    "    basal_wgs84 = surface_wgs84 - (delta_twtt * ((scipy.constants.c / np.sqrt(3.15)) / 2))\n",
    "\n",
    "    basal_layer['wgs84'] = basal_wgs84\n",
    "    return basal_layer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d5119796",
   "metadata": {},
   "outputs": [],
   "source": [
    "@delayed\n",
    "def compute_crossover_error_impl(stac_item_1, stac_item_2, intersection_geometry, layer_1, layer_2):\n",
    "    \"\"\"Implementation that receives actual layer values\"\"\"\n",
    "    try:\n",
    "        bed_1 = get_basal_layer_wgs84(stac_item_1, preloaded_layer=layer_1).rename({'lat': 'Latitude', 'lon': 'Longitude'})\n",
    "        bed_2 = get_basal_layer_wgs84(stac_item_2, preloaded_layer=layer_2).rename({'lat': 'Latitude', 'lon': 'Longitude'})\n",
    "\n",
    "        bed_1 = xopr.geometry.project_dataset(bed_1, \"EPSG:3031\")\n",
    "        bed_2 = xopr.geometry.project_dataset(bed_2, \"EPSG:3031\")\n",
    "\n",
    "        x, y = intersection_geometry.coords[0]\n",
    "\n",
    "        dist_1 = np.sqrt((bed_1['x'] - x)**2 + (bed_1['y'] - y)**2)\n",
    "        dist_2 = np.sqrt((bed_2['x'] - x)**2 + (bed_2['y'] - y)**2)\n",
    "\n",
    "        min_idx_1 = dist_1.argmin().item()\n",
    "        min_idx_2 = dist_2.argmin().item()\n",
    "\n",
    "        dist_between_pts = np.sqrt((bed_1['x'][min_idx_1] - bed_2['x'][min_idx_2])**2 + (bed_1['y'][min_idx_1] - bed_2['y'][min_idx_2])**2)\n",
    "\n",
    "        elev_1 = bed_1['wgs84'][min_idx_1].item()\n",
    "        elev_2 = bed_2['wgs84'][min_idx_2].item()\n",
    "\n",
    "        return elev_1, elev_2, dist_between_pts\n",
    "    except Exception as e:\n",
    "        print(f\"Error in compute_crossover_error: {e}\")\n",
    "        return None, None, None  # Return sentinel values on error\n",
    "\n",
    "def compute_crossover_error(stac_item_1, stac_item_2, intersection_geometry, preloaded_layer_1=None, preloaded_layer_2=None):\n",
    "    \"\"\"Wrapper that handles delayed objects properly\"\"\"\n",
    "    # These will be delayed objects or None\n",
    "    return compute_crossover_error_impl(stac_item_1, stac_item_2, intersection_geometry, preloaded_layer_1, preloaded_layer_2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c0326cca",
   "metadata": {},
   "outputs": [],
   "source": [
    "future_db_layers = {}\n",
    "future_results = {}\n",
    "for idx, row in intersections.iterrows():\n",
    "    stac_item_1 = stac_items_df.loc[row['id_1']].to_dict()\n",
    "    stac_item_2 = stac_items_df.loc[row['id_2']].to_dict()\n",
    "    stac_item_1['id'] = row['id_1']\n",
    "    stac_item_2['id'] = row['id_2']\n",
    "\n",
    "    # Fetch the layers from the database if available\n",
    "    db_key_1 = (row['collection_1'], row['opr:date_1'], row['opr:flight_1'])\n",
    "    db_key_2 = (row['collection_2'], row['opr:date_2'], row['opr:flight_2'])\n",
    "    if db_key_1 not in future_db_layers:\n",
    "        future_db_layers[db_key_1] = safe_get_layers_db(stac_item_1)\n",
    "    if db_key_2 not in future_db_layers:\n",
    "        future_db_layers[db_key_2] = safe_get_layers_db(stac_item_2)\n",
    "\n",
    "    # Create delayed task but DON'T compute yet\n",
    "    r = compute_crossover_error(\n",
    "        stac_item_1, stac_item_2, row.intersection_geometry,\n",
    "        preloaded_layer_1=future_db_layers.get(db_key_1),\n",
    "        preloaded_layer_2=future_db_layers.get(db_key_2)\n",
    "    )\n",
    "    future_results[idx] = r  # Store the delayed object, not the computed result"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fcc54f36",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Compute all results in parallel\n",
    "results = compute(*future_results.values())\n",
    "\n",
    "# Process the results\n",
    "for idx, result in zip(future_results.keys(), results):\n",
    "    try:\n",
    "        elev_1, elev_2, dist_between_pts = result\n",
    "        if elev_1 is not None and elev_2 is not None:  # Skip failed computations\n",
    "            intersections.at[idx, 'wgs84_1'] = elev_1\n",
    "            intersections.at[idx, 'wgs84_2'] = elev_2\n",
    "            intersections.at[idx, 'layer_pt_distance'] = dist_between_pts\n",
    "        else:\n",
    "            print(f\"Skipping intersection {idx} due to computation error\")\n",
    "    except Exception as e:\n",
    "        print(f\"Error processing intersection {idx}: {repr(e)}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bd589283",
   "metadata": {},
   "source": [
    "We now have all of our crossovers. Don't worry about a few errors in the cell above. This is normal as it tries to load layer data from both possible sources (files and database)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "114b3795",
   "metadata": {},
   "outputs": [],
   "source": [
    "intersections['elev_diff'] = np.abs(intersections['wgs84_1'] - intersections['wgs84_2'])\n",
    "# Set elev_diff to NaN where layer_pt_distance is large\n",
    "intersections.loc[intersections['layer_pt_distance'] > 100, 'elev_diff'] = np.nan"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "85dbbc60",
   "metadata": {},
   "outputs": [],
   "source": [
    "intersections_success = intersections.dropna().reset_index(drop=True)\n",
    "intersections_success['intersection_geometry_x'] = intersections_success['intersection_geometry'].apply(lambda geom: geom.x)\n",
    "intersections_success = intersections_success.sort_values(by='intersection_geometry_x', ascending=False).reset_index(drop=True)\n",
    "intersections_success['idx'] = intersections_success.index\n",
    "hover_tooltips = [\n",
    "    (\"Index\", \"@idx\"),\n",
    "    (\"Collection 1\", \"@collection_1\"),\n",
    "    (\"Collection 2\", \"@collection_2\"),\n",
    "    (\"Difference\", \"@elev_diff{0.00} m\"),\n",
    "]\n",
    "\n",
    "vlim = intersections_success['elev_diff'].abs().quantile(0.9)\n",
    "\n",
    "hv_int = intersections_success.hvplot(color='elev_diff', hover_cols=['idx', 'collection_1', 'collection_2', 'elev_diff'], hover_tooltips=hover_tooltips, clim=(0, vlim))\n",
    "#hv_int = hv_int.opts(scalebar=True) # Can enable if you want - requires hvplot >= 0.12.0\n",
    "(background_map * region_hv * flight_lines * hv_int).opts(frame_width=600, aspect='equal', active_tools=['pan', 'wheel_zoom'])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "883521b0",
   "metadata": {},
   "source": [
    "This map shows the differences in picked bed elevation at every crossing point where layer data was available. Explore around and see what you notice!"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ac87a4ce",
   "metadata": {},
   "source": [
    "### Step 4: Investigate individual crossovers by looking at the radar data\n",
    "\n",
    "If you hover over any crossover point in the map above, you'll get the index associated with each crossover. Enter one of those indices below to load and plot the corresponding radar data to see what's happening."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "222fc910",
   "metadata": {},
   "outputs": [],
   "source": [
    "selected_idx = 4"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "138fabb2",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Get intersection details\n",
    "intersect = intersections_success.loc[selected_idx]\n",
    "stac_1 = stac_items_df.loc[intersect['id_1']].to_dict()\n",
    "stac_2 = stac_items_df.loc[intersect['id_2']].to_dict()\n",
    "\n",
    "# Load frames\n",
    "frame_1 = opr.load_frame(stac_1)\n",
    "frame_1 = xopr.radar_util.add_along_track(frame_1)\n",
    "frame_1 = xopr.radar_util.interpolate_to_vertical_grid(frame_1, vertical_coordinate='wgs84')\n",
    "frame_2 = opr.load_frame(stac_2)\n",
    "frame_2 = xopr.radar_util.add_along_track(frame_2)\n",
    "frame_2 = xopr.radar_util.interpolate_to_vertical_grid(frame_2, vertical_coordinate='wgs84')\n",
    "\n",
    "# Project to EPSG:3031 and find closest points to intersection\n",
    "x_int, y_int = intersect.intersection_geometry.coords[0]\n",
    "frame_1_proj = xopr.geometry.project_dataset(frame_1, \"EPSG:3031\")\n",
    "frame_2_proj = xopr.geometry.project_dataset(frame_2, \"EPSG:3031\")\n",
    "\n",
    "# Find indices closest to intersection\n",
    "dist_1 = np.sqrt((frame_1_proj['x'] - x_int)**2 + (frame_1_proj['y'] - y_int)**2)\n",
    "dist_2 = np.sqrt((frame_2_proj['x'] - x_int)**2 + (frame_2_proj['y'] - y_int)**2)\n",
    "idx_1 = dist_1.argmin().item()\n",
    "idx_2 = dist_2.argmin().item()\n",
    "\n",
    "print(f\"Frame 1: {intersect['id_1']} from {intersect['collection_1']}\")\n",
    "print(f\"Frame 2: {intersect['id_2']} from {intersect['collection_2']}\")\n",
    "print(f\"Intersection at index {idx_1} (frame 1) and {idx_2} (frame 2)\")\n",
    "print(f\"Bed elevation difference: {intersect['elev_diff']:.2f} m\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "acee0a94",
   "metadata": {},
   "outputs": [],
   "source": [
    "def add_layers_to_frame(frame):\n",
    "    speed_in_ice = scipy.constants.c / np.sqrt(3.15)  # Approximate speed of light in ice (m/s)\n",
    "\n",
    "    layers = opr.get_layers(frame)\n",
    "    if len(layers) == 0:\n",
    "        print(f\"No layers found for granule {frame.attrs['granule']}\")\n",
    "        return frame\n",
    "    \n",
    "    has_surface = False\n",
    "\n",
    "    for layer_idx in layers:\n",
    "        frame[f'layer_{layer_idx}_twtt'] = layers[layer_idx]['twtt'].interp(coords={'slow_time': frame['slow_time']})\n",
    "\n",
    "        if layer_idx == 1:\n",
    "            has_surface = True\n",
    "            frame[f'layer_{layer_idx}_range'] = frame['layer_1_twtt'] * (scipy.constants.c / 2)\n",
    "            frame[f'layer_{layer_idx}_elevation'] = frame['Elevation'] - frame[f'layer_1_range']\n",
    "        elif has_surface:\n",
    "            twtt_from_surface = frame[f'layer_{layer_idx}_twtt'] - frame['layer_1_twtt']\n",
    "            frame[f'layer_{layer_idx}_range'] = (twtt_from_surface * (speed_in_ice / 2)) + frame['layer_1_range']\n",
    "            frame[f'layer_{layer_idx}_elevation'] = frame['Elevation'] - frame[f'layer_{layer_idx}_range']\n",
    "\n",
    "    return frame\n",
    "\n",
    "# Load layers for both frames\n",
    "frame_1 = add_layers_to_frame(frame_1)\n",
    "frame_2 = add_layers_to_frame(frame_2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "562zxg8hdzl",
   "metadata": {},
   "outputs": [],
   "source": [
    "clb_min_pct, clb_max_pct = 30, 97\n",
    "\n",
    "# Plot radargrams in elevation coordinates with layers\n",
    "fig, (ax1, ax2) = plt.subplots(2, 1, figsize=(15, 8))\n",
    "\n",
    "# Frame 1 radargram in elevation\n",
    "pwr_1_elev = 10*np.log10(np.abs(frame_1.Data))\n",
    "vmax_1 = np.percentile(pwr_1_elev, clb_max_pct)\n",
    "vmin_1 = np.percentile(pwr_1_elev, clb_min_pct)\n",
    "pwr_1_elev.plot.imshow(x='along_track', y='wgs84', cmap='gray', ax=ax1, vmin=vmin_1, vmax=vmax_1)\n",
    "ax1.axvline(frame_1.along_track[idx_1].values, color='red', linestyle='--', linewidth=2, label='Crossover')\n",
    "\n",
    "# Plot layers using elevation data\n",
    "if 'layer_1_elevation' in frame_1:\n",
    "    frame_1['layer_1_elevation'].plot(ax=ax1, x='along_track', linestyle=':', color='tab:blue', linewidth=2, label='Surface')\n",
    "if 'layer_2_elevation' in frame_1:\n",
    "    frame_1['layer_2_elevation'].plot(ax=ax1, x='along_track', linestyle=':', color='tab:orange', linewidth=2, label='Bed')\n",
    "\n",
    "ax1.set_title(f\"{intersect['collection_1']} - {intersect['id_1']} (Elevation view)\")\n",
    "ax1.set_ylabel('Elevation (m)')\n",
    "ax1.legend()\n",
    "\n",
    "# Frame 2 radargram in elevation\n",
    "pwr_2_elev = 10*np.log10(np.abs(frame_2.Data))\n",
    "vmax_2 = np.percentile(pwr_2_elev, clb_max_pct)\n",
    "vmin_2 = np.percentile(pwr_2_elev, clb_min_pct)\n",
    "pwr_2_elev.plot.imshow(x='along_track', y='wgs84', cmap='gray', ax=ax2, vmin=vmin_2, vmax=vmax_2)\n",
    "ax2.axvline(frame_2.along_track[idx_2].values, color='red', linestyle='--', linewidth=2, label='Crossover')\n",
    "\n",
    "# Plot layers using elevation data\n",
    "if 'layer_1_elevation' in frame_2:\n",
    "    frame_2['layer_1_elevation'].plot(ax=ax2, x='along_track', linestyle=':', color='tab:blue', linewidth=2, label='Surface')\n",
    "if 'layer_2_elevation' in frame_2:\n",
    "    frame_2['layer_2_elevation'].plot(ax=ax2, x='along_track', linestyle=':', color='tab:orange', linewidth=2, label='Bed')\n",
    "\n",
    "ax2.set_title(f\"{intersect['collection_2']} - {intersect['id_2']} (Elevation view)\")\n",
    "ax2.set_xlabel('Along track distance (m)')\n",
    "ax2.set_ylabel('Elevation (m)')\n",
    "ax2.legend()\n",
    "\n",
    "plt.suptitle(f\"Radargrams in elevation coordinates - Bed elev diff: {intersect['elev_diff']:.2f} m\", fontsize=14)\n",
    "plt.tight_layout()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "sucnjg98mmc",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Zoomed elevation plots around crossover\n",
    "fig, (ax1, ax2) = plt.subplots(2, 1, figsize=(15, 8))\n",
    "\n",
    "window_size = 300  # Number of traces on each side of intersection\n",
    "elev_window = np.maximum(intersect['elev_diff']*2.5, 100)  # Elevation window in meters around bed\n",
    "\n",
    "# Frame 1 zoomed\n",
    "idx_start_1 = max(0, idx_1 - window_size)\n",
    "idx_end_1 = min(len(frame_1.slow_time), idx_1 + window_size)\n",
    "\n",
    "pwr_1_zoom = frame_1.Data.isel(slow_time=slice(idx_start_1, idx_end_1))\n",
    "pwr_1_zoom_db = 10*np.log10(np.abs(pwr_1_zoom))\n",
    "pwr_1_zoom_db.plot.imshow(x='along_track', y='wgs84', cmap='gray', ax=ax1, vmin=vmin_1, vmax=vmax_1)\n",
    "ax1.axvline(frame_1.along_track[idx_1].values, color='red', linestyle='--', linewidth=2, label='Crossover')\n",
    "\n",
    "# Plot layers\n",
    "if 'layer_1_elevation' in frame_1:\n",
    "    layer_1_zoom = frame_1['layer_1_elevation'].isel(slow_time=slice(idx_start_1, idx_end_1))\n",
    "    layer_1_zoom.plot.scatter(ax=ax1, x='along_track', linestyle=':', color='tab:blue', linewidth=2, label='Surface', s=4)\n",
    "if 'layer_2_elevation' in frame_1:\n",
    "    layer_2_zoom = frame_1['layer_2_elevation'].isel(slow_time=slice(idx_start_1, idx_end_1))\n",
    "    layer_2_zoom.plot.scatter(ax=ax1, x='along_track', linestyle=':', color='tab:orange', linewidth=2, label='Bed', s=4)\n",
    "\n",
    "    bed_elev_1 = frame_1['layer_2_elevation'].isel(slow_time=idx_1).values\n",
    "    elev_min_1 = bed_elev_1 - elev_window/2\n",
    "    elev_max_1 = bed_elev_1 + elev_window/2\n",
    "    ax1.set_ylim(elev_min_1, elev_max_1)\n",
    "ax1.set_title(f\"{intersect['collection_1']} - Zoomed (Bed: {intersect['wgs84_1']:.1f} m)\")\n",
    "ax1.set_ylabel('Elevation (m)')\n",
    "ax1.legend()\n",
    "\n",
    "# Frame 2 zoomed\n",
    "idx_start_2 = max(0, idx_2 - window_size)\n",
    "idx_end_2 = min(len(frame_2.slow_time), idx_2 + window_size)\n",
    "\n",
    "pwr_2_zoom = frame_2.Data.isel(slow_time=slice(idx_start_2, idx_end_2))\n",
    "pwr_2_zoom_db = 10*np.log10(np.abs(pwr_2_zoom))\n",
    "pwr_2_zoom_db.plot.imshow(x='along_track', y='wgs84', cmap='gray', ax=ax2, vmin=vmin_2, vmax=vmax_2)\n",
    "ax2.axvline(frame_2.along_track[idx_2].values, color='red', linestyle='--', linewidth=2, label='Crossover')\n",
    "\n",
    "# Plot layers\n",
    "if 'layer_1_elevation' in frame_2:\n",
    "    layer_1_zoom = frame_2['layer_1_elevation'].isel(slow_time=slice(idx_start_2, idx_end_2))\n",
    "    layer_1_zoom.plot.scatter(ax=ax2, x='along_track', linestyle=':', color='tab:blue', linewidth=2, label='Surface', s=4)\n",
    "if 'layer_2_elevation' in frame_2:\n",
    "    layer_2_zoom = frame_2['layer_2_elevation'].isel(slow_time=slice(idx_start_2, idx_end_2))\n",
    "    layer_2_zoom.plot.scatter(ax=ax2, x='along_track', linestyle=':', color='tab:orange', linewidth=2, label='Bed', s=4)\n",
    "\n",
    "    bed_elev_2 = frame_2['layer_2_elevation'].isel(slow_time=idx_2).values\n",
    "    elev_min_2 = bed_elev_2 - elev_window/2\n",
    "    elev_max_2 = bed_elev_2 + elev_window/2\n",
    "    \n",
    "    ax2.set_ylim(elev_min_2, elev_max_2)\n",
    "ax2.set_title(f\"{intersect['collection_2']} - Zoomed (Bed: {intersect['wgs84_2']:.1f} m)\")\n",
    "ax2.set_xlabel('Along track distance (m)')\n",
    "ax2.set_ylabel('Elevation (m)')\n",
    "ax2.legend()\n",
    "\n",
    "plt.suptitle(f\"Elevation crossover comparison - Bed difference: {intersect['elev_diff']:.2f} m\", fontsize=14)\n",
    "plt.tight_layout()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4864be39",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "xopr",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
