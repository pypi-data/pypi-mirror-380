# Performance Improvement Backlog

## Critical Performance Issues (Production)

### Issue #1: 5+ Minute Report Generation Delay ‚ö†Ô∏è CRITICAL
**Severity**: Critical
**Impact**: Every `/invest:research-stock` request
**Timeline**: Observed in NVDA research execution

**Problem**:
- Report generation takes 5+ minutes (00:10:13 ‚Üí 00:15:35)
- No user feedback during this time
- Appears to be "hanging"

**Root Cause**:
- Main agent generating massive report in single operation
- Likely hitting token limits, requiring re-processing
- No streaming output

**Solution**:
- [ ] Implement streaming report generation (section by section)
- [ ] Add progress indicators during generation
- [ ] Break report into smaller chunks
- [ ] Consider template-based approach for consistent structure

**Priority**: P0 - Fix immediately
**Estimated effort**: 3 days

---

### Issue #2: Duplicate MCP Tool Calls (70% Waste) ‚ö†Ô∏è HIGH
**Severity**: High
**Impact**: Every multi-agent workflow
**Cost**: 3-4x redundant API calls

**Problem**:
```
Tool                      | Calls | Wasted
-------------------------|-------|--------
get_company_profile      | 4     | 3
get_company_financials   | 3     | 2
get_analyst_ratings      | 3     | 2
analyze_stock            | 3     | 2
```

**Root Cause**:
- No session-level caching
- Each agent makes independent tool calls
- No shared context between agents

**Solution**:
- [x] Create `SessionCache` class (implemented in `cache_manager.py`)
- [ ] Integrate caching into `InteractiveChat`
- [ ] Add cache statistics display
- [ ] Monitor cache hit rate (target: >80%)

**Priority**: P0 - Fix immediately
**Estimated effort**: 2 days

---

### Issue #3: Sequential Tool Execution (Slow)
**Severity**: Medium
**Impact**: Agent execution time
**Delay**: 2-3x slower than necessary

**Problem**:
- Agents make tool calls one at a time
- Not leveraging async/await for parallelism
- Could batch multiple calls

**Root Cause**:
- Claude SDK executes tool calls as they come
- No explicit batching in agent prompts

**Solution**:
- [ ] Update agent system prompts to encourage batching
- [ ] Pre-fetch all data before launching agents
- [ ] Use `asyncio.gather()` for parallel execution

**Priority**: P1 - Important
**Estimated effort**: 3 days

---

### Issue #4: No Progress Indicators
**Severity**: Medium
**Impact**: User experience
**Perception**: System appears frozen

**Problem**:
- 3+ minute gaps with no output
- User can't tell if system is working
- No way to estimate completion time

**Root Cause**:
- No status updates during long operations
- Missing progress tracking

**Solution**:
- [x] Add progress bars for long operations (v1.4.4)
- [x] Stream status updates every 30 seconds (v1.4.4)
- [x] Show "Still working..." messages (v1.4.4)
- [ ] Display estimated time remaining

**Status**: ‚úÖ Mostly Complete (v1.4.4)
**Priority**: P1 - Important
**Estimated effort**: 2 days

---

### Issue #5: Permission System Blocking File Operations ‚úÖ RESOLVED
**Severity**: Critical
**Impact**: Every workflow that writes files
**Timeline**: Observed in v1.4.4, Fixed in v1.4.5

**Problem**:
- File creation operations taking 7+ minutes (00:32:50 ‚Üí 00:39:31)
- Multiple failed Write attempts requiring fallback methods
- Permission prompts causing retry loops
- Bash heredoc and Python fallbacks still slow

**Evidence from v1.4.4 Execution**:
```
00:32:51 - First Write attempt ‚Üí fails
00:35:11 - Second Write to /tmp/workspace ‚Üí fails
00:36:30 - Bash cat heredoc attempt ‚Üí fails
00:38:44 - Python script attempt (2 min delay!)
00:39:31 - Still attempting file creation
```

**Root Cause**:
1. `can_use_tool` callback was provided even in `acceptEdits` mode
2. This overrode SDK's automatic approval of file operations
3. Permission handler was being called unnecessarily for Write/Edit/MultiEdit

**Solution Implemented** (v1.4.5):
- [x] Fixed callback condition to exclude `acceptEdits` and `bypassPermissions` modes
- [x] Added defense-in-depth fast-path in permission handler
- [x] Added permission performance tracking (checks count, time spent)
- [x] Display permission metrics in `/perf` command
- [x] Created comprehensive test suite (all tests passing)

**Code Changes**:
```python
# Before (v1.4.4) - BUG
can_use_tool=self._handle_tool_permission if self.interactive_permissions else None

# After (v1.4.5) - FIXED
should_use_permission_callback = (
    self.interactive_permissions and
    self.permission_mode not in ['acceptEdits', 'bypassPermissions']
)
can_use_tool=self._handle_tool_permission if should_use_permission_callback else None
```

**Testing**:
- ‚úÖ Test 1: acceptEdits mode doesn't use callback
- ‚úÖ Test 2: default mode uses callback when interactive=True
- ‚úÖ Test 3: bypassPermissions doesn't use callback
- ‚úÖ Test 4: interactive=False disables callback

**Impact**:
- **Fixed**: 7+ minute regression eliminated
- File operations now instant in acceptEdits mode
- Workflow performance restored to expected ~3 minutes
- All v1.4.3 and v1.4.4 improvements now working as intended

**Status**: ‚úÖ Resolved in v1.4.5
**Released**: 2025-10-01

---

### Issue #6: /perf and /cache Commands Not Displaying Output ‚úÖ RESOLVED
**Severity**: High
**Impact**: Performance monitoring and debugging
**Timeline**: Observed in v1.4.5 production, Fixed in v1.4.6

**Problem**:
- `/perf` command executes but shows no output (Duration: 17ms)
- `/cache` command executes but shows no output (Duration: 13ms)
- Both commands connect to Claude but don't display metrics panels
- Users cannot see cache hit rates or performance statistics

**Evidence from v1.4.5 Execution**:
```
[Navam] > /perf
You (Turn 4): /perf
‚úÖ Claude SDK Client connected (Turn 4)
üéØ Query completed (Turn 4)
‚è±Ô∏è  Duration: 17ms
[No output displayed]

[Navam] > /cache
You (Turn 5): /cache
‚úÖ Claude SDK Client connected (Turn 5)
üéØ Query completed (Turn 5)
‚è±Ô∏è  Duration: 13ms
[No output displayed]
```

**Root Cause**:
Commands `/cache` and `/perf` were NOT in the `builtin_commands` set in `_is_builtin_command()` method:
```python
# Line 1287-1292 in chat.py (v1.4.5) - THE BUG
builtin_commands = {
    '/help', '/api', '/agents', '/status', '/commands', '/new', '/tools', '/servers',
    '/clear', '/exit', '/quit', '/q'
    # Missing: '/cache', '/perf', '/performance'
}
```

This caused the commands to fall through to `process_query()` and be sent to Claude API instead of being handled locally.

**Solution Implemented** (v1.4.6):
- [x] Added `/cache`, `/perf`, and `/performance` to builtin_commands set
- [x] Fixed early return in `_show_performance_summary()` to show informative message
- [x] Added commands to `/commands` list for discoverability
- [x] Tested command detection (all tests passing)

**Code Changes**:
```python
# After (v1.4.6) - FIXED
builtin_commands = {
    '/help', '/api', '/agents', '/status', '/commands', '/new', '/tools', '/servers',
    '/clear', '/exit', '/quit', '/q', '/cache', '/perf', '/performance'
}
```

Also improved `_show_performance_summary()`:
```python
# Before (v1.4.5) - Silent failure
if not self.performance_metrics['workflow_start']:
    return  # Returns with no output

# After (v1.4.6) - Friendly message
if not self.performance_metrics['workflow_start']:
    perf_text += "[yellow]No workflow activity recorded yet.[/yellow]\n\n"
    perf_text += "[dim]Performance metrics will be tracked once you start using the system.[/dim]\n"
    self.console.print(Panel(perf_text, title="Performance Metrics", border_style="green"))
    return
```

**Testing**:
```bash
‚úÖ PASS: /cache -> builtin=True
‚úÖ PASS: /perf -> builtin=True
‚úÖ PASS: /performance -> builtin=True
‚úÖ PASS: /help -> builtin=True
‚úÖ PASS: /agents -> builtin=True
‚úÖ PASS: /unknown -> builtin=False
```

**Impact**:
- `/cache` and `/perf` commands now display metrics properly
- Users can monitor cache hit rates and performance statistics
- Better debugging and performance optimization experience
- Commands appear in `/commands` list for easy discovery

**Status**: ‚úÖ Resolved in v1.4.6
**Released**: 2025-10-01

**Priority**: P1 - High (affects debugging and monitoring)
**Estimated effort**: 1 day (actual: completed same day)

---

### Issue #7: File Write Operations Still Slow (2m 45s) üîç INVESTIGATING
**Severity**: Medium
**Impact**: Report generation workflows
**Timeline**: Observed in v1.4.5 production, Investigating in v1.4.7

**Problem**:
- Write to `/tmp/` directory: instant (00:59:10) ‚úÖ
- Write to `reports/` directory: 2m 45s delay (00:59:13 ‚Üí 01:01:58) ‚ùå
- Inconsistent behavior between different paths
- Still significant delay despite v1.4.5 permission fix

**Evidence from v1.4.5 Execution**:
```
00:59:10 - Write to /tmp/amazon_investment_report.md - instant ‚úÖ
00:59:13 - Check pwd command - instant ‚úÖ
01:01:58 - Write to reports/AMZN_Investment_Research_2025-10-01.md - 2m 45s delay ‚ùå
```

**Investigation Results** (v1.4.7):

1. **Python File I/O Test** - ‚úÖ NOT the bottleneck
   ```python
   Test 1: Write to /tmp - 0.0004s ‚úÖ
   Test 2: Write to reports/ - 0.0001s ‚úÖ
   Test 3: Large file (1.4MB) to reports/ - 0.0005s ‚úÖ
   ```
   Conclusion: Python file operations are instant for both /tmp and reports/ directories.

2. **Added Detailed Timing Instrumentation** (chat.py):
   - Store tool start time with tool_use_id for accurate duration tracking
   - Log completion time for all Write operations
   - Warn if Write takes > 5 seconds
   - Show status if Write takes > 1 second
   - DEBUG logging if permission handler unexpectedly called for Write

3. **Permission Mode Verification**:
   - Default permission_mode: `acceptEdits` (cli.py:28)
   - Should auto-approve Write/Edit/MultiEdit operations
   - Permission callback should NOT be provided in acceptEdits mode (v1.4.5 fix)

**Root Cause Hypothesis** (Updated):
The delay is NOT in Python file I/O. The bottleneck must be in:
1. **Claude Code SDK Write tool execution** - Something in the SDK pipeline
2. **Network latency** - If SDK is making network calls during Write
3. **File path resolution** - SDK may be doing slow path operations
4. **Tool result processing** - Delay in receiving/processing ToolResultBlock

**Production Test Results** (v1.4.7 - META research):

**CRITICAL FINDING #1: Write timing instrumentation not executing**
- No timing logs displayed despite Write operations completing
- No warnings for slow operations (> 5s threshold)
- No DEBUG logs for permission handler calls
- **Root Cause**: Timing code may not be in the execution path, or logs suppressed

**CRITICAL FINDING #2: Timing shows delay is BEFORE Write tool execution**
```
01:28:48 - Write tool execution starts (to /tmp)
01:33:28 - Write tool notification displayed (4m 40s gap!)
01:33:32 - Response continues (tool completed)

01:33:33 - pwd command (instant)
01:37:24 - Write tool execution starts (to reports/)
01:37:38 - Write tool notification + completion (14s total)
```

**Analysis**:
- The delay is NOT in the Write tool itself (tool completes in seconds)
- The delay is in the ~4-5 minute gap BEFORE the Write tool is called
- This suggests Claude is generating/thinking for 4-5 minutes before writing
- The 4,800 word report generation is happening during this "thinking" time

**CRITICAL FINDING #3: Cache and performance metrics not tracking**
- `/cache` shows 0 tool calls despite 20+ MCP calls
- `/perf` shows "No workflow activity recorded yet"
- Cache hit rate: 0.0%
- **Root Cause**: Metrics not being tracked for MCP tool calls through agents

**Changes Made** (v1.4.7):
```python
# chat.py - Track tool execution timing
self._tool_timings[block.id] = {
    'tool_name': tool_name,
    'start_time': tool_start_time,
    'tool_input': block.input
}

# chat.py - Log Write timing on completion
if tool_name == "Write" and 'file_path' in tool_input:
    duration = time.time() - timing_info['start_time']
    if duration > 5.0:
        self.notifications.show_warning(f"‚ö†Ô∏è  SLOW Write: {file_path} - {duration:.2f}s")
```

**Revised Root Cause** (v1.4.7 production test):
The "slow Write" is actually **slow report generation by Claude** before calling Write:
1. Claude spends 4-5 minutes generating the 4,800 word report in memory
2. Once generated, Write tool executes instantly (< 15 seconds)
3. The problem is NOT file I/O, NOT permissions, NOT SDK Write tool
4. **The problem IS: Claude taking too long to generate large reports**

**Solution Path** (Updated):
- [x] Confirmed: File I/O is instant (v1.4.7 production)
- [x] Confirmed: Write tool executes fast once called (v1.4.7 production)
- [ ] **NEW FOCUS**: Optimize report generation strategy
  - Stream report section-by-section instead of generating all at once
  - Use template-based approach to reduce generation time
  - Break into smaller chunks written progressively
- [ ] Fix: Cache and performance metrics not tracking agent tool calls
- [ ] Fix: Timing instrumentation not displaying logs

**Priority**: P1 - Medium-High (root cause identified)
**Estimated effort**: 2-3 days (focus shifted to report generation optimization)
**Target Release**: v1.5.0 (requires workflow changes)

---

### Issue #8: Cache Not Tracking MCP Tool Calls ‚ö†Ô∏è HIGH
**Severity**: High
**Impact**: Cache system not working for agent tool calls
**Timeline**: Confirmed in v1.4.7 production META research

**Problem**:
- `/cache` shows 0 tool calls despite 20+ MCP calls made
- Cache hit rate: 0.0%
- Multiple duplicate tool calls observed (4x analyze_stock, 4x get_company_financials, etc.)
- All duplicate calls hitting real APIs instead of cache
- Performance benefit completely lost

**Evidence from v1.4.7 Execution (META research)**:
```
Tool calls observed:
- mcp__stock-analyzer__analyze_stock (META) - 4 times
- mcp__company-research__get_company_profile (META) - 3 times
- mcp__company-research__get_company_financials (META) - 4 times
- mcp__news-analyzer__get_company_news (META) - 4 times

/cache command output:
  Total tool calls: 0
  Cache hits: 0
  Cache misses: 0
  Hit rate: 0.0%
  Current size: 0/100 entries
```

**Root Cause Hypothesis**:
1. Cache integration only tracks main workflow tool calls
2. Agent tool calls (through Task tool) bypass cache tracking
3. SessionCache.get() and .set() not being called for MCP tools
4. Cache may only work for direct tool calls, not nested agent calls

**Investigation Needed**:
- [ ] Check how agents execute MCP tool calls (through Claude SDK)
- [ ] Verify if cache_manager is integrated into agent execution path
- [ ] Add logging to SessionCache.get() and .set() to see if they're called
- [ ] Check if ClaudeSDKClient has its own tool execution path that bypasses our cache
- [ ] Test cache with direct MCP tool call (not through agent)

**Solution**:
- [ ] Integrate SessionCache into Claude SDK tool execution pipeline
- [ ] Ensure all MCP tool calls go through cache layer regardless of source
- [ ] Add cache wrapper around ClaudeSDKClient tool execution
- [ ] Test cache hit rate with known duplicate calls

**Impact if Not Fixed**:
- 70% of API calls remain duplicate (no caching benefit)
- Higher API costs and slower workflows
- Cache system completely ineffective for agent workflows

**Priority**: P0 - Critical (core feature not working)
**Estimated effort**: 2-3 days
**Target Release**: v1.5.0

---

## Critical Claude Code SDK Updates (Sonnet 4.5)

### Recent SDK Changes (September 2025)
1. **SDK Renamed**: "Claude Code SDK" ‚Üí "Claude Agent SDK"
2. **Sonnet 4.5 Released**: Best coding model, maintains focus for 30+ hours
3. **Extended Thinking Mode**: Hybrid reasoning for complex tasks
4. **Prompt Caching**: Up to 90% cost savings, 85% latency reduction

### Extended Thinking Mode Analysis

**How It Works**:
- Disabled by default, enable for complex coding work
- Significantly better performance on complex tasks
- **TRADE-OFF**: Impacts prompt caching efficiency
- Best when accuracy > latency

**Our Use Case (Multi-Agent Investment Research)**:
- 4,800 word report generation = complex task
- 4-5 minute generation time observed
- **HYPOTHESIS**: Extended thinking might be auto-enabled for complex responses
- This could explain the long "thinking" period before Write

**Action Items**:
- [ ] Check if extended thinking is enabled in our ClaudeCodeOptions
- [ ] Test with extended thinking explicitly disabled for report generation
- [ ] Consider: Enable extended thinking for analysis, disable for report writing
- [ ] Measure impact on generation time and quality

### Prompt Caching Opportunities

**What Can Be Cached** (5-minute TTL):
- System prompts (our investment workflow instructions)
- Large context (company fundamentals, financials, news)
- Tool definitions and agent descriptions
- Repeated MCP tool results

**Cost Savings Potential**:
- Cache write: 25% premium on input tokens
- Cache read: 90% discount (10% of base price)
- Example: 100K token prompt ‚Üí 90% cost reduction

**Why Our Cache Isn't Working**:
1. Agent tool calls bypass our SessionCache implementation
2. We're implementing application-level cache (wrong layer)
3. **SHOULD USE**: Anthropic's prompt caching at API level
4. Need to structure prompts to maximize cache hits

**Action Items**:
- [ ] Remove application-level SessionCache (not effective)
- [ ] Structure system prompts for prompt caching
- [ ] Use prompt caching headers in API calls
- [ ] Cache agent context between calls
- [ ] Monitor cache hit rates via API responses

## Proposed Architecture Changes

### Current Flow (9 minutes total)
```
User Request
  ‚Üì
Launch Agent 1 (60s)
  ‚Üí Tool Call 1 (10s)
  ‚Üí Tool Call 2 (10s)
  ‚Üí Tool Call 3 (10s)
  ‚Üì
Launch Agent 2 (90s)
  ‚Üí Tool Call 1 (duplicate! 10s)
  ‚Üí Tool Call 2 (duplicate! 10s)
  ‚Üí Tool Call 3 (10s)
  ‚Üì
Launch Agent 3 (60s)
  ‚Üí Tool Call 1 (duplicate! 10s)
  ‚Üí Tool Call 2 (10s)
  ‚Üì
Generate Report (300s!) ‚ö†Ô∏è
  ‚Üì
Done (540s total)
```

### Optimized Flow (3 minutes target)
```
User Request
  ‚Üì
Gather ALL Data (parallel, 30s)
  ‚Üí fetch_profile()     ‚îê
  ‚Üí fetch_financials()  ‚îú‚îÄ asyncio.gather()
  ‚Üí fetch_ratings()     ‚îò
  ‚Üì
Launch Agents (parallel, with data, 60s)
  ‚Üí Agent 1 (uses cached data) ‚îê
  ‚Üí Agent 2 (uses cached data) ‚îú‚îÄ asyncio.gather()
  ‚Üí Agent 3 (uses cached data) ‚îò
  ‚Üì
Stream Report (section by section, 60s)
  ‚Üí Executive Summary (10s)
  ‚Üí Fundamentals (15s)
  ‚Üí News Analysis (15s)
  ‚Üí Risk Assessment (10s)
  ‚Üí Synthesis (10s)
  ‚Üì
Done (150s total - 72% faster!)
```

---

## v1.5.0 Implementation Plan (Based on v1.4.7 Findings)

### Priority 1: Optimize Report Generation (Issue #7 Root Cause)
**Target**: Reduce 4-5 minute report generation to < 1 minute

**Approach 1: Incremental Report Writing**
```python
# Instead of generating entire report then writing:
# 1. Generate executive summary ‚Üí write
# 2. Generate fundamentals section ‚Üí append
# 3. Generate news analysis ‚Üí append
# 4. Generate risk assessment ‚Üí append
# 5. Generate synthesis ‚Üí append
```

**Approach 2: Control Extended Thinking**
- Check if extended thinking is auto-enabled for long responses
- Explicitly disable for report generation (favor speed)
- Enable only for critical analysis sections
- Test impact on generation time vs quality

**Approach 3: Template-Based Generation**
- Pre-define report structure
- Fill in sections with data rather than generating from scratch
- Reduce token generation from ~4,800 to ~2,000

**Implementation**:
- [ ] Modify `/invest:research-stock` workflow for incremental writes
- [ ] Add extended thinking control to ClaudeCodeOptions
- [ ] Create report template with data injection points
- [ ] Measure generation time improvement

### Priority 2: Replace Application Cache with Prompt Caching
**Target**: 70% cost reduction + faster agent execution

**Current Problem**:
- SessionCache at application level doesn't work for agent calls
- All duplicate tool calls hit real APIs
- No cost savings, no performance benefit

**Solution: Use Anthropic's Prompt Caching**
```python
# Structure prompts for caching:
# 1. Static content first (system prompts, tool definitions)
# 2. Cacheable context (company data, financials)
# 3. Variable content last (user query)
```

**Implementation**:
- [ ] Remove SessionCache from chat.py (ineffective)
- [ ] Structure system prompts for prompt caching
- [ ] Add cache control headers to API calls
- [ ] Pass agent results as cached context to next agents
- [ ] Monitor cache hit rates via API response headers

### Priority 3: Fix Performance Metrics Tracking
**Target**: Enable `/cache` and `/perf` commands to show actual data

**Current Problem**:
- No metrics tracked for agent tool calls
- Performance metrics show "No workflow activity"
- Can't measure optimization effectiveness

**Implementation**:
- [ ] Track metrics for agent-initiated tool calls
- [ ] Integrate with Claude SDK response metadata
- [ ] Display agent execution timings
- [ ] Show prompt caching statistics

## Implementation Plan (Legacy - Pre-v1.4.7)

### Phase 1: Emergency Fixes (Week 1)
**Goal**: Get to <5 minute total time

- [ ] Day 1-2: Implement session caching
  - Integrate `SessionCache` into `InteractiveChat`
  - Add cache statistics display
  - Test cache hit rate

- [ ] Day 3-4: Add progress indicators
  - Status updates every 30s
  - Progress bars for long operations
  - "Still working..." messages

- [ ] Day 5: Deploy and monitor
  - Release v1.4.3 with fixes
  - Monitor performance metrics
  - Gather user feedback

### Phase 2: Architecture Improvements (Week 2)
**Goal**: Get to <3 minute total time

- [ ] Day 1-2: Pre-fetch data pattern
  - Gather all data before agent launch
  - Pass data to agents as context
  - Eliminate duplicate calls

- [ ] Day 3-4: Streaming report generation
  - Break report into sections
  - Stream each section as completed
  - Add progress for each section

- [ ] Day 5: Performance testing
  - Benchmark against Phase 1
  - Verify <3 minute target
  - Load testing

### Phase 3: Polish & Monitoring (Week 3)
**Goal**: Production-ready monitoring

- [ ] Add performance monitoring dashboard
- [ ] Alert on slow requests (>4 minutes)
- [ ] Cache hit rate tracking
- [ ] Cost optimization analysis

---

## Success Criteria

### Performance Targets

| Metric | Current | Phase 1 Target | Phase 2 Target |
|--------|---------|----------------|----------------|
| Total time | 9 min | 5 min | 3 min |
| Cache hit rate | 0% | 50% | 80% |
| Time to first output | 3 min | 30 sec | 10 sec |
| Duplicate calls | 10 | 5 | 1 |

### User Experience

- [ ] No gaps >1 minute without feedback
- [ ] Clear progress indicators
- [ ] Estimated time remaining shown
- [ ] Cache statistics visible (optional)

### Cost Optimization

- [ ] 70% reduction in API calls
- [ ] Lower OpenAI/Claude API costs
- [ ] Faster time-to-value

---

## Monitoring & Alerts

### Key Metrics to Track

```python
# Add to InteractiveChat
class PerformanceMetrics:
    workflow_duration: float
    tool_calls_made: int
    cache_hits: int
    cache_misses: int
    time_to_first_output: float
    report_generation_time: float
```

### Alert Conditions

- Workflow takes >5 minutes ‚Üí Send alert
- Cache hit rate <50% ‚Üí Investigate
- Time to first output >2 minutes ‚Üí Warning
- Any single operation >3 minutes ‚Üí Log

---

## Testing Strategy

### Unit Tests

```python
def test_session_cache_hit():
    cache = SessionCache()
    cache.set('tool1', {'arg': 'val'}, 'result')
    assert cache.get('tool1', {'arg': 'val'}) == 'result'

def test_cache_expiration():
    cache = SessionCache(ttl_seconds=1)
    cache.set('tool1', {}, 'result')
    time.sleep(2)
    assert cache.get('tool1', {}) is None
```

### Integration Tests

```python
async def test_research_workflow_performance():
    start = time.time()
    result = await chat.research_stock('NVDA')
    duration = time.time() - start

    assert duration < 180  # 3 minutes
    assert result['cache_hit_rate'] > 0.8
```

### Load Tests

- Run 10 concurrent research requests
- Verify cache sharing works correctly
- Ensure no race conditions
- Monitor memory usage

---

## Documentation Updates

- [ ] Update README with performance benchmarks
- [ ] Document caching behavior
- [ ] Add performance tuning guide
- [ ] Create troubleshooting section

---

## Future Optimizations (Backlog)

### Cross-Session Caching (v1.5.0)
- Redis-based cache for popular stocks
- Pre-compute for top 50 stocks
- Update cache on market close

### Response Compression (v1.5.0)
- Compress large MCP responses
- Delta encoding for similar requests
- Reduce network transfer time

### Smart Prefetching (v1.6.0)
- Predict likely follow-up queries
- Prefetch in background
- Ready before user asks

### Parallel Agent Execution (v1.6.0)
- Launch all agents simultaneously
- Share data via message passing
- Aggregate results in real-time

---

*Last updated: 2025-10-01*
*Status: Planning ‚Üí Implementation (Phase 1)*
*Owner: Development Team*
