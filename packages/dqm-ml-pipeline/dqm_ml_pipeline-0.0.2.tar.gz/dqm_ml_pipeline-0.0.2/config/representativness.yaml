## Yaml pipeline configuration

---
# A really basic pipeline configuration
pipeline_config: 

  # Configuration for the data loader
  # Pour Domain Gap, on utilise PLUSIEURS dataloaders
  # Le gap sera calculé entre source et target
  dataloaders:
    source_dataset:
      type: "parquet"
      path: data/large_test_2m.parquet
      batch_size: 50000
      memory_limit: 2GB
      threads: 4
    
  metrics_processor:

    #Représentativité (distribution fitting) : voir aussi la comparaison entre deux distributions
    representativeness:
      type: "representativeness"
      columns: ["contrast","img_lantent_vector"] # TODO : remove for homogeneity
      metrics: ["chi-square", "grte", "shannon-entropy", "kolmogorov-smirnov"]

      input_columns: ["contrast"] # As for all metrics we define the input columns we are processing

      output_features:  None

      # List of output columns to compute associate to metric processor capabilities      
      # As for all Metrics, we can difine a dictionary between internal metric nam (here the metrics)
      # And define how many placeolder can be use in column name (here the column name for example)
      # TODO : not use currently
      output_metrics:  
        chi-quare: chi-square-{}
        grte: grte-{}
        shannon-entropy: shannon-entropy-{}
        kolmogorov-smirnov: kolmogorov-smirnov-{}

      distribution: "normal"  # ou "uniform"
      bins: 20
      distribution_params:  # optionnel : forcer mean/std et si uniforme min/max
        # mean: 128.0
        # std: 50.0

  outputs :
      
    metrics:
      type: "parquet" 
      path_pattern: "output/metrics_{}-{}.parquet"
      # All metrics shall not be a dictionarry, but scalars, 
      # TODO : add wildcart in columns name here (ex [*] => all metrics are exported)
      # TODO : not use currently
      columns: ['*']
      
