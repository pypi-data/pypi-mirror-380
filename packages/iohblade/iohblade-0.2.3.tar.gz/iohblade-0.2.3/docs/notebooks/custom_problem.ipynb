{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "93eb66df",
   "metadata": {},
   "source": [
    "# Adding a custom problem\n",
    "\n",
    "This tutorial demonstrates how to extend BLADE with your own optimization problem and evaluate it using **LLaMEA**."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "57700691",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Optional setup (required on COLAB)\n",
    "!pip install swig\n",
    "!pip install iohblade"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "b1a62c98",
   "metadata": {},
   "outputs": [],
   "source": [
    "from iohblade.problem import Problem\n",
    "from iohblade.experiment import Experiment\n",
    "from iohblade.llm import Ollama_LLM\n",
    "from iohblade.methods import LLaMEA\n",
    "from iohblade.loggers import ExperimentLogger\n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "41ea9029",
   "metadata": {},
   "outputs": [],
   "source": [
    "class CustomSphere(Problem):\n",
    "    def __init__(self, dims=5, budget_factor=1000, name='Sphere'):\n",
    "        super().__init__(name=name, training_instances=[(1,1)])\n",
    "\n",
    "    def evaluate(self, x):\n",
    "        return {'fitness': float(np.sum(np.array(x)**2))}\n",
    "    \n",
    "    def test(self, x):\n",
    "        pass\n",
    "\n",
    "    def to_dict(self):\n",
    "        return {\"name\":\"Sphere\"}"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1ad93cfb",
   "metadata": {},
   "source": [
    "<div class=\"alert alert-block alert-info\">\n",
    "<b>Tip:</b> Make sure OLlama is running and the model is downloaded before executing the next cell. \n",
    "When using COLAB, you might need to set up port forwarding to connect to your local Ollama instance or use Gemini/OpenAI instead.\n",
    "</div>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ea70d778",
   "metadata": {},
   "outputs": [],
   "source": [
    "llm = Ollama_LLM('qwen2.5-coder:14b') # Make sure Ollama is running and the model is downloaded.\n",
    "method = LLaMEA(llm, budget=30)\n",
    "problems = [CustomSphere()]\n",
    "logger = ExperimentLogger('custom_problem')\n",
    "experiment = Experiment(methods=[method], problems=problems, runs=1, exp_logger=logger, show_stdout=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ae017585",
   "metadata": {},
   "source": [
    "<div class=\"alert alert-block alert-warning\">\n",
    "<b>Warning:</b> The next step might take several hours to run (depending on the budget and number of runs) \n",
    "</div>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3f74903b",
   "metadata": {},
   "outputs": [],
   "source": [
    "experiment()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "iohblade",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
