{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "intro",
   "metadata": {},
   "source": [
    "# Visualising experiments\n",
    "\n",
    "This tutorial introduces the built-in plotting utilities defined in `plots.py`.\n",
    "These functions help you inspect and compare the results of a BLADE experiment."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "setup",
   "metadata": {},
   "source": [
    "We assume you have already executed an experiment and saved the results using an `ExperimentLogger`.\n",
    "Replace `results/simple_exp` with your own experiment folder."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "imports",
   "metadata": {},
   "outputs": [],
   "source": [
    "from iohblade.loggers import ExperimentLogger\n",
    "from iohblade.plots import plot_convergence, plot_experiment_CEG, plot_code_evolution_graphs, plot_boxplot_fitness, plot_boxplot_fitness_hue, fitness_table, plot_token_usage\n",
    "logger = ExperimentLogger('results/simple_exp')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "conv",
   "metadata": {},
   "source": [
    "## Convergence plot\n",
    "`plot_convergence` shows the average best fitness over time for all methods on each problem."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "conv_code",
   "metadata": {},
   "outputs": [],
   "source": [
    "plot_convergence(logger)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ceg",
   "metadata": {},
   "source": [
    "## Code evolution graphs (CEG)\n",
    "`plot_experiment_CEG` visualises how code evolves during optimisation. Each run is plotted separately."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ceg_code",
   "metadata": {},
   "outputs": [],
   "source": [
    "plot_experiment_CEG(logger)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "run_ceg",
   "metadata": {},
   "source": [
    "`plot_code_evolution_graphs` is the lower level function used by `plot_experiment_CEG`.\n",
    "It plots a single run with various complexity metrics."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "run_ceg_code",
   "metadata": {},
   "outputs": [],
   "source": [
    "run_data = logger.get_data().query('method_name == \"LLaMEA\" and seed == 1')\n",
    "plot_code_evolution_graphs(run_data, save=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "boxplot",
   "metadata": {},
   "source": [
    "## Boxplots\n",
    "Use `plot_boxplot_fitness` or `plot_boxplot_fitness_hue` to compare final fitness across methods or problems."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "boxplot_code",
   "metadata": {},
   "outputs": [],
   "source": [
    "plot_boxplot_fitness(logger)\n",
    "plot_boxplot_fitness_hue(logger)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "table",
   "metadata": {},
   "source": [
    "## Fitness table\n",
    "`fitness_table` creates a LaTeX table summarising mean and standard deviation per method/problem."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "table_code",
   "metadata": {},
   "outputs": [],
   "source": [
    "fitness_table(logger)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "tokens",
   "metadata": {},
   "source": [
    "## Token usage\n",
    "`plot_token_usage` shows how many API tokens were consumed by each method."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "tokens_code",
   "metadata": {},
   "outputs": [],
   "source": [
    "plot_token_usage(logger)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "name": "python",
   "pygments_lexer": "ipython3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
