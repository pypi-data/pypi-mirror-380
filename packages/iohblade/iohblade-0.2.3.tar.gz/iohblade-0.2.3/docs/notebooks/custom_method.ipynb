{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "823de055",
   "metadata": {},
   "source": [
    "# Implementing a custom LLM-EC algorithm\n",
    "\n",
    "In this tutorial we implement a simple optimizer and compare it with **LLaMEA** and **EoH**."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "4cd61b3e",
   "metadata": {},
   "outputs": [],
   "source": [
    "!pip install swig\n",
    "!pip install iohblade"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "7bd2c0b0",
   "metadata": {},
   "outputs": [],
   "source": [
    "from iohblade.method import Method\n",
    "from iohblade.experiment import Experiment\n",
    "from iohblade.llm import Ollama_LLM\n",
    "from iohblade.methods import LLaMEA, EoH\n",
    "from iohblade.problems import BBOB_SBOX\n",
    "from iohblade.loggers import ExperimentLogger"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "ecadf423",
   "metadata": {},
   "outputs": [],
   "source": [
    "class MyLLMOptimizer(Method):\n",
    "    def __init__(self, llm, budget=20, name='MyCustomOptimizer'):\n",
    "        super().__init__(llm, budget, name)\n",
    "\n",
    "    def __call__(self, problem):\n",
    "        msg = [{'role':'user','content': problem.get_prompt()}]\n",
    "        best = problem(self.llm.sample_solution(msg))\n",
    "        for _ in range(self.budget - 1):\n",
    "            msg = [\n",
    "                {'role':'user','content': problem.get_prompt()},\n",
    "                {'role':'assistant','content': best.code},\n",
    "                {'role':'user','content': 'Improve the algorithm.'}\n",
    "            ]\n",
    "            cand = problem(self.llm.sample_solution(msg))\n",
    "            if cand.fitness > best.fitness:\n",
    "                best = cand\n",
    "        return best\n",
    "\n",
    "    def to_dict(self):\n",
    "        return {'method_name': self.name, 'budget': self.budget}"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "456ee7fe",
   "metadata": {},
   "source": [
    "<div class=\"alert alert-block alert-info\">\n",
    "<b>Tip:</b> Make sure OLlama is running and the model is downloaded before executing the next cell. \n",
    "When using COLAB, you might need to set up port forwarding to connect to your local Ollama instance or use Gemini/OpenAI instead.\n",
    "</div>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "19cba1e9",
   "metadata": {},
   "outputs": [],
   "source": [
    "llm = Ollama_LLM('qwen2.5-coder:14b') # Make sure Ollama is running and the model is downloaded.\n",
    "budget = 10\n",
    "methods = [\n",
    "    LLaMEA(llm, budget=budget, name='LLaMEA'),\n",
    "    EoH(llm, budget=budget, name='EoH'),\n",
    "    MyLLMOptimizer(llm, budget=budget, name='MyCustomOptimizer'),\n",
    "]\n",
    "problems = [BBOB_SBOX(training_instances=[(1,1)], dims=[5], budget_factor=200, name='BBOB')]\n",
    "logger = ExperimentLogger('custom_method')\n",
    "experiment = Experiment(methods=methods, problems=problems, runs=3, show_stdout=True, exp_logger=logger)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bb1c2634",
   "metadata": {},
   "source": [
    "<div class=\"alert alert-block alert-warning\">\n",
    "<b>Warning:</b> The next step might take several hours to run (depending on the budget and number of runs) \n",
    "</div>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "68e8cd9d",
   "metadata": {},
   "outputs": [],
   "source": [
    "experiment() # This step might take several hours to run."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "iohblade",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
