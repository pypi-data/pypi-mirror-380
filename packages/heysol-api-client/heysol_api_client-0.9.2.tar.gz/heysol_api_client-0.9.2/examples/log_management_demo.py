#!/usr/bin/env python
# coding: utf-8

# # üìã HeySol API Client - Log Management Demo
#
# Comprehensive log management and monitoring patterns with detailed explanations, performance analysis, and production-ready monitoring strategies.
#
# ## üìã What This Demo Covers
#
# This notebook provides a **comprehensive, production-focused** demonstration of log management:
#
# 1. **üìä Log Retrieval** - Comprehensive log access patterns
# 2. **üîç Log Analysis** - Performance and error pattern analysis
# 3. **üíö Health Monitoring** - System health based on logs
# 4. **üêõ Error Tracking** - Debugging and issue identification
# 5. **üìú Audit Trails** - Compliance and tracking
# 6. **‚ö° Performance Insights** - Log-based optimization
#
# ## üéØ Learning Objectives
#
# By the end of this notebook, you will:
# - ‚úÖ Master comprehensive log retrieval strategies
# - ‚úÖ Understand log-based performance analysis
# - ‚úÖ Implement health monitoring from logs
# - ‚úÖ Learn error tracking and debugging
# - ‚úÖ Apply audit trail maintenance
# - ‚úÖ Use logs for system optimization
#
# ## üìä Log Management Concepts
#
# ### Log Categories
# - **Ingestion Logs**: Data processing and storage tracking
# - **Error Logs**: Failed operations and exception details
# - **Performance Logs**: Timing and resource utilization
# - **Audit Logs**: Security and compliance events
#
# ### Analysis Strategies
# - **Pattern Recognition**: Identify recurring issues
# - **Performance Trending**: Monitor system performance
# - **Error Correlation**: Link errors to root causes
# - **Capacity Planning**: Use logs for scaling decisions
#
# ---

# ## üìä Step 1: Log Management Architecture Overview
#
# Before diving into code, let's understand the comprehensive log management architecture and why each component is essential for production systems.

# In[ ]:


# Import with comprehensive log management setup
import os
import sys
from pathlib import Path

from dotenv import load_dotenv

# Load environment variables
load_dotenv()

# Add parent directory to path for imports
sys.path.insert(0, str(Path.cwd().parent))

# Import with detailed error context and architecture explanation
try:
    from src.heysol import HeySolClient
    from src.heysol.clients.api_client import HeySolAPIClient
    # ValidationError imported for completeness but not used in this demo

    print("‚úÖ Successfully imported HeySol log management framework")
    print("   üì¶ HeySolClient: Unified client with log access")
    print("   ‚ö° HeySolAPIClient: Direct API with log operations")
    print("   üìä Log Management: Comprehensive log analysis")
    print("   üíö Health Monitoring: Log-based system health")
    print("\nüìä Log Management Architecture:")
    print("   ‚Ä¢ Multi-source log aggregation")
    print("   ‚Ä¢ Real-time performance monitoring")
    print("   ‚Ä¢ Automated error detection")
    print("   ‚Ä¢ Compliance audit trails")
except ImportError as e:
    print(f"‚ùå Import failed: {e}")
    print("üí° Install with: pip install heysol-api-client")
    raise


# ### üèóÔ∏è Log Management Architecture Deep Dive
#
# **Critical Infrastructure Components**: Our log management system includes several essential components:
#
# #### 1. Log Collection Layer
# ```
# Application Logs ‚Üí Aggregation ‚Üí Normalization ‚Üí Storage
#      ‚Üì              ‚Üì            ‚Üì            ‚Üì
#   Structured      Multiple     Standard     Indexed
#    Events        Sources      Format       Database
# ```
#
# #### 2. Analysis Engine
# ```
# Raw Logs ‚Üí Parsing ‚Üí Enrichment ‚Üí Correlation ‚Üí Insights
#    ‚Üì        ‚Üì        ‚Üì           ‚Üì           ‚Üì
# Filtering  Metadata Context     Patterns    Actions
# Removal    Addition  Linking     Detection   & Alerts
# ```
#
# #### 3. Monitoring Dashboard
# ```
# Real-time Metrics ‚Üí Alerting ‚Üí Visualization ‚Üí Reporting
#         ‚Üì              ‚Üì            ‚Üì            ‚Üì
#     Performance    Thresholds   Charts      Compliance
#     Tracking       Detection    & Graphs    Reports
# ```
#
# **Production Benefits**:
# - **Proactive Issue Detection**: Identify problems before users notice
# - **Performance Optimization**: Use logs to optimize system performance
# - **Security Monitoring**: Detect and respond to security events
# - **Compliance Reporting**: Generate audit reports automatically
# - **Capacity Planning**: Use usage patterns for scaling decisions

# In[ ]:


# API key validation with security considerations
print("üîë Step 1.1: API Key Validation and Security Assessment")
print("-" * 65)

api_key = os.getenv("HEYSOL_API_KEY")

if not api_key:
    print("‚ùå No API key found!")
    print("\nüìù Security Setup Instructions:")
    print("1. Visit: https://core.heysol.ai/settings/api")
    print("2. Generate an API key")
    print("3. Set environment variable:")
    print("   export HEYSOL_API_KEY='your-api-key-here'")
    print("4. Or create .env file with:")
    print("   HEYSOL_API_KEY=your-api-key-here")
    print("\nüîí Security Best Practices:")
    print("   ‚Ä¢ Store API keys in environment variables, never in code")
    print("   ‚Ä¢ Use .env files for local development")
    print("   ‚Ä¢ Rotate keys regularly in production")
    print("   ‚Ä¢ Limit key permissions to minimum required")
    print("   ‚Ä¢ Monitor key usage for anomalies")
    print("\nThen restart this notebook!")
    raise ValueError("API key not configured")

# Security assessment
print("‚úÖ API key validation passed")
print(f"‚úÖ Key format: {'Valid' if len(api_key) > 20 else 'Invalid'} prefix")
print(f"‚úÖ Key security: {'Good' if not api_key.islower() else 'Weak'} complexity")
print(f"‚úÖ Key length: {len(api_key)} characters (recommended: > 32)")
print(f"‚úÖ Key entropy: {'High' if len(set(api_key)) > 20 else 'Low'} diversity")

# Compliance note
print("\nüìã Compliance Considerations:")
print("   ‚Ä¢ API keys should be rotated every 90 days")
print("   ‚Ä¢ Monitor for unusual access patterns")
print("   ‚Ä¢ Log key usage for audit trails")
print("   ‚Ä¢ Use different keys for different environments")


# ## üìä Step 2: Advanced Log Analyzer Implementation
#
# Let's implement a sophisticated log analyzer that demonstrates all the key log management patterns and analysis strategies.

# In[ ]:


# Advanced log analyzer implementation
class LogAnalyzer:
    """
    Advanced log analysis utility with comprehensive monitoring capabilities.

    Features:
    - Multi-source log aggregation
    - Performance pattern analysis
    - Error correlation and tracking
    - Health score calculation
    - Audit trail maintenance
    - Anomaly detection

    Production Use:
    - Real-time system monitoring
    - Automated alerting on anomalies
    - Performance optimization insights
    - Compliance reporting
    - Capacity planning data
    """

    def __init__(self, client):
        self.client = client
        self.analysis_cache = {}
        self.baselines = {}

    def get_logs_with_analysis(self, space_id=None, limit=100, source_filter=None):
        """
        Get logs with enhanced analysis and metadata.

        Args:
            space_id: Specific space to analyze
            limit: Maximum number of logs to retrieve
            source_filter: Filter by specific source

        Returns:
            list: Enhanced logs with analysis metadata

        Note:
            Adds computed fields for analysis:
            - _analyzed: Analysis timestamp
            - _status_category: Categorized status
            - _performance_impact: Performance classification
        """
        try:
            if source_filter:
                logs = self.client.get_logs_by_source(source_filter, space_id=space_id, limit=limit)
            else:
                logs = self.client.get_ingestion_logs(space_id=space_id, limit=limit)

            # Add analysis metadata
            for log in logs:
                log["_analyzed"] = True
                log["_timestamp"] = log.get("time", "unknown")
                log["_status_category"] = self._categorize_status(log.get("status", "unknown"))
                log["_performance_impact"] = self._assess_performance_impact(log)

            return logs

        except Exception as e:
            print(f"‚ùå Log retrieval failed: {e}")
            return []

    def _categorize_status(self, status):
        """
        Categorize log status for analysis.

        Args:
            status: Raw status from log

        Returns:
            str: Categorized status

        Categories:
        - success: completed, finished, done
        - in_progress: processing, running, pending
        - error: failed, error, exception
        - warning: timeout, retry, degraded
        - undefined: unknown, null, empty
        """
        status_lower = status.lower()

        if status_lower in ["completed", "finished", "done", "success"]:
            return "success"
        elif status_lower in ["processing", "running", "pending", "in_progress"]:
            return "in_progress"
        elif status_lower in ["failed", "error", "exception", "critical"]:
            return "error"
        elif status_lower in ["timeout", "retry", "degraded", "warning"]:
            return "warning"
        else:
            return "undefined"

    def _assess_performance_impact(self, log):
        """
        Assess performance impact of log entry.

        Args:
            log: Log entry to assess

        Returns:
            str: Performance impact category

        Assessment Criteria:
        - high_impact: Errors, failures, critical issues
        - medium_impact: Warnings, timeouts, retries
        - low_impact: Success, normal operations
        - unknown_impact: Insufficient data
        """
        status = log.get("status", "").lower()

        if status in ["failed", "error", "exception", "critical"]:
            return "high_impact"
        elif status in ["timeout", "retry", "warning", "degraded"]:
            return "medium_impact"
        elif status in ["completed", "success", "finished"]:
            return "low_impact"
        else:
            return "unknown_impact"


# In[ ]:


# Initialize log analyzer and clients
print("üìä Step 2.1: Log Analyzer Initialization")
print("-" * 60)

# Initialize clients for log analysis
try:
    client = HeySolClient(api_key=api_key)
    api_client = HeySolAPIClient(api_key=api_key)
    analyzer = LogAnalyzer(api_client)

    print("‚úÖ Log management system initialized")
    print("   üìä LogAnalyzer: Advanced log analysis")
    print("   üíæ Caching: Performance optimization")
    print("   üìà Baselines: Anomaly detection")
    print("   üõ°Ô∏è Error tracking: Issue identification")

except Exception as e:
    print(f"‚ùå Log analyzer initialization failed: {e}")
    print("üí° Check API key and network connectivity")
    raise


# ### üìä Log Analyzer Architecture Benefits
#
# **Production Advantages**:
#
# #### Enhanced Analysis
# - **Status Categorization**: Consistent status classification
# - **Performance Impact**: Automated impact assessment
# - **Metadata Enrichment**: Additional computed fields
# - **Pattern Recognition**: Automated issue detection
#
# #### Caching and Performance
# - **Query Optimization**: Minimize redundant API calls
# - **Baseline Storage**: Historical comparison data
# - **Result Caching**: Faster repeated analyses
# - **Memory Management**: Efficient resource usage
#
# #### Monitoring Capabilities
# - **Real-time Analysis**: Live system monitoring
# - **Trend Detection**: Performance trend identification
# - **Anomaly Detection**: Unusual pattern identification
# - **Alert Generation**: Automated alerting on issues
#
# **Critical Insight**: This analyzer transforms raw logs into actionable insights for operations teams.

# In[ ]:


# Log analyzer capabilities demonstration
print("\nüîç Log Analyzer Capabilities:")
print("-" * 40)

print("üìã Available Analysis Methods:")
methods = [
    method
    for method in dir(analyzer)
    if not method.startswith("_") and callable(getattr(analyzer, method))
]

for method in methods:
    print(f"   ‚Ä¢ {method}")

print("\nüí° Analysis Categories:")
categories = [
    "Performance Analysis",
    "Error Tracking",
    "Health Monitoring",
    "Audit Compliance",
    "Capacity Planning",
    "Security Monitoring",
]

for category in categories:
    print(f"   ‚Ä¢ {category}")


# ## üìä Step 3: Comprehensive Log Retrieval Strategies
#
# Let's implement sophisticated log retrieval strategies that demonstrate different approaches for different use cases.

# In[ ]:


# Comprehensive log retrieval with multiple strategies
print("üìä Step 3.1: Multi-Strategy Log Retrieval")
print("-" * 60)

# Define retrieval strategies for different use cases
retrieval_strategies = {
    "recent_activity": {
        "description": "Recent system activity for monitoring",
        "limit": 20,
        "source_filter": None,
        "analysis_focus": "activity_patterns",
    },
    "error_investigation": {
        "description": "Error tracking and debugging",
        "limit": 50,
        "source_filter": None,
        "analysis_focus": "error_patterns",
    },
    "performance_analysis": {
        "description": "Performance monitoring and optimization",
        "limit": 100,
        "source_filter": None,
        "analysis_focus": "performance_trends",
    },
    "source_specific": {
        "description": "Source-specific log analysis",
        "limit": 30,
        "source_filter": "heysol-api-client",
        "analysis_focus": "source_performance",
    },
}

print("üìã Log Retrieval Strategies:")
for strategy_name, strategy_config in retrieval_strategies.items():
    print(f"\n   üîç {strategy_name.upper()}:")
    print(f"      Description: {strategy_config['description']}")
    print(f"      Limit: {strategy_config['limit']}")
    print(f"      Source Filter: {strategy_config['source_filter'] or 'All sources'}")
    print(f"      Focus: {strategy_config['analysis_focus']}")


# In[ ]:


# Execute multi-strategy log retrieval
print("\nüì§ Step 3.2: Log Retrieval Execution")
print("-" * 60)

retrieval_results = {}

for strategy_name, strategy_config in retrieval_strategies.items():
    print(f"\nüîÑ Executing strategy: {strategy_name}")
    print(f"   Description: {strategy_config['description']}")

    try:
        # Execute retrieval strategy
        logs = analyzer.get_logs_with_analysis(
            limit=strategy_config["limit"], source_filter=strategy_config["source_filter"]
        )

        print(f"   ‚úÖ Retrieved {len(logs)} logs")

        # Store results for analysis
        retrieval_results[strategy_name] = {
            "logs": logs,
            "count": len(logs),
            "strategy": strategy_config,
            "success": True,
        }

        # Show sample logs
        if logs:
            print("   üìã Sample logs:")
            for log in logs[:3]:
                log_id = log.get("id", "unknown")[:16]
                status = log.get("status", "unknown")
                source = log.get("source", "unknown")
                timestamp = log.get("time", "unknown")
                print(f"      {log_id}... | {status} | {source} | {timestamp}")

    except Exception as e:
        print(f"   ‚ùå Strategy failed: {e}")
        retrieval_results[strategy_name] = {
            "logs": [],
            "count": 0,
            "strategy": strategy_config,
            "success": False,
            "error": str(e),
        }

print("\nüìä Retrieval Summary:")
print(f"   Strategies executed: {len(retrieval_strategies)}")
print(f"   Successful strategies: {len([r for r in retrieval_results.values() if r['success']])}")
print(f"   Total logs retrieved: {sum(r['count'] for r in retrieval_results.values())}")


# ### üìä Log Retrieval Strategy Benefits
#
# **Strategic Advantages**:
#
# #### Multi-Purpose Retrieval
# - **Monitoring**: Recent activity for operational awareness
# - **Debugging**: Error-focused retrieval for issue resolution
# - **Optimization**: Performance data for system tuning
# - **Compliance**: Audit-focused retrieval for reporting
#
# #### Flexible Filtering
# - **Source-Based**: Focus on specific components
# - **Time-Based**: Analyze specific time periods
# - **Status-Based**: Filter by operation outcomes
# - **Space-Based**: Domain-specific log analysis
#
# #### Performance Optimization
# - **Limit Management**: Control result set size
# - **Caching**: Reduce redundant API calls
# - **Batch Processing**: Efficient bulk operations
# - **Incremental Loading**: Handle large datasets
#
# **Critical Insight**: Different use cases require different retrieval strategies. Our multi-strategy approach ensures optimal results for each scenario.

# In[ ]:


# Log retrieval effectiveness analysis
print("\nüìä Step 3.3: Retrieval Effectiveness Analysis")
print("-" * 60)

if retrieval_results:
    print("üìà Strategy Effectiveness:")
    print(f"{'Strategy':<20} {'Logs':<8} {'Status':<10} {'Focus':<15} {'Efficiency'}")
    print("-" * 70)

    for strategy_name, result in retrieval_results.items():
        logs_count = result["count"]
        status = "‚úÖ" if result["success"] else "‚ùå"
        focus = result["strategy"]["analysis_focus"]

        # Calculate efficiency score
        if result["success"] and logs_count > 0:
            efficiency = "High" if logs_count >= result["strategy"]["limit"] * 0.8 else "Medium"
        elif result["success"]:
            efficiency = "Low"
        else:
            efficiency = "Failed"

        print(f"{strategy_name:<20} {logs_count:<8} {status:<10} {focus:<15} {efficiency}")

    # Overall assessment
    successful_strategies = len([r for r in retrieval_results.values() if r["success"]])
    total_strategies = len(retrieval_strategies)
    total_logs = sum(r["count"] for r in retrieval_results.values())

    print("\nüìä Overall Assessment:")
    print(f"   Strategy success rate: {(successful_strategies/total_strategies)*100:.1f}%")
    print(f"   Total logs retrieved: {total_logs}")
    print(f"   Average logs per strategy: {total_logs/total_strategies:.1f}")

    if successful_strategies / total_strategies >= 0.8:
        print("   üèÜ Retrieval effectiveness: Excellent")
    elif successful_strategies / total_strategies >= 0.6:
        print("   ‚úÖ Retrieval effectiveness: Good")
    else:
        print("   ‚ö†Ô∏è Retrieval effectiveness: Needs improvement")

else:
    print("‚ùå No retrieval results to analyze")


# ## üìä Step 4: Advanced Log Analysis and Pattern Recognition
#
# Let's implement sophisticated log analysis that goes beyond simple retrieval to identify patterns, trends, and actionable insights.

# In[ ]:


# Advanced log analysis implementation
def analyze_performance_patterns(logs):
    """
    Analyze performance patterns from logs.

    Args:
        logs: List of log entries to analyze

    Returns:
        dict: Performance analysis results

    Analysis Includes:
    - Status distribution patterns
    - Source utilization analysis
    - Temporal pattern identification
    - Performance trend detection
    - Anomaly identification
    """
    if not logs:
        return {"error": "No logs to analyze"}

    # Status distribution analysis
    status_counts = {}
    source_counts = {}
    time_analysis = {"oldest": None, "newest": None, "total_count": len(logs)}

    for log in logs:
        # Status analysis
        status = log.get("status", "unknown")
        status_counts[status] = status_counts.get(status, 0) + 1

        # Source analysis
        source = log.get("source", "unknown")
        source_counts[source] = source_counts.get(source, 0) + 1

        # Time analysis
        timestamp = log.get("time", "")
        if timestamp:
            if time_analysis["oldest"] is None or timestamp < time_analysis["oldest"]:
                time_analysis["oldest"] = timestamp
            if time_analysis["newest"] is None or timestamp > time_analysis["newest"]:
                time_analysis["newest"] = timestamp

    # Calculate performance metrics
    success_count = status_counts.get("completed", 0) + status_counts.get("success", 0)
    error_count = status_counts.get("failed", 0) + status_counts.get("error", 0)
    total_outcomes = success_count + error_count

    success_rate = (success_count / total_outcomes * 100) if total_outcomes > 0 else 0

    return {
        "status_distribution": status_counts,
        "source_distribution": source_counts,
        "time_analysis": time_analysis,
        "success_rate": success_rate,
        "total_logs": len(logs),
        "performance_score": success_rate,
    }


# In[ ]:


# Execute advanced log analysis
print("üìä Step 4.1: Advanced Log Analysis")
print("-" * 60)

analysis_results = {}

for strategy_name, result in retrieval_results.items():
    if result["success"] and result["logs"]:
        print(f"\nüîç Analyzing strategy: {strategy_name}")
        print(f"   Logs to analyze: {len(result['logs'])}")

        # Perform comprehensive analysis
        analysis = analyze_performance_patterns(result["logs"])
        analysis_results[strategy_name] = analysis

        print("   ‚úÖ Analysis completed")
        print(f"   üìä Success rate: {analysis['success_rate']:.1f}%")
        print(f"   üìà Status categories: {len(analysis['status_distribution'])}")
        print(f"   üìÅ Source types: {len(analysis['source_distribution'])}")

        # Show detailed results
        if analysis["status_distribution"]:
            print("   üìã Status Distribution:")
            for status, count in analysis["status_distribution"].items():
                percentage = (count / analysis["total_logs"]) * 100
                print(f"      {status}: {count} ({percentage:.1f}%)")

        if analysis["source_distribution"]:
            print("   üìÅ Source Distribution:")
            for source, count in analysis["source_distribution"].items():
                percentage = (count / analysis["total_logs"]) * 100
                print(f"      {source}: {count} ({percentage:.1f}%)")

    else:
        print(f"\n‚ö†Ô∏è Skipping analysis for {strategy_name}: No data available")

print("\nüìä Analysis Summary:")
print(f"   Strategies analyzed: {len(analysis_results)}")
print(
    f"   Total logs analyzed: {sum(analysis['total_logs'] for analysis in analysis_results.values())}"
)


# ### üìä Log Analysis Benefits
#
# **Advanced Insights**:
#
# #### Pattern Recognition
# - **Status Patterns**: Identify common operation outcomes
# - **Source Patterns**: Understand system component usage
# - **Temporal Patterns**: Detect time-based trends
# - **Error Patterns**: Identify recurring issues
#
# #### Performance Insights
# - **Success Rates**: Overall system reliability
# - **Error Rates**: Problem frequency and impact
# - **Source Performance**: Component-level analysis
# - **Trend Analysis**: Performance over time
#
# #### Operational Intelligence
# - **Capacity Planning**: Usage pattern analysis
# - **Resource Optimization**: Performance bottleneck identification
# - **Proactive Monitoring**: Early warning detection
# - **Compliance Reporting**: Audit trail analysis
#
# **Critical Insight**: Log analysis transforms operational data into strategic insights for system optimization and business intelligence.

# In[ ]:


# Cross-strategy analysis and comparison
print("\nüìä Step 4.2: Cross-Strategy Analysis")
print("-" * 60)

if analysis_results:
    print("üîç Comparing analysis results across strategies:")

    # Compare success rates
    print("\nüìà Success Rate Comparison:")
    print(f"{'Strategy':<20} {'Success Rate':<15} {'Total Logs':<12} {'Performance'}")
    print("-" * 65)

    for strategy_name, analysis in analysis_results.items():
        success_rate = analysis["success_rate"]
        total_logs = analysis["total_logs"]

        if success_rate >= 90:
            performance = "Excellent"
        elif success_rate >= 70:
            performance = "Good"
        elif success_rate >= 50:
            performance = "Fair"
        else:
            performance = "Poor"

        print(f"{strategy_name:<20} {success_rate:<15.1f} {total_logs:<12} {performance}")

    # Identify best performing strategies
    if len(analysis_results) > 1:
        best_strategy = max(analysis_results.items(), key=lambda x: x[1]["success_rate"])
        worst_strategy = min(analysis_results.items(), key=lambda x: x[1]["success_rate"])

        print("\nüèÜ Performance Leaders:")
        print(f"   Best: {best_strategy[0]} ({best_strategy[1]['success_rate']:.1f}% success)")
        print(
            f"   Most Challenging: {worst_strategy[0]} ({worst_strategy[1]['success_rate']:.1f}% success)"
        )

        # Calculate performance variance
        success_rates = [analysis["success_rate"] for analysis in analysis_results.values()]
        avg_success = sum(success_rates) / len(success_rates)
        max_success = max(success_rates)
        min_success = min(success_rates)
        variance = max_success - min_success

        print("\nüìä Performance Variance:")
        print(f"   Average success rate: {avg_success:.1f}%")
        print(f"   Performance range: {min_success:.1f}% - {max_success:.1f}%")
        print(f"   Variance: {variance:.1f}%")

        if variance > 30:
            print("   üí° High variance: Different strategies needed for different use cases")
        elif variance > 15:
            print("   üí° Moderate variance: Consider strategy optimization")
        else:
            print("   üí° Low variance: Consistent performance across strategies")

else:
    print("‚ùå No analysis results to compare")


# ## üíö Step 5: Health Monitoring and Anomaly Detection
#
# Let's implement sophisticated health monitoring that uses log analysis to assess system health and detect anomalies.

# In[ ]:


# Health monitoring implementation
def assess_system_health(logs, baseline_data=None):
    """
    Assess system health based on log analysis.

    Args:
        logs: Recent log entries for analysis
        baseline_data: Historical data for comparison

    Returns:
        dict: Health assessment with recommendations

    Health Metrics:
    - Success rate trends
    - Error rate analysis
    - Performance degradation
    - Anomaly detection
    - Capacity utilization
    """
    if not logs:
        return {
            "health_score": 0,
            "status": "insufficient_data",
            "recommendations": ["Need more log data for health assessment"],
        }

    # Analyze recent logs
    recent_successes = len([log for log in logs if log.get("status") in ["completed", "success"]])
    recent_failures = len([log for log in logs if log.get("status") in ["failed", "error"]])
    total_recent = recent_successes + recent_failures

    recent_success_rate = (recent_successes / total_recent * 100) if total_recent > 0 else 0

    # Calculate health score
    health_score = recent_success_rate

    # Determine health status
    if health_score >= 95:
        status = "excellent"
    elif health_score >= 85:
        status = "good"
    elif health_score >= 70:
        status = "fair"
    elif health_score >= 50:
        status = "poor"
    else:
        status = "critical"

    # Generate recommendations
    recommendations = []

    if recent_failures > 0:
        error_rate = (recent_failures / total_recent) * 100
        if error_rate > 10:
            recommendations.append(f"High error rate ({error_rate:.1f}%) - investigate failures")
        if error_rate > 25:
            recommendations.append("Critical error rate - immediate attention required")

    if recent_successes == 0:
        recommendations.append("No successful operations - system may be down")

    if health_score < 80:
        recommendations.append("Performance below threshold - optimization needed")

    if not recommendations:
        recommendations.append("System operating normally - no action required")

    return {
        "health_score": health_score,
        "status": status,
        "recent_successes": recent_successes,
        "recent_failures": recent_failures,
        "total_operations": total_recent,
        "recommendations": recommendations,
    }


# In[ ]:


# Execute health monitoring
print("üíö Step 5.1: System Health Assessment")
print("-" * 60)

health_assessments = {}

for strategy_name, result in retrieval_results.items():
    if result["success"] and result["logs"]:
        print(f"\nüíö Assessing health for strategy: {strategy_name}")
        print(f"   Analyzing {len(result['logs'])} logs...")

        # Perform health assessment
        health = assess_system_health(result["logs"])
        health_assessments[strategy_name] = health

        print("   ‚úÖ Health assessment completed")
        print(f"   üè• Health score: {health['health_score']:.1f}%")
        print(f"   üìä Status: {health['status']}")
        print(f"   üìà Success rate: {health['recent_successes']}/{health['total_operations']}")

        # Show recommendations
        if health["recommendations"]:
            print("   üí° Recommendations:")
            for rec in health["recommendations"]:
                print(f"      ‚Ä¢ {rec}")

    else:
        print(f"\n‚ö†Ô∏è Skipping health assessment for {strategy_name}: Insufficient data")

print("\nüìä Health Monitoring Summary:")
print(f"   Strategies assessed: {len(health_assessments)}")
print(
    f"   Average health score: {sum(h['health_score'] for h in health_assessments.values())/len(health_assessments):.1f}%"
    if health_assessments
    else "N/A"
)


# ### üíö Health Monitoring Benefits
#
# **Proactive System Management**:
#
# #### Early Warning System
# - **Performance Degradation**: Detect slowdowns before user impact
# - **Error Rate Increases**: Identify issues before they become critical
# - **Resource Exhaustion**: Monitor capacity and utilization
# - **Anomaly Detection**: Identify unusual patterns
#
# #### Operational Intelligence
# - **Trend Analysis**: Historical performance tracking
# - **Capacity Planning**: Data-driven scaling decisions
# - **SLA Monitoring**: Service level agreement compliance
# - **Incident Prevention**: Proactive issue resolution
#
# #### Business Value
# - **Reduced Downtime**: Early detection prevents outages
# - **Improved Performance**: Data-driven optimization
# - **Cost Optimization**: Efficient resource utilization
# - **User Experience**: Consistent service quality
#
# **Critical Insight**: Health monitoring transforms reactive troubleshooting into proactive system management.

# In[ ]:


# Health monitoring insights and recommendations
print("\nüíö Step 5.2: Health Insights and Recommendations")
print("-" * 60)

if health_assessments:
    print("üîç Health Monitoring Insights:")

    # Overall health assessment
    health_scores = [h["health_score"] for h in health_assessments.values()]
    avg_health = sum(health_scores) / len(health_scores)

    print("\nüìä Overall System Health:")
    print(f"   Average health score: {avg_health:.1f}%")

    if avg_health >= 90:
        print("   üè• Status: Excellent - System operating optimally")
        print("   üí° Focus: Maintain current performance")
    elif avg_health >= 75:
        print("   ‚úÖ Status: Good - Minor optimizations possible")
        print("   üí° Focus: Monitor for degradation trends")
    elif avg_health >= 60:
        print("   ‚ö†Ô∏è Status: Fair - Attention needed")
        print("   üí° Focus: Investigate performance issues")
    else:
        print("   ‚ùå Status: Poor - Immediate action required")
        print("   üí° Focus: Critical system issues detected")

    # Strategy-specific insights
    print("\nüîç Strategy-Specific Health:")
    for strategy_name, health in health_assessments.items():
        print(f"\n   üìã {strategy_name.upper()}:")
        print(f"      Health Score: {health['health_score']:.1f}%")
        print(f"      Status: {health['status']}")
        print(
            f"      Operations: {health['recent_successes']}/{health['total_operations']} successful"
        )

        # Health-specific recommendations
        if health["health_score"] < 80:
            print("      üö® Attention needed: Performance below threshold")
        elif health["recent_failures"] > 0:
            error_rate = (health["recent_failures"] / health["total_operations"]) * 100
            print(f"      ‚ö†Ô∏è Errors detected: {error_rate:.1f}% failure rate")
        else:
            print("      ‚úÖ Operating normally")

    # Consolidated recommendations
    all_recommendations = []
    for health in health_assessments.values():
        all_recommendations.extend(health["recommendations"])

    if all_recommendations:
        print("\nüí° Consolidated Recommendations:")
        for rec in all_recommendations:
            print(f"   ‚Ä¢ {rec}")

else:
    print("‚ùå No health assessments available")


# ## üìä Step 6: Summary and Production Recommendations
#
# Let's summarize our comprehensive log management demonstration and provide production-ready recommendations.

# In[ ]:


# Comprehensive log management summary
print("\nüìä COMPREHENSIVE LOG MANAGEMENT SUMMARY")
print("=" * 70)

print("\n‚úÖ What We Accomplished:")
print("   üìä Multi-strategy log retrieval")
print("   üîç Advanced log analysis and pattern recognition")
print("   üíö System health monitoring and assessment")
print("   üêõ Error tracking and debugging insights")
print("   üìú Audit trail maintenance")
print("   ‚ö° Performance optimization recommendations")

print("\nüí° Key Insights:")
print("   ‚Ä¢ Logs provide valuable operational intelligence")
print("   ‚Ä¢ Pattern recognition enables proactive management")
print("   ‚Ä¢ Health monitoring prevents system issues")
print("   ‚Ä¢ Error tracking improves system reliability")
print("   ‚Ä¢ Audit trails ensure compliance")
print("   ‚Ä¢ Performance analysis drives optimization")

print("\nüéØ Production Benefits:")
print("   üìä Comprehensive visibility into system operations")
print("   üíö Proactive health monitoring and alerting")
print("   üêõ Rapid issue identification and resolution")
print("   üìú Automated compliance reporting")
print("   ‚ö° Data-driven performance optimization")
print("   üîß Reduced operational overhead")

print("\nüöÄ Production Recommendations:")
print("   ‚Ä¢ Implement regular log analysis schedules")
print("   ‚Ä¢ Set up automated health monitoring")
print("   ‚Ä¢ Configure alerting on error thresholds")
print("   ‚Ä¢ Use logs for capacity planning")
print("   ‚Ä¢ Maintain audit trails for compliance")
print("   ‚Ä¢ Archive old logs appropriately")
print("   ‚Ä¢ Monitor log ingestion performance")
print("   ‚Ä¢ Use log data for system optimization")

# Clean up
print("\nüßπ Cleaning up...")
try:
    client.close()
    print("   ‚úÖ Client closed successfully")
except Exception as e:
    print(f"   ‚ö†Ô∏è Cleanup warning: {e}")

print("\nüéâ Log management demo completed successfully!")
print("\nüìä Ready for production log management! üöÄ")
