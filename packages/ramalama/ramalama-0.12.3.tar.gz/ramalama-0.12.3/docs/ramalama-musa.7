.TH "ramalama-musa 7" 
.nh
.ad l


.SH Setting Up RamaLama with MUSA Support on Linux systems
.PP
This guide walks through the steps required to set up RamaLama with MUSA support.

.SH Install the MT Linux Driver
.PP
Download the appropriate MUSA SDK and follow the installation instructions provided in the MT Linux Driver installation guide.

.SH Install the MT Container Toolkit
.PP
Obtain the latest MT CloudNative Toolkits and follow the installation instructions provided in the MT Container Toolkit installation guide.

.SH Setting Up MUSA Support
.PP
.RS

.nf
   $ (cd /usr/bin/musa \&\& sudo ./docker setup $PWD)
   $ docker info | grep mthreads
   Runtimes: mthreads mthreads\-experimental runc
   Default Runtime: mthreads

.fi
.RE

.SH Testing the Setup

.SH \fBTest the Installation\fP
.PP
Run the following command to verify setup:

.PP
.RS

.nf
   docker run \-\-rm \-\-env MTHREADS\_VISIBLE\_DEVICES=all ubuntu:22.04 mthreads\-gmi

.fi
.RE


.SH \fBExpected Output\fP
.PP
Verify everything is configured correctly, with output similar to this:

.PP
.RS

.nf
   Thu May 15 01:53:39 2025
   \-\-\-\-\-\-\-\-\-\-\-\-\-\-\-\-\-\-\-\-\-\-\-\-\-\-\-\-\-\-\-\-\-\-\-\-\-\-\-\-\-\-\-\-\-\-\-\-\-\-\-\-\-\-\-\-\-\-\-\-\-\-\-
       mthreads\-gmi:2.0.0           Driver Version:3.0.0
   \-\-\-\-\-\-\-\-\-\-\-\-\-\-\-\-\-\-\-\-\-\-\-\-\-\-\-\-\-\-\-\-\-\-\-\-\-\-\-\-\-\-\-\-\-\-\-\-\-\-\-\-\-\-\-\-\-\-\-\-\-\-\-
   ID   Name           |PCIe                |%GPU  Mem
        Device Type    |Pcie Lane Width     |Temp  MPC Capable
                                            |      ECC Mode
   +\-\-\-\-\-\-\-\-\-\-\-\-\-\-\-\-\-\-\-\-\-\-\-\-\-\-\-\-\-\-\-\-\-\-\-\-\-\-\-\-\-\-\-\-\-\-\-\-\-\-\-\-\-\-\-\-\-\-\-\-\-+
   0    MTT S80        |00000000:01:00.0    |0%    3419MiB(16384MiB)
        Physical       |16x(16x)            |59C   YES
                                            |      N/A
   \-\-\-\-\-\-\-\-\-\-\-\-\-\-\-\-\-\-\-\-\-\-\-\-\-\-\-\-\-\-\-\-\-\-\-\-\-\-\-\-\-\-\-\-\-\-\-\-\-\-\-\-\-\-\-\-\-\-\-\-\-\-\-

   \-\-\-\-\-\-\-\-\-\-\-\-\-\-\-\-\-\-\-\-\-\-\-\-\-\-\-\-\-\-\-\-\-\-\-\-\-\-\-\-\-\-\-\-\-\-\-\-\-\-\-\-\-\-\-\-\-\-\-\-\-\-\-
   Processes:
   ID   PID       Process name                         GPU Memory
                                                            Usage
   +\-\-\-\-\-\-\-\-\-\-\-\-\-\-\-\-\-\-\-\-\-\-\-\-\-\-\-\-\-\-\-\-\-\-\-\-\-\-\-\-\-\-\-\-\-\-\-\-\-\-\-\-\-\-\-\-\-\-\-\-\-+
      No running processes found
   \-\-\-\-\-\-\-\-\-\-\-\-\-\-\-\-\-\-\-\-\-\-\-\-\-\-\-\-\-\-\-\-\-\-\-\-\-\-\-\-\-\-\-\-\-\-\-\-\-\-\-\-\-\-\-\-\-\-\-\-\-\-\-

.fi
.RE

.SS MUSA\_VISIBLE\_DEVICES
.PP
RamaLama respects the \fB\fCMUSA\_VISIBLE\_DEVICES\fR environment variable if it's already set in your environment. If not set, RamaLama will default to using all the GPU detected by mthreads\-gmi.

.PP
You can specify which GPU devices should be visible to RamaLama by setting this variable before running RamaLama commands:

.PP
.RS

.nf
export MUSA\_VISIBLE\_DEVICES="0,1"  # Use GPUs 0 and 1
ramalama run granite

.fi
.RE

.PP
This is particularly useful in multi\-GPU systems where you want to dedicate specific GPUs to different workloads.

.SH HISTORY
.PP
May 2025, Originally compiled by Xiaodong Ye 
\[la]yeahdongcn@gmail.com\[ra]
