.TH "ramalama-daemon 1" 
.nh
.ad l

.SH NAME
.PP
ramalama\-daemon \- run a RamaLama REST server

.SH SYNOPSIS
.PP
\fBramalama daemon\fP [\fIoptions\fP] [start|run]

.SH DESCRIPTION
.PP
Inspect the specified AI Model about additional information
like the repository, its metadata and tensor information.

.SH OPTIONS
.SS \fB\-\-help\fP, \fB\-h\fP
.PP
Print usage message

.SH COMMANDS
.SS \fBstart\fP
.PP
pepares to run a new RamaLama REST server so it will be run either inside a RamaLama container or on the host

.SS \fBrun\fP
.PP
start a new RamaLama REST server

.SH EXAMPLES
.PP
Inspect the smollm:135m model for basic information

.PP
.RS

.nf
$ ramalama inspect smollm:135m
smollm:135m
   Path: /var/lib/ramalama/models/ollama/smollm:135m
   Registry: ollama
   Format: GGUF
   Version: 3
   Endianness: little
   Metadata: 39 entries
   Tensors: 272 entries

.fi
.RE

.PP
Inspect the smollm:135m model for all information in json format

.PP
.RS

.nf
$ ramalama inspect smollm:135m \-\-all \-\-json
{
    "Name": "smollm:135m",
    "Path": "/home/mengel/.local/share/ramalama/models/ollama/smollm:135m",
    "Registry": "ollama",
    "Format": "GGUF",
    "Version": 3,
    "LittleEndian": true,
    "Metadata": {
        "general.architecture": "llama",
        "general.base\_model.0.name": "SmolLM 135M",
        "general.base\_model.0.organization": "HuggingFaceTB",
        "general.base\_model.0.repo\_url": "https://huggingface.co/HuggingFaceTB/SmolLM\-135M",
        ...
    },
    "Tensors": [
        {
            "dimensions": [
                576,
                49152
            ],
            "n\_dimensions": 2,
            "name": "token\_embd.weight",
            "offset": 0,
            "type": 8
        },
        ...
    ]
}

.fi
.RE

.SH SEE ALSO
.PP
\fBramalama(1)\fP

.SH HISTORY
.PP
Feb 2025, Originally compiled by Michael Engel 
\[la]mengel@redhat.com\[ra]
