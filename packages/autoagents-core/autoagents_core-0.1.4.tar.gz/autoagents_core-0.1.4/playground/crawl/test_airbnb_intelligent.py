import os
import sys
sys.path.append(os.path.abspath(os.path.join(os.path.dirname(__file__), '../../')))

from src.autoagents_core.client.CrawlClient import CrawlClient, SiteConfig
from src.autoagents_core.client.ChatClient import ChatClient
from pydantic import BaseModel
from typing import List, Optional

def main():
    # å®šä¹‰æ•°æ® Schema
    class Review(BaseModel):
        name: str
        city: str
        review: str
        date: Optional[str] = None  # å…è®¸dateä¸ºç©º

    class ReviewList(BaseModel):
        reviews: List[Review]

    chat_client = ChatClient(
        agent_id="7e46d18945fc49379063e3057a143c58",
        personal_auth_key="339859fa69934ea8b2b0ebd19d94d7f1",
        personal_auth_secret="93TsBecJplOawEipqAdF7TJ0g4IoBMtA",
        base_url="https://uat.agentspro.cn"
    )
    client = CrawlClient(chat_client)

    print("=" * 60)
    print("ğŸ§  æ™ºèƒ½åŠ è½½ç³»ç»Ÿ - Trip.com è¯„è®ºæå–")
    print("ğŸ¯ ç›®æ ‡ï¼šæå–3ä»¶ã®å£ã‚³ãƒŸï¼ˆTrip.comè¯„è®ºï¼‰")
    print("=" * 60)

    # æ–¹æ¡ˆä¸€ï¼šä½¿ç”¨è‡ªå®šä¹‰é…ç½®ï¼ŒæŒ‡å®šæœŸæœ›æ•°é‡
    custom_trip_config = SiteConfig(
        name="Trip.comæ™ºèƒ½åŠ è½½ç‰ˆ",
        selectors=[
            '[class*="review"]', 
            '[class*="comment"]',
            '[data-testid*="review"]',
            '.user-review',
            '.review-item'
        ],
        wait_time=3000,
        scroll_behavior=True,
        custom_actions=[
            {"action": "wait", "params": {"time": 3000}},
            {"action": "click_if_exists", "params": {"selectors": [
                'button:has-text("ã™ã¹ã¦ã®å£ã‚³ãƒŸã‚’è¡¨ç¤º")',
                'button:has-text("Show all reviews")',
                'a:has-text("ã™ã¹ã¦ã®å£ã‚³ãƒŸã‚’è¡¨ç¤º")',
                'a:has-text("Show all reviews")',
                'a:has-text("å£ã‚³ãƒŸã‚’è¦‹ã‚‹")',
                'a:has-text("ãƒ¬ãƒ“ãƒ¥ãƒ¼ã‚’è¦‹ã‚‹")',
                '[data-testid*="show-all"]',
                '[data-testid*="read-all"]',
                '.show-all-reviews',
                '[class*="show-all"]',
                '[href*="review"]'
            ]}},
            {"action": "wait", "params": {"time": 4000}},
            {"action": "scroll", "params": {"direction": "bottom"}},
            {"action": "wait", "params": {"time": 2000}}
        ]
    )

    # æµ‹è¯•çˆ¬å–
    result = client.scrape_url(
        url="https://travel.rakuten.co.jp/HOTEL/189204/189204.html",
        schema=ReviewList,
        prompt="Extract all reviews with name, city, review content, and date",
        formats=["extract"],
        custom_config=custom_trip_config
    )

    print(f"\nğŸ† æœ€ç»ˆç»“æœ:")
    print(f"ğŸ“Š æå–çš„è¯„è®ºæ•°é‡: {len(result['extract'].reviews)}")
    print(f"ğŸ¯ æœŸæœ›æ•°é‡: 3")
    print(f"ğŸ“ˆ æˆåŠŸç‡: {len(result['extract'].reviews)/3*100:.1f}%")

    # æ˜¾ç¤ºå‰3ä¸ªè¯„è®ºä½œä¸ºç¤ºä¾‹
    print(f"\nğŸ“ è¯„è®ºç¤ºä¾‹ (å‰3ä¸ª):")
    for i, review in enumerate(result['extract'].reviews[:3], 1):
        print(f"{i}. {review.name} ({review.city}): {review.review[:50]}...")

if __name__ == "__main__":
    main() 