# pylint: disable=line-too-long,useless-suppression,too-many-lines
# coding=utf-8
# --------------------------------------------------------------------------
# Copyright (c) Microsoft Corporation. All rights reserved.
# Licensed under the MIT License. See License.txt in the project root for license information.
# Code generated by Microsoft (R) Python Code Generator.
# Changes may cause incorrect behavior and will be lost if the code is regenerated.
# --------------------------------------------------------------------------
# pylint: disable=useless-super-delegation

import datetime
from typing import Any, Literal, Mapping, Optional, TYPE_CHECKING, Union, overload

from ...agents._utils.model_base import Model as _Model, rest_discriminator, rest_field
from ._enums import (
    AnnotationType,
    CodeInterpreterOutputType,
    ComputerActionType,
    ComputerToolCallOutputItemOutputType,
    ItemContentType,
    ItemType,
    LocationType,
    ReasoningItemSummaryPartType,
    ResponseStreamEventType,
    ResponseTextFormatConfigurationType,
    ResponsesMessageRole,
    ToolChoiceObjectType,
    ToolType,
    WebSearchActionType,
)

if TYPE_CHECKING:
    from .. import models as _models
    from ...agents import _types, models as _azure_ai_agents_models5


class Tool(_Model):
    """Tool.

    You probably want to use the sub-classes and not this class directly. Known sub-classes are:
    A2ATool, AzureAISearchAgentTool, BingCustomSearchAgentTool, BingGroundingAgentTool,
    BrowserAutomationAgentTool, CaptureSemanticEventsTool, CaptureStructuredOutputsTool,
    CodeInterpreterTool, ComputerUsePreviewTool, ConnectedAgentAgentTool, MicrosoftFabricAgentTool,
    FileSearchTool, FunctionTool, ImageGenTool, LocalShellTool, MCPTool, OpenApiAgentTool,
    SharepointAgentTool, WebSearchPreviewTool

    :ivar type: Required. Known values are: "file_search", "function", "computer_use_preview",
     "web_search_preview", "mcp", "code_interpreter", "image_generation", "local_shell",
     "bing_grounding", "browser_automation", "fabric_dataagent", "sharepoint_grounding",
     "azure_ai_search", "openapi", "bing_custom_search", "connected_agent",
     "capture_structured_outputs", "capture_semantic_events", and "a2a".
    :vartype type: str or ~openai.models.ToolType
    """

    __mapping__: dict[str, _Model] = {}
    type: str = rest_discriminator(name="type", visibility=["read", "create", "update", "delete", "query"])
    """Required. Known values are: \"file_search\", \"function\", \"computer_use_preview\",
     \"web_search_preview\", \"mcp\", \"code_interpreter\", \"image_generation\", \"local_shell\",
     \"bing_grounding\", \"browser_automation\", \"fabric_dataagent\", \"sharepoint_grounding\",
     \"azure_ai_search\", \"openapi\", \"bing_custom_search\", \"connected_agent\",
     \"capture_structured_outputs\", \"capture_semantic_events\", and \"a2a\"."""

    @overload
    def __init__(
        self,
        *,
        type: str,
    ) -> None: ...

    @overload
    def __init__(self, mapping: Mapping[str, Any]) -> None:
        """
        :param mapping: raw JSON to initialize the model.
        :type mapping: Mapping[str, Any]
        """

    def __init__(self, *args: Any, **kwargs: Any) -> None:
        super().__init__(*args, **kwargs)


class Annotation(_Model):
    """Annotation.

    You probably want to use the sub-classes and not this class directly. Known sub-classes are:
    AnnotationFileCitation, AnnotationFilePath, AnnotationUrlCitation

    :ivar type: Required. Known values are: "file_citation", "url_citation", "file_path", and
     "container_file_citation".
    :vartype type: str or ~openai.models.AnnotationType
    """

    __mapping__: dict[str, _Model] = {}
    type: str = rest_discriminator(name="type", visibility=["read", "create", "update", "delete", "query"])
    """Required. Known values are: \"file_citation\", \"url_citation\", \"file_path\", and
     \"container_file_citation\"."""

    @overload
    def __init__(
        self,
        *,
        type: str,
    ) -> None: ...

    @overload
    def __init__(self, mapping: Mapping[str, Any]) -> None:
        """
        :param mapping: raw JSON to initialize the model.
        :type mapping: Mapping[str, Any]
        """

    def __init__(self, *args: Any, **kwargs: Any) -> None:
        super().__init__(*args, **kwargs)


class AnnotationFileCitation(Annotation, discriminator="file_citation"):
    """A citation to a file.

    :ivar type: The type of the file citation. Always ``file_citation``. Required.
    :vartype type: str or ~openai.models.FILE_CITATION
    :ivar file_id: The ID of the file. Required.
    :vartype file_id: str
    :ivar index: The index of the file in the list of files. Required.
    :vartype index: int
    :ivar filename: The filename of the file cited. Required.
    :vartype filename: str
    """

    type: Literal[AnnotationType.FILE_CITATION] = rest_discriminator(name="type", visibility=["read", "create", "update", "delete", "query"])  # type: ignore
    """The type of the file citation. Always ``file_citation``. Required."""
    file_id: str = rest_field(visibility=["read", "create", "update", "delete", "query"])
    """The ID of the file. Required."""
    index: int = rest_field(visibility=["read", "create", "update", "delete", "query"])
    """The index of the file in the list of files. Required."""
    filename: str = rest_field(visibility=["read", "create", "update", "delete", "query"])
    """The filename of the file cited. Required."""

    @overload
    def __init__(
        self,
        *,
        file_id: str,
        index: int,
        filename: str,
    ) -> None: ...

    @overload
    def __init__(self, mapping: Mapping[str, Any]) -> None:
        """
        :param mapping: raw JSON to initialize the model.
        :type mapping: Mapping[str, Any]
        """

    def __init__(self, *args: Any, **kwargs: Any) -> None:
        super().__init__(*args, **kwargs)
        self.type = AnnotationType.FILE_CITATION  # type: ignore


class AnnotationFilePath(Annotation, discriminator="file_path"):
    """A path to a file.

    :ivar type: The type of the file path. Always ``file_path``. Required.
    :vartype type: str or ~openai.models.FILE_PATH
    :ivar file_id: The ID of the file. Required.
    :vartype file_id: str
    :ivar index: The index of the file in the list of files. Required.
    :vartype index: int
    """

    type: Literal[AnnotationType.FILE_PATH] = rest_discriminator(name="type", visibility=["read", "create", "update", "delete", "query"])  # type: ignore
    """The type of the file path. Always ``file_path``. Required."""
    file_id: str = rest_field(visibility=["read", "create", "update", "delete", "query"])
    """The ID of the file. Required."""
    index: int = rest_field(visibility=["read", "create", "update", "delete", "query"])
    """The index of the file in the list of files. Required."""

    @overload
    def __init__(
        self,
        *,
        file_id: str,
        index: int,
    ) -> None: ...

    @overload
    def __init__(self, mapping: Mapping[str, Any]) -> None:
        """
        :param mapping: raw JSON to initialize the model.
        :type mapping: Mapping[str, Any]
        """

    def __init__(self, *args: Any, **kwargs: Any) -> None:
        super().__init__(*args, **kwargs)
        self.type = AnnotationType.FILE_PATH  # type: ignore


class AnnotationUrlCitation(Annotation, discriminator="url_citation"):
    """A citation for a web resource used to generate a model response.

    :ivar type: The type of the URL citation. Always ``url_citation``. Required.
    :vartype type: str or ~openai.models.URL_CITATION
    :ivar url: The URL of the web resource. Required.
    :vartype url: str
    :ivar start_index: The index of the first character of the URL citation in the message.
     Required.
    :vartype start_index: int
    :ivar end_index: The index of the last character of the URL citation in the message. Required.
    :vartype end_index: int
    :ivar title: The title of the web resource. Required.
    :vartype title: str
    """

    type: Literal[AnnotationType.URL_CITATION] = rest_discriminator(name="type", visibility=["read", "create", "update", "delete", "query"])  # type: ignore
    """The type of the URL citation. Always ``url_citation``. Required."""
    url: str = rest_field(visibility=["read", "create", "update", "delete", "query"])
    """The URL of the web resource. Required."""
    start_index: int = rest_field(visibility=["read", "create", "update", "delete", "query"])
    """The index of the first character of the URL citation in the message. Required."""
    end_index: int = rest_field(visibility=["read", "create", "update", "delete", "query"])
    """The index of the last character of the URL citation in the message. Required."""
    title: str = rest_field(visibility=["read", "create", "update", "delete", "query"])
    """The title of the web resource. Required."""

    @overload
    def __init__(
        self,
        *,
        url: str,
        start_index: int,
        end_index: int,
        title: str,
    ) -> None: ...

    @overload
    def __init__(self, mapping: Mapping[str, Any]) -> None:
        """
        :param mapping: raw JSON to initialize the model.
        :type mapping: Mapping[str, Any]
        """

    def __init__(self, *args: Any, **kwargs: Any) -> None:
        super().__init__(*args, **kwargs)
        self.type = AnnotationType.URL_CITATION  # type: ignore


class Location(_Model):
    """Location.

    You probably want to use the sub-classes and not this class directly. Known sub-classes are:
    ApproximateLocation

    :ivar type: Required. "approximate"
    :vartype type: str or ~openai.models.LocationType
    """

    __mapping__: dict[str, _Model] = {}
    type: str = rest_discriminator(name="type", visibility=["read", "create", "update", "delete", "query"])
    """Required. \"approximate\""""

    @overload
    def __init__(
        self,
        *,
        type: str,
    ) -> None: ...

    @overload
    def __init__(self, mapping: Mapping[str, Any]) -> None:
        """
        :param mapping: raw JSON to initialize the model.
        :type mapping: Mapping[str, Any]
        """

    def __init__(self, *args: Any, **kwargs: Any) -> None:
        super().__init__(*args, **kwargs)


class ApproximateLocation(Location, discriminator="approximate"):
    """ApproximateLocation.

    :ivar type: Required.
    :vartype type: str or ~openai.models.APPROXIMATE
    :ivar country:
    :vartype country: str
    :ivar region:
    :vartype region: str
    :ivar city:
    :vartype city: str
    :ivar timezone:
    :vartype timezone: str
    """

    type: Literal[LocationType.APPROXIMATE] = rest_discriminator(name="type", visibility=["read", "create", "update", "delete", "query"])  # type: ignore
    """Required."""
    country: Optional[str] = rest_field(visibility=["read", "create", "update", "delete", "query"])
    region: Optional[str] = rest_field(visibility=["read", "create", "update", "delete", "query"])
    city: Optional[str] = rest_field(visibility=["read", "create", "update", "delete", "query"])
    timezone: Optional[str] = rest_field(visibility=["read", "create", "update", "delete", "query"])

    @overload
    def __init__(
        self,
        *,
        country: Optional[str] = None,
        region: Optional[str] = None,
        city: Optional[str] = None,
        timezone: Optional[str] = None,
    ) -> None: ...

    @overload
    def __init__(self, mapping: Mapping[str, Any]) -> None:
        """
        :param mapping: raw JSON to initialize the model.
        :type mapping: Mapping[str, Any]
        """

    def __init__(self, *args: Any, **kwargs: Any) -> None:
        super().__init__(*args, **kwargs)
        self.type = LocationType.APPROXIMATE  # type: ignore


class CodeInterpreterOutput(_Model):
    """CodeInterpreterOutput.

    You probably want to use the sub-classes and not this class directly. Known sub-classes are:
    CodeInterpreterOutputImage, CodeInterpreterOutputLogs

    :ivar type: Required. Known values are: "logs" and "image".
    :vartype type: str or ~openai.models.CodeInterpreterOutputType
    """

    __mapping__: dict[str, _Model] = {}
    type: str = rest_discriminator(name="type", visibility=["read", "create", "update", "delete", "query"])
    """Required. Known values are: \"logs\" and \"image\"."""

    @overload
    def __init__(
        self,
        *,
        type: str,
    ) -> None: ...

    @overload
    def __init__(self, mapping: Mapping[str, Any]) -> None:
        """
        :param mapping: raw JSON to initialize the model.
        :type mapping: Mapping[str, Any]
        """

    def __init__(self, *args: Any, **kwargs: Any) -> None:
        super().__init__(*args, **kwargs)


class CodeInterpreterOutputImage(CodeInterpreterOutput, discriminator="image"):
    """The image output from the code interpreter.

    :ivar type: The type of the output. Always 'image'. Required.
    :vartype type: str or ~openai.models.IMAGE
    :ivar url: The URL of the image output from the code interpreter. Required.
    :vartype url: str
    """

    type: Literal[CodeInterpreterOutputType.IMAGE] = rest_discriminator(name="type", visibility=["read", "create", "update", "delete", "query"])  # type: ignore
    """The type of the output. Always 'image'. Required."""
    url: str = rest_field(visibility=["read", "create", "update", "delete", "query"])
    """The URL of the image output from the code interpreter. Required."""

    @overload
    def __init__(
        self,
        *,
        url: str,
    ) -> None: ...

    @overload
    def __init__(self, mapping: Mapping[str, Any]) -> None:
        """
        :param mapping: raw JSON to initialize the model.
        :type mapping: Mapping[str, Any]
        """

    def __init__(self, *args: Any, **kwargs: Any) -> None:
        super().__init__(*args, **kwargs)
        self.type = CodeInterpreterOutputType.IMAGE  # type: ignore


class CodeInterpreterOutputLogs(CodeInterpreterOutput, discriminator="logs"):
    """The logs output from the code interpreter.

    :ivar type: The type of the output. Always 'logs'. Required.
    :vartype type: str or ~openai.models.LOGS
    :ivar logs: The logs output from the code interpreter. Required.
    :vartype logs: str
    """

    type: Literal[CodeInterpreterOutputType.LOGS] = rest_discriminator(name="type", visibility=["read", "create", "update", "delete", "query"])  # type: ignore
    """The type of the output. Always 'logs'. Required."""
    logs: str = rest_field(visibility=["read", "create", "update", "delete", "query"])
    """The logs output from the code interpreter. Required."""

    @overload
    def __init__(
        self,
        *,
        logs: str,
    ) -> None: ...

    @overload
    def __init__(self, mapping: Mapping[str, Any]) -> None:
        """
        :param mapping: raw JSON to initialize the model.
        :type mapping: Mapping[str, Any]
        """

    def __init__(self, *args: Any, **kwargs: Any) -> None:
        super().__init__(*args, **kwargs)
        self.type = CodeInterpreterOutputType.LOGS  # type: ignore


class CodeInterpreterTool(Tool, discriminator="code_interpreter"):
    """A tool that runs Python code to help generate a response to a prompt.

    :ivar type: The type of the code interpreter tool. Always ``code_interpreter``. Required.
    :vartype type: str or ~openai.models.CODE_INTERPRETER
    :ivar container: The code interpreter container. Can be a container ID or an object that
     specifies uploaded file IDs to make available to your code. Required. Is either a str type or a
     CodeInterpreterToolAuto type.
    :vartype container: str or ~openai.models.CodeInterpreterToolAuto
    """

    type: Literal[ToolType.CODE_INTERPRETER] = rest_discriminator(name="type", visibility=["read", "create", "update", "delete", "query"])  # type: ignore
    """The type of the code interpreter tool. Always ``code_interpreter``. Required."""
    container: Union[str, "_models.CodeInterpreterToolAuto"] = rest_field(
        visibility=["read", "create", "update", "delete", "query"]
    )
    """The code interpreter container. Can be a container ID or an object that
     specifies uploaded file IDs to make available to your code. Required. Is either a str type or a
     CodeInterpreterToolAuto type."""

    @overload
    def __init__(
        self,
        *,
        container: Union[str, "_models.CodeInterpreterToolAuto"],
    ) -> None: ...

    @overload
    def __init__(self, mapping: Mapping[str, Any]) -> None:
        """
        :param mapping: raw JSON to initialize the model.
        :type mapping: Mapping[str, Any]
        """

    def __init__(self, *args: Any, **kwargs: Any) -> None:
        super().__init__(*args, **kwargs)
        self.type = ToolType.CODE_INTERPRETER  # type: ignore


class CodeInterpreterToolAuto(_Model):
    """Configuration for a code interpreter container. Optionally specify the IDs
    of the files to run the code on.

    :ivar type: Always ``auto``. Required. Default value is "auto".
    :vartype type: str
    :ivar file_ids: An optional list of uploaded files to make available to your code.
    :vartype file_ids: list[str]
    """

    type: Literal["auto"] = rest_field(visibility=["read", "create", "update", "delete", "query"])
    """Always ``auto``. Required. Default value is \"auto\"."""
    file_ids: Optional[list[str]] = rest_field(visibility=["read", "create", "update", "delete", "query"])
    """An optional list of uploaded files to make available to your code."""

    @overload
    def __init__(
        self,
        *,
        file_ids: Optional[list[str]] = None,
    ) -> None: ...

    @overload
    def __init__(self, mapping: Mapping[str, Any]) -> None:
        """
        :param mapping: raw JSON to initialize the model.
        :type mapping: Mapping[str, Any]
        """

    def __init__(self, *args: Any, **kwargs: Any) -> None:
        super().__init__(*args, **kwargs)
        self.type: Literal["auto"] = "auto"


class ItemParam(_Model):
    """Content item used to generate a response.

    You probably want to use the sub-classes and not this class directly. Known sub-classes are:
    CodeInterpreterToolCallItemParam, ComputerToolCallItemParam, ComputerToolCallOutputItemParam,
    FileSearchToolCallItemParam, FunctionToolCallItemParam, FunctionToolCallOutputItemParam,
    ImageGenToolCallItemParam, ItemReferenceItemParam, LocalShellToolCallItemParam,
    LocalShellToolCallOutputItemParam, MCPApprovalRequestItemParam, MCPApprovalResponseItemParam,
    MCPCallItemParam, MCPListToolsItemParam, ResponsesMessageItemParam, ReasoningItemParam,
    StructuredInputsItemParam, WebSearchToolCallItemParam

    :ivar type: Required. Known values are: "message", "file_search_call", "function_call",
     "function_call_output", "computer_call", "computer_call_output", "web_search_call",
     "reasoning", "item_reference", "image_generation_call", "code_interpreter_call",
     "local_shell_call", "local_shell_call_output", "mcp_list_tools", "mcp_approval_request",
     "mcp_approval_response", "mcp_call", "structured_inputs", "structured_outputs",
     "semantic_event", and "workflow_action".
    :vartype type: str or ~openai.models.ItemType
    """

    __mapping__: dict[str, _Model] = {}
    type: str = rest_discriminator(name="type", visibility=["read", "create", "update", "delete", "query"])
    """Required. Known values are: \"message\", \"file_search_call\", \"function_call\",
     \"function_call_output\", \"computer_call\", \"computer_call_output\", \"web_search_call\",
     \"reasoning\", \"item_reference\", \"image_generation_call\", \"code_interpreter_call\",
     \"local_shell_call\", \"local_shell_call_output\", \"mcp_list_tools\",
     \"mcp_approval_request\", \"mcp_approval_response\", \"mcp_call\", \"structured_inputs\",
     \"structured_outputs\", \"semantic_event\", and \"workflow_action\"."""

    @overload
    def __init__(
        self,
        *,
        type: str,
    ) -> None: ...

    @overload
    def __init__(self, mapping: Mapping[str, Any]) -> None:
        """
        :param mapping: raw JSON to initialize the model.
        :type mapping: Mapping[str, Any]
        """

    def __init__(self, *args: Any, **kwargs: Any) -> None:
        super().__init__(*args, **kwargs)


class CodeInterpreterToolCallItemParam(ItemParam, discriminator="code_interpreter_call"):
    """A tool call to run code.

    :ivar type: Required.
    :vartype type: str or ~openai.models.CODE_INTERPRETER_CALL
    :ivar container_id: The ID of the container used to run the code. Required.
    :vartype container_id: str
    :ivar code: The code to run, or null if not available. Required.
    :vartype code: str
    :ivar outputs: The outputs generated by the code interpreter, such as logs or images.
     Can be null if no outputs are available. Required.
    :vartype outputs: list[~openai.models.CodeInterpreterOutput]
    """

    type: Literal[ItemType.CODE_INTERPRETER_CALL] = rest_discriminator(name="type", visibility=["read", "create", "update", "delete", "query"])  # type: ignore
    """Required."""
    container_id: str = rest_field(visibility=["read", "create", "update", "delete", "query"])
    """The ID of the container used to run the code. Required."""
    code: str = rest_field(visibility=["read", "create", "update", "delete", "query"])
    """The code to run, or null if not available. Required."""
    outputs: list["_models.CodeInterpreterOutput"] = rest_field(
        visibility=["read", "create", "update", "delete", "query"]
    )
    """The outputs generated by the code interpreter, such as logs or images.
     Can be null if no outputs are available. Required."""

    @overload
    def __init__(
        self,
        *,
        container_id: str,
        code: str,
        outputs: list["_models.CodeInterpreterOutput"],
    ) -> None: ...

    @overload
    def __init__(self, mapping: Mapping[str, Any]) -> None:
        """
        :param mapping: raw JSON to initialize the model.
        :type mapping: Mapping[str, Any]
        """

    def __init__(self, *args: Any, **kwargs: Any) -> None:
        super().__init__(*args, **kwargs)
        self.type = ItemType.CODE_INTERPRETER_CALL  # type: ignore


class ItemResource(_Model):
    """Content item used to generate a response.

    You probably want to use the sub-classes and not this class directly. Known sub-classes are:
    CodeInterpreterToolCallItemResource, ComputerToolCallItemResource,
    ComputerToolCallOutputItemResource, FileSearchToolCallItemResource,
    FunctionToolCallItemResource, FunctionToolCallOutputItemResource, ImageGenToolCallItemResource,
    LocalShellToolCallItemResource, LocalShellToolCallOutputItemResource,
    MCPApprovalRequestItemResource, MCPApprovalResponseItemResource, MCPCallItemResource,
    MCPListToolsItemResource, ResponsesMessageItemResource, ReasoningItemResource,
    SemanticEventsOutputItemResource, StructuredInputsItemResource, StructuredOutputsItemResource,
    WebSearchToolCallItemResource, WorkflowActionOutputItemResource

    :ivar type: Required. Known values are: "message", "file_search_call", "function_call",
     "function_call_output", "computer_call", "computer_call_output", "web_search_call",
     "reasoning", "item_reference", "image_generation_call", "code_interpreter_call",
     "local_shell_call", "local_shell_call_output", "mcp_list_tools", "mcp_approval_request",
     "mcp_approval_response", "mcp_call", "structured_inputs", "structured_outputs",
     "semantic_event", and "workflow_action".
    :vartype type: str or ~openai.models.ItemType
    :ivar id: Required.
    :vartype id: str
    """

    __mapping__: dict[str, _Model] = {}
    type: str = rest_discriminator(name="type", visibility=["read", "create", "update", "delete", "query"])
    """Required. Known values are: \"message\", \"file_search_call\", \"function_call\",
     \"function_call_output\", \"computer_call\", \"computer_call_output\", \"web_search_call\",
     \"reasoning\", \"item_reference\", \"image_generation_call\", \"code_interpreter_call\",
     \"local_shell_call\", \"local_shell_call_output\", \"mcp_list_tools\",
     \"mcp_approval_request\", \"mcp_approval_response\", \"mcp_call\", \"structured_inputs\",
     \"structured_outputs\", \"semantic_event\", and \"workflow_action\"."""
    id: str = rest_field(visibility=["read", "create", "update", "delete", "query"])
    """Required."""

    @overload
    def __init__(
        self,
        *,
        type: str,
        id: str,  # pylint: disable=redefined-builtin
    ) -> None: ...

    @overload
    def __init__(self, mapping: Mapping[str, Any]) -> None:
        """
        :param mapping: raw JSON to initialize the model.
        :type mapping: Mapping[str, Any]
        """

    def __init__(self, *args: Any, **kwargs: Any) -> None:
        super().__init__(*args, **kwargs)


class CodeInterpreterToolCallItemResource(ItemResource, discriminator="code_interpreter_call"):
    """A tool call to run code.

    :ivar id: Required.
    :vartype id: str
    :ivar type: Required.
    :vartype type: str or ~openai.models.CODE_INTERPRETER_CALL
    :ivar status: Required. Is one of the following types: Literal["in_progress"],
     Literal["completed"], Literal["incomplete"], Literal["interpreting"], Literal["failed"]
    :vartype status: str or str or str or str or str
    :ivar container_id: The ID of the container used to run the code. Required.
    :vartype container_id: str
    :ivar code: The code to run, or null if not available. Required.
    :vartype code: str
    :ivar outputs: The outputs generated by the code interpreter, such as logs or images.
     Can be null if no outputs are available. Required.
    :vartype outputs: list[~openai.models.CodeInterpreterOutput]
    """

    type: Literal[ItemType.CODE_INTERPRETER_CALL] = rest_discriminator(name="type", visibility=["read", "create", "update", "delete", "query"])  # type: ignore
    """Required."""
    status: Literal["in_progress", "completed", "incomplete", "interpreting", "failed"] = rest_field(
        visibility=["read", "create", "update", "delete", "query"]
    )
    """Required. Is one of the following types: Literal[\"in_progress\"], Literal[\"completed\"],
     Literal[\"incomplete\"], Literal[\"interpreting\"], Literal[\"failed\"]"""
    container_id: str = rest_field(visibility=["read", "create", "update", "delete", "query"])
    """The ID of the container used to run the code. Required."""
    code: str = rest_field(visibility=["read", "create", "update", "delete", "query"])
    """The code to run, or null if not available. Required."""
    outputs: list["_models.CodeInterpreterOutput"] = rest_field(
        visibility=["read", "create", "update", "delete", "query"]
    )
    """The outputs generated by the code interpreter, such as logs or images.
     Can be null if no outputs are available. Required."""

    @overload
    def __init__(
        self,
        *,
        id: str,  # pylint: disable=redefined-builtin
        status: Literal["in_progress", "completed", "incomplete", "interpreting", "failed"],
        container_id: str,
        code: str,
        outputs: list["_models.CodeInterpreterOutput"],
    ) -> None: ...

    @overload
    def __init__(self, mapping: Mapping[str, Any]) -> None:
        """
        :param mapping: raw JSON to initialize the model.
        :type mapping: Mapping[str, Any]
        """

    def __init__(self, *args: Any, **kwargs: Any) -> None:
        super().__init__(*args, **kwargs)
        self.type = ItemType.CODE_INTERPRETER_CALL  # type: ignore


class ComparisonFilter(_Model):
    """A filter used to compare a specified attribute key to a given value using a defined comparison
    operation.

    :ivar type: Specifies the comparison operator: ``eq``, ``ne``, ``gt``, ``gte``, ``lt``,
     ``lte``.

     * `eq`: equals
     * `ne`: not equal
     * `gt`: greater than
     * `gte`: greater than or equal
     * `lt`: less than
     * `lte`: less than or equal. Required. Is one of the following types: Literal["eq"],
     Literal["ne"], Literal["gt"], Literal["gte"], Literal["lt"], Literal["lte"]
    :vartype type: str or str or str or str or str or str
    :ivar key: The key to compare against the value. Required.
    :vartype key: str
    :ivar value: The value to compare against the attribute key; supports string, number, or
     boolean types. Required. Is one of the following types: str, float, bool
    :vartype value: str or float or bool
    """

    type: Literal["eq", "ne", "gt", "gte", "lt", "lte"] = rest_field(
        visibility=["read", "create", "update", "delete", "query"]
    )
    """Specifies the comparison operator: ``eq``, ``ne``, ``gt``, ``gte``, ``lt``, ``lte``.
     
     * `eq`: equals
     * `ne`: not equal
     * `gt`: greater than
     * `gte`: greater than or equal
     * `lt`: less than
     * `lte`: less than or equal. Required. Is one of the following types: Literal[\"eq\"],
     Literal[\"ne\"], Literal[\"gt\"], Literal[\"gte\"], Literal[\"lt\"], Literal[\"lte\"]"""
    key: str = rest_field(visibility=["read", "create", "update", "delete", "query"])
    """The key to compare against the value. Required."""
    value: Union[str, float, bool] = rest_field(visibility=["read", "create", "update", "delete", "query"])
    """The value to compare against the attribute key; supports string, number, or boolean types.
     Required. Is one of the following types: str, float, bool"""

    @overload
    def __init__(
        self,
        *,
        type: Literal["eq", "ne", "gt", "gte", "lt", "lte"],
        key: str,
        value: Union[str, float, bool],
    ) -> None: ...

    @overload
    def __init__(self, mapping: Mapping[str, Any]) -> None:
        """
        :param mapping: raw JSON to initialize the model.
        :type mapping: Mapping[str, Any]
        """

    def __init__(self, *args: Any, **kwargs: Any) -> None:
        super().__init__(*args, **kwargs)


class CompoundFilter(_Model):
    """Combine multiple filters using ``and`` or ``or``.

    :ivar type: Type of operation: ``and`` or ``or``. Required. Is either a Literal["and"] type or
     a Literal["or"] type.
    :vartype type: str or str
    :ivar filters: Array of filters to combine. Items can be ``ComparisonFilter`` or
     ``CompoundFilter``. Required.
    :vartype filters: list[~openai.models.ComparisonFilter or ~openai.models.CompoundFilter]
    """

    type: Literal["and", "or"] = rest_field(visibility=["read", "create", "update", "delete", "query"])
    """Type of operation: ``and`` or ``or``. Required. Is either a Literal[\"and\"] type or a
     Literal[\"or\"] type."""
    filters: list[Union["_models.ComparisonFilter", "_models.CompoundFilter"]] = rest_field(
        visibility=["read", "create", "update", "delete", "query"]
    )
    """Array of filters to combine. Items can be ``ComparisonFilter`` or ``CompoundFilter``. Required."""

    @overload
    def __init__(
        self,
        *,
        type: Literal["and", "or"],
        filters: list[Union["_models.ComparisonFilter", "_models.CompoundFilter"]],
    ) -> None: ...

    @overload
    def __init__(self, mapping: Mapping[str, Any]) -> None:
        """
        :param mapping: raw JSON to initialize the model.
        :type mapping: Mapping[str, Any]
        """

    def __init__(self, *args: Any, **kwargs: Any) -> None:
        super().__init__(*args, **kwargs)


class ComputerAction(_Model):
    """ComputerAction.

    You probably want to use the sub-classes and not this class directly. Known sub-classes are:
    ComputerActionClick, ComputerActionDoubleClick, ComputerActionDrag, ComputerActionKeyPress,
    ComputerActionMove, ComputerActionScreenshot, ComputerActionScroll, ComputerActionTypeKeys,
    ComputerActionWait

    :ivar type: Required. Known values are: "screenshot", "click", "double_click", "scroll",
     "type", "wait", "keypress", "drag", and "move".
    :vartype type: str or ~openai.models.ComputerActionType
    """

    __mapping__: dict[str, _Model] = {}
    type: str = rest_discriminator(name="type", visibility=["read", "create", "update", "delete", "query"])
    """Required. Known values are: \"screenshot\", \"click\", \"double_click\", \"scroll\", \"type\",
     \"wait\", \"keypress\", \"drag\", and \"move\"."""

    @overload
    def __init__(
        self,
        *,
        type: str,
    ) -> None: ...

    @overload
    def __init__(self, mapping: Mapping[str, Any]) -> None:
        """
        :param mapping: raw JSON to initialize the model.
        :type mapping: Mapping[str, Any]
        """

    def __init__(self, *args: Any, **kwargs: Any) -> None:
        super().__init__(*args, **kwargs)


class ComputerActionClick(ComputerAction, discriminator="click"):
    """A click action.

    :ivar type: Specifies the event type. For a click action, this property is
     always set to ``click``. Required.
    :vartype type: str or ~openai.models.CLICK
    :ivar button: Indicates which mouse button was pressed during the click. One of ``left``,
     ``right``, ``wheel``, ``back``, or ``forward``. Required. Is one of the following types:
     Literal["left"], Literal["right"], Literal["wheel"], Literal["back"], Literal["forward"]
    :vartype button: str or str or str or str or str
    :ivar x: The x-coordinate where the click occurred. Required.
    :vartype x: int
    :ivar y: The y-coordinate where the click occurred. Required.
    :vartype y: int
    """

    type: Literal[ComputerActionType.CLICK] = rest_discriminator(name="type", visibility=["read", "create", "update", "delete", "query"])  # type: ignore
    """Specifies the event type. For a click action, this property is
     always set to ``click``. Required."""
    button: Literal["left", "right", "wheel", "back", "forward"] = rest_field(
        visibility=["read", "create", "update", "delete", "query"]
    )
    """Indicates which mouse button was pressed during the click. One of ``left``, ``right``,
     ``wheel``, ``back``, or ``forward``. Required. Is one of the following types:
     Literal[\"left\"], Literal[\"right\"], Literal[\"wheel\"], Literal[\"back\"],
     Literal[\"forward\"]"""
    x: int = rest_field(visibility=["read", "create", "update", "delete", "query"])
    """The x-coordinate where the click occurred. Required."""
    y: int = rest_field(visibility=["read", "create", "update", "delete", "query"])
    """The y-coordinate where the click occurred. Required."""

    @overload
    def __init__(
        self,
        *,
        button: Literal["left", "right", "wheel", "back", "forward"],
        x: int,
        y: int,
    ) -> None: ...

    @overload
    def __init__(self, mapping: Mapping[str, Any]) -> None:
        """
        :param mapping: raw JSON to initialize the model.
        :type mapping: Mapping[str, Any]
        """

    def __init__(self, *args: Any, **kwargs: Any) -> None:
        super().__init__(*args, **kwargs)
        self.type = ComputerActionType.CLICK  # type: ignore


class ComputerActionDoubleClick(ComputerAction, discriminator="double_click"):
    """A double click action.

    :ivar type: Specifies the event type. For a double click action, this property is
     always set to ``double_click``. Required.
    :vartype type: str or ~openai.models.DOUBLE_CLICK
    :ivar x: The x-coordinate where the double click occurred. Required.
    :vartype x: int
    :ivar y: The y-coordinate where the double click occurred. Required.
    :vartype y: int
    """

    type: Literal[ComputerActionType.DOUBLE_CLICK] = rest_discriminator(name="type", visibility=["read", "create", "update", "delete", "query"])  # type: ignore
    """Specifies the event type. For a double click action, this property is
     always set to ``double_click``. Required."""
    x: int = rest_field(visibility=["read", "create", "update", "delete", "query"])
    """The x-coordinate where the double click occurred. Required."""
    y: int = rest_field(visibility=["read", "create", "update", "delete", "query"])
    """The y-coordinate where the double click occurred. Required."""

    @overload
    def __init__(
        self,
        *,
        x: int,
        y: int,
    ) -> None: ...

    @overload
    def __init__(self, mapping: Mapping[str, Any]) -> None:
        """
        :param mapping: raw JSON to initialize the model.
        :type mapping: Mapping[str, Any]
        """

    def __init__(self, *args: Any, **kwargs: Any) -> None:
        super().__init__(*args, **kwargs)
        self.type = ComputerActionType.DOUBLE_CLICK  # type: ignore


class ComputerActionDrag(ComputerAction, discriminator="drag"):
    """A drag action.

    :ivar type: Specifies the event type. For a drag action, this property is
     always set to ``drag``. Required.
    :vartype type: str or ~openai.models.DRAG
    :ivar path: An array of coordinates representing the path of the drag action. Coordinates will
     appear as an array
     of objects, eg

     .. code-block::

        [
          { x: 100, y: 200 },
          { x: 200, y: 300 }
        ]. Required.
    :vartype path: list[~openai.models.Coordinate]
    """

    type: Literal[ComputerActionType.DRAG] = rest_discriminator(name="type", visibility=["read", "create", "update", "delete", "query"])  # type: ignore
    """Specifies the event type. For a drag action, this property is
     always set to ``drag``. Required."""
    path: list["_models.Coordinate"] = rest_field(visibility=["read", "create", "update", "delete", "query"])
    """An array of coordinates representing the path of the drag action. Coordinates will appear as an
     array
     of objects, eg
     
     .. code-block::
     
        [
          { x: 100, y: 200 },
          { x: 200, y: 300 }
        ]. Required."""

    @overload
    def __init__(
        self,
        *,
        path: list["_models.Coordinate"],
    ) -> None: ...

    @overload
    def __init__(self, mapping: Mapping[str, Any]) -> None:
        """
        :param mapping: raw JSON to initialize the model.
        :type mapping: Mapping[str, Any]
        """

    def __init__(self, *args: Any, **kwargs: Any) -> None:
        super().__init__(*args, **kwargs)
        self.type = ComputerActionType.DRAG  # type: ignore


class ComputerActionKeyPress(ComputerAction, discriminator="keypress"):
    """A collection of keypresses the model would like to perform.

    :ivar type: Specifies the event type. For a keypress action, this property is
     always set to ``keypress``. Required.
    :vartype type: str or ~openai.models.KEYPRESS
    :ivar keys_property: The combination of keys the model is requesting to be pressed. This is an
     array of strings, each representing a key. Required.
    :vartype keys_property: list[str]
    """

    type: Literal[ComputerActionType.KEYPRESS] = rest_discriminator(name="type", visibility=["read", "create", "update", "delete", "query"])  # type: ignore
    """Specifies the event type. For a keypress action, this property is
     always set to ``keypress``. Required."""
    keys_property: list[str] = rest_field(name="keys", visibility=["read", "create", "update", "delete", "query"])
    """The combination of keys the model is requesting to be pressed. This is an
     array of strings, each representing a key. Required."""

    @overload
    def __init__(
        self,
        *,
        keys_property: list[str],
    ) -> None: ...

    @overload
    def __init__(self, mapping: Mapping[str, Any]) -> None:
        """
        :param mapping: raw JSON to initialize the model.
        :type mapping: Mapping[str, Any]
        """

    def __init__(self, *args: Any, **kwargs: Any) -> None:
        super().__init__(*args, **kwargs)
        self.type = ComputerActionType.KEYPRESS  # type: ignore


class ComputerActionMove(ComputerAction, discriminator="move"):
    """A mouse move action.

    :ivar type: Specifies the event type. For a move action, this property is
     always set to ``move``. Required.
    :vartype type: str or ~openai.models.MOVE
    :ivar x: The x-coordinate to move to. Required.
    :vartype x: int
    :ivar y: The y-coordinate to move to. Required.
    :vartype y: int
    """

    type: Literal[ComputerActionType.MOVE] = rest_discriminator(name="type", visibility=["read", "create", "update", "delete", "query"])  # type: ignore
    """Specifies the event type. For a move action, this property is
     always set to ``move``. Required."""
    x: int = rest_field(visibility=["read", "create", "update", "delete", "query"])
    """The x-coordinate to move to. Required."""
    y: int = rest_field(visibility=["read", "create", "update", "delete", "query"])
    """The y-coordinate to move to. Required."""

    @overload
    def __init__(
        self,
        *,
        x: int,
        y: int,
    ) -> None: ...

    @overload
    def __init__(self, mapping: Mapping[str, Any]) -> None:
        """
        :param mapping: raw JSON to initialize the model.
        :type mapping: Mapping[str, Any]
        """

    def __init__(self, *args: Any, **kwargs: Any) -> None:
        super().__init__(*args, **kwargs)
        self.type = ComputerActionType.MOVE  # type: ignore


class ComputerActionScreenshot(ComputerAction, discriminator="screenshot"):
    """A screenshot action.

    :ivar type: Specifies the event type. For a screenshot action, this property is
     always set to ``screenshot``. Required.
    :vartype type: str or ~openai.models.SCREENSHOT
    """

    type: Literal[ComputerActionType.SCREENSHOT] = rest_discriminator(name="type", visibility=["read", "create", "update", "delete", "query"])  # type: ignore
    """Specifies the event type. For a screenshot action, this property is
     always set to ``screenshot``. Required."""

    @overload
    def __init__(
        self,
    ) -> None: ...

    @overload
    def __init__(self, mapping: Mapping[str, Any]) -> None:
        """
        :param mapping: raw JSON to initialize the model.
        :type mapping: Mapping[str, Any]
        """

    def __init__(self, *args: Any, **kwargs: Any) -> None:
        super().__init__(*args, **kwargs)
        self.type = ComputerActionType.SCREENSHOT  # type: ignore


class ComputerActionScroll(ComputerAction, discriminator="scroll"):
    """A scroll action.

    :ivar type: Specifies the event type. For a scroll action, this property is
     always set to ``scroll``. Required.
    :vartype type: str or ~openai.models.SCROLL
    :ivar x: The x-coordinate where the scroll occurred. Required.
    :vartype x: int
    :ivar y: The y-coordinate where the scroll occurred. Required.
    :vartype y: int
    :ivar scroll_x: The horizontal scroll distance. Required.
    :vartype scroll_x: int
    :ivar scroll_y: The vertical scroll distance. Required.
    :vartype scroll_y: int
    """

    type: Literal[ComputerActionType.SCROLL] = rest_discriminator(name="type", visibility=["read", "create", "update", "delete", "query"])  # type: ignore
    """Specifies the event type. For a scroll action, this property is
     always set to ``scroll``. Required."""
    x: int = rest_field(visibility=["read", "create", "update", "delete", "query"])
    """The x-coordinate where the scroll occurred. Required."""
    y: int = rest_field(visibility=["read", "create", "update", "delete", "query"])
    """The y-coordinate where the scroll occurred. Required."""
    scroll_x: int = rest_field(visibility=["read", "create", "update", "delete", "query"])
    """The horizontal scroll distance. Required."""
    scroll_y: int = rest_field(visibility=["read", "create", "update", "delete", "query"])
    """The vertical scroll distance. Required."""

    @overload
    def __init__(
        self,
        *,
        x: int,
        y: int,
        scroll_x: int,
        scroll_y: int,
    ) -> None: ...

    @overload
    def __init__(self, mapping: Mapping[str, Any]) -> None:
        """
        :param mapping: raw JSON to initialize the model.
        :type mapping: Mapping[str, Any]
        """

    def __init__(self, *args: Any, **kwargs: Any) -> None:
        super().__init__(*args, **kwargs)
        self.type = ComputerActionType.SCROLL  # type: ignore


class ComputerActionTypeKeys(ComputerAction, discriminator="type"):
    """An action to type in text.

    :ivar type: Specifies the event type. For a type action, this property is
     always set to ``type``. Required.
    :vartype type: str or ~openai.models.TYPE
    :ivar text: The text to type. Required.
    :vartype text: str
    """

    type: Literal[ComputerActionType.TYPE] = rest_discriminator(name="type", visibility=["read", "create", "update", "delete", "query"])  # type: ignore
    """Specifies the event type. For a type action, this property is
     always set to ``type``. Required."""
    text: str = rest_field(visibility=["read", "create", "update", "delete", "query"])
    """The text to type. Required."""

    @overload
    def __init__(
        self,
        *,
        text: str,
    ) -> None: ...

    @overload
    def __init__(self, mapping: Mapping[str, Any]) -> None:
        """
        :param mapping: raw JSON to initialize the model.
        :type mapping: Mapping[str, Any]
        """

    def __init__(self, *args: Any, **kwargs: Any) -> None:
        super().__init__(*args, **kwargs)
        self.type = ComputerActionType.TYPE  # type: ignore


class ComputerActionWait(ComputerAction, discriminator="wait"):
    """A wait action.

    :ivar type: Specifies the event type. For a wait action, this property is
     always set to ``wait``. Required.
    :vartype type: str or ~openai.models.WAIT
    """

    type: Literal[ComputerActionType.WAIT] = rest_discriminator(name="type", visibility=["read", "create", "update", "delete", "query"])  # type: ignore
    """Specifies the event type. For a wait action, this property is
     always set to ``wait``. Required."""

    @overload
    def __init__(
        self,
    ) -> None: ...

    @overload
    def __init__(self, mapping: Mapping[str, Any]) -> None:
        """
        :param mapping: raw JSON to initialize the model.
        :type mapping: Mapping[str, Any]
        """

    def __init__(self, *args: Any, **kwargs: Any) -> None:
        super().__init__(*args, **kwargs)
        self.type = ComputerActionType.WAIT  # type: ignore


class ComputerToolCallItemParam(ItemParam, discriminator="computer_call"):
    """A tool call to a computer use tool. See the
    `computer use guide </docs/guides/tools-computer-use>`_ for more information.

    :ivar type: Required.
    :vartype type: str or ~openai.models.COMPUTER_CALL
    :ivar call_id: An identifier used when responding to the tool call with output. Required.
    :vartype call_id: str
    :ivar action: Required.
    :vartype action: ~openai.models.ComputerAction
    :ivar pending_safety_checks: The pending safety checks for the computer call. Required.
    :vartype pending_safety_checks: list[~openai.models.ComputerToolCallSafetyCheck]
    """

    type: Literal[ItemType.COMPUTER_CALL] = rest_discriminator(name="type", visibility=["read", "create", "update", "delete", "query"])  # type: ignore
    """Required."""
    call_id: str = rest_field(visibility=["read", "create", "update", "delete", "query"])
    """An identifier used when responding to the tool call with output. Required."""
    action: "_models.ComputerAction" = rest_field(visibility=["read", "create", "update", "delete", "query"])
    """Required."""
    pending_safety_checks: list["_models.ComputerToolCallSafetyCheck"] = rest_field(
        visibility=["read", "create", "update", "delete", "query"]
    )
    """The pending safety checks for the computer call. Required."""

    @overload
    def __init__(
        self,
        *,
        call_id: str,
        action: "_models.ComputerAction",
        pending_safety_checks: list["_models.ComputerToolCallSafetyCheck"],
    ) -> None: ...

    @overload
    def __init__(self, mapping: Mapping[str, Any]) -> None:
        """
        :param mapping: raw JSON to initialize the model.
        :type mapping: Mapping[str, Any]
        """

    def __init__(self, *args: Any, **kwargs: Any) -> None:
        super().__init__(*args, **kwargs)
        self.type = ItemType.COMPUTER_CALL  # type: ignore


class ComputerToolCallItemResource(ItemResource, discriminator="computer_call"):
    """A tool call to a computer use tool. See the
    `computer use guide </docs/guides/tools-computer-use>`_ for more information.

    :ivar id: Required.
    :vartype id: str
    :ivar type: Required.
    :vartype type: str or ~openai.models.COMPUTER_CALL
    :ivar status: The status of the item. One of ``in_progress``, ``completed``, or
     ``incomplete``. Populated when items are returned via API. Required. Is one of the following
     types: Literal["in_progress"], Literal["completed"], Literal["incomplete"]
    :vartype status: str or str or str
    :ivar call_id: An identifier used when responding to the tool call with output. Required.
    :vartype call_id: str
    :ivar action: Required.
    :vartype action: ~openai.models.ComputerAction
    :ivar pending_safety_checks: The pending safety checks for the computer call. Required.
    :vartype pending_safety_checks: list[~openai.models.ComputerToolCallSafetyCheck]
    """

    type: Literal[ItemType.COMPUTER_CALL] = rest_discriminator(name="type", visibility=["read", "create", "update", "delete", "query"])  # type: ignore
    """Required."""
    status: Literal["in_progress", "completed", "incomplete"] = rest_field(
        visibility=["read", "create", "update", "delete", "query"]
    )
    """The status of the item. One of ``in_progress``, ``completed``, or
     ``incomplete``. Populated when items are returned via API. Required. Is one of the following
     types: Literal[\"in_progress\"], Literal[\"completed\"], Literal[\"incomplete\"]"""
    call_id: str = rest_field(visibility=["read", "create", "update", "delete", "query"])
    """An identifier used when responding to the tool call with output. Required."""
    action: "_models.ComputerAction" = rest_field(visibility=["read", "create", "update", "delete", "query"])
    """Required."""
    pending_safety_checks: list["_models.ComputerToolCallSafetyCheck"] = rest_field(
        visibility=["read", "create", "update", "delete", "query"]
    )
    """The pending safety checks for the computer call. Required."""

    @overload
    def __init__(
        self,
        *,
        id: str,  # pylint: disable=redefined-builtin
        status: Literal["in_progress", "completed", "incomplete"],
        call_id: str,
        action: "_models.ComputerAction",
        pending_safety_checks: list["_models.ComputerToolCallSafetyCheck"],
    ) -> None: ...

    @overload
    def __init__(self, mapping: Mapping[str, Any]) -> None:
        """
        :param mapping: raw JSON to initialize the model.
        :type mapping: Mapping[str, Any]
        """

    def __init__(self, *args: Any, **kwargs: Any) -> None:
        super().__init__(*args, **kwargs)
        self.type = ItemType.COMPUTER_CALL  # type: ignore


class ComputerToolCallOutputItemOutput(_Model):
    """ComputerToolCallOutputItemOutput.

    You probably want to use the sub-classes and not this class directly. Known sub-classes are:
    ComputerToolCallOutputItemOutputComputerScreenshot

    :ivar type: Required. "computer_screenshot"
    :vartype type: str or ~openai.models.ComputerToolCallOutputItemOutputType
    """

    __mapping__: dict[str, _Model] = {}
    type: str = rest_discriminator(name="type", visibility=["read", "create", "update", "delete", "query"])
    """Required. \"computer_screenshot\""""

    @overload
    def __init__(
        self,
        *,
        type: str,
    ) -> None: ...

    @overload
    def __init__(self, mapping: Mapping[str, Any]) -> None:
        """
        :param mapping: raw JSON to initialize the model.
        :type mapping: Mapping[str, Any]
        """

    def __init__(self, *args: Any, **kwargs: Any) -> None:
        super().__init__(*args, **kwargs)


class ComputerToolCallOutputItemOutputComputerScreenshot(
    ComputerToolCallOutputItemOutput, discriminator="computer_screenshot"
):  # pylint: disable=name-too-long
    """ComputerToolCallOutputItemOutputComputerScreenshot.

    :ivar type: Required.
    :vartype type: str or ~openai.models.SCREENSHOT
    :ivar image_url:
    :vartype image_url: str
    :ivar file_id:
    :vartype file_id: str
    """

    type: Literal[ComputerToolCallOutputItemOutputType.SCREENSHOT] = rest_discriminator(name="type", visibility=["read", "create", "update", "delete", "query"])  # type: ignore
    """Required."""
    image_url: Optional[str] = rest_field(visibility=["read", "create", "update", "delete", "query"])
    file_id: Optional[str] = rest_field(visibility=["read", "create", "update", "delete", "query"])

    @overload
    def __init__(
        self,
        *,
        image_url: Optional[str] = None,
        file_id: Optional[str] = None,
    ) -> None: ...

    @overload
    def __init__(self, mapping: Mapping[str, Any]) -> None:
        """
        :param mapping: raw JSON to initialize the model.
        :type mapping: Mapping[str, Any]
        """

    def __init__(self, *args: Any, **kwargs: Any) -> None:
        super().__init__(*args, **kwargs)
        self.type = ComputerToolCallOutputItemOutputType.SCREENSHOT  # type: ignore


class ComputerToolCallOutputItemParam(ItemParam, discriminator="computer_call_output"):
    """The output of a computer tool call.

    :ivar type: Required.
    :vartype type: str or ~openai.models.COMPUTER_CALL_OUTPUT
    :ivar call_id: The ID of the computer tool call that produced the output. Required.
    :vartype call_id: str
    :ivar acknowledged_safety_checks: The safety checks reported by the API that have been
     acknowledged by the
     developer.
    :vartype acknowledged_safety_checks: list[~openai.models.ComputerToolCallSafetyCheck]
    :ivar output: Required.
    :vartype output: ~openai.models.ComputerToolCallOutputItemOutput
    """

    type: Literal[ItemType.COMPUTER_CALL_OUTPUT] = rest_discriminator(name="type", visibility=["read", "create", "update", "delete", "query"])  # type: ignore
    """Required."""
    call_id: str = rest_field(visibility=["read", "create", "update", "delete", "query"])
    """The ID of the computer tool call that produced the output. Required."""
    acknowledged_safety_checks: Optional[list["_models.ComputerToolCallSafetyCheck"]] = rest_field(
        visibility=["read", "create", "update", "delete", "query"]
    )
    """The safety checks reported by the API that have been acknowledged by the
     developer."""
    output: "_models.ComputerToolCallOutputItemOutput" = rest_field(
        visibility=["read", "create", "update", "delete", "query"]
    )
    """Required."""

    @overload
    def __init__(
        self,
        *,
        call_id: str,
        output: "_models.ComputerToolCallOutputItemOutput",
        acknowledged_safety_checks: Optional[list["_models.ComputerToolCallSafetyCheck"]] = None,
    ) -> None: ...

    @overload
    def __init__(self, mapping: Mapping[str, Any]) -> None:
        """
        :param mapping: raw JSON to initialize the model.
        :type mapping: Mapping[str, Any]
        """

    def __init__(self, *args: Any, **kwargs: Any) -> None:
        super().__init__(*args, **kwargs)
        self.type = ItemType.COMPUTER_CALL_OUTPUT  # type: ignore


class ComputerToolCallOutputItemResource(ItemResource, discriminator="computer_call_output"):
    """The output of a computer tool call.

    :ivar id: Required.
    :vartype id: str
    :ivar type: Required.
    :vartype type: str or ~openai.models.COMPUTER_CALL_OUTPUT
    :ivar status: The status of the item. One of ``in_progress``, ``completed``, or
     ``incomplete``. Populated when items are returned via API. Required. Is one of the following
     types: Literal["in_progress"], Literal["completed"], Literal["incomplete"]
    :vartype status: str or str or str
    :ivar call_id: The ID of the computer tool call that produced the output. Required.
    :vartype call_id: str
    :ivar acknowledged_safety_checks: The safety checks reported by the API that have been
     acknowledged by the
     developer.
    :vartype acknowledged_safety_checks: list[~openai.models.ComputerToolCallSafetyCheck]
    :ivar output: Required.
    :vartype output: ~openai.models.ComputerToolCallOutputItemOutput
    """

    type: Literal[ItemType.COMPUTER_CALL_OUTPUT] = rest_discriminator(name="type", visibility=["read", "create", "update", "delete", "query"])  # type: ignore
    """Required."""
    status: Literal["in_progress", "completed", "incomplete"] = rest_field(
        visibility=["read", "create", "update", "delete", "query"]
    )
    """The status of the item. One of ``in_progress``, ``completed``, or
     ``incomplete``. Populated when items are returned via API. Required. Is one of the following
     types: Literal[\"in_progress\"], Literal[\"completed\"], Literal[\"incomplete\"]"""
    call_id: str = rest_field(visibility=["read", "create", "update", "delete", "query"])
    """The ID of the computer tool call that produced the output. Required."""
    acknowledged_safety_checks: Optional[list["_models.ComputerToolCallSafetyCheck"]] = rest_field(
        visibility=["read", "create", "update", "delete", "query"]
    )
    """The safety checks reported by the API that have been acknowledged by the
     developer."""
    output: "_models.ComputerToolCallOutputItemOutput" = rest_field(
        visibility=["read", "create", "update", "delete", "query"]
    )
    """Required."""

    @overload
    def __init__(
        self,
        *,
        id: str,  # pylint: disable=redefined-builtin
        status: Literal["in_progress", "completed", "incomplete"],
        call_id: str,
        output: "_models.ComputerToolCallOutputItemOutput",
        acknowledged_safety_checks: Optional[list["_models.ComputerToolCallSafetyCheck"]] = None,
    ) -> None: ...

    @overload
    def __init__(self, mapping: Mapping[str, Any]) -> None:
        """
        :param mapping: raw JSON to initialize the model.
        :type mapping: Mapping[str, Any]
        """

    def __init__(self, *args: Any, **kwargs: Any) -> None:
        super().__init__(*args, **kwargs)
        self.type = ItemType.COMPUTER_CALL_OUTPUT  # type: ignore


class ComputerToolCallSafetyCheck(_Model):
    """A pending safety check for the computer call.

    :ivar id: The ID of the pending safety check. Required.
    :vartype id: str
    :ivar code: The type of the pending safety check. Required.
    :vartype code: str
    :ivar message: Details about the pending safety check. Required.
    :vartype message: str
    """

    id: str = rest_field(visibility=["read", "create", "update", "delete", "query"])
    """The ID of the pending safety check. Required."""
    code: str = rest_field(visibility=["read", "create", "update", "delete", "query"])
    """The type of the pending safety check. Required."""
    message: str = rest_field(visibility=["read", "create", "update", "delete", "query"])
    """Details about the pending safety check. Required."""

    @overload
    def __init__(
        self,
        *,
        id: str,  # pylint: disable=redefined-builtin
        code: str,
        message: str,
    ) -> None: ...

    @overload
    def __init__(self, mapping: Mapping[str, Any]) -> None:
        """
        :param mapping: raw JSON to initialize the model.
        :type mapping: Mapping[str, Any]
        """

    def __init__(self, *args: Any, **kwargs: Any) -> None:
        super().__init__(*args, **kwargs)


class ComputerUsePreviewTool(Tool, discriminator="computer_use_preview"):
    """A tool that controls a virtual computer. Learn more about the `computer tool
    <https://platform.openai.com/docs/guides/tools-computer-use>`_.

    :ivar type: The type of the computer use tool. Always ``computer_use_preview``. Required.
    :vartype type: str or ~openai.models.COMPUTER_USE_PREVIEW
    :ivar environment: The type of computer environment to control. Required. Is one of the
     following types: Literal["windows"], Literal["mac"], Literal["linux"], Literal["ubuntu"],
     Literal["browser"]
    :vartype environment: str or str or str or str or str
    :ivar display_width: The width of the computer display. Required.
    :vartype display_width: int
    :ivar display_height: The height of the computer display. Required.
    :vartype display_height: int
    """

    type: Literal[ToolType.COMPUTER_USE_PREVIEW] = rest_discriminator(name="type", visibility=["read", "create", "update", "delete", "query"])  # type: ignore
    """The type of the computer use tool. Always ``computer_use_preview``. Required."""
    environment: Literal["windows", "mac", "linux", "ubuntu", "browser"] = rest_field(
        visibility=["read", "create", "update", "delete", "query"]
    )
    """The type of computer environment to control. Required. Is one of the following types:
     Literal[\"windows\"], Literal[\"mac\"], Literal[\"linux\"], Literal[\"ubuntu\"],
     Literal[\"browser\"]"""
    display_width: int = rest_field(visibility=["read", "create", "update", "delete", "query"])
    """The width of the computer display. Required."""
    display_height: int = rest_field(visibility=["read", "create", "update", "delete", "query"])
    """The height of the computer display. Required."""

    @overload
    def __init__(
        self,
        *,
        environment: Literal["windows", "mac", "linux", "ubuntu", "browser"],
        display_width: int,
        display_height: int,
    ) -> None: ...

    @overload
    def __init__(self, mapping: Mapping[str, Any]) -> None:
        """
        :param mapping: raw JSON to initialize the model.
        :type mapping: Mapping[str, Any]
        """

    def __init__(self, *args: Any, **kwargs: Any) -> None:
        super().__init__(*args, **kwargs)
        self.type = ToolType.COMPUTER_USE_PREVIEW  # type: ignore


class ConversationResource(_Model):
    """ConversationResource.

    :ivar id: The unique ID of the conversation. Required.
    :vartype id: str
    :ivar object: The object type, which is always 'conversation'. Required. Default value is
     "conversation".
    :vartype object: str
    :ivar created_at: Required.
    :vartype created_at: ~datetime.datetime
    :ivar metadata: Set of 16 key-value pairs that can be attached to an object. This can be
     useful for storing additional information about the object in a structured
     format, and querying for objects via API or the dashboard.

     Keys are strings with a maximum length of 64 characters. Values are strings
     with a maximum length of 512 characters. Required.
    :vartype metadata: dict[str, str]
    """

    id: str = rest_field(visibility=["read", "create", "update", "delete", "query"])
    """The unique ID of the conversation. Required."""
    object: Literal["conversation"] = rest_field(visibility=["read", "create", "update", "delete", "query"])
    """The object type, which is always 'conversation'. Required. Default value is \"conversation\"."""
    created_at: datetime.datetime = rest_field(
        visibility=["read", "create", "update", "delete", "query"], format="unix-timestamp"
    )
    """Required."""
    metadata: dict[str, str] = rest_field(visibility=["read", "create", "update", "delete", "query"])
    """Set of 16 key-value pairs that can be attached to an object. This can be
     useful for storing additional information about the object in a structured
     format, and querying for objects via API or the dashboard.
     
     Keys are strings with a maximum length of 64 characters. Values are strings
     with a maximum length of 512 characters. Required."""

    @overload
    def __init__(
        self,
        *,
        id: str,  # pylint: disable=redefined-builtin
        created_at: datetime.datetime,
        metadata: dict[str, str],
    ) -> None: ...

    @overload
    def __init__(self, mapping: Mapping[str, Any]) -> None:
        """
        :param mapping: raw JSON to initialize the model.
        :type mapping: Mapping[str, Any]
        """

    def __init__(self, *args: Any, **kwargs: Any) -> None:
        super().__init__(*args, **kwargs)
        self.object: Literal["conversation"] = "conversation"


class Coordinate(_Model):
    """An x/y coordinate pair, e.g. ``{ x: 100, y: 200 }``.

    :ivar x: The x-coordinate. Required.
    :vartype x: int
    :ivar y: The y-coordinate. Required.
    :vartype y: int
    """

    x: int = rest_field(visibility=["read", "create", "update", "delete", "query"])
    """The x-coordinate. Required."""
    y: int = rest_field(visibility=["read", "create", "update", "delete", "query"])
    """The y-coordinate. Required."""

    @overload
    def __init__(
        self,
        *,
        x: int,
        y: int,
    ) -> None: ...

    @overload
    def __init__(self, mapping: Mapping[str, Any]) -> None:
        """
        :param mapping: raw JSON to initialize the model.
        :type mapping: Mapping[str, Any]
        """

    def __init__(self, *args: Any, **kwargs: Any) -> None:
        super().__init__(*args, **kwargs)


class CreateResponse(_Model):
    """CreateResponse.

    :ivar metadata: Set of 16 key-value pairs that can be attached to an object. This can be
     useful for storing additional information about the object in a structured
     format, and querying for objects via API or the dashboard.

     Keys are strings with a maximum length of 64 characters. Values are strings
     with a maximum length of 512 characters.
    :vartype metadata: dict[str, str]
    :ivar temperature: What sampling temperature to use, between 0 and 2. Higher values like 0.8
     will make the output more random, while lower values like 0.2 will make it more focused and
     deterministic.
     We generally recommend altering this or ``top_p`` but not both.
    :vartype temperature: float
    :ivar top_p: An alternative to sampling with temperature, called nucleus sampling,
     where the model considers the results of the tokens with top_p probability
     mass. So 0.1 means only the tokens comprising the top 10% probability mass
     are considered.

     We generally recommend altering this or ``temperature`` but not both.
    :vartype top_p: float
    :ivar user: A unique identifier representing your end-user, which can help OpenAI to monitor
     and detect abuse. `Learn more </docs/guides/safety-best-practices#end-user-ids>`_.
    :vartype user: str
    :ivar service_tier: Note: service_tier is not applicable to Azure OpenAI. Known values are:
     "auto", "default", "flex", "scale", and "priority".
    :vartype service_tier: str or ~openai.models.ServiceTier
    :ivar top_logprobs: An integer between 0 and 20 specifying the number of most likely tokens to
     return at each token position, each with an associated log probability.
    :vartype top_logprobs: int
    :ivar previous_response_id: The unique ID of the previous response to the model. Use this to
     create multi-turn conversations. Learn more about
     `conversation state </docs/guides/conversation-state>`_.
    :vartype previous_response_id: str
    :ivar model: The model deployment to use for the creation of this response.
    :vartype model: str
    :ivar reasoning:
    :vartype reasoning: ~openai.models.Reasoning
    :ivar background: Whether to run the model response in the background.
     `Learn more </docs/guides/background>`_.
    :vartype background: bool
    :ivar max_output_tokens: An upper bound for the number of tokens that can be generated for a
     response, including visible output tokens and `reasoning tokens </docs/guides/reasoning>`_.
    :vartype max_output_tokens: int
    :ivar max_tool_calls: The maximum number of total calls to built-in tools that can be processed
     in a response. This maximum number applies across all built-in tool calls, not per individual
     tool. Any further attempts to call a tool by the model will be ignored.
    :vartype max_tool_calls: int
    :ivar text: Configuration options for a text response from the model. Can be plain
     text or structured JSON data. Learn more:

     * [Text inputs and outputs](/docs/guides/text)
     * [Structured Outputs](/docs/guides/structured-outputs).
    :vartype text: ~openai.models.CreateResponseRequestText
    :ivar tools: An array of tools the model may call while generating a response. You
     can specify which tool to use by setting the ``tool_choice`` parameter.

     The two categories of tools you can provide the model are:



     * **Built-in tools**: Tools that are provided by OpenAI that extend the
     model's capabilities, like file search.
     * **Function calls (custom tools)**: Functions that are defined by you,
     enabling the model to call your own code.
    :vartype tools: list[~openai.models.Tool]
    :ivar tool_choice: How the model should select which tool (or tools) to use when generating
     a response. See the ``tools`` parameter to see how to specify which tools
     the model can call. Is either a Union[str, "_openai_models4.ToolChoiceOptions"] type or a
     ToolChoiceObject type.
    :vartype tool_choice: str or ~openai.models.ToolChoiceOptions or
     ~openai.models.ToolChoiceObject
    :ivar prompt:
    :vartype prompt: ~openai.models.Prompt
    :ivar truncation: The truncation strategy to use for the model response.

     * `auto`: If the context of this response and previous ones exceeds
     the model's context window size, the model will truncate the
     response to fit the context window by dropping input items in the
     middle of the conversation.
     * `disabled` (default): If a model response will exceed the context window
     size for a model, the request will fail with a 400 error. Is either a Literal["auto"] type or a
     Literal["disabled"] type.
    :vartype truncation: str or str
    :ivar input: Text, image, or file inputs to the model, used to generate a response.

     Learn more:

     * [Text inputs and outputs](/docs/guides/text)
     * [Image inputs](/docs/guides/images)
     * [File inputs](/docs/guides/pdf-files)
     * [Conversation state](/docs/guides/conversation-state)
     * [Function calling](/docs/guides/function-calling). Is either a str type or a
     [Union["_openai_models4.ImplicitUserMessage", "_openai_models4.ItemParam"]] type.
    :vartype input: str or list[~openai.models.ImplicitUserMessage or ~openai.models.ItemParam]
    :ivar include: Specify additional output data to include in the model response. Currently
     supported values are:

     * `code_interpreter_call.outputs`: Includes the outputs of python code execution
     in code interpreter tool call items.
     * `computer_call_output.output.image_url`: Include image urls from the computer call output.
     * `file_search_call.results`: Include the search results of
     the file search tool call.
     * `message.input_image.image_url`: Include image urls from the input message.
     * `message.output_text.logprobs`: Include logprobs with assistant messages.
     * `reasoning.encrypted_content`: Includes an encrypted version of reasoning
     tokens in reasoning item outputs. This enables reasoning items to be used in
     multi-turn conversations when using the Responses API statelessly (like
     when the `store` parameter is set to `false`, or when an organization is
     enrolled in the zero data retention program).
    :vartype include: list[str or ~openai.models.Includable]
    :ivar parallel_tool_calls: Whether to allow the model to run tool calls in parallel.
    :vartype parallel_tool_calls: bool
    :ivar store: Whether to store the generated model response for later retrieval via
     API.
    :vartype store: bool
    :ivar instructions: A system (or developer) message inserted into the model's context.

     When using along with ``previous_response_id``, the instructions from a previous
     response will not be carried over to the next response. This makes it simple
     to swap out system (or developer) messages in new responses.
    :vartype instructions: str
    :ivar stream: If set to true, the model response data will be streamed to the client
     as it is generated using `server-sent events
     <https://developer.mozilla.org/en-US/docs/Web/API/Server-sent_events/Using_server-sent_events#Event_stream_format>`_.
     See the `Streaming section below </docs/api-reference/responses-streaming>`_
     for more information.
    :vartype stream: bool
    :ivar conversation: Is either a str type or a CreateResponseRequestConversation1 type.
    :vartype conversation: str or ~openai.models.CreateResponseRequestConversation1
    :ivar agent: The agent to use for generating the response.
    :vartype agent: ~azure.ai.agents.models.AgentReference
    """

    metadata: Optional[dict[str, str]] = rest_field(visibility=["read", "create", "update", "delete", "query"])
    """Set of 16 key-value pairs that can be attached to an object. This can be
     useful for storing additional information about the object in a structured
     format, and querying for objects via API or the dashboard.
     
     Keys are strings with a maximum length of 64 characters. Values are strings
     with a maximum length of 512 characters."""
    temperature: Optional[float] = rest_field(visibility=["read", "create", "update", "delete", "query"])
    """What sampling temperature to use, between 0 and 2. Higher values like 0.8 will make the output
     more random, while lower values like 0.2 will make it more focused and deterministic.
     We generally recommend altering this or ``top_p`` but not both."""
    top_p: Optional[float] = rest_field(visibility=["read", "create", "update", "delete", "query"])
    """An alternative to sampling with temperature, called nucleus sampling,
     where the model considers the results of the tokens with top_p probability
     mass. So 0.1 means only the tokens comprising the top 10% probability mass
     are considered.
     
     We generally recommend altering this or ``temperature`` but not both."""
    user: Optional[str] = rest_field(visibility=["read", "create", "update", "delete", "query"])
    """A unique identifier representing your end-user, which can help OpenAI to monitor and detect
     abuse. `Learn more </docs/guides/safety-best-practices#end-user-ids>`_."""
    service_tier: Optional[Union[str, "_models.ServiceTier"]] = rest_field(
        visibility=["read", "create", "update", "delete", "query"]
    )
    """Note: service_tier is not applicable to Azure OpenAI. Known values are: \"auto\", \"default\",
     \"flex\", \"scale\", and \"priority\"."""
    top_logprobs: Optional[int] = rest_field(visibility=["read", "create", "update", "delete", "query"])
    """An integer between 0 and 20 specifying the number of most likely tokens to return at each token
     position, each with an associated log probability."""
    previous_response_id: Optional[str] = rest_field(visibility=["read", "create", "update", "delete", "query"])
    """The unique ID of the previous response to the model. Use this to
     create multi-turn conversations. Learn more about
     `conversation state </docs/guides/conversation-state>`_."""
    model: Optional[str] = rest_field(visibility=["read", "create", "update", "delete", "query"])
    """The model deployment to use for the creation of this response."""
    reasoning: Optional["_models.Reasoning"] = rest_field(visibility=["read", "create", "update", "delete", "query"])
    background: Optional[bool] = rest_field(visibility=["read", "create", "update", "delete", "query"])
    """Whether to run the model response in the background.
     `Learn more </docs/guides/background>`_."""
    max_output_tokens: Optional[int] = rest_field(visibility=["read", "create", "update", "delete", "query"])
    """An upper bound for the number of tokens that can be generated for a response, including visible
     output tokens and `reasoning tokens </docs/guides/reasoning>`_."""
    max_tool_calls: Optional[int] = rest_field(visibility=["read", "create", "update", "delete", "query"])
    """The maximum number of total calls to built-in tools that can be processed in a response. This
     maximum number applies across all built-in tool calls, not per individual tool. Any further
     attempts to call a tool by the model will be ignored."""
    text: Optional["_models.CreateResponseRequestText"] = rest_field(
        visibility=["read", "create", "update", "delete", "query"]
    )
    """Configuration options for a text response from the model. Can be plain
     text or structured JSON data. Learn more:
     
     * [Text inputs and outputs](/docs/guides/text)
     * [Structured Outputs](/docs/guides/structured-outputs)."""
    tools: Optional[list["_models.Tool"]] = rest_field(visibility=["read", "create", "update", "delete", "query"])
    """An array of tools the model may call while generating a response. You
     can specify which tool to use by setting the ``tool_choice`` parameter.
     
     The two categories of tools you can provide the model are:
     
     
     
     * **Built-in tools**: Tools that are provided by OpenAI that extend the
     model's capabilities, like file search.
     * **Function calls (custom tools)**: Functions that are defined by you,
     enabling the model to call your own code."""
    tool_choice: Optional[Union[str, "_models.ToolChoiceOptions", "_models.ToolChoiceObject"]] = rest_field(
        visibility=["read", "create", "update", "delete", "query"]
    )
    """How the model should select which tool (or tools) to use when generating
     a response. See the ``tools`` parameter to see how to specify which tools
     the model can call. Is either a Union[str, \"_openai_models4.ToolChoiceOptions\"] type or a
     ToolChoiceObject type."""
    prompt: Optional["_models.Prompt"] = rest_field(visibility=["read", "create", "update", "delete", "query"])
    truncation: Optional[Literal["auto", "disabled"]] = rest_field(
        visibility=["read", "create", "update", "delete", "query"]
    )
    """The truncation strategy to use for the model response.
     
     * `auto`: If the context of this response and previous ones exceeds
     the model's context window size, the model will truncate the
     response to fit the context window by dropping input items in the
     middle of the conversation.
     * `disabled` (default): If a model response will exceed the context window
     size for a model, the request will fail with a 400 error. Is either a Literal[\"auto\"] type or
     a Literal[\"disabled\"] type."""
    input: Optional[Union[str, list[Union["_models.ImplicitUserMessage", "_models.ItemParam"]]]] = rest_field(
        visibility=["read", "create", "update", "delete", "query"]
    )
    """Text, image, or file inputs to the model, used to generate a response.
     
     Learn more:
     
     * [Text inputs and outputs](/docs/guides/text)
     * [Image inputs](/docs/guides/images)
     * [File inputs](/docs/guides/pdf-files)
     * [Conversation state](/docs/guides/conversation-state)
     * [Function calling](/docs/guides/function-calling). Is either a str type or a
     [Union[\"_openai_models4.ImplicitUserMessage\", \"_openai_models4.ItemParam\"]] type."""
    include: Optional[list[Union[str, "_models.Includable"]]] = rest_field(
        visibility=["read", "create", "update", "delete", "query"]
    )
    """Specify additional output data to include in the model response. Currently
     supported values are:
     
     * `code_interpreter_call.outputs`: Includes the outputs of python code execution
     in code interpreter tool call items.
     * `computer_call_output.output.image_url`: Include image urls from the computer call output.
     * `file_search_call.results`: Include the search results of
     the file search tool call.
     * `message.input_image.image_url`: Include image urls from the input message.
     * `message.output_text.logprobs`: Include logprobs with assistant messages.
     * `reasoning.encrypted_content`: Includes an encrypted version of reasoning
     tokens in reasoning item outputs. This enables reasoning items to be used in
     multi-turn conversations when using the Responses API statelessly (like
     when the `store` parameter is set to `false`, or when an organization is
     enrolled in the zero data retention program)."""
    parallel_tool_calls: Optional[bool] = rest_field(visibility=["read", "create", "update", "delete", "query"])
    """Whether to allow the model to run tool calls in parallel."""
    store: Optional[bool] = rest_field(visibility=["read", "create", "update", "delete", "query"])
    """Whether to store the generated model response for later retrieval via
     API."""
    instructions: Optional[str] = rest_field(visibility=["read", "create", "update", "delete", "query"])
    """A system (or developer) message inserted into the model's context.
     
     When using along with ``previous_response_id``, the instructions from a previous
     response will not be carried over to the next response. This makes it simple
     to swap out system (or developer) messages in new responses."""
    stream: Optional[bool] = rest_field(visibility=["read", "create", "update", "delete", "query"])
    """If set to true, the model response data will be streamed to the client
     as it is generated using `server-sent events
     <https://developer.mozilla.org/en-US/docs/Web/API/Server-sent_events/Using_server-sent_events#Event_stream_format>`_.
     See the `Streaming section below </docs/api-reference/responses-streaming>`_
     for more information."""
    conversation: Optional[Union[str, "_models.CreateResponseRequestConversation1"]] = rest_field(
        visibility=["read", "create", "update", "delete", "query"]
    )
    """Is either a str type or a CreateResponseRequestConversation1 type."""
    agent: Optional["_azure_ai_agents_models5.AgentReference"] = rest_field(
        visibility=["read", "create", "update", "delete", "query"]
    )
    """The agent to use for generating the response."""

    @overload
    def __init__(  # pylint: disable=too-many-locals
        self,
        *,
        metadata: Optional[dict[str, str]] = None,
        temperature: Optional[float] = None,
        top_p: Optional[float] = None,
        user: Optional[str] = None,
        service_tier: Optional[Union[str, "_models.ServiceTier"]] = None,
        top_logprobs: Optional[int] = None,
        previous_response_id: Optional[str] = None,
        model: Optional[str] = None,
        reasoning: Optional["_models.Reasoning"] = None,
        background: Optional[bool] = None,
        max_output_tokens: Optional[int] = None,
        max_tool_calls: Optional[int] = None,
        text: Optional["_models.CreateResponseRequestText"] = None,
        tools: Optional[list["_models.Tool"]] = None,
        tool_choice: Optional[Union[str, "_models.ToolChoiceOptions", "_models.ToolChoiceObject"]] = None,
        prompt: Optional["_models.Prompt"] = None,
        truncation: Optional[Literal["auto", "disabled"]] = None,
        input: Optional[Union[str, list[Union["_models.ImplicitUserMessage", "_models.ItemParam"]]]] = None,
        include: Optional[list[Union[str, "_models.Includable"]]] = None,
        parallel_tool_calls: Optional[bool] = None,
        store: Optional[bool] = None,
        instructions: Optional[str] = None,
        stream: Optional[bool] = None,
        conversation: Optional[Union[str, "_models.CreateResponseRequestConversation1"]] = None,
        agent: Optional["_azure_ai_agents_models5.AgentReference"] = None,
    ) -> None: ...

    @overload
    def __init__(self, mapping: Mapping[str, Any]) -> None:
        """
        :param mapping: raw JSON to initialize the model.
        :type mapping: Mapping[str, Any]
        """

    def __init__(self, *args: Any, **kwargs: Any) -> None:
        super().__init__(*args, **kwargs)


class CreateResponseRequestConversation1(_Model):
    """CreateResponseRequestConversation1.

    :ivar id: Required.
    :vartype id: str
    """

    id: str = rest_field(visibility=["read", "create", "update", "delete", "query"])
    """Required."""

    @overload
    def __init__(
        self,
        *,
        id: str,  # pylint: disable=redefined-builtin
    ) -> None: ...

    @overload
    def __init__(self, mapping: Mapping[str, Any]) -> None:
        """
        :param mapping: raw JSON to initialize the model.
        :type mapping: Mapping[str, Any]
        """

    def __init__(self, *args: Any, **kwargs: Any) -> None:
        super().__init__(*args, **kwargs)


class CreateResponseRequestText(_Model):
    """CreateResponseRequestText.

    :ivar format:
    :vartype format: ~openai.models.ResponseTextFormatConfiguration
    """

    format: Optional["_models.ResponseTextFormatConfiguration"] = rest_field(
        visibility=["read", "create", "update", "delete", "query"]
    )

    @overload
    def __init__(
        self,
        *,
        format: Optional["_models.ResponseTextFormatConfiguration"] = None,
    ) -> None: ...

    @overload
    def __init__(self, mapping: Mapping[str, Any]) -> None:
        """
        :param mapping: raw JSON to initialize the model.
        :type mapping: Mapping[str, Any]
        """

    def __init__(self, *args: Any, **kwargs: Any) -> None:
        super().__init__(*args, **kwargs)


class DeletedConversationResource(_Model):
    """DeletedConversationResource.

    :ivar object: Required. Default value is "conversation.deleted".
    :vartype object: str
    :ivar deleted: Required.
    :vartype deleted: bool
    :ivar id: Required.
    :vartype id: str
    """

    object: Literal["conversation.deleted"] = rest_field(visibility=["read", "create", "update", "delete", "query"])
    """Required. Default value is \"conversation.deleted\"."""
    deleted: bool = rest_field(visibility=["read", "create", "update", "delete", "query"])
    """Required."""
    id: str = rest_field(visibility=["read", "create", "update", "delete", "query"])
    """Required."""

    @overload
    def __init__(
        self,
        *,
        deleted: bool,
        id: str,  # pylint: disable=redefined-builtin
    ) -> None: ...

    @overload
    def __init__(self, mapping: Mapping[str, Any]) -> None:
        """
        :param mapping: raw JSON to initialize the model.
        :type mapping: Mapping[str, Any]
        """

    def __init__(self, *args: Any, **kwargs: Any) -> None:
        super().__init__(*args, **kwargs)
        self.object: Literal["conversation.deleted"] = "conversation.deleted"


class FileSearchTool(Tool, discriminator="file_search"):
    """A tool that searches for relevant content from uploaded files. Learn more about the `file
    search tool <https://platform.openai.com/docs/guides/tools-file-search>`_.

    :ivar type: The type of the file search tool. Always ``file_search``. Required.
    :vartype type: str or ~openai.models.FILE_SEARCH
    :ivar vector_store_ids: The IDs of the vector stores to search. Required.
    :vartype vector_store_ids: list[str]
    :ivar max_num_results: The maximum number of results to return. This number should be between 1
     and 50 inclusive.
    :vartype max_num_results: int
    :ivar ranking_options: Ranking options for search.
    :vartype ranking_options: ~openai.models.RankingOptions
    :ivar filters: A filter to apply. Is either a ComparisonFilter type or a CompoundFilter type.
    :vartype filters: ~openai.models.ComparisonFilter or ~openai.models.CompoundFilter
    """

    type: Literal[ToolType.FILE_SEARCH] = rest_discriminator(name="type", visibility=["read", "create", "update", "delete", "query"])  # type: ignore
    """The type of the file search tool. Always ``file_search``. Required."""
    vector_store_ids: list[str] = rest_field(visibility=["read", "create", "update", "delete", "query"])
    """The IDs of the vector stores to search. Required."""
    max_num_results: Optional[int] = rest_field(visibility=["read", "create", "update", "delete", "query"])
    """The maximum number of results to return. This number should be between 1 and 50 inclusive."""
    ranking_options: Optional["_models.RankingOptions"] = rest_field(
        visibility=["read", "create", "update", "delete", "query"]
    )
    """Ranking options for search."""
    filters: Optional["_types.Filters"] = rest_field(visibility=["read", "create", "update", "delete", "query"])
    """A filter to apply. Is either a ComparisonFilter type or a CompoundFilter type."""

    @overload
    def __init__(
        self,
        *,
        vector_store_ids: list[str],
        max_num_results: Optional[int] = None,
        ranking_options: Optional["_models.RankingOptions"] = None,
        filters: Optional["_types.Filters"] = None,
    ) -> None: ...

    @overload
    def __init__(self, mapping: Mapping[str, Any]) -> None:
        """
        :param mapping: raw JSON to initialize the model.
        :type mapping: Mapping[str, Any]
        """

    def __init__(self, *args: Any, **kwargs: Any) -> None:
        super().__init__(*args, **kwargs)
        self.type = ToolType.FILE_SEARCH  # type: ignore


class FileSearchToolCallItemParam(ItemParam, discriminator="file_search_call"):
    """The results of a file search tool call. See the
    `file search guide </docs/guides/tools-file-search>`_ for more information.

    :ivar type: Required.
    :vartype type: str or ~openai.models.FILE_SEARCH_CALL
    :ivar queries: The queries used to search for files. Required.
    :vartype queries: list[str]
    :ivar results: The results of the file search tool call.
    :vartype results: list[~openai.models.FileSearchToolCallItemParamResult]
    """

    type: Literal[ItemType.FILE_SEARCH_CALL] = rest_discriminator(name="type", visibility=["read", "create", "update", "delete", "query"])  # type: ignore
    """Required."""
    queries: list[str] = rest_field(visibility=["read", "create", "update", "delete", "query"])
    """The queries used to search for files. Required."""
    results: Optional[list["_models.FileSearchToolCallItemParamResult"]] = rest_field(
        visibility=["read", "create", "update", "delete", "query"]
    )
    """The results of the file search tool call."""

    @overload
    def __init__(
        self,
        *,
        queries: list[str],
        results: Optional[list["_models.FileSearchToolCallItemParamResult"]] = None,
    ) -> None: ...

    @overload
    def __init__(self, mapping: Mapping[str, Any]) -> None:
        """
        :param mapping: raw JSON to initialize the model.
        :type mapping: Mapping[str, Any]
        """

    def __init__(self, *args: Any, **kwargs: Any) -> None:
        super().__init__(*args, **kwargs)
        self.type = ItemType.FILE_SEARCH_CALL  # type: ignore


class FileSearchToolCallItemParamResult(_Model):
    """FileSearchToolCallItemParamResult.

    :ivar file_id: The unique ID of the file.
    :vartype file_id: str
    :ivar text: The text that was retrieved from the file.
    :vartype text: str
    :ivar filename: The name of the file.
    :vartype filename: str
    :ivar attributes:
    :vartype attributes: ~openai.models.VectorStoreFileAttributes
    :ivar score: The relevance score of the file - a value between 0 and 1.
    :vartype score: float
    """

    file_id: Optional[str] = rest_field(visibility=["read", "create", "update", "delete", "query"])
    """The unique ID of the file."""
    text: Optional[str] = rest_field(visibility=["read", "create", "update", "delete", "query"])
    """The text that was retrieved from the file."""
    filename: Optional[str] = rest_field(visibility=["read", "create", "update", "delete", "query"])
    """The name of the file."""
    attributes: Optional["_models.VectorStoreFileAttributes"] = rest_field(
        visibility=["read", "create", "update", "delete", "query"]
    )
    score: Optional[float] = rest_field(visibility=["read", "create", "update", "delete", "query"])
    """The relevance score of the file - a value between 0 and 1."""

    @overload
    def __init__(
        self,
        *,
        file_id: Optional[str] = None,
        text: Optional[str] = None,
        filename: Optional[str] = None,
        attributes: Optional["_models.VectorStoreFileAttributes"] = None,
        score: Optional[float] = None,
    ) -> None: ...

    @overload
    def __init__(self, mapping: Mapping[str, Any]) -> None:
        """
        :param mapping: raw JSON to initialize the model.
        :type mapping: Mapping[str, Any]
        """

    def __init__(self, *args: Any, **kwargs: Any) -> None:
        super().__init__(*args, **kwargs)


class FileSearchToolCallItemResource(ItemResource, discriminator="file_search_call"):
    """The results of a file search tool call. See the
    `file search guide </docs/guides/tools-file-search>`_ for more information.

    :ivar id: Required.
    :vartype id: str
    :ivar type: Required.
    :vartype type: str or ~openai.models.FILE_SEARCH_CALL
    :ivar status: The status of the file search tool call. One of ``in_progress``,
     ``searching``, ``incomplete`` or ``failed``,. Required. Is one of the following types:
     Literal["in_progress"], Literal["searching"], Literal["completed"], Literal["incomplete"],
     Literal["failed"]
    :vartype status: str or str or str or str or str
    :ivar queries: The queries used to search for files. Required.
    :vartype queries: list[str]
    :ivar results: The results of the file search tool call.
    :vartype results: list[~openai.models.FileSearchToolCallItemParamResult]
    """

    type: Literal[ItemType.FILE_SEARCH_CALL] = rest_discriminator(name="type", visibility=["read", "create", "update", "delete", "query"])  # type: ignore
    """Required."""
    status: Literal["in_progress", "searching", "completed", "incomplete", "failed"] = rest_field(
        visibility=["read", "create", "update", "delete", "query"]
    )
    """The status of the file search tool call. One of ``in_progress``,
     ``searching``, ``incomplete`` or ``failed``,. Required. Is one of the following types:
     Literal[\"in_progress\"], Literal[\"searching\"], Literal[\"completed\"],
     Literal[\"incomplete\"], Literal[\"failed\"]"""
    queries: list[str] = rest_field(visibility=["read", "create", "update", "delete", "query"])
    """The queries used to search for files. Required."""
    results: Optional[list["_models.FileSearchToolCallItemParamResult"]] = rest_field(
        visibility=["read", "create", "update", "delete", "query"]
    )
    """The results of the file search tool call."""

    @overload
    def __init__(
        self,
        *,
        id: str,  # pylint: disable=redefined-builtin
        status: Literal["in_progress", "searching", "completed", "incomplete", "failed"],
        queries: list[str],
        results: Optional[list["_models.FileSearchToolCallItemParamResult"]] = None,
    ) -> None: ...

    @overload
    def __init__(self, mapping: Mapping[str, Any]) -> None:
        """
        :param mapping: raw JSON to initialize the model.
        :type mapping: Mapping[str, Any]
        """

    def __init__(self, *args: Any, **kwargs: Any) -> None:
        super().__init__(*args, **kwargs)
        self.type = ItemType.FILE_SEARCH_CALL  # type: ignore


class FunctionTool(Tool, discriminator="function"):
    """Defines a function in your own code the model can choose to call. Learn more about `function
    calling <https://platform.openai.com/docs/guides/function-calling>`_.

    :ivar type: The type of the function tool. Always ``function``. Required.
    :vartype type: str or ~openai.models.FUNCTION
    :ivar name: The name of the function to call. Required.
    :vartype name: str
    :ivar description: A description of the function. Used by the model to determine whether or not
     to call the function.
    :vartype description: str
    :ivar parameters: A JSON schema object describing the parameters of the function. Required.
    :vartype parameters: any
    :ivar strict: Whether to enforce strict parameter validation. Default ``true``. Required.
    :vartype strict: bool
    """

    type: Literal[ToolType.FUNCTION] = rest_discriminator(name="type", visibility=["read", "create", "update", "delete", "query"])  # type: ignore
    """The type of the function tool. Always ``function``. Required."""
    name: str = rest_field(visibility=["read", "create", "update", "delete", "query"])
    """The name of the function to call. Required."""
    description: Optional[str] = rest_field(visibility=["read", "create", "update", "delete", "query"])
    """A description of the function. Used by the model to determine whether or not to call the
     function."""
    parameters: Any = rest_field(visibility=["read", "create", "update", "delete", "query"])
    """A JSON schema object describing the parameters of the function. Required."""
    strict: bool = rest_field(visibility=["read", "create", "update", "delete", "query"])
    """Whether to enforce strict parameter validation. Default ``true``. Required."""

    @overload
    def __init__(
        self,
        *,
        name: str,
        parameters: Any,
        strict: bool,
        description: Optional[str] = None,
    ) -> None: ...

    @overload
    def __init__(self, mapping: Mapping[str, Any]) -> None:
        """
        :param mapping: raw JSON to initialize the model.
        :type mapping: Mapping[str, Any]
        """

    def __init__(self, *args: Any, **kwargs: Any) -> None:
        super().__init__(*args, **kwargs)
        self.type = ToolType.FUNCTION  # type: ignore


class FunctionToolCallItemParam(ItemParam, discriminator="function_call"):
    """A tool call to run a function. See the
    `function calling guide </docs/guides/function-calling>`_ for more information.

    :ivar type: Required.
    :vartype type: str or ~openai.models.FUNCTION_CALL
    :ivar call_id: The unique ID of the function tool call generated by the model. Required.
    :vartype call_id: str
    :ivar name: The name of the function to run. Required.
    :vartype name: str
    :ivar arguments: A JSON string of the arguments to pass to the function. Required.
    :vartype arguments: str
    """

    type: Literal[ItemType.FUNCTION_CALL] = rest_discriminator(name="type", visibility=["read", "create", "update", "delete", "query"])  # type: ignore
    """Required."""
    call_id: str = rest_field(visibility=["read", "create", "update", "delete", "query"])
    """The unique ID of the function tool call generated by the model. Required."""
    name: str = rest_field(visibility=["read", "create", "update", "delete", "query"])
    """The name of the function to run. Required."""
    arguments: str = rest_field(visibility=["read", "create", "update", "delete", "query"])
    """A JSON string of the arguments to pass to the function. Required."""

    @overload
    def __init__(
        self,
        *,
        call_id: str,
        name: str,
        arguments: str,
    ) -> None: ...

    @overload
    def __init__(self, mapping: Mapping[str, Any]) -> None:
        """
        :param mapping: raw JSON to initialize the model.
        :type mapping: Mapping[str, Any]
        """

    def __init__(self, *args: Any, **kwargs: Any) -> None:
        super().__init__(*args, **kwargs)
        self.type = ItemType.FUNCTION_CALL  # type: ignore


class FunctionToolCallItemResource(ItemResource, discriminator="function_call"):
    """A tool call to run a function. See the
    `function calling guide </docs/guides/function-calling>`_ for more information.

    :ivar id: Required.
    :vartype id: str
    :ivar type: Required.
    :vartype type: str or ~openai.models.FUNCTION_CALL
    :ivar status: The status of the item. One of ``in_progress``, ``completed``, or
     ``incomplete``. Populated when items are returned via API. Required. Is one of the following
     types: Literal["in_progress"], Literal["completed"], Literal["incomplete"]
    :vartype status: str or str or str
    :ivar call_id: The unique ID of the function tool call generated by the model. Required.
    :vartype call_id: str
    :ivar name: The name of the function to run. Required.
    :vartype name: str
    :ivar arguments: A JSON string of the arguments to pass to the function. Required.
    :vartype arguments: str
    """

    type: Literal[ItemType.FUNCTION_CALL] = rest_discriminator(name="type", visibility=["read", "create", "update", "delete", "query"])  # type: ignore
    """Required."""
    status: Literal["in_progress", "completed", "incomplete"] = rest_field(
        visibility=["read", "create", "update", "delete", "query"]
    )
    """The status of the item. One of ``in_progress``, ``completed``, or
     ``incomplete``. Populated when items are returned via API. Required. Is one of the following
     types: Literal[\"in_progress\"], Literal[\"completed\"], Literal[\"incomplete\"]"""
    call_id: str = rest_field(visibility=["read", "create", "update", "delete", "query"])
    """The unique ID of the function tool call generated by the model. Required."""
    name: str = rest_field(visibility=["read", "create", "update", "delete", "query"])
    """The name of the function to run. Required."""
    arguments: str = rest_field(visibility=["read", "create", "update", "delete", "query"])
    """A JSON string of the arguments to pass to the function. Required."""

    @overload
    def __init__(
        self,
        *,
        id: str,  # pylint: disable=redefined-builtin
        status: Literal["in_progress", "completed", "incomplete"],
        call_id: str,
        name: str,
        arguments: str,
    ) -> None: ...

    @overload
    def __init__(self, mapping: Mapping[str, Any]) -> None:
        """
        :param mapping: raw JSON to initialize the model.
        :type mapping: Mapping[str, Any]
        """

    def __init__(self, *args: Any, **kwargs: Any) -> None:
        super().__init__(*args, **kwargs)
        self.type = ItemType.FUNCTION_CALL  # type: ignore


class FunctionToolCallOutputItemParam(ItemParam, discriminator="function_call_output"):
    """The output of a function tool call.

    :ivar type: Required.
    :vartype type: str or ~openai.models.FUNCTION_CALL_OUTPUT
    :ivar call_id: The unique ID of the function tool call generated by the model. Required.
    :vartype call_id: str
    :ivar output: A JSON string of the output of the function tool call. Required.
    :vartype output: str
    """

    type: Literal[ItemType.FUNCTION_CALL_OUTPUT] = rest_discriminator(name="type", visibility=["read", "create", "update", "delete", "query"])  # type: ignore
    """Required."""
    call_id: str = rest_field(visibility=["read", "create", "update", "delete", "query"])
    """The unique ID of the function tool call generated by the model. Required."""
    output: str = rest_field(visibility=["read", "create", "update", "delete", "query"])
    """A JSON string of the output of the function tool call. Required."""

    @overload
    def __init__(
        self,
        *,
        call_id: str,
        output: str,
    ) -> None: ...

    @overload
    def __init__(self, mapping: Mapping[str, Any]) -> None:
        """
        :param mapping: raw JSON to initialize the model.
        :type mapping: Mapping[str, Any]
        """

    def __init__(self, *args: Any, **kwargs: Any) -> None:
        super().__init__(*args, **kwargs)
        self.type = ItemType.FUNCTION_CALL_OUTPUT  # type: ignore


class FunctionToolCallOutputItemResource(ItemResource, discriminator="function_call_output"):
    """The output of a function tool call.

    :ivar id: Required.
    :vartype id: str
    :ivar type: Required.
    :vartype type: str or ~openai.models.FUNCTION_CALL_OUTPUT
    :ivar status: The status of the item. One of ``in_progress``, ``completed``, or
     ``incomplete``. Populated when items are returned via API. Required. Is one of the following
     types: Literal["in_progress"], Literal["completed"], Literal["incomplete"]
    :vartype status: str or str or str
    :ivar call_id: The unique ID of the function tool call generated by the model. Required.
    :vartype call_id: str
    :ivar output: A JSON string of the output of the function tool call. Required.
    :vartype output: str
    """

    type: Literal[ItemType.FUNCTION_CALL_OUTPUT] = rest_discriminator(name="type", visibility=["read", "create", "update", "delete", "query"])  # type: ignore
    """Required."""
    status: Literal["in_progress", "completed", "incomplete"] = rest_field(
        visibility=["read", "create", "update", "delete", "query"]
    )
    """The status of the item. One of ``in_progress``, ``completed``, or
     ``incomplete``. Populated when items are returned via API. Required. Is one of the following
     types: Literal[\"in_progress\"], Literal[\"completed\"], Literal[\"incomplete\"]"""
    call_id: str = rest_field(visibility=["read", "create", "update", "delete", "query"])
    """The unique ID of the function tool call generated by the model. Required."""
    output: str = rest_field(visibility=["read", "create", "update", "delete", "query"])
    """A JSON string of the output of the function tool call. Required."""

    @overload
    def __init__(
        self,
        *,
        id: str,  # pylint: disable=redefined-builtin
        status: Literal["in_progress", "completed", "incomplete"],
        call_id: str,
        output: str,
    ) -> None: ...

    @overload
    def __init__(self, mapping: Mapping[str, Any]) -> None:
        """
        :param mapping: raw JSON to initialize the model.
        :type mapping: Mapping[str, Any]
        """

    def __init__(self, *args: Any, **kwargs: Any) -> None:
        super().__init__(*args, **kwargs)
        self.type = ItemType.FUNCTION_CALL_OUTPUT  # type: ignore


class ImageGenTool(Tool, discriminator="image_generation"):
    """A tool that generates images using a model like ``gpt-image-1``.

    :ivar type: The type of the image generation tool. Always ``image_generation``. Required.
    :vartype type: str or ~openai.models.IMAGE_GENERATION
    :ivar model: The image generation model to use. Default: ``gpt-image-1``. Default value is
     "gpt-image-1".
    :vartype model: str
    :ivar quality: The quality of the generated image. One of ``low``, ``medium``, ``high``,
     or ``auto``. Default: ``auto``. Is one of the following types: Literal["low"],
     Literal["medium"], Literal["high"], Literal["auto"]
    :vartype quality: str or str or str or str
    :ivar size: The size of the generated image. One of ``1024x1024``, ``1024x1536``,
     ``1536x1024``, or ``auto``. Default: ``auto``. Is one of the following types:
     Literal["1024x1024"], Literal["1024x1536"], Literal["1536x1024"], Literal["auto"]
    :vartype size: str or str or str or str
    :ivar output_format: The output format of the generated image. One of ``png``, ``webp``, or
     ``jpeg``. Default: ``png``. Is one of the following types: Literal["png"], Literal["webp"],
     Literal["jpeg"]
    :vartype output_format: str or str or str
    :ivar output_compression: Compression level for the output image. Default: 100.
    :vartype output_compression: int
    :ivar moderation: Moderation level for the generated image. Default: ``auto``. Is either a
     Literal["auto"] type or a Literal["low"] type.
    :vartype moderation: str or str
    :ivar background: Background type for the generated image. One of ``transparent``,
     ``opaque``, or ``auto``. Default: ``auto``. Is one of the following types:
     Literal["transparent"], Literal["opaque"], Literal["auto"]
    :vartype background: str or str or str
    :ivar input_image_mask: Optional mask for inpainting. Contains ``image_url``
     (string, optional) and ``file_id`` (string, optional).
    :vartype input_image_mask: ~openai.models.ImageGenToolInputImageMask
    :ivar partial_images: Number of partial images to generate in streaming mode, from 0 (default
     value) to 3.
    :vartype partial_images: int
    """

    type: Literal[ToolType.IMAGE_GENERATION] = rest_discriminator(name="type", visibility=["read", "create", "update", "delete", "query"])  # type: ignore
    """The type of the image generation tool. Always ``image_generation``. Required."""
    model: Optional[Literal["gpt-image-1"]] = rest_field(visibility=["read", "create", "update", "delete", "query"])
    """The image generation model to use. Default: ``gpt-image-1``. Default value is \"gpt-image-1\"."""
    quality: Optional[Literal["low", "medium", "high", "auto"]] = rest_field(
        visibility=["read", "create", "update", "delete", "query"]
    )
    """The quality of the generated image. One of ``low``, ``medium``, ``high``,
     or ``auto``. Default: ``auto``. Is one of the following types: Literal[\"low\"],
     Literal[\"medium\"], Literal[\"high\"], Literal[\"auto\"]"""
    size: Optional[Literal["1024x1024", "1024x1536", "1536x1024", "auto"]] = rest_field(
        visibility=["read", "create", "update", "delete", "query"]
    )
    """The size of the generated image. One of ``1024x1024``, ``1024x1536``,
     ``1536x1024``, or ``auto``. Default: ``auto``. Is one of the following types:
     Literal[\"1024x1024\"], Literal[\"1024x1536\"], Literal[\"1536x1024\"], Literal[\"auto\"]"""
    output_format: Optional[Literal["png", "webp", "jpeg"]] = rest_field(
        visibility=["read", "create", "update", "delete", "query"]
    )
    """The output format of the generated image. One of ``png``, ``webp``, or
     ``jpeg``. Default: ``png``. Is one of the following types: Literal[\"png\"], Literal[\"webp\"],
     Literal[\"jpeg\"]"""
    output_compression: Optional[int] = rest_field(visibility=["read", "create", "update", "delete", "query"])
    """Compression level for the output image. Default: 100."""
    moderation: Optional[Literal["auto", "low"]] = rest_field(
        visibility=["read", "create", "update", "delete", "query"]
    )
    """Moderation level for the generated image. Default: ``auto``. Is either a Literal[\"auto\"] type
     or a Literal[\"low\"] type."""
    background: Optional[Literal["transparent", "opaque", "auto"]] = rest_field(
        visibility=["read", "create", "update", "delete", "query"]
    )
    """Background type for the generated image. One of ``transparent``,
     ``opaque``, or ``auto``. Default: ``auto``. Is one of the following types:
     Literal[\"transparent\"], Literal[\"opaque\"], Literal[\"auto\"]"""
    input_image_mask: Optional["_models.ImageGenToolInputImageMask"] = rest_field(
        visibility=["read", "create", "update", "delete", "query"]
    )
    """Optional mask for inpainting. Contains ``image_url``
     (string, optional) and ``file_id`` (string, optional)."""
    partial_images: Optional[int] = rest_field(visibility=["read", "create", "update", "delete", "query"])
    """Number of partial images to generate in streaming mode, from 0 (default value) to 3."""

    @overload
    def __init__(
        self,
        *,
        model: Optional[Literal["gpt-image-1"]] = None,
        quality: Optional[Literal["low", "medium", "high", "auto"]] = None,
        size: Optional[Literal["1024x1024", "1024x1536", "1536x1024", "auto"]] = None,
        output_format: Optional[Literal["png", "webp", "jpeg"]] = None,
        output_compression: Optional[int] = None,
        moderation: Optional[Literal["auto", "low"]] = None,
        background: Optional[Literal["transparent", "opaque", "auto"]] = None,
        input_image_mask: Optional["_models.ImageGenToolInputImageMask"] = None,
        partial_images: Optional[int] = None,
    ) -> None: ...

    @overload
    def __init__(self, mapping: Mapping[str, Any]) -> None:
        """
        :param mapping: raw JSON to initialize the model.
        :type mapping: Mapping[str, Any]
        """

    def __init__(self, *args: Any, **kwargs: Any) -> None:
        super().__init__(*args, **kwargs)
        self.type = ToolType.IMAGE_GENERATION  # type: ignore


class ImageGenToolCallItemParam(ItemParam, discriminator="image_generation_call"):
    """An image generation request made by the model.

    :ivar type: Required.
    :vartype type: str or ~openai.models.IMAGE_GENERATION_CALL
    :ivar result: The generated image encoded in base64. Required.
    :vartype result: str
    """

    type: Literal[ItemType.IMAGE_GENERATION_CALL] = rest_discriminator(name="type", visibility=["read", "create", "update", "delete", "query"])  # type: ignore
    """Required."""
    result: str = rest_field(visibility=["read", "create", "update", "delete", "query"])
    """The generated image encoded in base64. Required."""

    @overload
    def __init__(
        self,
        *,
        result: str,
    ) -> None: ...

    @overload
    def __init__(self, mapping: Mapping[str, Any]) -> None:
        """
        :param mapping: raw JSON to initialize the model.
        :type mapping: Mapping[str, Any]
        """

    def __init__(self, *args: Any, **kwargs: Any) -> None:
        super().__init__(*args, **kwargs)
        self.type = ItemType.IMAGE_GENERATION_CALL  # type: ignore


class ImageGenToolCallItemResource(ItemResource, discriminator="image_generation_call"):
    """An image generation request made by the model.

    :ivar id: Required.
    :vartype id: str
    :ivar type: Required.
    :vartype type: str or ~openai.models.IMAGE_GENERATION_CALL
    :ivar status: Required. Is one of the following types: Literal["in_progress"],
     Literal["completed"], Literal["generating"], Literal["failed"]
    :vartype status: str or str or str or str
    :ivar result: The generated image encoded in base64. Required.
    :vartype result: str
    """

    type: Literal[ItemType.IMAGE_GENERATION_CALL] = rest_discriminator(name="type", visibility=["read", "create", "update", "delete", "query"])  # type: ignore
    """Required."""
    status: Literal["in_progress", "completed", "generating", "failed"] = rest_field(
        visibility=["read", "create", "update", "delete", "query"]
    )
    """Required. Is one of the following types: Literal[\"in_progress\"], Literal[\"completed\"],
     Literal[\"generating\"], Literal[\"failed\"]"""
    result: str = rest_field(visibility=["read", "create", "update", "delete", "query"])
    """The generated image encoded in base64. Required."""

    @overload
    def __init__(
        self,
        *,
        id: str,  # pylint: disable=redefined-builtin
        status: Literal["in_progress", "completed", "generating", "failed"],
        result: str,
    ) -> None: ...

    @overload
    def __init__(self, mapping: Mapping[str, Any]) -> None:
        """
        :param mapping: raw JSON to initialize the model.
        :type mapping: Mapping[str, Any]
        """

    def __init__(self, *args: Any, **kwargs: Any) -> None:
        super().__init__(*args, **kwargs)
        self.type = ItemType.IMAGE_GENERATION_CALL  # type: ignore


class ImageGenToolInputImageMask(_Model):
    """ImageGenToolInputImageMask.

    :ivar image_url: Base64-encoded mask image.
    :vartype image_url: str
    :ivar file_id: File ID for the mask image.
    :vartype file_id: str
    """

    image_url: Optional[str] = rest_field(visibility=["read", "create", "update", "delete", "query"])
    """Base64-encoded mask image."""
    file_id: Optional[str] = rest_field(visibility=["read", "create", "update", "delete", "query"])
    """File ID for the mask image."""

    @overload
    def __init__(
        self,
        *,
        image_url: Optional[str] = None,
        file_id: Optional[str] = None,
    ) -> None: ...

    @overload
    def __init__(self, mapping: Mapping[str, Any]) -> None:
        """
        :param mapping: raw JSON to initialize the model.
        :type mapping: Mapping[str, Any]
        """

    def __init__(self, *args: Any, **kwargs: Any) -> None:
        super().__init__(*args, **kwargs)


class ImplicitUserMessage(_Model):
    """ImplicitUserMessage.

    :ivar content: Required. Is either a str type or a [ItemContent] type.
    :vartype content: str or list[~openai.models.ItemContent]
    """

    content: Union["str", list["_models.ItemContent"]] = rest_field(
        visibility=["read", "create", "update", "delete", "query"]
    )
    """Required. Is either a str type or a [ItemContent] type."""

    @overload
    def __init__(
        self,
        *,
        content: Union[str, list["_models.ItemContent"]],
    ) -> None: ...

    @overload
    def __init__(self, mapping: Mapping[str, Any]) -> None:
        """
        :param mapping: raw JSON to initialize the model.
        :type mapping: Mapping[str, Any]
        """

    def __init__(self, *args: Any, **kwargs: Any) -> None:
        super().__init__(*args, **kwargs)


class ItemContent(_Model):
    """ItemContent.

    You probably want to use the sub-classes and not this class directly. Known sub-classes are:
    ItemContentInputAudio, ItemContentInputFile, ItemContentInputImage, ItemContentInputText,
    ItemContentOutputAudio, ItemContentOutputText, ItemContentRefusal

    :ivar type: Required. Known values are: "input_text", "input_audio", "input_image",
     "input_file", "output_text", "output_audio", and "refusal".
    :vartype type: str or ~openai.models.ItemContentType
    """

    __mapping__: dict[str, _Model] = {}
    type: str = rest_discriminator(name="type", visibility=["read", "create", "update", "delete", "query"])
    """Required. Known values are: \"input_text\", \"input_audio\", \"input_image\", \"input_file\",
     \"output_text\", \"output_audio\", and \"refusal\"."""

    @overload
    def __init__(
        self,
        *,
        type: str,
    ) -> None: ...

    @overload
    def __init__(self, mapping: Mapping[str, Any]) -> None:
        """
        :param mapping: raw JSON to initialize the model.
        :type mapping: Mapping[str, Any]
        """

    def __init__(self, *args: Any, **kwargs: Any) -> None:
        super().__init__(*args, **kwargs)


class ItemContentInputAudio(ItemContent, discriminator="input_audio"):
    """An audio input to the model.

    :ivar type: The type of the input item. Always ``input_audio``. Required.
    :vartype type: str or ~openai.models.INPUT_AUDIO
    :ivar data: Base64-encoded audio data. Required.
    :vartype data: str
    :ivar format: The format of the audio data. Currently supported formats are ``mp3`` and
     ``wav``. Required. Is either a Literal["mp3"] type or a Literal["wav"] type.
    :vartype format: str or str
    """

    type: Literal[ItemContentType.INPUT_AUDIO] = rest_discriminator(name="type", visibility=["read", "create", "update", "delete", "query"])  # type: ignore
    """The type of the input item. Always ``input_audio``. Required."""
    data: str = rest_field(visibility=["read", "create", "update", "delete", "query"])
    """Base64-encoded audio data. Required."""
    format: Literal["mp3", "wav"] = rest_field(visibility=["read", "create", "update", "delete", "query"])
    """The format of the audio data. Currently supported formats are ``mp3`` and
     ``wav``. Required. Is either a Literal[\"mp3\"] type or a Literal[\"wav\"] type."""

    @overload
    def __init__(
        self,
        *,
        data: str,
        format: Literal["mp3", "wav"],
    ) -> None: ...

    @overload
    def __init__(self, mapping: Mapping[str, Any]) -> None:
        """
        :param mapping: raw JSON to initialize the model.
        :type mapping: Mapping[str, Any]
        """

    def __init__(self, *args: Any, **kwargs: Any) -> None:
        super().__init__(*args, **kwargs)
        self.type = ItemContentType.INPUT_AUDIO  # type: ignore


class ItemContentInputFile(ItemContent, discriminator="input_file"):
    """A file input to the model.

    :ivar type: The type of the input item. Always ``input_file``. Required.
    :vartype type: str or ~openai.models.INPUT_FILE
    :ivar file_id: The ID of the file to be sent to the model.
    :vartype file_id: str
    :ivar filename: The name of the file to be sent to the model.
    :vartype filename: str
    :ivar file_data: The content of the file to be sent to the model.
    :vartype file_data: str
    """

    type: Literal[ItemContentType.INPUT_FILE] = rest_discriminator(name="type", visibility=["read", "create", "update", "delete", "query"])  # type: ignore
    """The type of the input item. Always ``input_file``. Required."""
    file_id: Optional[str] = rest_field(visibility=["read", "create", "update", "delete", "query"])
    """The ID of the file to be sent to the model."""
    filename: Optional[str] = rest_field(visibility=["read", "create", "update", "delete", "query"])
    """The name of the file to be sent to the model."""
    file_data: Optional[str] = rest_field(visibility=["read", "create", "update", "delete", "query"])
    """The content of the file to be sent to the model."""

    @overload
    def __init__(
        self,
        *,
        file_id: Optional[str] = None,
        filename: Optional[str] = None,
        file_data: Optional[str] = None,
    ) -> None: ...

    @overload
    def __init__(self, mapping: Mapping[str, Any]) -> None:
        """
        :param mapping: raw JSON to initialize the model.
        :type mapping: Mapping[str, Any]
        """

    def __init__(self, *args: Any, **kwargs: Any) -> None:
        super().__init__(*args, **kwargs)
        self.type = ItemContentType.INPUT_FILE  # type: ignore


class ItemContentInputImage(ItemContent, discriminator="input_image"):
    """An image input to the model. Learn about `image inputs </docs/guides/vision>`_.

    :ivar type: The type of the input item. Always ``input_image``. Required.
    :vartype type: str or ~openai.models.INPUT_IMAGE
    :ivar image_url: The URL of the image to be sent to the model. A fully qualified URL or base64
     encoded image in a data URL.
    :vartype image_url: str
    :ivar file_id: The ID of the file to be sent to the model.
    :vartype file_id: str
    :ivar detail: The detail level of the image to be sent to the model. One of ``high``, ``low``,
     or ``auto``. Defaults to ``auto``. Is one of the following types: Literal["low"],
     Literal["high"], Literal["auto"]
    :vartype detail: str or str or str
    """

    type: Literal[ItemContentType.INPUT_IMAGE] = rest_discriminator(name="type", visibility=["read", "create", "update", "delete", "query"])  # type: ignore
    """The type of the input item. Always ``input_image``. Required."""
    image_url: Optional[str] = rest_field(visibility=["read", "create", "update", "delete", "query"])
    """The URL of the image to be sent to the model. A fully qualified URL or base64 encoded image in
     a data URL."""
    file_id: Optional[str] = rest_field(visibility=["read", "create", "update", "delete", "query"])
    """The ID of the file to be sent to the model."""
    detail: Optional[Literal["low", "high", "auto"]] = rest_field(
        visibility=["read", "create", "update", "delete", "query"]
    )
    """The detail level of the image to be sent to the model. One of ``high``, ``low``, or ``auto``.
     Defaults to ``auto``. Is one of the following types: Literal[\"low\"], Literal[\"high\"],
     Literal[\"auto\"]"""

    @overload
    def __init__(
        self,
        *,
        image_url: Optional[str] = None,
        file_id: Optional[str] = None,
        detail: Optional[Literal["low", "high", "auto"]] = None,
    ) -> None: ...

    @overload
    def __init__(self, mapping: Mapping[str, Any]) -> None:
        """
        :param mapping: raw JSON to initialize the model.
        :type mapping: Mapping[str, Any]
        """

    def __init__(self, *args: Any, **kwargs: Any) -> None:
        super().__init__(*args, **kwargs)
        self.type = ItemContentType.INPUT_IMAGE  # type: ignore


class ItemContentInputText(ItemContent, discriminator="input_text"):
    """A text input to the model.

    :ivar type: The type of the input item. Always ``input_text``. Required.
    :vartype type: str or ~openai.models.INPUT_TEXT
    :ivar text: The text input to the model. Required.
    :vartype text: str
    """

    type: Literal[ItemContentType.INPUT_TEXT] = rest_discriminator(name="type", visibility=["read", "create", "update", "delete", "query"])  # type: ignore
    """The type of the input item. Always ``input_text``. Required."""
    text: str = rest_field(visibility=["read", "create", "update", "delete", "query"])
    """The text input to the model. Required."""

    @overload
    def __init__(
        self,
        *,
        text: str,
    ) -> None: ...

    @overload
    def __init__(self, mapping: Mapping[str, Any]) -> None:
        """
        :param mapping: raw JSON to initialize the model.
        :type mapping: Mapping[str, Any]
        """

    def __init__(self, *args: Any, **kwargs: Any) -> None:
        super().__init__(*args, **kwargs)
        self.type = ItemContentType.INPUT_TEXT  # type: ignore


class ItemContentOutputAudio(ItemContent, discriminator="output_audio"):
    """An audio output from the model.

    :ivar type: The type of the output audio. Always ``output_audio``. Required.
    :vartype type: str or ~openai.models.OUTPUT_AUDIO
    :ivar data: Base64-encoded audio data from the model. Required.
    :vartype data: str
    :ivar transcript: The transcript of the audio data from the model. Required.
    :vartype transcript: str
    """

    type: Literal[ItemContentType.OUTPUT_AUDIO] = rest_discriminator(name="type", visibility=["read", "create", "update", "delete", "query"])  # type: ignore
    """The type of the output audio. Always ``output_audio``. Required."""
    data: str = rest_field(visibility=["read", "create", "update", "delete", "query"])
    """Base64-encoded audio data from the model. Required."""
    transcript: str = rest_field(visibility=["read", "create", "update", "delete", "query"])
    """The transcript of the audio data from the model. Required."""

    @overload
    def __init__(
        self,
        *,
        data: str,
        transcript: str,
    ) -> None: ...

    @overload
    def __init__(self, mapping: Mapping[str, Any]) -> None:
        """
        :param mapping: raw JSON to initialize the model.
        :type mapping: Mapping[str, Any]
        """

    def __init__(self, *args: Any, **kwargs: Any) -> None:
        super().__init__(*args, **kwargs)
        self.type = ItemContentType.OUTPUT_AUDIO  # type: ignore


class ItemContentOutputText(ItemContent, discriminator="output_text"):
    """A text output from the model.

    :ivar type: The type of the output text. Always ``output_text``. Required.
    :vartype type: str or ~openai.models.OUTPUT_TEXT
    :ivar text: The text output from the model. Required.
    :vartype text: str
    :ivar annotations: The annotations of the text output. Required.
    :vartype annotations: list[~openai.models.Annotation]
    :ivar logprobs:
    :vartype logprobs: list[~openai.models.LogProb]
    """

    type: Literal[ItemContentType.OUTPUT_TEXT] = rest_discriminator(name="type", visibility=["read", "create", "update", "delete", "query"])  # type: ignore
    """The type of the output text. Always ``output_text``. Required."""
    text: str = rest_field(visibility=["read", "create", "update", "delete", "query"])
    """The text output from the model. Required."""
    annotations: list["_models.Annotation"] = rest_field(visibility=["read", "create", "update", "delete", "query"])
    """The annotations of the text output. Required."""
    logprobs: Optional[list["_models.LogProb"]] = rest_field(visibility=["read", "create", "update", "delete", "query"])

    @overload
    def __init__(
        self,
        *,
        text: str,
        annotations: list["_models.Annotation"],
        logprobs: Optional[list["_models.LogProb"]] = None,
    ) -> None: ...

    @overload
    def __init__(self, mapping: Mapping[str, Any]) -> None:
        """
        :param mapping: raw JSON to initialize the model.
        :type mapping: Mapping[str, Any]
        """

    def __init__(self, *args: Any, **kwargs: Any) -> None:
        super().__init__(*args, **kwargs)
        self.type = ItemContentType.OUTPUT_TEXT  # type: ignore


class ItemContentRefusal(ItemContent, discriminator="refusal"):
    """A refusal from the model.

    :ivar type: The type of the refusal. Always ``refusal``. Required.
    :vartype type: str or ~openai.models.REFUSAL
    :ivar refusal: The refusal explanationfrom the model. Required.
    :vartype refusal: str
    """

    type: Literal[ItemContentType.REFUSAL] = rest_discriminator(name="type", visibility=["read", "create", "update", "delete", "query"])  # type: ignore
    """The type of the refusal. Always ``refusal``. Required."""
    refusal: str = rest_field(visibility=["read", "create", "update", "delete", "query"])
    """The refusal explanationfrom the model. Required."""

    @overload
    def __init__(
        self,
        *,
        refusal: str,
    ) -> None: ...

    @overload
    def __init__(self, mapping: Mapping[str, Any]) -> None:
        """
        :param mapping: raw JSON to initialize the model.
        :type mapping: Mapping[str, Any]
        """

    def __init__(self, *args: Any, **kwargs: Any) -> None:
        super().__init__(*args, **kwargs)
        self.type = ItemContentType.REFUSAL  # type: ignore


class ItemReferenceItemParam(ItemParam, discriminator="item_reference"):
    """An internal identifier for an item to reference.

    :ivar type: Required.
    :vartype type: str or ~openai.models.ITEM_REFERENCE
    :ivar id: The service-originated ID of the previously generated response item being referenced.
     Required.
    :vartype id: str
    """

    type: Literal[ItemType.ITEM_REFERENCE] = rest_discriminator(name="type", visibility=["read", "create", "update", "delete", "query"])  # type: ignore
    """Required."""
    id: str = rest_field(visibility=["read", "create", "update", "delete", "query"])
    """The service-originated ID of the previously generated response item being referenced. Required."""

    @overload
    def __init__(
        self,
        *,
        id: str,  # pylint: disable=redefined-builtin
    ) -> None: ...

    @overload
    def __init__(self, mapping: Mapping[str, Any]) -> None:
        """
        :param mapping: raw JSON to initialize the model.
        :type mapping: Mapping[str, Any]
        """

    def __init__(self, *args: Any, **kwargs: Any) -> None:
        super().__init__(*args, **kwargs)
        self.type = ItemType.ITEM_REFERENCE  # type: ignore


class LocalShellExecAction(_Model):
    """Execute a shell command on the server.

    :ivar type: The type of the local shell action. Always ``exec``. Required. Default value is
     "exec".
    :vartype type: str
    :ivar command: The command to run. Required.
    :vartype command: list[str]
    :ivar timeout_ms: Optional timeout in milliseconds for the command.
    :vartype timeout_ms: int
    :ivar working_directory: Optional working directory to run the command in.
    :vartype working_directory: str
    :ivar env: Environment variables to set for the command. Required.
    :vartype env: dict[str, str]
    :ivar user: Optional user to run the command as.
    :vartype user: str
    """

    type: Literal["exec"] = rest_field(visibility=["read", "create", "update", "delete", "query"])
    """The type of the local shell action. Always ``exec``. Required. Default value is \"exec\"."""
    command: list[str] = rest_field(visibility=["read", "create", "update", "delete", "query"])
    """The command to run. Required."""
    timeout_ms: Optional[int] = rest_field(visibility=["read", "create", "update", "delete", "query"])
    """Optional timeout in milliseconds for the command."""
    working_directory: Optional[str] = rest_field(visibility=["read", "create", "update", "delete", "query"])
    """Optional working directory to run the command in."""
    env: dict[str, str] = rest_field(visibility=["read", "create", "update", "delete", "query"])
    """Environment variables to set for the command. Required."""
    user: Optional[str] = rest_field(visibility=["read", "create", "update", "delete", "query"])
    """Optional user to run the command as."""

    @overload
    def __init__(
        self,
        *,
        command: list[str],
        env: dict[str, str],
        timeout_ms: Optional[int] = None,
        working_directory: Optional[str] = None,
        user: Optional[str] = None,
    ) -> None: ...

    @overload
    def __init__(self, mapping: Mapping[str, Any]) -> None:
        """
        :param mapping: raw JSON to initialize the model.
        :type mapping: Mapping[str, Any]
        """

    def __init__(self, *args: Any, **kwargs: Any) -> None:
        super().__init__(*args, **kwargs)
        self.type: Literal["exec"] = "exec"


class LocalShellTool(Tool, discriminator="local_shell"):
    """A tool that allows the model to execute shell commands in a local environment.

    :ivar type: The type of the local shell tool. Always ``local_shell``. Required.
    :vartype type: str or ~openai.models.LOCAL_SHELL
    """

    type: Literal[ToolType.LOCAL_SHELL] = rest_discriminator(name="type", visibility=["read", "create", "update", "delete", "query"])  # type: ignore
    """The type of the local shell tool. Always ``local_shell``. Required."""

    @overload
    def __init__(
        self,
    ) -> None: ...

    @overload
    def __init__(self, mapping: Mapping[str, Any]) -> None:
        """
        :param mapping: raw JSON to initialize the model.
        :type mapping: Mapping[str, Any]
        """

    def __init__(self, *args: Any, **kwargs: Any) -> None:
        super().__init__(*args, **kwargs)
        self.type = ToolType.LOCAL_SHELL  # type: ignore


class LocalShellToolCallItemParam(ItemParam, discriminator="local_shell_call"):
    """A tool call to run a command on the local shell.

    :ivar type: Required.
    :vartype type: str or ~openai.models.LOCAL_SHELL_CALL
    :ivar call_id: The unique ID of the local shell tool call generated by the model. Required.
    :vartype call_id: str
    :ivar action: Required.
    :vartype action: ~openai.models.LocalShellExecAction
    """

    type: Literal[ItemType.LOCAL_SHELL_CALL] = rest_discriminator(name="type", visibility=["read", "create", "update", "delete", "query"])  # type: ignore
    """Required."""
    call_id: str = rest_field(visibility=["read", "create", "update", "delete", "query"])
    """The unique ID of the local shell tool call generated by the model. Required."""
    action: "_models.LocalShellExecAction" = rest_field(visibility=["read", "create", "update", "delete", "query"])
    """Required."""

    @overload
    def __init__(
        self,
        *,
        call_id: str,
        action: "_models.LocalShellExecAction",
    ) -> None: ...

    @overload
    def __init__(self, mapping: Mapping[str, Any]) -> None:
        """
        :param mapping: raw JSON to initialize the model.
        :type mapping: Mapping[str, Any]
        """

    def __init__(self, *args: Any, **kwargs: Any) -> None:
        super().__init__(*args, **kwargs)
        self.type = ItemType.LOCAL_SHELL_CALL  # type: ignore


class LocalShellToolCallItemResource(ItemResource, discriminator="local_shell_call"):
    """A tool call to run a command on the local shell.

    :ivar id: Required.
    :vartype id: str
    :ivar type: Required.
    :vartype type: str or ~openai.models.LOCAL_SHELL_CALL
    :ivar status: Required. Is one of the following types: Literal["in_progress"],
     Literal["completed"], Literal["incomplete"]
    :vartype status: str or str or str
    :ivar call_id: The unique ID of the local shell tool call generated by the model. Required.
    :vartype call_id: str
    :ivar action: Required.
    :vartype action: ~openai.models.LocalShellExecAction
    """

    type: Literal[ItemType.LOCAL_SHELL_CALL] = rest_discriminator(name="type", visibility=["read", "create", "update", "delete", "query"])  # type: ignore
    """Required."""
    status: Literal["in_progress", "completed", "incomplete"] = rest_field(
        visibility=["read", "create", "update", "delete", "query"]
    )
    """Required. Is one of the following types: Literal[\"in_progress\"], Literal[\"completed\"],
     Literal[\"incomplete\"]"""
    call_id: str = rest_field(visibility=["read", "create", "update", "delete", "query"])
    """The unique ID of the local shell tool call generated by the model. Required."""
    action: "_models.LocalShellExecAction" = rest_field(visibility=["read", "create", "update", "delete", "query"])
    """Required."""

    @overload
    def __init__(
        self,
        *,
        id: str,  # pylint: disable=redefined-builtin
        status: Literal["in_progress", "completed", "incomplete"],
        call_id: str,
        action: "_models.LocalShellExecAction",
    ) -> None: ...

    @overload
    def __init__(self, mapping: Mapping[str, Any]) -> None:
        """
        :param mapping: raw JSON to initialize the model.
        :type mapping: Mapping[str, Any]
        """

    def __init__(self, *args: Any, **kwargs: Any) -> None:
        super().__init__(*args, **kwargs)
        self.type = ItemType.LOCAL_SHELL_CALL  # type: ignore


class LocalShellToolCallOutputItemParam(ItemParam, discriminator="local_shell_call_output"):
    """The output of a local shell tool call.

    :ivar type: Required.
    :vartype type: str or ~openai.models.LOCAL_SHELL_CALL_OUTPUT
    :ivar output: A JSON string of the output of the local shell tool call. Required.
    :vartype output: str
    """

    type: Literal[ItemType.LOCAL_SHELL_CALL_OUTPUT] = rest_discriminator(name="type", visibility=["read", "create", "update", "delete", "query"])  # type: ignore
    """Required."""
    output: str = rest_field(visibility=["read", "create", "update", "delete", "query"])
    """A JSON string of the output of the local shell tool call. Required."""

    @overload
    def __init__(
        self,
        *,
        output: str,
    ) -> None: ...

    @overload
    def __init__(self, mapping: Mapping[str, Any]) -> None:
        """
        :param mapping: raw JSON to initialize the model.
        :type mapping: Mapping[str, Any]
        """

    def __init__(self, *args: Any, **kwargs: Any) -> None:
        super().__init__(*args, **kwargs)
        self.type = ItemType.LOCAL_SHELL_CALL_OUTPUT  # type: ignore


class LocalShellToolCallOutputItemResource(ItemResource, discriminator="local_shell_call_output"):
    """The output of a local shell tool call.

    :ivar id: Required.
    :vartype id: str
    :ivar type: Required.
    :vartype type: str or ~openai.models.LOCAL_SHELL_CALL_OUTPUT
    :ivar status: Required. Is one of the following types: Literal["in_progress"],
     Literal["completed"], Literal["incomplete"]
    :vartype status: str or str or str
    :ivar output: A JSON string of the output of the local shell tool call. Required.
    :vartype output: str
    """

    type: Literal[ItemType.LOCAL_SHELL_CALL_OUTPUT] = rest_discriminator(name="type", visibility=["read", "create", "update", "delete", "query"])  # type: ignore
    """Required."""
    status: Literal["in_progress", "completed", "incomplete"] = rest_field(
        visibility=["read", "create", "update", "delete", "query"]
    )
    """Required. Is one of the following types: Literal[\"in_progress\"], Literal[\"completed\"],
     Literal[\"incomplete\"]"""
    output: str = rest_field(visibility=["read", "create", "update", "delete", "query"])
    """A JSON string of the output of the local shell tool call. Required."""

    @overload
    def __init__(
        self,
        *,
        id: str,  # pylint: disable=redefined-builtin
        status: Literal["in_progress", "completed", "incomplete"],
        output: str,
    ) -> None: ...

    @overload
    def __init__(self, mapping: Mapping[str, Any]) -> None:
        """
        :param mapping: raw JSON to initialize the model.
        :type mapping: Mapping[str, Any]
        """

    def __init__(self, *args: Any, **kwargs: Any) -> None:
        super().__init__(*args, **kwargs)
        self.type = ItemType.LOCAL_SHELL_CALL_OUTPUT  # type: ignore


class LogProb(_Model):
    """The log probability of a token.

    :ivar token: Required.
    :vartype token: str
    :ivar logprob: Required.
    :vartype logprob: float
    :ivar bytes: Required.
    :vartype bytes: list[int]
    :ivar top_logprobs: Required.
    :vartype top_logprobs: list[~openai.models.TopLogProb]
    """

    token: str = rest_field(visibility=["read", "create", "update", "delete", "query"])
    """Required."""
    logprob: float = rest_field(visibility=["read", "create", "update", "delete", "query"])
    """Required."""
    bytes: list[int] = rest_field(visibility=["read", "create", "update", "delete", "query"])
    """Required."""
    top_logprobs: list["_models.TopLogProb"] = rest_field(visibility=["read", "create", "update", "delete", "query"])
    """Required."""

    @overload
    def __init__(
        self,
        *,
        token: str,
        logprob: float,
        bytes: list[int],
        top_logprobs: list["_models.TopLogProb"],
    ) -> None: ...

    @overload
    def __init__(self, mapping: Mapping[str, Any]) -> None:
        """
        :param mapping: raw JSON to initialize the model.
        :type mapping: Mapping[str, Any]
        """

    def __init__(self, *args: Any, **kwargs: Any) -> None:
        super().__init__(*args, **kwargs)


class MCPApprovalRequestItemParam(ItemParam, discriminator="mcp_approval_request"):
    """A request for human approval of a tool invocation.

    :ivar type: Required.
    :vartype type: str or ~openai.models.MCP_APPROVAL_REQUEST
    :ivar server_label: The label of the MCP server making the request. Required.
    :vartype server_label: str
    :ivar name: The name of the tool to run. Required.
    :vartype name: str
    :ivar arguments: A JSON string of arguments for the tool. Required.
    :vartype arguments: str
    """

    type: Literal[ItemType.MCP_APPROVAL_REQUEST] = rest_discriminator(name="type", visibility=["read", "create", "update", "delete", "query"])  # type: ignore
    """Required."""
    server_label: str = rest_field(visibility=["read", "create", "update", "delete", "query"])
    """The label of the MCP server making the request. Required."""
    name: str = rest_field(visibility=["read", "create", "update", "delete", "query"])
    """The name of the tool to run. Required."""
    arguments: str = rest_field(visibility=["read", "create", "update", "delete", "query"])
    """A JSON string of arguments for the tool. Required."""

    @overload
    def __init__(
        self,
        *,
        server_label: str,
        name: str,
        arguments: str,
    ) -> None: ...

    @overload
    def __init__(self, mapping: Mapping[str, Any]) -> None:
        """
        :param mapping: raw JSON to initialize the model.
        :type mapping: Mapping[str, Any]
        """

    def __init__(self, *args: Any, **kwargs: Any) -> None:
        super().__init__(*args, **kwargs)
        self.type = ItemType.MCP_APPROVAL_REQUEST  # type: ignore


class MCPApprovalRequestItemResource(ItemResource, discriminator="mcp_approval_request"):
    """A request for human approval of a tool invocation.

    :ivar id: Required.
    :vartype id: str
    :ivar type: Required.
    :vartype type: str or ~openai.models.MCP_APPROVAL_REQUEST
    :ivar server_label: The label of the MCP server making the request. Required.
    :vartype server_label: str
    :ivar name: The name of the tool to run. Required.
    :vartype name: str
    :ivar arguments: A JSON string of arguments for the tool. Required.
    :vartype arguments: str
    """

    type: Literal[ItemType.MCP_APPROVAL_REQUEST] = rest_discriminator(name="type", visibility=["read", "create", "update", "delete", "query"])  # type: ignore
    """Required."""
    server_label: str = rest_field(visibility=["read", "create", "update", "delete", "query"])
    """The label of the MCP server making the request. Required."""
    name: str = rest_field(visibility=["read", "create", "update", "delete", "query"])
    """The name of the tool to run. Required."""
    arguments: str = rest_field(visibility=["read", "create", "update", "delete", "query"])
    """A JSON string of arguments for the tool. Required."""

    @overload
    def __init__(
        self,
        *,
        id: str,  # pylint: disable=redefined-builtin
        server_label: str,
        name: str,
        arguments: str,
    ) -> None: ...

    @overload
    def __init__(self, mapping: Mapping[str, Any]) -> None:
        """
        :param mapping: raw JSON to initialize the model.
        :type mapping: Mapping[str, Any]
        """

    def __init__(self, *args: Any, **kwargs: Any) -> None:
        super().__init__(*args, **kwargs)
        self.type = ItemType.MCP_APPROVAL_REQUEST  # type: ignore


class MCPApprovalResponseItemParam(ItemParam, discriminator="mcp_approval_response"):
    """A response to an MCP approval request.

    :ivar type: Required.
    :vartype type: str or ~openai.models.MCP_APPROVAL_RESPONSE
    :ivar approval_request_id: The ID of the approval request being answered. Required.
    :vartype approval_request_id: str
    :ivar approve: Whether the request was approved. Required.
    :vartype approve: bool
    :ivar reason: Optional reason for the decision.
    :vartype reason: str
    """

    type: Literal[ItemType.MCP_APPROVAL_RESPONSE] = rest_discriminator(name="type", visibility=["read", "create", "update", "delete", "query"])  # type: ignore
    """Required."""
    approval_request_id: str = rest_field(visibility=["read", "create", "update", "delete", "query"])
    """The ID of the approval request being answered. Required."""
    approve: bool = rest_field(visibility=["read", "create", "update", "delete", "query"])
    """Whether the request was approved. Required."""
    reason: Optional[str] = rest_field(visibility=["read", "create", "update", "delete", "query"])
    """Optional reason for the decision."""

    @overload
    def __init__(
        self,
        *,
        approval_request_id: str,
        approve: bool,
        reason: Optional[str] = None,
    ) -> None: ...

    @overload
    def __init__(self, mapping: Mapping[str, Any]) -> None:
        """
        :param mapping: raw JSON to initialize the model.
        :type mapping: Mapping[str, Any]
        """

    def __init__(self, *args: Any, **kwargs: Any) -> None:
        super().__init__(*args, **kwargs)
        self.type = ItemType.MCP_APPROVAL_RESPONSE  # type: ignore


class MCPApprovalResponseItemResource(ItemResource, discriminator="mcp_approval_response"):
    """A response to an MCP approval request.

    :ivar id: Required.
    :vartype id: str
    :ivar type: Required.
    :vartype type: str or ~openai.models.MCP_APPROVAL_RESPONSE
    :ivar approval_request_id: The ID of the approval request being answered. Required.
    :vartype approval_request_id: str
    :ivar approve: Whether the request was approved. Required.
    :vartype approve: bool
    :ivar reason: Optional reason for the decision.
    :vartype reason: str
    """

    type: Literal[ItemType.MCP_APPROVAL_RESPONSE] = rest_discriminator(name="type", visibility=["read", "create", "update", "delete", "query"])  # type: ignore
    """Required."""
    approval_request_id: str = rest_field(visibility=["read", "create", "update", "delete", "query"])
    """The ID of the approval request being answered. Required."""
    approve: bool = rest_field(visibility=["read", "create", "update", "delete", "query"])
    """Whether the request was approved. Required."""
    reason: Optional[str] = rest_field(visibility=["read", "create", "update", "delete", "query"])
    """Optional reason for the decision."""

    @overload
    def __init__(
        self,
        *,
        id: str,  # pylint: disable=redefined-builtin
        approval_request_id: str,
        approve: bool,
        reason: Optional[str] = None,
    ) -> None: ...

    @overload
    def __init__(self, mapping: Mapping[str, Any]) -> None:
        """
        :param mapping: raw JSON to initialize the model.
        :type mapping: Mapping[str, Any]
        """

    def __init__(self, *args: Any, **kwargs: Any) -> None:
        super().__init__(*args, **kwargs)
        self.type = ItemType.MCP_APPROVAL_RESPONSE  # type: ignore


class MCPCallItemParam(ItemParam, discriminator="mcp_call"):
    """An invocation of a tool on an MCP server.

    :ivar type: Required.
    :vartype type: str or ~openai.models.MCP_CALL
    :ivar server_label: The label of the MCP server running the tool. Required.
    :vartype server_label: str
    :ivar name: The name of the tool that was run. Required.
    :vartype name: str
    :ivar arguments: A JSON string of the arguments passed to the tool. Required.
    :vartype arguments: str
    :ivar output: The output from the tool call.
    :vartype output: str
    :ivar error: The error from the tool call, if any.
    :vartype error: str
    """

    type: Literal[ItemType.MCP_CALL] = rest_discriminator(name="type", visibility=["read", "create", "update", "delete", "query"])  # type: ignore
    """Required."""
    server_label: str = rest_field(visibility=["read", "create", "update", "delete", "query"])
    """The label of the MCP server running the tool. Required."""
    name: str = rest_field(visibility=["read", "create", "update", "delete", "query"])
    """The name of the tool that was run. Required."""
    arguments: str = rest_field(visibility=["read", "create", "update", "delete", "query"])
    """A JSON string of the arguments passed to the tool. Required."""
    output: Optional[str] = rest_field(visibility=["read", "create", "update", "delete", "query"])
    """The output from the tool call."""
    error: Optional[str] = rest_field(visibility=["read", "create", "update", "delete", "query"])
    """The error from the tool call, if any."""

    @overload
    def __init__(
        self,
        *,
        server_label: str,
        name: str,
        arguments: str,
        output: Optional[str] = None,
        error: Optional[str] = None,
    ) -> None: ...

    @overload
    def __init__(self, mapping: Mapping[str, Any]) -> None:
        """
        :param mapping: raw JSON to initialize the model.
        :type mapping: Mapping[str, Any]
        """

    def __init__(self, *args: Any, **kwargs: Any) -> None:
        super().__init__(*args, **kwargs)
        self.type = ItemType.MCP_CALL  # type: ignore


class MCPCallItemResource(ItemResource, discriminator="mcp_call"):
    """An invocation of a tool on an MCP server.

    :ivar id: Required.
    :vartype id: str
    :ivar type: Required.
    :vartype type: str or ~openai.models.MCP_CALL
    :ivar server_label: The label of the MCP server running the tool. Required.
    :vartype server_label: str
    :ivar name: The name of the tool that was run. Required.
    :vartype name: str
    :ivar arguments: A JSON string of the arguments passed to the tool. Required.
    :vartype arguments: str
    :ivar output: The output from the tool call.
    :vartype output: str
    :ivar error: The error from the tool call, if any.
    :vartype error: str
    """

    type: Literal[ItemType.MCP_CALL] = rest_discriminator(name="type", visibility=["read", "create", "update", "delete", "query"])  # type: ignore
    """Required."""
    server_label: str = rest_field(visibility=["read", "create", "update", "delete", "query"])
    """The label of the MCP server running the tool. Required."""
    name: str = rest_field(visibility=["read", "create", "update", "delete", "query"])
    """The name of the tool that was run. Required."""
    arguments: str = rest_field(visibility=["read", "create", "update", "delete", "query"])
    """A JSON string of the arguments passed to the tool. Required."""
    output: Optional[str] = rest_field(visibility=["read", "create", "update", "delete", "query"])
    """The output from the tool call."""
    error: Optional[str] = rest_field(visibility=["read", "create", "update", "delete", "query"])
    """The error from the tool call, if any."""

    @overload
    def __init__(
        self,
        *,
        id: str,  # pylint: disable=redefined-builtin
        server_label: str,
        name: str,
        arguments: str,
        output: Optional[str] = None,
        error: Optional[str] = None,
    ) -> None: ...

    @overload
    def __init__(self, mapping: Mapping[str, Any]) -> None:
        """
        :param mapping: raw JSON to initialize the model.
        :type mapping: Mapping[str, Any]
        """

    def __init__(self, *args: Any, **kwargs: Any) -> None:
        super().__init__(*args, **kwargs)
        self.type = ItemType.MCP_CALL  # type: ignore


class MCPListToolsItemParam(ItemParam, discriminator="mcp_list_tools"):
    """A list of tools available on an MCP server.

    :ivar type: Required.
    :vartype type: str or ~openai.models.MCP_LIST_TOOLS
    :ivar server_label: The label of the MCP server. Required.
    :vartype server_label: str
    :ivar tools: The tools available on the server. Required.
    :vartype tools: list[~openai.models.MCPListToolsTool]
    :ivar error: Error message if the server could not list tools.
    :vartype error: str
    """

    type: Literal[ItemType.MCP_LIST_TOOLS] = rest_discriminator(name="type", visibility=["read", "create", "update", "delete", "query"])  # type: ignore
    """Required."""
    server_label: str = rest_field(visibility=["read", "create", "update", "delete", "query"])
    """The label of the MCP server. Required."""
    tools: list["_models.MCPListToolsTool"] = rest_field(visibility=["read", "create", "update", "delete", "query"])
    """The tools available on the server. Required."""
    error: Optional[str] = rest_field(visibility=["read", "create", "update", "delete", "query"])
    """Error message if the server could not list tools."""

    @overload
    def __init__(
        self,
        *,
        server_label: str,
        tools: list["_models.MCPListToolsTool"],
        error: Optional[str] = None,
    ) -> None: ...

    @overload
    def __init__(self, mapping: Mapping[str, Any]) -> None:
        """
        :param mapping: raw JSON to initialize the model.
        :type mapping: Mapping[str, Any]
        """

    def __init__(self, *args: Any, **kwargs: Any) -> None:
        super().__init__(*args, **kwargs)
        self.type = ItemType.MCP_LIST_TOOLS  # type: ignore


class MCPListToolsItemResource(ItemResource, discriminator="mcp_list_tools"):
    """A list of tools available on an MCP server.

    :ivar id: Required.
    :vartype id: str
    :ivar type: Required.
    :vartype type: str or ~openai.models.MCP_LIST_TOOLS
    :ivar server_label: The label of the MCP server. Required.
    :vartype server_label: str
    :ivar tools: The tools available on the server. Required.
    :vartype tools: list[~openai.models.MCPListToolsTool]
    :ivar error: Error message if the server could not list tools.
    :vartype error: str
    """

    type: Literal[ItemType.MCP_LIST_TOOLS] = rest_discriminator(name="type", visibility=["read", "create", "update", "delete", "query"])  # type: ignore
    """Required."""
    server_label: str = rest_field(visibility=["read", "create", "update", "delete", "query"])
    """The label of the MCP server. Required."""
    tools: list["_models.MCPListToolsTool"] = rest_field(visibility=["read", "create", "update", "delete", "query"])
    """The tools available on the server. Required."""
    error: Optional[str] = rest_field(visibility=["read", "create", "update", "delete", "query"])
    """Error message if the server could not list tools."""

    @overload
    def __init__(
        self,
        *,
        id: str,  # pylint: disable=redefined-builtin
        server_label: str,
        tools: list["_models.MCPListToolsTool"],
        error: Optional[str] = None,
    ) -> None: ...

    @overload
    def __init__(self, mapping: Mapping[str, Any]) -> None:
        """
        :param mapping: raw JSON to initialize the model.
        :type mapping: Mapping[str, Any]
        """

    def __init__(self, *args: Any, **kwargs: Any) -> None:
        super().__init__(*args, **kwargs)
        self.type = ItemType.MCP_LIST_TOOLS  # type: ignore


class MCPListToolsTool(_Model):
    """A tool available on an MCP server.

    :ivar name: The name of the tool. Required.
    :vartype name: str
    :ivar description: The description of the tool.
    :vartype description: str
    :ivar input_schema: The JSON schema describing the tool's input. Required.
    :vartype input_schema: any
    :ivar annotations: Additional annotations about the tool.
    :vartype annotations: any
    """

    name: str = rest_field(visibility=["read", "create", "update", "delete", "query"])
    """The name of the tool. Required."""
    description: Optional[str] = rest_field(visibility=["read", "create", "update", "delete", "query"])
    """The description of the tool."""
    input_schema: Any = rest_field(visibility=["read", "create", "update", "delete", "query"])
    """The JSON schema describing the tool's input. Required."""
    annotations: Optional[Any] = rest_field(visibility=["read", "create", "update", "delete", "query"])
    """Additional annotations about the tool."""

    @overload
    def __init__(
        self,
        *,
        name: str,
        input_schema: Any,
        description: Optional[str] = None,
        annotations: Optional[Any] = None,
    ) -> None: ...

    @overload
    def __init__(self, mapping: Mapping[str, Any]) -> None:
        """
        :param mapping: raw JSON to initialize the model.
        :type mapping: Mapping[str, Any]
        """

    def __init__(self, *args: Any, **kwargs: Any) -> None:
        super().__init__(*args, **kwargs)


class MCPTool(Tool, discriminator="mcp"):
    """Give the model access to additional tools via remote Model Context Protocol
    (MCP) servers. `Learn more about MCP </docs/guides/tools-remote-mcp>`_.

    :ivar type: The type of the MCP tool. Always ``mcp``. Required.
    :vartype type: str or ~openai.models.MCP
    :ivar server_label: A label for this MCP server, used to identify it in tool calls. Required.
    :vartype server_label: str
    :ivar server_url: The URL for the MCP server. Required.
    :vartype server_url: str
    :ivar headers: Optional HTTP headers to send to the MCP server. Use for authentication
     or other purposes.
    :vartype headers: dict[str, str]
    :ivar allowed_tools: List of allowed tool names or a filter object. Is either a [str] type or a
     MCPToolAllowedTools1 type.
    :vartype allowed_tools: list[str] or ~openai.models.MCPToolAllowedTools1
    :ivar require_approval: Specify which of the MCP server's tools require approval. Is one of the
     following types: MCPToolRequireApproval1, Literal["always"], Literal["never"]
    :vartype require_approval: ~openai.models.MCPToolRequireApproval1 or str or str
    :ivar project_connection_id: The connection ID in the project for the MCP server. The
     connection stores authentication and other connection details needed to connect to the MCP
     server. Required.
    :vartype project_connection_id: str
    """

    type: Literal[ToolType.MCP] = rest_discriminator(name="type", visibility=["read", "create", "update", "delete", "query"])  # type: ignore
    """The type of the MCP tool. Always ``mcp``. Required."""
    server_label: str = rest_field(visibility=["read", "create", "update", "delete", "query"])
    """A label for this MCP server, used to identify it in tool calls. Required."""
    server_url: str = rest_field(visibility=["read", "create", "update", "delete", "query"])
    """The URL for the MCP server. Required."""
    headers: Optional[dict[str, str]] = rest_field(visibility=["read", "create", "update", "delete", "query"])
    """Optional HTTP headers to send to the MCP server. Use for authentication
     or other purposes."""
    allowed_tools: Optional[Union[list[str], "_models.MCPToolAllowedTools1"]] = rest_field(
        visibility=["read", "create", "update", "delete", "query"]
    )
    """List of allowed tool names or a filter object. Is either a [str] type or a MCPToolAllowedTools1
     type."""
    require_approval: Optional[Union["_models.MCPToolRequireApproval1", Literal["always"], Literal["never"]]] = (
        rest_field(visibility=["read", "create", "update", "delete", "query"])
    )
    """Specify which of the MCP server's tools require approval. Is one of the following types:
     MCPToolRequireApproval1, Literal[\"always\"], Literal[\"never\"]"""
    project_connection_id: str = rest_field(visibility=["read", "create", "update", "delete", "query"])
    """The connection ID in the project for the MCP server. The connection stores authentication and
     other connection details needed to connect to the MCP server. Required."""

    @overload
    def __init__(
        self,
        *,
        server_label: str,
        server_url: str,
        project_connection_id: str,
        headers: Optional[dict[str, str]] = None,
        allowed_tools: Optional[Union[list[str], "_models.MCPToolAllowedTools1"]] = None,
        require_approval: Optional[
            Union["_models.MCPToolRequireApproval1", Literal["always"], Literal["never"]]
        ] = None,
    ) -> None: ...

    @overload
    def __init__(self, mapping: Mapping[str, Any]) -> None:
        """
        :param mapping: raw JSON to initialize the model.
        :type mapping: Mapping[str, Any]
        """

    def __init__(self, *args: Any, **kwargs: Any) -> None:
        super().__init__(*args, **kwargs)
        self.type = ToolType.MCP  # type: ignore


class MCPToolAllowedTools1(_Model):
    """MCPToolAllowedTools1.

    :ivar tool_names: List of allowed tool names.
    :vartype tool_names: list[str]
    """

    tool_names: Optional[list[str]] = rest_field(visibility=["read", "create", "update", "delete", "query"])
    """List of allowed tool names."""

    @overload
    def __init__(
        self,
        *,
        tool_names: Optional[list[str]] = None,
    ) -> None: ...

    @overload
    def __init__(self, mapping: Mapping[str, Any]) -> None:
        """
        :param mapping: raw JSON to initialize the model.
        :type mapping: Mapping[str, Any]
        """

    def __init__(self, *args: Any, **kwargs: Any) -> None:
        super().__init__(*args, **kwargs)


class MCPToolRequireApproval1(_Model):
    """MCPToolRequireApproval1.

    :ivar always: A list of tools that always require approval.
    :vartype always: ~openai.models.MCPToolRequireApprovalAlways
    :ivar never: A list of tools that never require approval.
    :vartype never: ~openai.models.MCPToolRequireApprovalNever
    """

    always: Optional["_models.MCPToolRequireApprovalAlways"] = rest_field(
        visibility=["read", "create", "update", "delete", "query"]
    )
    """A list of tools that always require approval."""
    never: Optional["_models.MCPToolRequireApprovalNever"] = rest_field(
        visibility=["read", "create", "update", "delete", "query"]
    )
    """A list of tools that never require approval."""

    @overload
    def __init__(
        self,
        *,
        always: Optional["_models.MCPToolRequireApprovalAlways"] = None,
        never: Optional["_models.MCPToolRequireApprovalNever"] = None,
    ) -> None: ...

    @overload
    def __init__(self, mapping: Mapping[str, Any]) -> None:
        """
        :param mapping: raw JSON to initialize the model.
        :type mapping: Mapping[str, Any]
        """

    def __init__(self, *args: Any, **kwargs: Any) -> None:
        super().__init__(*args, **kwargs)


class MCPToolRequireApprovalAlways(_Model):
    """MCPToolRequireApprovalAlways.

    :ivar tool_names: List of tools that require approval.
    :vartype tool_names: list[str]
    """

    tool_names: Optional[list[str]] = rest_field(visibility=["read", "create", "update", "delete", "query"])
    """List of tools that require approval."""

    @overload
    def __init__(
        self,
        *,
        tool_names: Optional[list[str]] = None,
    ) -> None: ...

    @overload
    def __init__(self, mapping: Mapping[str, Any]) -> None:
        """
        :param mapping: raw JSON to initialize the model.
        :type mapping: Mapping[str, Any]
        """

    def __init__(self, *args: Any, **kwargs: Any) -> None:
        super().__init__(*args, **kwargs)


class MCPToolRequireApprovalNever(_Model):
    """MCPToolRequireApprovalNever.

    :ivar tool_names: List of tools that do not require approval.
    :vartype tool_names: list[str]
    """

    tool_names: Optional[list[str]] = rest_field(visibility=["read", "create", "update", "delete", "query"])
    """List of tools that do not require approval."""

    @overload
    def __init__(
        self,
        *,
        tool_names: Optional[list[str]] = None,
    ) -> None: ...

    @overload
    def __init__(self, mapping: Mapping[str, Any]) -> None:
        """
        :param mapping: raw JSON to initialize the model.
        :type mapping: Mapping[str, Any]
        """

    def __init__(self, *args: Any, **kwargs: Any) -> None:
        super().__init__(*args, **kwargs)


class Prompt(_Model):
    """Reference to a prompt template and its variables.
    `Learn more </docs/guides/text?api-mode=responses#reusable-prompts>`_.

    :ivar id: The unique identifier of the prompt template to use. Required.
    :vartype id: str
    :ivar version: Optional version of the prompt template.
    :vartype version: str
    :ivar variables:
    :vartype variables: ~openai.models.ResponsePromptVariables
    """

    id: str = rest_field(visibility=["read", "create", "update", "delete", "query"])
    """The unique identifier of the prompt template to use. Required."""
    version: Optional[str] = rest_field(visibility=["read", "create", "update", "delete", "query"])
    """Optional version of the prompt template."""
    variables: Optional["_models.ResponsePromptVariables"] = rest_field(
        visibility=["read", "create", "update", "delete", "query"]
    )

    @overload
    def __init__(
        self,
        *,
        id: str,  # pylint: disable=redefined-builtin
        version: Optional[str] = None,
        variables: Optional["_models.ResponsePromptVariables"] = None,
    ) -> None: ...

    @overload
    def __init__(self, mapping: Mapping[str, Any]) -> None:
        """
        :param mapping: raw JSON to initialize the model.
        :type mapping: Mapping[str, Any]
        """

    def __init__(self, *args: Any, **kwargs: Any) -> None:
        super().__init__(*args, **kwargs)


class RankingOptions(_Model):
    """RankingOptions.

    :ivar ranker: The ranker to use for the file search. Is either a Literal["auto"] type or a
     Literal["default-2024-11-15"] type.
    :vartype ranker: str or str
    :ivar score_threshold: The score threshold for the file search, a number between 0 and 1.
     Numbers closer to 1 will attempt to return only the most relevant results, but may return fewer
     results.
    :vartype score_threshold: float
    """

    ranker: Optional[Literal["auto", "default-2024-11-15"]] = rest_field(
        visibility=["read", "create", "update", "delete", "query"]
    )
    """The ranker to use for the file search. Is either a Literal[\"auto\"] type or a
     Literal[\"default-2024-11-15\"] type."""
    score_threshold: Optional[float] = rest_field(visibility=["read", "create", "update", "delete", "query"])
    """The score threshold for the file search, a number between 0 and 1. Numbers closer to 1 will
     attempt to return only the most relevant results, but may return fewer results."""

    @overload
    def __init__(
        self,
        *,
        ranker: Optional[Literal["auto", "default-2024-11-15"]] = None,
        score_threshold: Optional[float] = None,
    ) -> None: ...

    @overload
    def __init__(self, mapping: Mapping[str, Any]) -> None:
        """
        :param mapping: raw JSON to initialize the model.
        :type mapping: Mapping[str, Any]
        """

    def __init__(self, *args: Any, **kwargs: Any) -> None:
        super().__init__(*args, **kwargs)


class Reasoning(_Model):
    """**o-series models only**

    Configuration options for
    `reasoning models <https://platform.openai.com/docs/guides/reasoning>`_.

    :ivar effort: Known values are: "low", "medium", and "high".
    :vartype effort: str or ~openai.models.ReasoningEffort
    :ivar summary: A summary of the reasoning performed by the model. This can be
     useful for debugging and understanding the model's reasoning process.
     One of ``auto``, ``concise``, or ``detailed``. Is one of the following types: Literal["auto"],
     Literal["concise"], Literal["detailed"]
    :vartype summary: str or str or str
    :ivar generate_summary: **Deprecated:** use ``summary`` instead.

     A summary of the reasoning performed by the model. This can be
     useful for debugging and understanding the model's reasoning process.
     One of ``auto``, ``concise``, or ``detailed``. Is one of the following types: Literal["auto"],
     Literal["concise"], Literal["detailed"]
    :vartype generate_summary: str or str or str
    """

    effort: Optional[Union[str, "_models.ReasoningEffort"]] = rest_field(
        visibility=["read", "create", "update", "delete", "query"]
    )
    """Known values are: \"low\", \"medium\", and \"high\"."""
    summary: Optional[Literal["auto", "concise", "detailed"]] = rest_field(
        visibility=["read", "create", "update", "delete", "query"]
    )
    """A summary of the reasoning performed by the model. This can be
     useful for debugging and understanding the model's reasoning process.
     One of ``auto``, ``concise``, or ``detailed``. Is one of the following types:
     Literal[\"auto\"], Literal[\"concise\"], Literal[\"detailed\"]"""
    generate_summary: Optional[Literal["auto", "concise", "detailed"]] = rest_field(
        visibility=["read", "create", "update", "delete", "query"]
    )
    """**Deprecated:** use ``summary`` instead.
     
     A summary of the reasoning performed by the model. This can be
     useful for debugging and understanding the model's reasoning process.
     One of ``auto``, ``concise``, or ``detailed``. Is one of the following types:
     Literal[\"auto\"], Literal[\"concise\"], Literal[\"detailed\"]"""

    @overload
    def __init__(
        self,
        *,
        effort: Optional[Union[str, "_models.ReasoningEffort"]] = None,
        summary: Optional[Literal["auto", "concise", "detailed"]] = None,
        generate_summary: Optional[Literal["auto", "concise", "detailed"]] = None,
    ) -> None: ...

    @overload
    def __init__(self, mapping: Mapping[str, Any]) -> None:
        """
        :param mapping: raw JSON to initialize the model.
        :type mapping: Mapping[str, Any]
        """

    def __init__(self, *args: Any, **kwargs: Any) -> None:
        super().__init__(*args, **kwargs)


class ReasoningItemParam(ItemParam, discriminator="reasoning"):
    """A description of the chain of thought used by a reasoning model while generating
    a response. Be sure to include these items in your ``input`` to the Responses API
    for subsequent turns of a conversation if you are manually
    `managing context </docs/guides/conversation-state>`_.

    :ivar type: Required.
    :vartype type: str or ~openai.models.REASONING
    :ivar encrypted_content: The encrypted content of the reasoning item - populated when a
     response is
     generated with ``reasoning.encrypted_content`` in the ``include`` parameter.
    :vartype encrypted_content: str
    :ivar summary: Reasoning text contents. Required.
    :vartype summary: list[~openai.models.ReasoningItemSummaryPart]
    """

    type: Literal[ItemType.REASONING] = rest_discriminator(name="type", visibility=["read", "create", "update", "delete", "query"])  # type: ignore
    """Required."""
    encrypted_content: Optional[str] = rest_field(visibility=["read", "create", "update", "delete", "query"])
    """The encrypted content of the reasoning item - populated when a response is
     generated with ``reasoning.encrypted_content`` in the ``include`` parameter."""
    summary: list["_models.ReasoningItemSummaryPart"] = rest_field(
        visibility=["read", "create", "update", "delete", "query"]
    )
    """Reasoning text contents. Required."""

    @overload
    def __init__(
        self,
        *,
        summary: list["_models.ReasoningItemSummaryPart"],
        encrypted_content: Optional[str] = None,
    ) -> None: ...

    @overload
    def __init__(self, mapping: Mapping[str, Any]) -> None:
        """
        :param mapping: raw JSON to initialize the model.
        :type mapping: Mapping[str, Any]
        """

    def __init__(self, *args: Any, **kwargs: Any) -> None:
        super().__init__(*args, **kwargs)
        self.type = ItemType.REASONING  # type: ignore


class ReasoningItemResource(ItemResource, discriminator="reasoning"):
    """A description of the chain of thought used by a reasoning model while generating
    a response. Be sure to include these items in your ``input`` to the Responses API
    for subsequent turns of a conversation if you are manually
    `managing context </docs/guides/conversation-state>`_.

    :ivar id: Required.
    :vartype id: str
    :ivar type: Required.
    :vartype type: str or ~openai.models.REASONING
    :ivar encrypted_content: The encrypted content of the reasoning item - populated when a
     response is
     generated with ``reasoning.encrypted_content`` in the ``include`` parameter.
    :vartype encrypted_content: str
    :ivar summary: Reasoning text contents. Required.
    :vartype summary: list[~openai.models.ReasoningItemSummaryPart]
    """

    type: Literal[ItemType.REASONING] = rest_discriminator(name="type", visibility=["read", "create", "update", "delete", "query"])  # type: ignore
    """Required."""
    encrypted_content: Optional[str] = rest_field(visibility=["read", "create", "update", "delete", "query"])
    """The encrypted content of the reasoning item - populated when a response is
     generated with ``reasoning.encrypted_content`` in the ``include`` parameter."""
    summary: list["_models.ReasoningItemSummaryPart"] = rest_field(
        visibility=["read", "create", "update", "delete", "query"]
    )
    """Reasoning text contents. Required."""

    @overload
    def __init__(
        self,
        *,
        id: str,  # pylint: disable=redefined-builtin
        summary: list["_models.ReasoningItemSummaryPart"],
        encrypted_content: Optional[str] = None,
    ) -> None: ...

    @overload
    def __init__(self, mapping: Mapping[str, Any]) -> None:
        """
        :param mapping: raw JSON to initialize the model.
        :type mapping: Mapping[str, Any]
        """

    def __init__(self, *args: Any, **kwargs: Any) -> None:
        super().__init__(*args, **kwargs)
        self.type = ItemType.REASONING  # type: ignore


class ReasoningItemSummaryPart(_Model):
    """ReasoningItemSummaryPart.

    You probably want to use the sub-classes and not this class directly. Known sub-classes are:
    ReasoningItemSummaryTextPart

    :ivar type: Required. "summary_text"
    :vartype type: str or ~openai.models.ReasoningItemSummaryPartType
    """

    __mapping__: dict[str, _Model] = {}
    type: str = rest_discriminator(name="type", visibility=["read", "create", "update", "delete", "query"])
    """Required. \"summary_text\""""

    @overload
    def __init__(
        self,
        *,
        type: str,
    ) -> None: ...

    @overload
    def __init__(self, mapping: Mapping[str, Any]) -> None:
        """
        :param mapping: raw JSON to initialize the model.
        :type mapping: Mapping[str, Any]
        """

    def __init__(self, *args: Any, **kwargs: Any) -> None:
        super().__init__(*args, **kwargs)


class ReasoningItemSummaryTextPart(ReasoningItemSummaryPart, discriminator="summary_text"):
    """ReasoningItemSummaryTextPart.

    :ivar type: Required.
    :vartype type: str or ~openai.models.SUMMARY_TEXT
    :ivar text: Required.
    :vartype text: str
    """

    type: Literal[ReasoningItemSummaryPartType.SUMMARY_TEXT] = rest_discriminator(name="type", visibility=["read", "create", "update", "delete", "query"])  # type: ignore
    """Required."""
    text: str = rest_field(visibility=["read", "create", "update", "delete", "query"])
    """Required."""

    @overload
    def __init__(
        self,
        *,
        text: str,
    ) -> None: ...

    @overload
    def __init__(self, mapping: Mapping[str, Any]) -> None:
        """
        :param mapping: raw JSON to initialize the model.
        :type mapping: Mapping[str, Any]
        """

    def __init__(self, *args: Any, **kwargs: Any) -> None:
        super().__init__(*args, **kwargs)
        self.type = ReasoningItemSummaryPartType.SUMMARY_TEXT  # type: ignore


class Response(_Model):
    """Response.

    :ivar metadata: Set of 16 key-value pairs that can be attached to an object. This can be
     useful for storing additional information about the object in a structured
     format, and querying for objects via API or the dashboard.

     Keys are strings with a maximum length of 64 characters. Values are strings
     with a maximum length of 512 characters. Required.
    :vartype metadata: dict[str, str]
    :ivar temperature: What sampling temperature to use, between 0 and 2. Higher values like 0.8
     will make the output more random, while lower values like 0.2 will make it more focused and
     deterministic.
     We generally recommend altering this or ``top_p`` but not both. Required.
    :vartype temperature: float
    :ivar top_p: An alternative to sampling with temperature, called nucleus sampling,
     where the model considers the results of the tokens with top_p probability
     mass. So 0.1 means only the tokens comprising the top 10% probability mass
     are considered.

     We generally recommend altering this or ``temperature`` but not both. Required.
    :vartype top_p: float
    :ivar user: A unique identifier representing your end-user, which can help OpenAI to monitor
     and detect abuse. `Learn more </docs/guides/safety-best-practices#end-user-ids>`_. Required.
    :vartype user: str
    :ivar service_tier: Note: service_tier is not applicable to Azure OpenAI. Known values are:
     "auto", "default", "flex", "scale", and "priority".
    :vartype service_tier: str or ~openai.models.ServiceTier
    :ivar top_logprobs: An integer between 0 and 20 specifying the number of most likely tokens to
     return at each token position, each with an associated log probability.
    :vartype top_logprobs: int
    :ivar previous_response_id: The unique ID of the previous response to the model. Use this to
     create multi-turn conversations. Learn more about
     `conversation state </docs/guides/conversation-state>`_.
    :vartype previous_response_id: str
    :ivar model: The model deployment to use for the creation of this response.
    :vartype model: str
    :ivar reasoning:
    :vartype reasoning: ~openai.models.Reasoning
    :ivar background: Whether to run the model response in the background.
     `Learn more </docs/guides/background>`_.
    :vartype background: bool
    :ivar max_output_tokens: An upper bound for the number of tokens that can be generated for a
     response, including visible output tokens and `reasoning tokens </docs/guides/reasoning>`_.
    :vartype max_output_tokens: int
    :ivar max_tool_calls: The maximum number of total calls to built-in tools that can be processed
     in a response. This maximum number applies across all built-in tool calls, not per individual
     tool. Any further attempts to call a tool by the model will be ignored.
    :vartype max_tool_calls: int
    :ivar text: Configuration options for a text response from the model. Can be plain
     text or structured JSON data. Learn more:

     * [Text inputs and outputs](/docs/guides/text)
     * [Structured Outputs](/docs/guides/structured-outputs).
    :vartype text: ~openai.models.CreateResponseRequestText
    :ivar tools: An array of tools the model may call while generating a response. You
     can specify which tool to use by setting the ``tool_choice`` parameter.

     The two categories of tools you can provide the model are:



     * **Built-in tools**: Tools that are provided by OpenAI that extend the
     model's capabilities, like [web search](/docs/guides/tools-web-search)
     or [file search](/docs/guides/tools-file-search). Learn more about
     [built-in tools](/docs/guides/tools).
     * **Function calls (custom tools)**: Functions that are defined by you,
     enabling the model to call your own code. Learn more about
     [function calling](/docs/guides/function-calling).
    :vartype tools: list[~openai.models.Tool]
    :ivar tool_choice: How the model should select which tool (or tools) to use when generating
     a response. See the ``tools`` parameter to see how to specify which tools
     the model can call. Is either a Union[str, "_openai_models4.ToolChoiceOptions"] type or a
     ToolChoiceObject type.
    :vartype tool_choice: str or ~openai.models.ToolChoiceOptions or
     ~openai.models.ToolChoiceObject
    :ivar prompt:
    :vartype prompt: ~openai.models.Prompt
    :ivar truncation: The truncation strategy to use for the model response.

     * `auto`: If the context of this response and previous ones exceeds
     the model's context window size, the model will truncate the
     response to fit the context window by dropping input items in the
     middle of the conversation.
     * `disabled` (default): If a model response will exceed the context window
     size for a model, the request will fail with a 400 error. Is either a Literal["auto"] type or a
     Literal["disabled"] type.
    :vartype truncation: str or str
    :ivar id: Unique identifier for this Response. Required.
    :vartype id: str
    :ivar object: The object type of this resource - always set to ``response``. Required. Default
     value is "response".
    :vartype object: str
    :ivar status: The status of the response generation. One of ``completed``, ``failed``,
     ``in_progress``, ``cancelled``, ``queued``, or ``incomplete``. Is one of the following types:
     Literal["completed"], Literal["failed"], Literal["in_progress"], Literal["cancelled"],
     Literal["queued"], Literal["incomplete"]
    :vartype status: str or str or str or str or str or str
    :ivar created_at: Unix timestamp (in seconds) of when this Response was created. Required.
    :vartype created_at: ~datetime.datetime
    :ivar error: Required.
    :vartype error: ~openai.models.ResponseError
    :ivar incomplete_details: Details about why the response is incomplete. Required.
    :vartype incomplete_details: ~openai.models.ResponseIncompleteDetails1
    :ivar output: An array of content items generated by the model.



     * The length and order of items in the `output` array is dependent
     on the model's response.
     * Rather than accessing the first item in the `output` array and
     assuming it's an `assistant` message with the content generated by
     the model, you might consider using the `output_text` property where
     supported in SDKs. Required.
    :vartype output: list[~openai.models.ItemResource]
    :ivar instructions: A system (or developer) message inserted into the model's context.

     When using along with ``previous_response_id``, the instructions from a previous
     response will not be carried over to the next response. This makes it simple
     to swap out system (or developer) messages in new responses. Required. Is either a str type or
     a [ItemParam] type.
    :vartype instructions: str or list[~openai.models.ItemParam]
    :ivar output_text: SDK-only convenience property that contains the aggregated text output
     from all ``output_text`` items in the ``output`` array, if any are present.
     Supported in the Python and JavaScript SDKs.
    :vartype output_text: str
    :ivar usage:
    :vartype usage: ~openai.models.ResponseUsage
    :ivar parallel_tool_calls: Whether to allow the model to run tool calls in parallel. Required.
    :vartype parallel_tool_calls: bool
    :ivar conversation: Required.
    :vartype conversation: ~openai.models.ResponseConversation1
    :ivar agent: The agent used for this response.
    :vartype agent: ~azure.ai.agents.models.AgentId
    """

    metadata: dict[str, str] = rest_field(visibility=["read", "create", "update", "delete", "query"])
    """Set of 16 key-value pairs that can be attached to an object. This can be
     useful for storing additional information about the object in a structured
     format, and querying for objects via API or the dashboard.
     
     Keys are strings with a maximum length of 64 characters. Values are strings
     with a maximum length of 512 characters. Required."""
    temperature: float = rest_field(visibility=["read", "create", "update", "delete", "query"])
    """What sampling temperature to use, between 0 and 2. Higher values like 0.8 will make the output
     more random, while lower values like 0.2 will make it more focused and deterministic.
     We generally recommend altering this or ``top_p`` but not both. Required."""
    top_p: float = rest_field(visibility=["read", "create", "update", "delete", "query"])
    """An alternative to sampling with temperature, called nucleus sampling,
     where the model considers the results of the tokens with top_p probability
     mass. So 0.1 means only the tokens comprising the top 10% probability mass
     are considered.
     
     We generally recommend altering this or ``temperature`` but not both. Required."""
    user: str = rest_field(visibility=["read", "create", "update", "delete", "query"])
    """A unique identifier representing your end-user, which can help OpenAI to monitor and detect
     abuse. `Learn more </docs/guides/safety-best-practices#end-user-ids>`_. Required."""
    service_tier: Optional[Union[str, "_models.ServiceTier"]] = rest_field(
        visibility=["read", "create", "update", "delete", "query"]
    )
    """Note: service_tier is not applicable to Azure OpenAI. Known values are: \"auto\", \"default\",
     \"flex\", \"scale\", and \"priority\"."""
    top_logprobs: Optional[int] = rest_field(visibility=["read", "create", "update", "delete", "query"])
    """An integer between 0 and 20 specifying the number of most likely tokens to return at each token
     position, each with an associated log probability."""
    previous_response_id: Optional[str] = rest_field(visibility=["read", "create", "update", "delete", "query"])
    """The unique ID of the previous response to the model. Use this to
     create multi-turn conversations. Learn more about
     `conversation state </docs/guides/conversation-state>`_."""
    model: Optional[str] = rest_field(visibility=["read", "create", "update", "delete", "query"])
    """The model deployment to use for the creation of this response."""
    reasoning: Optional["_models.Reasoning"] = rest_field(visibility=["read", "create", "update", "delete", "query"])
    background: Optional[bool] = rest_field(visibility=["read", "create", "update", "delete", "query"])
    """Whether to run the model response in the background.
     `Learn more </docs/guides/background>`_."""
    max_output_tokens: Optional[int] = rest_field(visibility=["read", "create", "update", "delete", "query"])
    """An upper bound for the number of tokens that can be generated for a response, including visible
     output tokens and `reasoning tokens </docs/guides/reasoning>`_."""
    max_tool_calls: Optional[int] = rest_field(visibility=["read", "create", "update", "delete", "query"])
    """The maximum number of total calls to built-in tools that can be processed in a response. This
     maximum number applies across all built-in tool calls, not per individual tool. Any further
     attempts to call a tool by the model will be ignored."""
    text: Optional["_models.CreateResponseRequestText"] = rest_field(
        visibility=["read", "create", "update", "delete", "query"]
    )
    """Configuration options for a text response from the model. Can be plain
     text or structured JSON data. Learn more:
     
     * [Text inputs and outputs](/docs/guides/text)
     * [Structured Outputs](/docs/guides/structured-outputs)."""
    tools: Optional[list["_models.Tool"]] = rest_field(visibility=["read", "create", "update", "delete", "query"])
    """An array of tools the model may call while generating a response. You
     can specify which tool to use by setting the ``tool_choice`` parameter.
     
     The two categories of tools you can provide the model are:
     
     
     
     * **Built-in tools**: Tools that are provided by OpenAI that extend the
     model's capabilities, like [web search](/docs/guides/tools-web-search)
     or [file search](/docs/guides/tools-file-search). Learn more about
     [built-in tools](/docs/guides/tools).
     * **Function calls (custom tools)**: Functions that are defined by you,
     enabling the model to call your own code. Learn more about
     [function calling](/docs/guides/function-calling)."""
    tool_choice: Optional[Union[str, "_models.ToolChoiceOptions", "_models.ToolChoiceObject"]] = rest_field(
        visibility=["read", "create", "update", "delete", "query"]
    )
    """How the model should select which tool (or tools) to use when generating
     a response. See the ``tools`` parameter to see how to specify which tools
     the model can call. Is either a Union[str, \"_openai_models4.ToolChoiceOptions\"] type or a
     ToolChoiceObject type."""
    prompt: Optional["_models.Prompt"] = rest_field(visibility=["read", "create", "update", "delete", "query"])
    truncation: Optional[Literal["auto", "disabled"]] = rest_field(
        visibility=["read", "create", "update", "delete", "query"]
    )
    """The truncation strategy to use for the model response.
     
     * `auto`: If the context of this response and previous ones exceeds
     the model's context window size, the model will truncate the
     response to fit the context window by dropping input items in the
     middle of the conversation.
     * `disabled` (default): If a model response will exceed the context window
     size for a model, the request will fail with a 400 error. Is either a Literal[\"auto\"] type or
     a Literal[\"disabled\"] type."""
    id: str = rest_field(visibility=["read", "create", "update", "delete", "query"])
    """Unique identifier for this Response. Required."""
    object: Literal["response"] = rest_field(visibility=["read", "create", "update", "delete", "query"])
    """The object type of this resource - always set to ``response``. Required. Default value is
     \"response\"."""
    status: Optional[Literal["completed", "failed", "in_progress", "cancelled", "queued", "incomplete"]] = rest_field(
        visibility=["read", "create", "update", "delete", "query"]
    )
    """The status of the response generation. One of ``completed``, ``failed``,
     ``in_progress``, ``cancelled``, ``queued``, or ``incomplete``. Is one of the following types:
     Literal[\"completed\"], Literal[\"failed\"], Literal[\"in_progress\"], Literal[\"cancelled\"],
     Literal[\"queued\"], Literal[\"incomplete\"]"""
    created_at: datetime.datetime = rest_field(
        visibility=["read", "create", "update", "delete", "query"], format="unix-timestamp"
    )
    """Unix timestamp (in seconds) of when this Response was created. Required."""
    error: "_models.ResponseError" = rest_field(visibility=["read", "create", "update", "delete", "query"])
    """Required."""
    incomplete_details: "_models.ResponseIncompleteDetails1" = rest_field(
        visibility=["read", "create", "update", "delete", "query"]
    )
    """Details about why the response is incomplete. Required."""
    output: list["_models.ItemResource"] = rest_field(visibility=["read", "create", "update", "delete", "query"])
    """An array of content items generated by the model.
     
     
     
     * The length and order of items in the `output` array is dependent
     on the model's response.
     * Rather than accessing the first item in the `output` array and
     assuming it's an `assistant` message with the content generated by
     the model, you might consider using the `output_text` property where
     supported in SDKs. Required."""
    instructions: Union[str, list["_models.ItemParam"]] = rest_field(
        visibility=["read", "create", "update", "delete", "query"]
    )
    """A system (or developer) message inserted into the model's context.
     
     When using along with ``previous_response_id``, the instructions from a previous
     response will not be carried over to the next response. This makes it simple
     to swap out system (or developer) messages in new responses. Required. Is either a str type or
     a [ItemParam] type."""
    output_text: Optional[str] = rest_field(visibility=["read", "create", "update", "delete", "query"])
    """SDK-only convenience property that contains the aggregated text output
     from all ``output_text`` items in the ``output`` array, if any are present.
     Supported in the Python and JavaScript SDKs."""
    usage: Optional["_models.ResponseUsage"] = rest_field(visibility=["read", "create", "update", "delete", "query"])
    parallel_tool_calls: bool = rest_field(visibility=["read", "create", "update", "delete", "query"])
    """Whether to allow the model to run tool calls in parallel. Required."""
    conversation: "_models.ResponseConversation1" = rest_field(
        visibility=["read", "create", "update", "delete", "query"]
    )
    """Required."""
    agent: Optional["_azure_ai_agents_models5.AgentId"] = rest_field(
        visibility=["read", "create", "update", "delete", "query"]
    )
    """The agent used for this response."""

    @overload
    def __init__(  # pylint: disable=too-many-locals
        self,
        *,
        metadata: dict[str, str],
        temperature: float,
        top_p: float,
        user: str,
        id: str,  # pylint: disable=redefined-builtin
        created_at: datetime.datetime,
        error: "_models.ResponseError",
        incomplete_details: "_models.ResponseIncompleteDetails1",
        output: list["_models.ItemResource"],
        instructions: Union[str, list["_models.ItemParam"]],
        parallel_tool_calls: bool,
        conversation: "_models.ResponseConversation1",
        service_tier: Optional[Union[str, "_models.ServiceTier"]] = None,
        top_logprobs: Optional[int] = None,
        previous_response_id: Optional[str] = None,
        model: Optional[str] = None,
        reasoning: Optional["_models.Reasoning"] = None,
        background: Optional[bool] = None,
        max_output_tokens: Optional[int] = None,
        max_tool_calls: Optional[int] = None,
        text: Optional["_models.CreateResponseRequestText"] = None,
        tools: Optional[list["_models.Tool"]] = None,
        tool_choice: Optional[Union[str, "_models.ToolChoiceOptions", "_models.ToolChoiceObject"]] = None,
        prompt: Optional["_models.Prompt"] = None,
        truncation: Optional[Literal["auto", "disabled"]] = None,
        status: Optional[Literal["completed", "failed", "in_progress", "cancelled", "queued", "incomplete"]] = None,
        output_text: Optional[str] = None,
        usage: Optional["_models.ResponseUsage"] = None,
        agent: Optional["_azure_ai_agents_models5.AgentId"] = None,
    ) -> None: ...

    @overload
    def __init__(self, mapping: Mapping[str, Any]) -> None:
        """
        :param mapping: raw JSON to initialize the model.
        :type mapping: Mapping[str, Any]
        """

    def __init__(self, *args: Any, **kwargs: Any) -> None:
        super().__init__(*args, **kwargs)
        self.object: Literal["response"] = "response"


class ResponseStreamEvent(_Model):
    """ResponseStreamEvent.

    You probably want to use the sub-classes and not this class directly. Known sub-classes are:
    ResponseErrorEvent, ResponseCodeInterpreterCallCompletedEvent,
    ResponseCodeInterpreterCallInProgressEvent, ResponseCodeInterpreterCallInterpretingEvent,
    ResponseCodeInterpreterCallCodeDeltaEvent, ResponseCodeInterpreterCallCodeDoneEvent,
    ResponseCompletedEvent, ResponseContentPartAddedEvent, ResponseContentPartDoneEvent,
    ResponseCreatedEvent, ResponseFailedEvent, ResponseFileSearchCallCompletedEvent,
    ResponseFileSearchCallInProgressEvent, ResponseFileSearchCallSearchingEvent,
    ResponseFunctionCallArgumentsDeltaEvent, ResponseFunctionCallArgumentsDoneEvent,
    ResponseImageGenCallCompletedEvent, ResponseImageGenCallGeneratingEvent,
    ResponseImageGenCallInProgressEvent, ResponseImageGenCallPartialImageEvent,
    ResponseInProgressEvent, ResponseIncompleteEvent, ResponseMCPCallArgumentsDeltaEvent,
    ResponseMCPCallArgumentsDoneEvent, ResponseMCPCallCompletedEvent, ResponseMCPCallFailedEvent,
    ResponseMCPCallInProgressEvent, ResponseMCPListToolsCompletedEvent,
    ResponseMCPListToolsFailedEvent, ResponseMCPListToolsInProgressEvent,
    ResponseOutputItemAddedEvent, ResponseOutputItemDoneEvent, ResponseTextDeltaEvent,
    ResponseTextDoneEvent, ResponseQueuedEvent, ResponseReasoningDeltaEvent,
    ResponseReasoningDoneEvent, ResponseReasoningSummaryDeltaEvent,
    ResponseReasoningSummaryDoneEvent, ResponseReasoningSummaryPartAddedEvent,
    ResponseReasoningSummaryPartDoneEvent, ResponseReasoningSummaryTextDeltaEvent,
    ResponseReasoningSummaryTextDoneEvent, ResponseRefusalDeltaEvent, ResponseRefusalDoneEvent,
    ResponseWebSearchCallCompletedEvent, ResponseWebSearchCallInProgressEvent,
    ResponseWebSearchCallSearchingEvent

    :ivar type: Required. Known values are: "response.audio.delta", "response.audio.done",
     "response.audio_transcript.delta", "response.audio_transcript.done",
     "response.code_interpreter_call_code.delta", "response.code_interpreter_call_code.done",
     "response.code_interpreter_call.completed", "response.code_interpreter_call.in_progress",
     "response.code_interpreter_call.interpreting", "response.completed",
     "response.content_part.added", "response.content_part.done", "response.created", "error",
     "response.file_search_call.completed", "response.file_search_call.in_progress",
     "response.file_search_call.searching", "response.function_call_arguments.delta",
     "response.function_call_arguments.done", "response.in_progress", "response.failed",
     "response.incomplete", "response.output_item.added", "response.output_item.done",
     "response.refusal.delta", "response.refusal.done", "response.output_text.annotation.added",
     "response.output_text.delta", "response.output_text.done",
     "response.reasoning_summary_part.added", "response.reasoning_summary_part.done",
     "response.reasoning_summary_text.delta", "response.reasoning_summary_text.done",
     "response.web_search_call.completed", "response.web_search_call.in_progress",
     "response.web_search_call.searching", "response.image_generation_call.completed",
     "response.image_generation_call.generating", "response.image_generation_call.in_progress",
     "response.image_generation_call.partial_image", "response.mcp_call.arguments_delta",
     "response.mcp_call.arguments_done", "response.mcp_call.completed", "response.mcp_call.failed",
     "response.mcp_call.in_progress", "response.mcp_list_tools.completed",
     "response.mcp_list_tools.failed", "response.mcp_list_tools.in_progress", "response.queued",
     "response.reasoning.delta", "response.reasoning.done", "response.reasoning_summary.delta", and
     "response.reasoning_summary.done".
    :vartype type: str or ~openai.models.ResponseStreamEventType
    :ivar sequence_number: The sequence number for this event. Required.
    :vartype sequence_number: int
    """

    __mapping__: dict[str, _Model] = {}
    type: str = rest_discriminator(name="type", visibility=["read", "create", "update", "delete", "query"])
    """Required. Known values are: \"response.audio.delta\", \"response.audio.done\",
     \"response.audio_transcript.delta\", \"response.audio_transcript.done\",
     \"response.code_interpreter_call_code.delta\", \"response.code_interpreter_call_code.done\",
     \"response.code_interpreter_call.completed\", \"response.code_interpreter_call.in_progress\",
     \"response.code_interpreter_call.interpreting\", \"response.completed\",
     \"response.content_part.added\", \"response.content_part.done\", \"response.created\",
     \"error\", \"response.file_search_call.completed\", \"response.file_search_call.in_progress\",
     \"response.file_search_call.searching\", \"response.function_call_arguments.delta\",
     \"response.function_call_arguments.done\", \"response.in_progress\", \"response.failed\",
     \"response.incomplete\", \"response.output_item.added\", \"response.output_item.done\",
     \"response.refusal.delta\", \"response.refusal.done\",
     \"response.output_text.annotation.added\", \"response.output_text.delta\",
     \"response.output_text.done\", \"response.reasoning_summary_part.added\",
     \"response.reasoning_summary_part.done\", \"response.reasoning_summary_text.delta\",
     \"response.reasoning_summary_text.done\", \"response.web_search_call.completed\",
     \"response.web_search_call.in_progress\", \"response.web_search_call.searching\",
     \"response.image_generation_call.completed\", \"response.image_generation_call.generating\",
     \"response.image_generation_call.in_progress\",
     \"response.image_generation_call.partial_image\", \"response.mcp_call.arguments_delta\",
     \"response.mcp_call.arguments_done\", \"response.mcp_call.completed\",
     \"response.mcp_call.failed\", \"response.mcp_call.in_progress\",
     \"response.mcp_list_tools.completed\", \"response.mcp_list_tools.failed\",
     \"response.mcp_list_tools.in_progress\", \"response.queued\", \"response.reasoning.delta\",
     \"response.reasoning.done\", \"response.reasoning_summary.delta\", and
     \"response.reasoning_summary.done\"."""
    sequence_number: int = rest_field(visibility=["read", "create", "update", "delete", "query"])
    """The sequence number for this event. Required."""

    @overload
    def __init__(
        self,
        *,
        type: str,
        sequence_number: int,
    ) -> None: ...

    @overload
    def __init__(self, mapping: Mapping[str, Any]) -> None:
        """
        :param mapping: raw JSON to initialize the model.
        :type mapping: Mapping[str, Any]
        """

    def __init__(self, *args: Any, **kwargs: Any) -> None:
        super().__init__(*args, **kwargs)


class ResponseCodeInterpreterCallCodeDeltaEvent(
    ResponseStreamEvent, discriminator="response.code_interpreter_call_code.delta"
):  # pylint: disable=name-too-long
    """Emitted when a partial code snippet is streamed by the code interpreter.

    :ivar sequence_number: The sequence number for this event. Required.
    :vartype sequence_number: int
    :ivar type: The type of the event. Always ``response.code_interpreter_call_code.delta``.
     Required.
    :vartype type: str or ~openai.models.RESPONSE_CODE_INTERPRETER_CALL_CODE_DELTA
    :ivar output_index: The index of the output item in the response for which the code is being
     streamed. Required.
    :vartype output_index: int
    :ivar item_id: The unique identifier of the code interpreter tool call item. Required.
    :vartype item_id: str
    :ivar delta: The partial code snippet being streamed by the code interpreter. Required.
    :vartype delta: str
    """

    type: Literal[ResponseStreamEventType.RESPONSE_CODE_INTERPRETER_CALL_CODE_DELTA] = rest_discriminator(name="type", visibility=["read", "create", "update", "delete", "query"])  # type: ignore
    """The type of the event. Always ``response.code_interpreter_call_code.delta``. Required."""
    output_index: int = rest_field(visibility=["read", "create", "update", "delete", "query"])
    """The index of the output item in the response for which the code is being streamed. Required."""
    item_id: str = rest_field(visibility=["read", "create", "update", "delete", "query"])
    """The unique identifier of the code interpreter tool call item. Required."""
    delta: str = rest_field(visibility=["read", "create", "update", "delete", "query"])
    """The partial code snippet being streamed by the code interpreter. Required."""

    @overload
    def __init__(
        self,
        *,
        sequence_number: int,
        output_index: int,
        item_id: str,
        delta: str,
    ) -> None: ...

    @overload
    def __init__(self, mapping: Mapping[str, Any]) -> None:
        """
        :param mapping: raw JSON to initialize the model.
        :type mapping: Mapping[str, Any]
        """

    def __init__(self, *args: Any, **kwargs: Any) -> None:
        super().__init__(*args, **kwargs)
        self.type = ResponseStreamEventType.RESPONSE_CODE_INTERPRETER_CALL_CODE_DELTA  # type: ignore


class ResponseCodeInterpreterCallCodeDoneEvent(
    ResponseStreamEvent, discriminator="response.code_interpreter_call_code.done"
):
    """Emitted when the code snippet is finalized by the code interpreter.

    :ivar sequence_number: The sequence number for this event. Required.
    :vartype sequence_number: int
    :ivar type: The type of the event. Always ``response.code_interpreter_call_code.done``.
     Required.
    :vartype type: str or ~openai.models.RESPONSE_CODE_INTERPRETER_CALL_CODE_DONE
    :ivar output_index: The index of the output item in the response for which the code is
     finalized. Required.
    :vartype output_index: int
    :ivar item_id: The unique identifier of the code interpreter tool call item. Required.
    :vartype item_id: str
    :ivar code: The final code snippet output by the code interpreter. Required.
    :vartype code: str
    """

    type: Literal[ResponseStreamEventType.RESPONSE_CODE_INTERPRETER_CALL_CODE_DONE] = rest_discriminator(name="type", visibility=["read", "create", "update", "delete", "query"])  # type: ignore
    """The type of the event. Always ``response.code_interpreter_call_code.done``. Required."""
    output_index: int = rest_field(visibility=["read", "create", "update", "delete", "query"])
    """The index of the output item in the response for which the code is finalized. Required."""
    item_id: str = rest_field(visibility=["read", "create", "update", "delete", "query"])
    """The unique identifier of the code interpreter tool call item. Required."""
    code: str = rest_field(visibility=["read", "create", "update", "delete", "query"])
    """The final code snippet output by the code interpreter. Required."""

    @overload
    def __init__(
        self,
        *,
        sequence_number: int,
        output_index: int,
        item_id: str,
        code: str,
    ) -> None: ...

    @overload
    def __init__(self, mapping: Mapping[str, Any]) -> None:
        """
        :param mapping: raw JSON to initialize the model.
        :type mapping: Mapping[str, Any]
        """

    def __init__(self, *args: Any, **kwargs: Any) -> None:
        super().__init__(*args, **kwargs)
        self.type = ResponseStreamEventType.RESPONSE_CODE_INTERPRETER_CALL_CODE_DONE  # type: ignore


class ResponseCodeInterpreterCallCompletedEvent(
    ResponseStreamEvent, discriminator="response.code_interpreter_call.completed"
):  # pylint: disable=name-too-long
    """Emitted when the code interpreter call is completed.

    :ivar sequence_number: The sequence number for this event. Required.
    :vartype sequence_number: int
    :ivar type: The type of the event. Always ``response.code_interpreter_call.completed``.
     Required.
    :vartype type: str or ~openai.models.RESPONSE_CODE_INTERPRETER_CALL_COMPLETED
    :ivar output_index: The index of the output item in the response for which the code interpreter
     call is completed. Required.
    :vartype output_index: int
    :ivar item_id: The unique identifier of the code interpreter tool call item. Required.
    :vartype item_id: str
    """

    type: Literal[ResponseStreamEventType.RESPONSE_CODE_INTERPRETER_CALL_COMPLETED] = rest_discriminator(name="type", visibility=["read", "create", "update", "delete", "query"])  # type: ignore
    """The type of the event. Always ``response.code_interpreter_call.completed``. Required."""
    output_index: int = rest_field(visibility=["read", "create", "update", "delete", "query"])
    """The index of the output item in the response for which the code interpreter call is completed.
     Required."""
    item_id: str = rest_field(visibility=["read", "create", "update", "delete", "query"])
    """The unique identifier of the code interpreter tool call item. Required."""

    @overload
    def __init__(
        self,
        *,
        sequence_number: int,
        output_index: int,
        item_id: str,
    ) -> None: ...

    @overload
    def __init__(self, mapping: Mapping[str, Any]) -> None:
        """
        :param mapping: raw JSON to initialize the model.
        :type mapping: Mapping[str, Any]
        """

    def __init__(self, *args: Any, **kwargs: Any) -> None:
        super().__init__(*args, **kwargs)
        self.type = ResponseStreamEventType.RESPONSE_CODE_INTERPRETER_CALL_COMPLETED  # type: ignore


class ResponseCodeInterpreterCallInProgressEvent(
    ResponseStreamEvent, discriminator="response.code_interpreter_call.in_progress"
):  # pylint: disable=name-too-long
    """Emitted when a code interpreter call is in progress.

    :ivar sequence_number: The sequence number for this event. Required.
    :vartype sequence_number: int
    :ivar type: The type of the event. Always ``response.code_interpreter_call.in_progress``.
     Required.
    :vartype type: str or ~openai.models.RESPONSE_CODE_INTERPRETER_CALL_IN_PROGRESS
    :ivar output_index: The index of the output item in the response for which the code interpreter
     call is in progress. Required.
    :vartype output_index: int
    :ivar item_id: The unique identifier of the code interpreter tool call item. Required.
    :vartype item_id: str
    """

    type: Literal[ResponseStreamEventType.RESPONSE_CODE_INTERPRETER_CALL_IN_PROGRESS] = rest_discriminator(name="type", visibility=["read", "create", "update", "delete", "query"])  # type: ignore
    """The type of the event. Always ``response.code_interpreter_call.in_progress``. Required."""
    output_index: int = rest_field(visibility=["read", "create", "update", "delete", "query"])
    """The index of the output item in the response for which the code interpreter call is in
     progress. Required."""
    item_id: str = rest_field(visibility=["read", "create", "update", "delete", "query"])
    """The unique identifier of the code interpreter tool call item. Required."""

    @overload
    def __init__(
        self,
        *,
        sequence_number: int,
        output_index: int,
        item_id: str,
    ) -> None: ...

    @overload
    def __init__(self, mapping: Mapping[str, Any]) -> None:
        """
        :param mapping: raw JSON to initialize the model.
        :type mapping: Mapping[str, Any]
        """

    def __init__(self, *args: Any, **kwargs: Any) -> None:
        super().__init__(*args, **kwargs)
        self.type = ResponseStreamEventType.RESPONSE_CODE_INTERPRETER_CALL_IN_PROGRESS  # type: ignore


class ResponseCodeInterpreterCallInterpretingEvent(
    ResponseStreamEvent, discriminator="response.code_interpreter_call.interpreting"
):  # pylint: disable=name-too-long
    """Emitted when the code interpreter is actively interpreting the code snippet.

    :ivar sequence_number: The sequence number for this event. Required.
    :vartype sequence_number: int
    :ivar type: The type of the event. Always ``response.code_interpreter_call.interpreting``.
     Required.
    :vartype type: str or ~openai.models.RESPONSE_CODE_INTERPRETER_CALL_INTERPRETING
    :ivar output_index: The index of the output item in the response for which the code interpreter
     is interpreting code. Required.
    :vartype output_index: int
    :ivar item_id: The unique identifier of the code interpreter tool call item. Required.
    :vartype item_id: str
    """

    type: Literal[ResponseStreamEventType.RESPONSE_CODE_INTERPRETER_CALL_INTERPRETING] = rest_discriminator(name="type", visibility=["read", "create", "update", "delete", "query"])  # type: ignore
    """The type of the event. Always ``response.code_interpreter_call.interpreting``. Required."""
    output_index: int = rest_field(visibility=["read", "create", "update", "delete", "query"])
    """The index of the output item in the response for which the code interpreter is interpreting
     code. Required."""
    item_id: str = rest_field(visibility=["read", "create", "update", "delete", "query"])
    """The unique identifier of the code interpreter tool call item. Required."""

    @overload
    def __init__(
        self,
        *,
        sequence_number: int,
        output_index: int,
        item_id: str,
    ) -> None: ...

    @overload
    def __init__(self, mapping: Mapping[str, Any]) -> None:
        """
        :param mapping: raw JSON to initialize the model.
        :type mapping: Mapping[str, Any]
        """

    def __init__(self, *args: Any, **kwargs: Any) -> None:
        super().__init__(*args, **kwargs)
        self.type = ResponseStreamEventType.RESPONSE_CODE_INTERPRETER_CALL_INTERPRETING  # type: ignore


class ResponseCompletedEvent(ResponseStreamEvent, discriminator="response.completed"):
    """Emitted when the model response is complete.

    :ivar sequence_number: The sequence number for this event. Required.
    :vartype sequence_number: int
    :ivar type: The type of the event. Always ``response.completed``. Required.
    :vartype type: str or ~openai.models.RESPONSE_COMPLETED
    :ivar response: Properties of the completed response. Required.
    :vartype response: ~openai.models.Response
    """

    type: Literal[ResponseStreamEventType.RESPONSE_COMPLETED] = rest_discriminator(name="type", visibility=["read", "create", "update", "delete", "query"])  # type: ignore
    """The type of the event. Always ``response.completed``. Required."""
    response: "_models.Response" = rest_field(visibility=["read", "create", "update", "delete", "query"])
    """Properties of the completed response. Required."""

    @overload
    def __init__(
        self,
        *,
        sequence_number: int,
        response: "_models.Response",
    ) -> None: ...

    @overload
    def __init__(self, mapping: Mapping[str, Any]) -> None:
        """
        :param mapping: raw JSON to initialize the model.
        :type mapping: Mapping[str, Any]
        """

    def __init__(self, *args: Any, **kwargs: Any) -> None:
        super().__init__(*args, **kwargs)
        self.type = ResponseStreamEventType.RESPONSE_COMPLETED  # type: ignore


class ResponseContentPartAddedEvent(ResponseStreamEvent, discriminator="response.content_part.added"):
    """Emitted when a new content part is added.

    :ivar sequence_number: The sequence number for this event. Required.
    :vartype sequence_number: int
    :ivar type: The type of the event. Always ``response.content_part.added``. Required.
    :vartype type: str or ~openai.models.RESPONSE_CONTENT_PART_ADDED
    :ivar item_id: The ID of the output item that the content part was added to. Required.
    :vartype item_id: str
    :ivar output_index: The index of the output item that the content part was added to. Required.
    :vartype output_index: int
    :ivar content_index: The index of the content part that was added. Required.
    :vartype content_index: int
    :ivar part: The content part that was added. Required.
    :vartype part: ~openai.models.ItemContent
    """

    type: Literal[ResponseStreamEventType.RESPONSE_CONTENT_PART_ADDED] = rest_discriminator(name="type", visibility=["read", "create", "update", "delete", "query"])  # type: ignore
    """The type of the event. Always ``response.content_part.added``. Required."""
    item_id: str = rest_field(visibility=["read", "create", "update", "delete", "query"])
    """The ID of the output item that the content part was added to. Required."""
    output_index: int = rest_field(visibility=["read", "create", "update", "delete", "query"])
    """The index of the output item that the content part was added to. Required."""
    content_index: int = rest_field(visibility=["read", "create", "update", "delete", "query"])
    """The index of the content part that was added. Required."""
    part: "_models.ItemContent" = rest_field(visibility=["read", "create", "update", "delete", "query"])
    """The content part that was added. Required."""

    @overload
    def __init__(
        self,
        *,
        sequence_number: int,
        item_id: str,
        output_index: int,
        content_index: int,
        part: "_models.ItemContent",
    ) -> None: ...

    @overload
    def __init__(self, mapping: Mapping[str, Any]) -> None:
        """
        :param mapping: raw JSON to initialize the model.
        :type mapping: Mapping[str, Any]
        """

    def __init__(self, *args: Any, **kwargs: Any) -> None:
        super().__init__(*args, **kwargs)
        self.type = ResponseStreamEventType.RESPONSE_CONTENT_PART_ADDED  # type: ignore


class ResponseContentPartDoneEvent(ResponseStreamEvent, discriminator="response.content_part.done"):
    """Emitted when a content part is done.

    :ivar sequence_number: The sequence number for this event. Required.
    :vartype sequence_number: int
    :ivar type: The type of the event. Always ``response.content_part.done``. Required.
    :vartype type: str or ~openai.models.RESPONSE_CONTENT_PART_DONE
    :ivar item_id: The ID of the output item that the content part was added to. Required.
    :vartype item_id: str
    :ivar output_index: The index of the output item that the content part was added to. Required.
    :vartype output_index: int
    :ivar content_index: The index of the content part that is done. Required.
    :vartype content_index: int
    :ivar part: The content part that is done. Required.
    :vartype part: ~openai.models.ItemContent
    """

    type: Literal[ResponseStreamEventType.RESPONSE_CONTENT_PART_DONE] = rest_discriminator(name="type", visibility=["read", "create", "update", "delete", "query"])  # type: ignore
    """The type of the event. Always ``response.content_part.done``. Required."""
    item_id: str = rest_field(visibility=["read", "create", "update", "delete", "query"])
    """The ID of the output item that the content part was added to. Required."""
    output_index: int = rest_field(visibility=["read", "create", "update", "delete", "query"])
    """The index of the output item that the content part was added to. Required."""
    content_index: int = rest_field(visibility=["read", "create", "update", "delete", "query"])
    """The index of the content part that is done. Required."""
    part: "_models.ItemContent" = rest_field(visibility=["read", "create", "update", "delete", "query"])
    """The content part that is done. Required."""

    @overload
    def __init__(
        self,
        *,
        sequence_number: int,
        item_id: str,
        output_index: int,
        content_index: int,
        part: "_models.ItemContent",
    ) -> None: ...

    @overload
    def __init__(self, mapping: Mapping[str, Any]) -> None:
        """
        :param mapping: raw JSON to initialize the model.
        :type mapping: Mapping[str, Any]
        """

    def __init__(self, *args: Any, **kwargs: Any) -> None:
        super().__init__(*args, **kwargs)
        self.type = ResponseStreamEventType.RESPONSE_CONTENT_PART_DONE  # type: ignore


class ResponseConversation1(_Model):
    """ResponseConversation1.

    :ivar id: Required.
    :vartype id: str
    """

    id: str = rest_field(visibility=["read", "create", "update", "delete", "query"])
    """Required."""

    @overload
    def __init__(
        self,
        *,
        id: str,  # pylint: disable=redefined-builtin
    ) -> None: ...

    @overload
    def __init__(self, mapping: Mapping[str, Any]) -> None:
        """
        :param mapping: raw JSON to initialize the model.
        :type mapping: Mapping[str, Any]
        """

    def __init__(self, *args: Any, **kwargs: Any) -> None:
        super().__init__(*args, **kwargs)


class ResponseCreatedEvent(ResponseStreamEvent, discriminator="response.created"):
    """An event that is emitted when a response is created.

    :ivar sequence_number: The sequence number for this event. Required.
    :vartype sequence_number: int
    :ivar type: The type of the event. Always ``response.created``. Required.
    :vartype type: str or ~openai.models.RESPONSE_CREATED
    :ivar response: The response that was created. Required.
    :vartype response: ~openai.models.Response
    """

    type: Literal[ResponseStreamEventType.RESPONSE_CREATED] = rest_discriminator(name="type", visibility=["read", "create", "update", "delete", "query"])  # type: ignore
    """The type of the event. Always ``response.created``. Required."""
    response: "_models.Response" = rest_field(visibility=["read", "create", "update", "delete", "query"])
    """The response that was created. Required."""

    @overload
    def __init__(
        self,
        *,
        sequence_number: int,
        response: "_models.Response",
    ) -> None: ...

    @overload
    def __init__(self, mapping: Mapping[str, Any]) -> None:
        """
        :param mapping: raw JSON to initialize the model.
        :type mapping: Mapping[str, Any]
        """

    def __init__(self, *args: Any, **kwargs: Any) -> None:
        super().__init__(*args, **kwargs)
        self.type = ResponseStreamEventType.RESPONSE_CREATED  # type: ignore


class ResponseError(_Model):
    """An error object returned when the model fails to generate a Response.

    :ivar code: Required. Known values are: "server_error", "rate_limit_exceeded",
     "invalid_prompt", "vector_store_timeout", "invalid_image", "invalid_image_format",
     "invalid_base64_image", "invalid_image_url", "image_too_large", "image_too_small",
     "image_parse_error", "image_content_policy_violation", "invalid_image_mode",
     "image_file_too_large", "unsupported_image_media_type", "empty_image_file",
     "failed_to_download_image", and "image_file_not_found".
    :vartype code: str or ~openai.models.ResponseErrorCode
    :ivar message: A human-readable description of the error. Required.
    :vartype message: str
    """

    code: Union[str, "_models.ResponseErrorCode"] = rest_field(
        visibility=["read", "create", "update", "delete", "query"]
    )
    """Required. Known values are: \"server_error\", \"rate_limit_exceeded\", \"invalid_prompt\",
     \"vector_store_timeout\", \"invalid_image\", \"invalid_image_format\",
     \"invalid_base64_image\", \"invalid_image_url\", \"image_too_large\", \"image_too_small\",
     \"image_parse_error\", \"image_content_policy_violation\", \"invalid_image_mode\",
     \"image_file_too_large\", \"unsupported_image_media_type\", \"empty_image_file\",
     \"failed_to_download_image\", and \"image_file_not_found\"."""
    message: str = rest_field(visibility=["read", "create", "update", "delete", "query"])
    """A human-readable description of the error. Required."""

    @overload
    def __init__(
        self,
        *,
        code: Union[str, "_models.ResponseErrorCode"],
        message: str,
    ) -> None: ...

    @overload
    def __init__(self, mapping: Mapping[str, Any]) -> None:
        """
        :param mapping: raw JSON to initialize the model.
        :type mapping: Mapping[str, Any]
        """

    def __init__(self, *args: Any, **kwargs: Any) -> None:
        super().__init__(*args, **kwargs)


class ResponseErrorEvent(ResponseStreamEvent, discriminator="error"):
    """Emitted when an error occurs.

    :ivar sequence_number: The sequence number for this event. Required.
    :vartype sequence_number: int
    :ivar type: The type of the event. Always ``error``. Required.
    :vartype type: str or ~openai.models.ERROR
    :ivar code: The error code. Required.
    :vartype code: str
    :ivar message: The error message. Required.
    :vartype message: str
    :ivar param: The error parameter. Required.
    :vartype param: str
    """

    type: Literal[ResponseStreamEventType.ERROR] = rest_discriminator(name="type", visibility=["read", "create", "update", "delete", "query"])  # type: ignore
    """The type of the event. Always ``error``. Required."""
    code: str = rest_field(visibility=["read", "create", "update", "delete", "query"])
    """The error code. Required."""
    message: str = rest_field(visibility=["read", "create", "update", "delete", "query"])
    """The error message. Required."""
    param: str = rest_field(visibility=["read", "create", "update", "delete", "query"])
    """The error parameter. Required."""

    @overload
    def __init__(
        self,
        *,
        sequence_number: int,
        code: str,
        message: str,
        param: str,
    ) -> None: ...

    @overload
    def __init__(self, mapping: Mapping[str, Any]) -> None:
        """
        :param mapping: raw JSON to initialize the model.
        :type mapping: Mapping[str, Any]
        """

    def __init__(self, *args: Any, **kwargs: Any) -> None:
        super().__init__(*args, **kwargs)
        self.type = ResponseStreamEventType.ERROR  # type: ignore


class ResponseFailedEvent(ResponseStreamEvent, discriminator="response.failed"):
    """An event that is emitted when a response fails.

    :ivar sequence_number: The sequence number for this event. Required.
    :vartype sequence_number: int
    :ivar type: The type of the event. Always ``response.failed``. Required.
    :vartype type: str or ~openai.models.RESPONSE_FAILED
    :ivar response: The response that failed. Required.
    :vartype response: ~openai.models.Response
    """

    type: Literal[ResponseStreamEventType.RESPONSE_FAILED] = rest_discriminator(name="type", visibility=["read", "create", "update", "delete", "query"])  # type: ignore
    """The type of the event. Always ``response.failed``. Required."""
    response: "_models.Response" = rest_field(visibility=["read", "create", "update", "delete", "query"])
    """The response that failed. Required."""

    @overload
    def __init__(
        self,
        *,
        sequence_number: int,
        response: "_models.Response",
    ) -> None: ...

    @overload
    def __init__(self, mapping: Mapping[str, Any]) -> None:
        """
        :param mapping: raw JSON to initialize the model.
        :type mapping: Mapping[str, Any]
        """

    def __init__(self, *args: Any, **kwargs: Any) -> None:
        super().__init__(*args, **kwargs)
        self.type = ResponseStreamEventType.RESPONSE_FAILED  # type: ignore


class ResponseFileSearchCallCompletedEvent(ResponseStreamEvent, discriminator="response.file_search_call.completed"):
    """Emitted when a file search call is completed (results found).

    :ivar sequence_number: The sequence number for this event. Required.
    :vartype sequence_number: int
    :ivar type: The type of the event. Always ``response.file_search_call.completed``. Required.
    :vartype type: str or ~openai.models.RESPONSE_FILE_SEARCH_CALL_COMPLETED
    :ivar output_index: The index of the output item that the file search call is initiated.
     Required.
    :vartype output_index: int
    :ivar item_id: The ID of the output item that the file search call is initiated. Required.
    :vartype item_id: str
    """

    type: Literal[ResponseStreamEventType.RESPONSE_FILE_SEARCH_CALL_COMPLETED] = rest_discriminator(name="type", visibility=["read", "create", "update", "delete", "query"])  # type: ignore
    """The type of the event. Always ``response.file_search_call.completed``. Required."""
    output_index: int = rest_field(visibility=["read", "create", "update", "delete", "query"])
    """The index of the output item that the file search call is initiated. Required."""
    item_id: str = rest_field(visibility=["read", "create", "update", "delete", "query"])
    """The ID of the output item that the file search call is initiated. Required."""

    @overload
    def __init__(
        self,
        *,
        sequence_number: int,
        output_index: int,
        item_id: str,
    ) -> None: ...

    @overload
    def __init__(self, mapping: Mapping[str, Any]) -> None:
        """
        :param mapping: raw JSON to initialize the model.
        :type mapping: Mapping[str, Any]
        """

    def __init__(self, *args: Any, **kwargs: Any) -> None:
        super().__init__(*args, **kwargs)
        self.type = ResponseStreamEventType.RESPONSE_FILE_SEARCH_CALL_COMPLETED  # type: ignore


class ResponseFileSearchCallInProgressEvent(ResponseStreamEvent, discriminator="response.file_search_call.in_progress"):
    """Emitted when a file search call is initiated.

    :ivar sequence_number: The sequence number for this event. Required.
    :vartype sequence_number: int
    :ivar type: The type of the event. Always ``response.file_search_call.in_progress``. Required.
    :vartype type: str or ~openai.models.RESPONSE_FILE_SEARCH_CALL_IN_PROGRESS
    :ivar output_index: The index of the output item that the file search call is initiated.
     Required.
    :vartype output_index: int
    :ivar item_id: The ID of the output item that the file search call is initiated. Required.
    :vartype item_id: str
    """

    type: Literal[ResponseStreamEventType.RESPONSE_FILE_SEARCH_CALL_IN_PROGRESS] = rest_discriminator(name="type", visibility=["read", "create", "update", "delete", "query"])  # type: ignore
    """The type of the event. Always ``response.file_search_call.in_progress``. Required."""
    output_index: int = rest_field(visibility=["read", "create", "update", "delete", "query"])
    """The index of the output item that the file search call is initiated. Required."""
    item_id: str = rest_field(visibility=["read", "create", "update", "delete", "query"])
    """The ID of the output item that the file search call is initiated. Required."""

    @overload
    def __init__(
        self,
        *,
        sequence_number: int,
        output_index: int,
        item_id: str,
    ) -> None: ...

    @overload
    def __init__(self, mapping: Mapping[str, Any]) -> None:
        """
        :param mapping: raw JSON to initialize the model.
        :type mapping: Mapping[str, Any]
        """

    def __init__(self, *args: Any, **kwargs: Any) -> None:
        super().__init__(*args, **kwargs)
        self.type = ResponseStreamEventType.RESPONSE_FILE_SEARCH_CALL_IN_PROGRESS  # type: ignore


class ResponseFileSearchCallSearchingEvent(ResponseStreamEvent, discriminator="response.file_search_call.searching"):
    """Emitted when a file search is currently searching.

    :ivar sequence_number: The sequence number for this event. Required.
    :vartype sequence_number: int
    :ivar type: The type of the event. Always ``response.file_search_call.searching``. Required.
    :vartype type: str or ~openai.models.RESPONSE_FILE_SEARCH_CALL_SEARCHING
    :ivar output_index: The index of the output item that the file search call is searching.
     Required.
    :vartype output_index: int
    :ivar item_id: The ID of the output item that the file search call is initiated. Required.
    :vartype item_id: str
    """

    type: Literal[ResponseStreamEventType.RESPONSE_FILE_SEARCH_CALL_SEARCHING] = rest_discriminator(name="type", visibility=["read", "create", "update", "delete", "query"])  # type: ignore
    """The type of the event. Always ``response.file_search_call.searching``. Required."""
    output_index: int = rest_field(visibility=["read", "create", "update", "delete", "query"])
    """The index of the output item that the file search call is searching. Required."""
    item_id: str = rest_field(visibility=["read", "create", "update", "delete", "query"])
    """The ID of the output item that the file search call is initiated. Required."""

    @overload
    def __init__(
        self,
        *,
        sequence_number: int,
        output_index: int,
        item_id: str,
    ) -> None: ...

    @overload
    def __init__(self, mapping: Mapping[str, Any]) -> None:
        """
        :param mapping: raw JSON to initialize the model.
        :type mapping: Mapping[str, Any]
        """

    def __init__(self, *args: Any, **kwargs: Any) -> None:
        super().__init__(*args, **kwargs)
        self.type = ResponseStreamEventType.RESPONSE_FILE_SEARCH_CALL_SEARCHING  # type: ignore


class ResponseFormatJsonSchemaSchema(_Model):
    """The schema for the response format, described as a JSON Schema object.
    Learn how to build JSON schemas `here <https://json-schema.org/>`_.

    """


class ResponseFunctionCallArgumentsDeltaEvent(
    ResponseStreamEvent, discriminator="response.function_call_arguments.delta"
):
    """Emitted when there is a partial function-call arguments delta.

    :ivar sequence_number: The sequence number for this event. Required.
    :vartype sequence_number: int
    :ivar type: The type of the event. Always ``response.function_call_arguments.delta``. Required.
    :vartype type: str or ~openai.models.RESPONSE_FUNCTION_CALL_ARGUMENTS_DELTA
    :ivar item_id: The ID of the output item that the function-call arguments delta is added to.
     Required.
    :vartype item_id: str
    :ivar output_index: The index of the output item that the function-call arguments delta is
     added to. Required.
    :vartype output_index: int
    :ivar delta: The function-call arguments delta that is added. Required.
    :vartype delta: str
    """

    type: Literal[ResponseStreamEventType.RESPONSE_FUNCTION_CALL_ARGUMENTS_DELTA] = rest_discriminator(name="type", visibility=["read", "create", "update", "delete", "query"])  # type: ignore
    """The type of the event. Always ``response.function_call_arguments.delta``. Required."""
    item_id: str = rest_field(visibility=["read", "create", "update", "delete", "query"])
    """The ID of the output item that the function-call arguments delta is added to. Required."""
    output_index: int = rest_field(visibility=["read", "create", "update", "delete", "query"])
    """The index of the output item that the function-call arguments delta is added to. Required."""
    delta: str = rest_field(visibility=["read", "create", "update", "delete", "query"])
    """The function-call arguments delta that is added. Required."""

    @overload
    def __init__(
        self,
        *,
        sequence_number: int,
        item_id: str,
        output_index: int,
        delta: str,
    ) -> None: ...

    @overload
    def __init__(self, mapping: Mapping[str, Any]) -> None:
        """
        :param mapping: raw JSON to initialize the model.
        :type mapping: Mapping[str, Any]
        """

    def __init__(self, *args: Any, **kwargs: Any) -> None:
        super().__init__(*args, **kwargs)
        self.type = ResponseStreamEventType.RESPONSE_FUNCTION_CALL_ARGUMENTS_DELTA  # type: ignore


class ResponseFunctionCallArgumentsDoneEvent(
    ResponseStreamEvent, discriminator="response.function_call_arguments.done"
):
    """Emitted when function-call arguments are finalized.

    :ivar sequence_number: The sequence number for this event. Required.
    :vartype sequence_number: int
    :ivar type: Required.
    :vartype type: str or ~openai.models.RESPONSE_FUNCTION_CALL_ARGUMENTS_DONE
    :ivar item_id: The ID of the item. Required.
    :vartype item_id: str
    :ivar output_index: The index of the output item. Required.
    :vartype output_index: int
    :ivar arguments: The function-call arguments. Required.
    :vartype arguments: str
    """

    type: Literal[ResponseStreamEventType.RESPONSE_FUNCTION_CALL_ARGUMENTS_DONE] = rest_discriminator(name="type", visibility=["read", "create", "update", "delete", "query"])  # type: ignore
    """Required."""
    item_id: str = rest_field(visibility=["read", "create", "update", "delete", "query"])
    """The ID of the item. Required."""
    output_index: int = rest_field(visibility=["read", "create", "update", "delete", "query"])
    """The index of the output item. Required."""
    arguments: str = rest_field(visibility=["read", "create", "update", "delete", "query"])
    """The function-call arguments. Required."""

    @overload
    def __init__(
        self,
        *,
        sequence_number: int,
        item_id: str,
        output_index: int,
        arguments: str,
    ) -> None: ...

    @overload
    def __init__(self, mapping: Mapping[str, Any]) -> None:
        """
        :param mapping: raw JSON to initialize the model.
        :type mapping: Mapping[str, Any]
        """

    def __init__(self, *args: Any, **kwargs: Any) -> None:
        super().__init__(*args, **kwargs)
        self.type = ResponseStreamEventType.RESPONSE_FUNCTION_CALL_ARGUMENTS_DONE  # type: ignore


class ResponseImageGenCallCompletedEvent(ResponseStreamEvent, discriminator="response.image_generation_call.completed"):
    """Emitted when an image generation tool call has completed and the final image is available.

    :ivar sequence_number: The sequence number for this event. Required.
    :vartype sequence_number: int
    :ivar type: The type of the event. Always 'response.image_generation_call.completed'. Required.
    :vartype type: str or ~openai.models.RESPONSE_IMAGE_GENERATION_CALL_COMPLETED
    :ivar output_index: The index of the output item in the response's output array. Required.
    :vartype output_index: int
    :ivar item_id: The unique identifier of the image generation item being processed. Required.
    :vartype item_id: str
    """

    type: Literal[ResponseStreamEventType.RESPONSE_IMAGE_GENERATION_CALL_COMPLETED] = rest_discriminator(name="type", visibility=["read", "create", "update", "delete", "query"])  # type: ignore
    """The type of the event. Always 'response.image_generation_call.completed'. Required."""
    output_index: int = rest_field(visibility=["read", "create", "update", "delete", "query"])
    """The index of the output item in the response's output array. Required."""
    item_id: str = rest_field(visibility=["read", "create", "update", "delete", "query"])
    """The unique identifier of the image generation item being processed. Required."""

    @overload
    def __init__(
        self,
        *,
        sequence_number: int,
        output_index: int,
        item_id: str,
    ) -> None: ...

    @overload
    def __init__(self, mapping: Mapping[str, Any]) -> None:
        """
        :param mapping: raw JSON to initialize the model.
        :type mapping: Mapping[str, Any]
        """

    def __init__(self, *args: Any, **kwargs: Any) -> None:
        super().__init__(*args, **kwargs)
        self.type = ResponseStreamEventType.RESPONSE_IMAGE_GENERATION_CALL_COMPLETED  # type: ignore


class ResponseImageGenCallGeneratingEvent(
    ResponseStreamEvent, discriminator="response.image_generation_call.generating"
):
    """Emitted when an image generation tool call is actively generating an image (intermediate
    state).

    :ivar sequence_number: The sequence number for this event. Required.
    :vartype sequence_number: int
    :ivar type: The type of the event. Always 'response.image_generation_call.generating'.
     Required.
    :vartype type: str or ~openai.models.RESPONSE_IMAGE_GENERATION_CALL_GENERATING
    :ivar output_index: The index of the output item in the response's output array. Required.
    :vartype output_index: int
    :ivar item_id: The unique identifier of the image generation item being processed. Required.
    :vartype item_id: str
    """

    type: Literal[ResponseStreamEventType.RESPONSE_IMAGE_GENERATION_CALL_GENERATING] = rest_discriminator(name="type", visibility=["read", "create", "update", "delete", "query"])  # type: ignore
    """The type of the event. Always 'response.image_generation_call.generating'. Required."""
    output_index: int = rest_field(visibility=["read", "create", "update", "delete", "query"])
    """The index of the output item in the response's output array. Required."""
    item_id: str = rest_field(visibility=["read", "create", "update", "delete", "query"])
    """The unique identifier of the image generation item being processed. Required."""

    @overload
    def __init__(
        self,
        *,
        sequence_number: int,
        output_index: int,
        item_id: str,
    ) -> None: ...

    @overload
    def __init__(self, mapping: Mapping[str, Any]) -> None:
        """
        :param mapping: raw JSON to initialize the model.
        :type mapping: Mapping[str, Any]
        """

    def __init__(self, *args: Any, **kwargs: Any) -> None:
        super().__init__(*args, **kwargs)
        self.type = ResponseStreamEventType.RESPONSE_IMAGE_GENERATION_CALL_GENERATING  # type: ignore


class ResponseImageGenCallInProgressEvent(
    ResponseStreamEvent, discriminator="response.image_generation_call.in_progress"
):
    """Emitted when an image generation tool call is in progress.

    :ivar sequence_number: The sequence number for this event. Required.
    :vartype sequence_number: int
    :ivar type: The type of the event. Always 'response.image_generation_call.in_progress'.
     Required.
    :vartype type: str or ~openai.models.RESPONSE_IMAGE_GENERATION_CALL_IN_PROGRESS
    :ivar output_index: The index of the output item in the response's output array. Required.
    :vartype output_index: int
    :ivar item_id: The unique identifier of the image generation item being processed. Required.
    :vartype item_id: str
    """

    type: Literal[ResponseStreamEventType.RESPONSE_IMAGE_GENERATION_CALL_IN_PROGRESS] = rest_discriminator(name="type", visibility=["read", "create", "update", "delete", "query"])  # type: ignore
    """The type of the event. Always 'response.image_generation_call.in_progress'. Required."""
    output_index: int = rest_field(visibility=["read", "create", "update", "delete", "query"])
    """The index of the output item in the response's output array. Required."""
    item_id: str = rest_field(visibility=["read", "create", "update", "delete", "query"])
    """The unique identifier of the image generation item being processed. Required."""

    @overload
    def __init__(
        self,
        *,
        sequence_number: int,
        output_index: int,
        item_id: str,
    ) -> None: ...

    @overload
    def __init__(self, mapping: Mapping[str, Any]) -> None:
        """
        :param mapping: raw JSON to initialize the model.
        :type mapping: Mapping[str, Any]
        """

    def __init__(self, *args: Any, **kwargs: Any) -> None:
        super().__init__(*args, **kwargs)
        self.type = ResponseStreamEventType.RESPONSE_IMAGE_GENERATION_CALL_IN_PROGRESS  # type: ignore


class ResponseImageGenCallPartialImageEvent(
    ResponseStreamEvent, discriminator="response.image_generation_call.partial_image"
):
    """Emitted when a partial image is available during image generation streaming.

    :ivar sequence_number: The sequence number for this event. Required.
    :vartype sequence_number: int
    :ivar type: The type of the event. Always 'response.image_generation_call.partial_image'.
     Required.
    :vartype type: str or ~openai.models.RESPONSE_IMAGE_GENERATION_CALL_PARTIAL_IMAGE
    :ivar output_index: The index of the output item in the response's output array. Required.
    :vartype output_index: int
    :ivar item_id: The unique identifier of the image generation item being processed. Required.
    :vartype item_id: str
    :ivar partial_image_index: 0-based index for the partial image (backend is 1-based, but this is
     0-based for the user). Required.
    :vartype partial_image_index: int
    :ivar partial_image_b64: Base64-encoded partial image data, suitable for rendering as an image.
     Required.
    :vartype partial_image_b64: str
    """

    type: Literal[ResponseStreamEventType.RESPONSE_IMAGE_GENERATION_CALL_PARTIAL_IMAGE] = rest_discriminator(name="type", visibility=["read", "create", "update", "delete", "query"])  # type: ignore
    """The type of the event. Always 'response.image_generation_call.partial_image'. Required."""
    output_index: int = rest_field(visibility=["read", "create", "update", "delete", "query"])
    """The index of the output item in the response's output array. Required."""
    item_id: str = rest_field(visibility=["read", "create", "update", "delete", "query"])
    """The unique identifier of the image generation item being processed. Required."""
    partial_image_index: int = rest_field(visibility=["read", "create", "update", "delete", "query"])
    """0-based index for the partial image (backend is 1-based, but this is 0-based for the user).
     Required."""
    partial_image_b64: str = rest_field(visibility=["read", "create", "update", "delete", "query"])
    """Base64-encoded partial image data, suitable for rendering as an image. Required."""

    @overload
    def __init__(
        self,
        *,
        sequence_number: int,
        output_index: int,
        item_id: str,
        partial_image_index: int,
        partial_image_b64: str,
    ) -> None: ...

    @overload
    def __init__(self, mapping: Mapping[str, Any]) -> None:
        """
        :param mapping: raw JSON to initialize the model.
        :type mapping: Mapping[str, Any]
        """

    def __init__(self, *args: Any, **kwargs: Any) -> None:
        super().__init__(*args, **kwargs)
        self.type = ResponseStreamEventType.RESPONSE_IMAGE_GENERATION_CALL_PARTIAL_IMAGE  # type: ignore


class ResponseIncompleteDetails1(_Model):
    """ResponseIncompleteDetails1.

    :ivar reason: The reason why the response is incomplete. Is either a
     Literal["max_output_tokens"] type or a Literal["content_filter"] type.
    :vartype reason: str or str
    """

    reason: Optional[Literal["max_output_tokens", "content_filter"]] = rest_field(
        visibility=["read", "create", "update", "delete", "query"]
    )
    """The reason why the response is incomplete. Is either a Literal[\"max_output_tokens\"] type or a
     Literal[\"content_filter\"] type."""

    @overload
    def __init__(
        self,
        *,
        reason: Optional[Literal["max_output_tokens", "content_filter"]] = None,
    ) -> None: ...

    @overload
    def __init__(self, mapping: Mapping[str, Any]) -> None:
        """
        :param mapping: raw JSON to initialize the model.
        :type mapping: Mapping[str, Any]
        """

    def __init__(self, *args: Any, **kwargs: Any) -> None:
        super().__init__(*args, **kwargs)


class ResponseIncompleteEvent(ResponseStreamEvent, discriminator="response.incomplete"):
    """An event that is emitted when a response finishes as incomplete.

    :ivar sequence_number: The sequence number for this event. Required.
    :vartype sequence_number: int
    :ivar type: The type of the event. Always ``response.incomplete``. Required.
    :vartype type: str or ~openai.models.RESPONSE_INCOMPLETE
    :ivar response: The response that was incomplete. Required.
    :vartype response: ~openai.models.Response
    """

    type: Literal[ResponseStreamEventType.RESPONSE_INCOMPLETE] = rest_discriminator(name="type", visibility=["read", "create", "update", "delete", "query"])  # type: ignore
    """The type of the event. Always ``response.incomplete``. Required."""
    response: "_models.Response" = rest_field(visibility=["read", "create", "update", "delete", "query"])
    """The response that was incomplete. Required."""

    @overload
    def __init__(
        self,
        *,
        sequence_number: int,
        response: "_models.Response",
    ) -> None: ...

    @overload
    def __init__(self, mapping: Mapping[str, Any]) -> None:
        """
        :param mapping: raw JSON to initialize the model.
        :type mapping: Mapping[str, Any]
        """

    def __init__(self, *args: Any, **kwargs: Any) -> None:
        super().__init__(*args, **kwargs)
        self.type = ResponseStreamEventType.RESPONSE_INCOMPLETE  # type: ignore


class ResponseInProgressEvent(ResponseStreamEvent, discriminator="response.in_progress"):
    """Emitted when the response is in progress.

    :ivar sequence_number: The sequence number for this event. Required.
    :vartype sequence_number: int
    :ivar type: The type of the event. Always ``response.in_progress``. Required.
    :vartype type: str or ~openai.models.RESPONSE_IN_PROGRESS
    :ivar response: The response that is in progress. Required.
    :vartype response: ~openai.models.Response
    """

    type: Literal[ResponseStreamEventType.RESPONSE_IN_PROGRESS] = rest_discriminator(name="type", visibility=["read", "create", "update", "delete", "query"])  # type: ignore
    """The type of the event. Always ``response.in_progress``. Required."""
    response: "_models.Response" = rest_field(visibility=["read", "create", "update", "delete", "query"])
    """The response that is in progress. Required."""

    @overload
    def __init__(
        self,
        *,
        sequence_number: int,
        response: "_models.Response",
    ) -> None: ...

    @overload
    def __init__(self, mapping: Mapping[str, Any]) -> None:
        """
        :param mapping: raw JSON to initialize the model.
        :type mapping: Mapping[str, Any]
        """

    def __init__(self, *args: Any, **kwargs: Any) -> None:
        super().__init__(*args, **kwargs)
        self.type = ResponseStreamEventType.RESPONSE_IN_PROGRESS  # type: ignore


class ResponseMCPCallArgumentsDeltaEvent(ResponseStreamEvent, discriminator="response.mcp_call.arguments_delta"):
    """Emitted when there is a delta (partial update) to the arguments of an MCP tool call.

    :ivar sequence_number: The sequence number for this event. Required.
    :vartype sequence_number: int
    :ivar type: The type of the event. Always 'response.mcp_call.arguments_delta'. Required.
    :vartype type: str or ~openai.models.RESPONSE_MCP_CALL_ARGUMENTS_DELTA
    :ivar output_index: The index of the output item in the response's output array. Required.
    :vartype output_index: int
    :ivar item_id: The unique identifier of the MCP tool call item being processed. Required.
    :vartype item_id: str
    :ivar delta: The partial update to the arguments for the MCP tool call. Required.
    :vartype delta: any
    """

    type: Literal[ResponseStreamEventType.RESPONSE_MCP_CALL_ARGUMENTS_DELTA] = rest_discriminator(name="type", visibility=["read", "create", "update", "delete", "query"])  # type: ignore
    """The type of the event. Always 'response.mcp_call.arguments_delta'. Required."""
    output_index: int = rest_field(visibility=["read", "create", "update", "delete", "query"])
    """The index of the output item in the response's output array. Required."""
    item_id: str = rest_field(visibility=["read", "create", "update", "delete", "query"])
    """The unique identifier of the MCP tool call item being processed. Required."""
    delta: Any = rest_field(visibility=["read", "create", "update", "delete", "query"])
    """The partial update to the arguments for the MCP tool call. Required."""

    @overload
    def __init__(
        self,
        *,
        sequence_number: int,
        output_index: int,
        item_id: str,
        delta: Any,
    ) -> None: ...

    @overload
    def __init__(self, mapping: Mapping[str, Any]) -> None:
        """
        :param mapping: raw JSON to initialize the model.
        :type mapping: Mapping[str, Any]
        """

    def __init__(self, *args: Any, **kwargs: Any) -> None:
        super().__init__(*args, **kwargs)
        self.type = ResponseStreamEventType.RESPONSE_MCP_CALL_ARGUMENTS_DELTA  # type: ignore


class ResponseMCPCallArgumentsDoneEvent(ResponseStreamEvent, discriminator="response.mcp_call.arguments_done"):
    """Emitted when the arguments for an MCP tool call are finalized.

    :ivar sequence_number: The sequence number for this event. Required.
    :vartype sequence_number: int
    :ivar type: The type of the event. Always 'response.mcp_call.arguments_done'. Required.
    :vartype type: str or ~openai.models.RESPONSE_MCP_CALL_ARGUMENTS_DONE
    :ivar output_index: The index of the output item in the response's output array. Required.
    :vartype output_index: int
    :ivar item_id: The unique identifier of the MCP tool call item being processed. Required.
    :vartype item_id: str
    :ivar arguments: The finalized arguments for the MCP tool call. Required.
    :vartype arguments: any
    """

    type: Literal[ResponseStreamEventType.RESPONSE_MCP_CALL_ARGUMENTS_DONE] = rest_discriminator(name="type", visibility=["read", "create", "update", "delete", "query"])  # type: ignore
    """The type of the event. Always 'response.mcp_call.arguments_done'. Required."""
    output_index: int = rest_field(visibility=["read", "create", "update", "delete", "query"])
    """The index of the output item in the response's output array. Required."""
    item_id: str = rest_field(visibility=["read", "create", "update", "delete", "query"])
    """The unique identifier of the MCP tool call item being processed. Required."""
    arguments: Any = rest_field(visibility=["read", "create", "update", "delete", "query"])
    """The finalized arguments for the MCP tool call. Required."""

    @overload
    def __init__(
        self,
        *,
        sequence_number: int,
        output_index: int,
        item_id: str,
        arguments: Any,
    ) -> None: ...

    @overload
    def __init__(self, mapping: Mapping[str, Any]) -> None:
        """
        :param mapping: raw JSON to initialize the model.
        :type mapping: Mapping[str, Any]
        """

    def __init__(self, *args: Any, **kwargs: Any) -> None:
        super().__init__(*args, **kwargs)
        self.type = ResponseStreamEventType.RESPONSE_MCP_CALL_ARGUMENTS_DONE  # type: ignore


class ResponseMCPCallCompletedEvent(ResponseStreamEvent, discriminator="response.mcp_call.completed"):
    """Emitted when an MCP  tool call has completed successfully.

    :ivar sequence_number: The sequence number for this event. Required.
    :vartype sequence_number: int
    :ivar type: The type of the event. Always 'response.mcp_call.completed'. Required.
    :vartype type: str or ~openai.models.RESPONSE_MCP_CALL_COMPLETED
    """

    type: Literal[ResponseStreamEventType.RESPONSE_MCP_CALL_COMPLETED] = rest_discriminator(name="type", visibility=["read", "create", "update", "delete", "query"])  # type: ignore
    """The type of the event. Always 'response.mcp_call.completed'. Required."""

    @overload
    def __init__(
        self,
        *,
        sequence_number: int,
    ) -> None: ...

    @overload
    def __init__(self, mapping: Mapping[str, Any]) -> None:
        """
        :param mapping: raw JSON to initialize the model.
        :type mapping: Mapping[str, Any]
        """

    def __init__(self, *args: Any, **kwargs: Any) -> None:
        super().__init__(*args, **kwargs)
        self.type = ResponseStreamEventType.RESPONSE_MCP_CALL_COMPLETED  # type: ignore


class ResponseMCPCallFailedEvent(ResponseStreamEvent, discriminator="response.mcp_call.failed"):
    """Emitted when an MCP  tool call has failed.

    :ivar sequence_number: The sequence number for this event. Required.
    :vartype sequence_number: int
    :ivar type: The type of the event. Always 'response.mcp_call.failed'. Required.
    :vartype type: str or ~openai.models.RESPONSE_MCP_CALL_FAILED
    """

    type: Literal[ResponseStreamEventType.RESPONSE_MCP_CALL_FAILED] = rest_discriminator(name="type", visibility=["read", "create", "update", "delete", "query"])  # type: ignore
    """The type of the event. Always 'response.mcp_call.failed'. Required."""

    @overload
    def __init__(
        self,
        *,
        sequence_number: int,
    ) -> None: ...

    @overload
    def __init__(self, mapping: Mapping[str, Any]) -> None:
        """
        :param mapping: raw JSON to initialize the model.
        :type mapping: Mapping[str, Any]
        """

    def __init__(self, *args: Any, **kwargs: Any) -> None:
        super().__init__(*args, **kwargs)
        self.type = ResponseStreamEventType.RESPONSE_MCP_CALL_FAILED  # type: ignore


class ResponseMCPCallInProgressEvent(ResponseStreamEvent, discriminator="response.mcp_call.in_progress"):
    """Emitted when an MCP  tool call is in progress.

    :ivar sequence_number: The sequence number for this event. Required.
    :vartype sequence_number: int
    :ivar type: The type of the event. Always 'response.mcp_call.in_progress'. Required.
    :vartype type: str or ~openai.models.RESPONSE_MCP_CALL_IN_PROGRESS
    :ivar output_index: The index of the output item in the response's output array. Required.
    :vartype output_index: int
    :ivar item_id: The unique identifier of the MCP tool call item being processed. Required.
    :vartype item_id: str
    """

    type: Literal[ResponseStreamEventType.RESPONSE_MCP_CALL_IN_PROGRESS] = rest_discriminator(name="type", visibility=["read", "create", "update", "delete", "query"])  # type: ignore
    """The type of the event. Always 'response.mcp_call.in_progress'. Required."""
    output_index: int = rest_field(visibility=["read", "create", "update", "delete", "query"])
    """The index of the output item in the response's output array. Required."""
    item_id: str = rest_field(visibility=["read", "create", "update", "delete", "query"])
    """The unique identifier of the MCP tool call item being processed. Required."""

    @overload
    def __init__(
        self,
        *,
        sequence_number: int,
        output_index: int,
        item_id: str,
    ) -> None: ...

    @overload
    def __init__(self, mapping: Mapping[str, Any]) -> None:
        """
        :param mapping: raw JSON to initialize the model.
        :type mapping: Mapping[str, Any]
        """

    def __init__(self, *args: Any, **kwargs: Any) -> None:
        super().__init__(*args, **kwargs)
        self.type = ResponseStreamEventType.RESPONSE_MCP_CALL_IN_PROGRESS  # type: ignore


class ResponseMCPListToolsCompletedEvent(ResponseStreamEvent, discriminator="response.mcp_list_tools.completed"):
    """Emitted when the list of available MCP tools has been successfully retrieved.

    :ivar sequence_number: The sequence number for this event. Required.
    :vartype sequence_number: int
    :ivar type: The type of the event. Always 'response.mcp_list_tools.completed'. Required.
    :vartype type: str or ~openai.models.RESPONSE_MCP_LIST_TOOLS_COMPLETED
    """

    type: Literal[ResponseStreamEventType.RESPONSE_MCP_LIST_TOOLS_COMPLETED] = rest_discriminator(name="type", visibility=["read", "create", "update", "delete", "query"])  # type: ignore
    """The type of the event. Always 'response.mcp_list_tools.completed'. Required."""

    @overload
    def __init__(
        self,
        *,
        sequence_number: int,
    ) -> None: ...

    @overload
    def __init__(self, mapping: Mapping[str, Any]) -> None:
        """
        :param mapping: raw JSON to initialize the model.
        :type mapping: Mapping[str, Any]
        """

    def __init__(self, *args: Any, **kwargs: Any) -> None:
        super().__init__(*args, **kwargs)
        self.type = ResponseStreamEventType.RESPONSE_MCP_LIST_TOOLS_COMPLETED  # type: ignore


class ResponseMCPListToolsFailedEvent(ResponseStreamEvent, discriminator="response.mcp_list_tools.failed"):
    """Emitted when the attempt to list available MCP tools has failed.

    :ivar sequence_number: The sequence number for this event. Required.
    :vartype sequence_number: int
    :ivar type: The type of the event. Always 'response.mcp_list_tools.failed'. Required.
    :vartype type: str or ~openai.models.RESPONSE_MCP_LIST_TOOLS_FAILED
    """

    type: Literal[ResponseStreamEventType.RESPONSE_MCP_LIST_TOOLS_FAILED] = rest_discriminator(name="type", visibility=["read", "create", "update", "delete", "query"])  # type: ignore
    """The type of the event. Always 'response.mcp_list_tools.failed'. Required."""

    @overload
    def __init__(
        self,
        *,
        sequence_number: int,
    ) -> None: ...

    @overload
    def __init__(self, mapping: Mapping[str, Any]) -> None:
        """
        :param mapping: raw JSON to initialize the model.
        :type mapping: Mapping[str, Any]
        """

    def __init__(self, *args: Any, **kwargs: Any) -> None:
        super().__init__(*args, **kwargs)
        self.type = ResponseStreamEventType.RESPONSE_MCP_LIST_TOOLS_FAILED  # type: ignore


class ResponseMCPListToolsInProgressEvent(ResponseStreamEvent, discriminator="response.mcp_list_tools.in_progress"):
    """Emitted when the system is in the process of retrieving the list of available MCP tools.

    :ivar sequence_number: The sequence number for this event. Required.
    :vartype sequence_number: int
    :ivar type: The type of the event. Always 'response.mcp_list_tools.in_progress'. Required.
    :vartype type: str or ~openai.models.RESPONSE_MCP_LIST_TOOLS_IN_PROGRESS
    """

    type: Literal[ResponseStreamEventType.RESPONSE_MCP_LIST_TOOLS_IN_PROGRESS] = rest_discriminator(name="type", visibility=["read", "create", "update", "delete", "query"])  # type: ignore
    """The type of the event. Always 'response.mcp_list_tools.in_progress'. Required."""

    @overload
    def __init__(
        self,
        *,
        sequence_number: int,
    ) -> None: ...

    @overload
    def __init__(self, mapping: Mapping[str, Any]) -> None:
        """
        :param mapping: raw JSON to initialize the model.
        :type mapping: Mapping[str, Any]
        """

    def __init__(self, *args: Any, **kwargs: Any) -> None:
        super().__init__(*args, **kwargs)
        self.type = ResponseStreamEventType.RESPONSE_MCP_LIST_TOOLS_IN_PROGRESS  # type: ignore


class ResponseOutputItemAddedEvent(ResponseStreamEvent, discriminator="response.output_item.added"):
    """Emitted when a new output item is added.

    :ivar sequence_number: The sequence number for this event. Required.
    :vartype sequence_number: int
    :ivar type: The type of the event. Always ``response.output_item.added``. Required.
    :vartype type: str or ~openai.models.RESPONSE_OUTPUT_ITEM_ADDED
    :ivar output_index: The index of the output item that was added. Required.
    :vartype output_index: int
    :ivar item: The output item that was added. Required.
    :vartype item: ~openai.models.ItemResource
    """

    type: Literal[ResponseStreamEventType.RESPONSE_OUTPUT_ITEM_ADDED] = rest_discriminator(name="type", visibility=["read", "create", "update", "delete", "query"])  # type: ignore
    """The type of the event. Always ``response.output_item.added``. Required."""
    output_index: int = rest_field(visibility=["read", "create", "update", "delete", "query"])
    """The index of the output item that was added. Required."""
    item: "_models.ItemResource" = rest_field(visibility=["read", "create", "update", "delete", "query"])
    """The output item that was added. Required."""

    @overload
    def __init__(
        self,
        *,
        sequence_number: int,
        output_index: int,
        item: "_models.ItemResource",
    ) -> None: ...

    @overload
    def __init__(self, mapping: Mapping[str, Any]) -> None:
        """
        :param mapping: raw JSON to initialize the model.
        :type mapping: Mapping[str, Any]
        """

    def __init__(self, *args: Any, **kwargs: Any) -> None:
        super().__init__(*args, **kwargs)
        self.type = ResponseStreamEventType.RESPONSE_OUTPUT_ITEM_ADDED  # type: ignore


class ResponseOutputItemDoneEvent(ResponseStreamEvent, discriminator="response.output_item.done"):
    """Emitted when an output item is marked done.

    :ivar sequence_number: The sequence number for this event. Required.
    :vartype sequence_number: int
    :ivar type: The type of the event. Always ``response.output_item.done``. Required.
    :vartype type: str or ~openai.models.RESPONSE_OUTPUT_ITEM_DONE
    :ivar output_index: The index of the output item that was marked done. Required.
    :vartype output_index: int
    :ivar item: The output item that was marked done. Required.
    :vartype item: ~openai.models.ItemResource
    """

    type: Literal[ResponseStreamEventType.RESPONSE_OUTPUT_ITEM_DONE] = rest_discriminator(name="type", visibility=["read", "create", "update", "delete", "query"])  # type: ignore
    """The type of the event. Always ``response.output_item.done``. Required."""
    output_index: int = rest_field(visibility=["read", "create", "update", "delete", "query"])
    """The index of the output item that was marked done. Required."""
    item: "_models.ItemResource" = rest_field(visibility=["read", "create", "update", "delete", "query"])
    """The output item that was marked done. Required."""

    @overload
    def __init__(
        self,
        *,
        sequence_number: int,
        output_index: int,
        item: "_models.ItemResource",
    ) -> None: ...

    @overload
    def __init__(self, mapping: Mapping[str, Any]) -> None:
        """
        :param mapping: raw JSON to initialize the model.
        :type mapping: Mapping[str, Any]
        """

    def __init__(self, *args: Any, **kwargs: Any) -> None:
        super().__init__(*args, **kwargs)
        self.type = ResponseStreamEventType.RESPONSE_OUTPUT_ITEM_DONE  # type: ignore


class ResponsePromptVariables(_Model):
    """Optional map of values to substitute in for variables in your
    prompt. The substitution values can either be strings, or other
    Response input types like images or files.

    """


class ResponseQueuedEvent(ResponseStreamEvent, discriminator="response.queued"):
    """Emitted when a response is queued and waiting to be processed.

    :ivar sequence_number: The sequence number for this event. Required.
    :vartype sequence_number: int
    :ivar type: The type of the event. Always 'response.queued'. Required.
    :vartype type: str or ~openai.models.RESPONSE_QUEUED
    :ivar response: The full response object that is queued. Required.
    :vartype response: ~openai.models.Response
    """

    type: Literal[ResponseStreamEventType.RESPONSE_QUEUED] = rest_discriminator(name="type", visibility=["read", "create", "update", "delete", "query"])  # type: ignore
    """The type of the event. Always 'response.queued'. Required."""
    response: "_models.Response" = rest_field(visibility=["read", "create", "update", "delete", "query"])
    """The full response object that is queued. Required."""

    @overload
    def __init__(
        self,
        *,
        sequence_number: int,
        response: "_models.Response",
    ) -> None: ...

    @overload
    def __init__(self, mapping: Mapping[str, Any]) -> None:
        """
        :param mapping: raw JSON to initialize the model.
        :type mapping: Mapping[str, Any]
        """

    def __init__(self, *args: Any, **kwargs: Any) -> None:
        super().__init__(*args, **kwargs)
        self.type = ResponseStreamEventType.RESPONSE_QUEUED  # type: ignore


class ResponseReasoningDeltaEvent(ResponseStreamEvent, discriminator="response.reasoning.delta"):
    """Emitted when there is a delta (partial update) to the reasoning content.

    :ivar sequence_number: The sequence number for this event. Required.
    :vartype sequence_number: int
    :ivar type: The type of the event. Always 'response.reasoning.delta'. Required.
    :vartype type: str or ~openai.models.RESPONSE_REASONING_DELTA
    :ivar item_id: The unique identifier of the item for which reasoning is being updated.
     Required.
    :vartype item_id: str
    :ivar output_index: The index of the output item in the response's output array. Required.
    :vartype output_index: int
    :ivar content_index: The index of the reasoning content part within the output item. Required.
    :vartype content_index: int
    :ivar delta: The partial update to the reasoning content. Required.
    :vartype delta: any
    """

    type: Literal[ResponseStreamEventType.RESPONSE_REASONING_DELTA] = rest_discriminator(name="type", visibility=["read", "create", "update", "delete", "query"])  # type: ignore
    """The type of the event. Always 'response.reasoning.delta'. Required."""
    item_id: str = rest_field(visibility=["read", "create", "update", "delete", "query"])
    """The unique identifier of the item for which reasoning is being updated. Required."""
    output_index: int = rest_field(visibility=["read", "create", "update", "delete", "query"])
    """The index of the output item in the response's output array. Required."""
    content_index: int = rest_field(visibility=["read", "create", "update", "delete", "query"])
    """The index of the reasoning content part within the output item. Required."""
    delta: Any = rest_field(visibility=["read", "create", "update", "delete", "query"])
    """The partial update to the reasoning content. Required."""

    @overload
    def __init__(
        self,
        *,
        sequence_number: int,
        item_id: str,
        output_index: int,
        content_index: int,
        delta: Any,
    ) -> None: ...

    @overload
    def __init__(self, mapping: Mapping[str, Any]) -> None:
        """
        :param mapping: raw JSON to initialize the model.
        :type mapping: Mapping[str, Any]
        """

    def __init__(self, *args: Any, **kwargs: Any) -> None:
        super().__init__(*args, **kwargs)
        self.type = ResponseStreamEventType.RESPONSE_REASONING_DELTA  # type: ignore


class ResponseReasoningDoneEvent(ResponseStreamEvent, discriminator="response.reasoning.done"):
    """Emitted when the reasoning content is finalized for an item.

    :ivar sequence_number: The sequence number for this event. Required.
    :vartype sequence_number: int
    :ivar type: The type of the event. Always 'response.reasoning.done'. Required.
    :vartype type: str or ~openai.models.RESPONSE_REASONING_DONE
    :ivar item_id: The unique identifier of the item for which reasoning is finalized. Required.
    :vartype item_id: str
    :ivar output_index: The index of the output item in the response's output array. Required.
    :vartype output_index: int
    :ivar content_index: The index of the reasoning content part within the output item. Required.
    :vartype content_index: int
    :ivar text: The finalized reasoning text. Required.
    :vartype text: str
    """

    type: Literal[ResponseStreamEventType.RESPONSE_REASONING_DONE] = rest_discriminator(name="type", visibility=["read", "create", "update", "delete", "query"])  # type: ignore
    """The type of the event. Always 'response.reasoning.done'. Required."""
    item_id: str = rest_field(visibility=["read", "create", "update", "delete", "query"])
    """The unique identifier of the item for which reasoning is finalized. Required."""
    output_index: int = rest_field(visibility=["read", "create", "update", "delete", "query"])
    """The index of the output item in the response's output array. Required."""
    content_index: int = rest_field(visibility=["read", "create", "update", "delete", "query"])
    """The index of the reasoning content part within the output item. Required."""
    text: str = rest_field(visibility=["read", "create", "update", "delete", "query"])
    """The finalized reasoning text. Required."""

    @overload
    def __init__(
        self,
        *,
        sequence_number: int,
        item_id: str,
        output_index: int,
        content_index: int,
        text: str,
    ) -> None: ...

    @overload
    def __init__(self, mapping: Mapping[str, Any]) -> None:
        """
        :param mapping: raw JSON to initialize the model.
        :type mapping: Mapping[str, Any]
        """

    def __init__(self, *args: Any, **kwargs: Any) -> None:
        super().__init__(*args, **kwargs)
        self.type = ResponseStreamEventType.RESPONSE_REASONING_DONE  # type: ignore


class ResponseReasoningSummaryDeltaEvent(ResponseStreamEvent, discriminator="response.reasoning_summary.delta"):
    """Emitted when there is a delta (partial update) to the reasoning summary content.

    :ivar sequence_number: The sequence number for this event. Required.
    :vartype sequence_number: int
    :ivar type: The type of the event. Always 'response.reasoning_summary.delta'. Required.
    :vartype type: str or ~openai.models.RESPONSE_REASONING_SUMMARY_DELTA
    :ivar item_id: The unique identifier of the item for which the reasoning summary is being
     updated. Required.
    :vartype item_id: str
    :ivar output_index: The index of the output item in the response's output array. Required.
    :vartype output_index: int
    :ivar summary_index: The index of the summary part within the output item. Required.
    :vartype summary_index: int
    :ivar delta: The partial update to the reasoning summary content. Required.
    :vartype delta: any
    """

    type: Literal[ResponseStreamEventType.RESPONSE_REASONING_SUMMARY_DELTA] = rest_discriminator(name="type", visibility=["read", "create", "update", "delete", "query"])  # type: ignore
    """The type of the event. Always 'response.reasoning_summary.delta'. Required."""
    item_id: str = rest_field(visibility=["read", "create", "update", "delete", "query"])
    """The unique identifier of the item for which the reasoning summary is being updated. Required."""
    output_index: int = rest_field(visibility=["read", "create", "update", "delete", "query"])
    """The index of the output item in the response's output array. Required."""
    summary_index: int = rest_field(visibility=["read", "create", "update", "delete", "query"])
    """The index of the summary part within the output item. Required."""
    delta: Any = rest_field(visibility=["read", "create", "update", "delete", "query"])
    """The partial update to the reasoning summary content. Required."""

    @overload
    def __init__(
        self,
        *,
        sequence_number: int,
        item_id: str,
        output_index: int,
        summary_index: int,
        delta: Any,
    ) -> None: ...

    @overload
    def __init__(self, mapping: Mapping[str, Any]) -> None:
        """
        :param mapping: raw JSON to initialize the model.
        :type mapping: Mapping[str, Any]
        """

    def __init__(self, *args: Any, **kwargs: Any) -> None:
        super().__init__(*args, **kwargs)
        self.type = ResponseStreamEventType.RESPONSE_REASONING_SUMMARY_DELTA  # type: ignore


class ResponseReasoningSummaryDoneEvent(ResponseStreamEvent, discriminator="response.reasoning_summary.done"):
    """Emitted when the reasoning summary content is finalized for an item.

    :ivar sequence_number: The sequence number for this event. Required.
    :vartype sequence_number: int
    :ivar type: The type of the event. Always 'response.reasoning_summary.done'. Required.
    :vartype type: str or ~openai.models.RESPONSE_REASONING_SUMMARY_DONE
    :ivar item_id: The unique identifier of the item for which the reasoning summary is finalized.
     Required.
    :vartype item_id: str
    :ivar output_index: The index of the output item in the response's output array. Required.
    :vartype output_index: int
    :ivar summary_index: The index of the summary part within the output item. Required.
    :vartype summary_index: int
    :ivar text: The finalized reasoning summary text. Required.
    :vartype text: str
    """

    type: Literal[ResponseStreamEventType.RESPONSE_REASONING_SUMMARY_DONE] = rest_discriminator(name="type", visibility=["read", "create", "update", "delete", "query"])  # type: ignore
    """The type of the event. Always 'response.reasoning_summary.done'. Required."""
    item_id: str = rest_field(visibility=["read", "create", "update", "delete", "query"])
    """The unique identifier of the item for which the reasoning summary is finalized. Required."""
    output_index: int = rest_field(visibility=["read", "create", "update", "delete", "query"])
    """The index of the output item in the response's output array. Required."""
    summary_index: int = rest_field(visibility=["read", "create", "update", "delete", "query"])
    """The index of the summary part within the output item. Required."""
    text: str = rest_field(visibility=["read", "create", "update", "delete", "query"])
    """The finalized reasoning summary text. Required."""

    @overload
    def __init__(
        self,
        *,
        sequence_number: int,
        item_id: str,
        output_index: int,
        summary_index: int,
        text: str,
    ) -> None: ...

    @overload
    def __init__(self, mapping: Mapping[str, Any]) -> None:
        """
        :param mapping: raw JSON to initialize the model.
        :type mapping: Mapping[str, Any]
        """

    def __init__(self, *args: Any, **kwargs: Any) -> None:
        super().__init__(*args, **kwargs)
        self.type = ResponseStreamEventType.RESPONSE_REASONING_SUMMARY_DONE  # type: ignore


class ResponseReasoningSummaryPartAddedEvent(
    ResponseStreamEvent, discriminator="response.reasoning_summary_part.added"
):
    """Emitted when a new reasoning summary part is added.

    :ivar sequence_number: The sequence number for this event. Required.
    :vartype sequence_number: int
    :ivar type: The type of the event. Always ``response.reasoning_summary_part.added``. Required.
    :vartype type: str or ~openai.models.RESPONSE_REASONING_SUMMARY_PART_ADDED
    :ivar item_id: The ID of the item this summary part is associated with. Required.
    :vartype item_id: str
    :ivar output_index: The index of the output item this summary part is associated with.
     Required.
    :vartype output_index: int
    :ivar summary_index: The index of the summary part within the reasoning summary. Required.
    :vartype summary_index: int
    :ivar part: The summary part that was added. Required.
    :vartype part: ~openai.models.ReasoningItemSummaryPart
    """

    type: Literal[ResponseStreamEventType.RESPONSE_REASONING_SUMMARY_PART_ADDED] = rest_discriminator(name="type", visibility=["read", "create", "update", "delete", "query"])  # type: ignore
    """The type of the event. Always ``response.reasoning_summary_part.added``. Required."""
    item_id: str = rest_field(visibility=["read", "create", "update", "delete", "query"])
    """The ID of the item this summary part is associated with. Required."""
    output_index: int = rest_field(visibility=["read", "create", "update", "delete", "query"])
    """The index of the output item this summary part is associated with. Required."""
    summary_index: int = rest_field(visibility=["read", "create", "update", "delete", "query"])
    """The index of the summary part within the reasoning summary. Required."""
    part: "_models.ReasoningItemSummaryPart" = rest_field(visibility=["read", "create", "update", "delete", "query"])
    """The summary part that was added. Required."""

    @overload
    def __init__(
        self,
        *,
        sequence_number: int,
        item_id: str,
        output_index: int,
        summary_index: int,
        part: "_models.ReasoningItemSummaryPart",
    ) -> None: ...

    @overload
    def __init__(self, mapping: Mapping[str, Any]) -> None:
        """
        :param mapping: raw JSON to initialize the model.
        :type mapping: Mapping[str, Any]
        """

    def __init__(self, *args: Any, **kwargs: Any) -> None:
        super().__init__(*args, **kwargs)
        self.type = ResponseStreamEventType.RESPONSE_REASONING_SUMMARY_PART_ADDED  # type: ignore


class ResponseReasoningSummaryPartDoneEvent(ResponseStreamEvent, discriminator="response.reasoning_summary_part.done"):
    """Emitted when a reasoning summary part is completed.

    :ivar sequence_number: The sequence number for this event. Required.
    :vartype sequence_number: int
    :ivar type: The type of the event. Always ``response.reasoning_summary_part.done``. Required.
    :vartype type: str or ~openai.models.RESPONSE_REASONING_SUMMARY_PART_DONE
    :ivar item_id: The ID of the item this summary part is associated with. Required.
    :vartype item_id: str
    :ivar output_index: The index of the output item this summary part is associated with.
     Required.
    :vartype output_index: int
    :ivar summary_index: The index of the summary part within the reasoning summary. Required.
    :vartype summary_index: int
    :ivar part: The completed summary part. Required.
    :vartype part: ~openai.models.ReasoningItemSummaryPart
    """

    type: Literal[ResponseStreamEventType.RESPONSE_REASONING_SUMMARY_PART_DONE] = rest_discriminator(name="type", visibility=["read", "create", "update", "delete", "query"])  # type: ignore
    """The type of the event. Always ``response.reasoning_summary_part.done``. Required."""
    item_id: str = rest_field(visibility=["read", "create", "update", "delete", "query"])
    """The ID of the item this summary part is associated with. Required."""
    output_index: int = rest_field(visibility=["read", "create", "update", "delete", "query"])
    """The index of the output item this summary part is associated with. Required."""
    summary_index: int = rest_field(visibility=["read", "create", "update", "delete", "query"])
    """The index of the summary part within the reasoning summary. Required."""
    part: "_models.ReasoningItemSummaryPart" = rest_field(visibility=["read", "create", "update", "delete", "query"])
    """The completed summary part. Required."""

    @overload
    def __init__(
        self,
        *,
        sequence_number: int,
        item_id: str,
        output_index: int,
        summary_index: int,
        part: "_models.ReasoningItemSummaryPart",
    ) -> None: ...

    @overload
    def __init__(self, mapping: Mapping[str, Any]) -> None:
        """
        :param mapping: raw JSON to initialize the model.
        :type mapping: Mapping[str, Any]
        """

    def __init__(self, *args: Any, **kwargs: Any) -> None:
        super().__init__(*args, **kwargs)
        self.type = ResponseStreamEventType.RESPONSE_REASONING_SUMMARY_PART_DONE  # type: ignore


class ResponseReasoningSummaryTextDeltaEvent(
    ResponseStreamEvent, discriminator="response.reasoning_summary_text.delta"
):
    """Emitted when a delta is added to a reasoning summary text.

    :ivar sequence_number: The sequence number for this event. Required.
    :vartype sequence_number: int
    :ivar type: The type of the event. Always ``response.reasoning_summary_text.delta``. Required.
    :vartype type: str or ~openai.models.RESPONSE_REASONING_SUMMARY_TEXT_DELTA
    :ivar item_id: The ID of the item this summary text delta is associated with. Required.
    :vartype item_id: str
    :ivar output_index: The index of the output item this summary text delta is associated with.
     Required.
    :vartype output_index: int
    :ivar summary_index: The index of the summary part within the reasoning summary. Required.
    :vartype summary_index: int
    :ivar delta: The text delta that was added to the summary. Required.
    :vartype delta: str
    """

    type: Literal[ResponseStreamEventType.RESPONSE_REASONING_SUMMARY_TEXT_DELTA] = rest_discriminator(name="type", visibility=["read", "create", "update", "delete", "query"])  # type: ignore
    """The type of the event. Always ``response.reasoning_summary_text.delta``. Required."""
    item_id: str = rest_field(visibility=["read", "create", "update", "delete", "query"])
    """The ID of the item this summary text delta is associated with. Required."""
    output_index: int = rest_field(visibility=["read", "create", "update", "delete", "query"])
    """The index of the output item this summary text delta is associated with. Required."""
    summary_index: int = rest_field(visibility=["read", "create", "update", "delete", "query"])
    """The index of the summary part within the reasoning summary. Required."""
    delta: str = rest_field(visibility=["read", "create", "update", "delete", "query"])
    """The text delta that was added to the summary. Required."""

    @overload
    def __init__(
        self,
        *,
        sequence_number: int,
        item_id: str,
        output_index: int,
        summary_index: int,
        delta: str,
    ) -> None: ...

    @overload
    def __init__(self, mapping: Mapping[str, Any]) -> None:
        """
        :param mapping: raw JSON to initialize the model.
        :type mapping: Mapping[str, Any]
        """

    def __init__(self, *args: Any, **kwargs: Any) -> None:
        super().__init__(*args, **kwargs)
        self.type = ResponseStreamEventType.RESPONSE_REASONING_SUMMARY_TEXT_DELTA  # type: ignore


class ResponseReasoningSummaryTextDoneEvent(ResponseStreamEvent, discriminator="response.reasoning_summary_text.done"):
    """Emitted when a reasoning summary text is completed.

    :ivar sequence_number: The sequence number for this event. Required.
    :vartype sequence_number: int
    :ivar type: The type of the event. Always ``response.reasoning_summary_text.done``. Required.
    :vartype type: str or ~openai.models.RESPONSE_REASONING_SUMMARY_TEXT_DONE
    :ivar item_id: The ID of the item this summary text is associated with. Required.
    :vartype item_id: str
    :ivar output_index: The index of the output item this summary text is associated with.
     Required.
    :vartype output_index: int
    :ivar summary_index: The index of the summary part within the reasoning summary. Required.
    :vartype summary_index: int
    :ivar text: The full text of the completed reasoning summary. Required.
    :vartype text: str
    """

    type: Literal[ResponseStreamEventType.RESPONSE_REASONING_SUMMARY_TEXT_DONE] = rest_discriminator(name="type", visibility=["read", "create", "update", "delete", "query"])  # type: ignore
    """The type of the event. Always ``response.reasoning_summary_text.done``. Required."""
    item_id: str = rest_field(visibility=["read", "create", "update", "delete", "query"])
    """The ID of the item this summary text is associated with. Required."""
    output_index: int = rest_field(visibility=["read", "create", "update", "delete", "query"])
    """The index of the output item this summary text is associated with. Required."""
    summary_index: int = rest_field(visibility=["read", "create", "update", "delete", "query"])
    """The index of the summary part within the reasoning summary. Required."""
    text: str = rest_field(visibility=["read", "create", "update", "delete", "query"])
    """The full text of the completed reasoning summary. Required."""

    @overload
    def __init__(
        self,
        *,
        sequence_number: int,
        item_id: str,
        output_index: int,
        summary_index: int,
        text: str,
    ) -> None: ...

    @overload
    def __init__(self, mapping: Mapping[str, Any]) -> None:
        """
        :param mapping: raw JSON to initialize the model.
        :type mapping: Mapping[str, Any]
        """

    def __init__(self, *args: Any, **kwargs: Any) -> None:
        super().__init__(*args, **kwargs)
        self.type = ResponseStreamEventType.RESPONSE_REASONING_SUMMARY_TEXT_DONE  # type: ignore


class ResponseRefusalDeltaEvent(ResponseStreamEvent, discriminator="response.refusal.delta"):
    """Emitted when there is a partial refusal text.

    :ivar sequence_number: The sequence number for this event. Required.
    :vartype sequence_number: int
    :ivar type: The type of the event. Always ``response.refusal.delta``. Required.
    :vartype type: str or ~openai.models.RESPONSE_REFUSAL_DELTA
    :ivar item_id: The ID of the output item that the refusal text is added to. Required.
    :vartype item_id: str
    :ivar output_index: The index of the output item that the refusal text is added to. Required.
    :vartype output_index: int
    :ivar content_index: The index of the content part that the refusal text is added to. Required.
    :vartype content_index: int
    :ivar delta: The refusal text that is added. Required.
    :vartype delta: str
    """

    type: Literal[ResponseStreamEventType.RESPONSE_REFUSAL_DELTA] = rest_discriminator(name="type", visibility=["read", "create", "update", "delete", "query"])  # type: ignore
    """The type of the event. Always ``response.refusal.delta``. Required."""
    item_id: str = rest_field(visibility=["read", "create", "update", "delete", "query"])
    """The ID of the output item that the refusal text is added to. Required."""
    output_index: int = rest_field(visibility=["read", "create", "update", "delete", "query"])
    """The index of the output item that the refusal text is added to. Required."""
    content_index: int = rest_field(visibility=["read", "create", "update", "delete", "query"])
    """The index of the content part that the refusal text is added to. Required."""
    delta: str = rest_field(visibility=["read", "create", "update", "delete", "query"])
    """The refusal text that is added. Required."""

    @overload
    def __init__(
        self,
        *,
        sequence_number: int,
        item_id: str,
        output_index: int,
        content_index: int,
        delta: str,
    ) -> None: ...

    @overload
    def __init__(self, mapping: Mapping[str, Any]) -> None:
        """
        :param mapping: raw JSON to initialize the model.
        :type mapping: Mapping[str, Any]
        """

    def __init__(self, *args: Any, **kwargs: Any) -> None:
        super().__init__(*args, **kwargs)
        self.type = ResponseStreamEventType.RESPONSE_REFUSAL_DELTA  # type: ignore


class ResponseRefusalDoneEvent(ResponseStreamEvent, discriminator="response.refusal.done"):
    """Emitted when refusal text is finalized.

    :ivar sequence_number: The sequence number for this event. Required.
    :vartype sequence_number: int
    :ivar type: The type of the event. Always ``response.refusal.done``. Required.
    :vartype type: str or ~openai.models.RESPONSE_REFUSAL_DONE
    :ivar item_id: The ID of the output item that the refusal text is finalized. Required.
    :vartype item_id: str
    :ivar output_index: The index of the output item that the refusal text is finalized. Required.
    :vartype output_index: int
    :ivar content_index: The index of the content part that the refusal text is finalized.
     Required.
    :vartype content_index: int
    :ivar refusal: The refusal text that is finalized. Required.
    :vartype refusal: str
    """

    type: Literal[ResponseStreamEventType.RESPONSE_REFUSAL_DONE] = rest_discriminator(name="type", visibility=["read", "create", "update", "delete", "query"])  # type: ignore
    """The type of the event. Always ``response.refusal.done``. Required."""
    item_id: str = rest_field(visibility=["read", "create", "update", "delete", "query"])
    """The ID of the output item that the refusal text is finalized. Required."""
    output_index: int = rest_field(visibility=["read", "create", "update", "delete", "query"])
    """The index of the output item that the refusal text is finalized. Required."""
    content_index: int = rest_field(visibility=["read", "create", "update", "delete", "query"])
    """The index of the content part that the refusal text is finalized. Required."""
    refusal: str = rest_field(visibility=["read", "create", "update", "delete", "query"])
    """The refusal text that is finalized. Required."""

    @overload
    def __init__(
        self,
        *,
        sequence_number: int,
        item_id: str,
        output_index: int,
        content_index: int,
        refusal: str,
    ) -> None: ...

    @overload
    def __init__(self, mapping: Mapping[str, Any]) -> None:
        """
        :param mapping: raw JSON to initialize the model.
        :type mapping: Mapping[str, Any]
        """

    def __init__(self, *args: Any, **kwargs: Any) -> None:
        super().__init__(*args, **kwargs)
        self.type = ResponseStreamEventType.RESPONSE_REFUSAL_DONE  # type: ignore


class ResponsesMessageItemParam(ItemParam, discriminator="message"):
    """A response message item, representing a role and content, as provided as client request
    parameters.

    You probably want to use the sub-classes and not this class directly. Known sub-classes are:
    ResponsesAssistantMessageItemParam, ResponsesDeveloperMessageItemParam,
    ResponsesSystemMessageItemParam, ResponsesUserMessageItemParam

    :ivar type: The type of the responses item, which is always 'message'. Required.
    :vartype type: str or ~openai.models.MESSAGE
    :ivar role: The role associated with the message. Required. Known values are: "system",
     "developer", "user", and "assistant".
    :vartype role: str or ~openai.models.ResponsesMessageRole
    """

    __mapping__: dict[str, _Model] = {}
    type: Literal[ItemType.MESSAGE] = rest_discriminator(name="type", visibility=["read", "create", "update", "delete", "query"])  # type: ignore
    """The type of the responses item, which is always 'message'. Required."""
    role: str = rest_discriminator(name="role", visibility=["read", "create", "update", "delete", "query"])
    """The role associated with the message. Required. Known values are: \"system\", \"developer\",
     \"user\", and \"assistant\"."""

    @overload
    def __init__(
        self,
        *,
        role: str,
    ) -> None: ...

    @overload
    def __init__(self, mapping: Mapping[str, Any]) -> None:
        """
        :param mapping: raw JSON to initialize the model.
        :type mapping: Mapping[str, Any]
        """

    def __init__(self, *args: Any, **kwargs: Any) -> None:
        super().__init__(*args, **kwargs)
        self.type = ItemType.MESSAGE  # type: ignore


class ResponsesAssistantMessageItemParam(ResponsesMessageItemParam, discriminator="assistant"):
    """A message parameter item with the ``assistant`` role.

    :ivar type: The type of the responses item, which is always 'message'. Required.
    :vartype type: str or ~openai.models.MESSAGE
    :ivar role: The role of the message, which is always ``assistant``. Required.
    :vartype role: str or ~openai.models.ASSISTANT
    :ivar content: The content associated with the message. Required. Is either a str type or a
     [ItemContent] type.
    :vartype content: str or list[~openai.models.ItemContent]
    """

    __mapping__: dict[str, _Model] = {}
    role: Literal[ResponsesMessageRole.ASSISTANT] = rest_discriminator(name="role", visibility=["read", "create", "update", "delete", "query"])  # type: ignore
    """The role of the message, which is always ``assistant``. Required."""
    content: Union["str", list["_models.ItemContent"]] = rest_field(
        visibility=["read", "create", "update", "delete", "query"]
    )
    """The content associated with the message. Required. Is either a str type or a [ItemContent]
     type."""

    @overload
    def __init__(
        self,
        *,
        content: Union[str, list["_models.ItemContent"]],
    ) -> None: ...

    @overload
    def __init__(self, mapping: Mapping[str, Any]) -> None:
        """
        :param mapping: raw JSON to initialize the model.
        :type mapping: Mapping[str, Any]
        """

    def __init__(self, *args: Any, **kwargs: Any) -> None:
        super().__init__(*args, **kwargs)
        self.role = ResponsesMessageRole.ASSISTANT  # type: ignore


class ResponsesMessageItemResource(ItemResource, discriminator="message"):
    """A response message resource item, representing a role and content, as provided on service
    responses.

    You probably want to use the sub-classes and not this class directly. Known sub-classes are:
    ResponsesAssistantMessageItemResource, ResponsesDeveloperMessageItemResource,
    ResponsesSystemMessageItemResource, ResponsesUserMessageItemResource

    :ivar id: Required.
    :vartype id: str
    :ivar type: The type of the responses item, which is always 'message'. Required.
    :vartype type: str or ~openai.models.MESSAGE
    :ivar status: The status of the item. One of ``in_progress``, ``completed``, or
     ``incomplete``. Populated when items are returned via API. Required. Is one of the following
     types: Literal["in_progress"], Literal["completed"], Literal["incomplete"]
    :vartype status: str or str or str
    :ivar role: The role associated with the message. Required. Known values are: "system",
     "developer", "user", and "assistant".
    :vartype role: str or ~openai.models.ResponsesMessageRole
    """

    __mapping__: dict[str, _Model] = {}
    type: Literal[ItemType.MESSAGE] = rest_discriminator(name="type", visibility=["read", "create", "update", "delete", "query"])  # type: ignore
    """The type of the responses item, which is always 'message'. Required."""
    status: Literal["in_progress", "completed", "incomplete"] = rest_field(
        visibility=["read", "create", "update", "delete", "query"]
    )
    """The status of the item. One of ``in_progress``, ``completed``, or
     ``incomplete``. Populated when items are returned via API. Required. Is one of the following
     types: Literal[\"in_progress\"], Literal[\"completed\"], Literal[\"incomplete\"]"""
    role: str = rest_discriminator(name="role", visibility=["read", "create", "update", "delete", "query"])
    """The role associated with the message. Required. Known values are: \"system\", \"developer\",
     \"user\", and \"assistant\"."""

    @overload
    def __init__(
        self,
        *,
        id: str,  # pylint: disable=redefined-builtin
        status: Literal["in_progress", "completed", "incomplete"],
        role: str,
    ) -> None: ...

    @overload
    def __init__(self, mapping: Mapping[str, Any]) -> None:
        """
        :param mapping: raw JSON to initialize the model.
        :type mapping: Mapping[str, Any]
        """

    def __init__(self, *args: Any, **kwargs: Any) -> None:
        super().__init__(*args, **kwargs)
        self.type = ItemType.MESSAGE  # type: ignore


class ResponsesAssistantMessageItemResource(ResponsesMessageItemResource, discriminator="assistant"):
    """A message resource item with the ``assistant`` role.

    :ivar id: Required.
    :vartype id: str
    :ivar type: The type of the responses item, which is always 'message'. Required.
    :vartype type: str or ~openai.models.MESSAGE
    :ivar status: The status of the item. One of ``in_progress``, ``completed``, or
     ``incomplete``. Populated when items are returned via API. Required. Is one of the following
     types: Literal["in_progress"], Literal["completed"], Literal["incomplete"]
    :vartype status: str or str or str
    :ivar role: The role of the message, which is always ``assistant``. Required.
    :vartype role: str or ~openai.models.ASSISTANT
    :ivar content: The content associated with the message. Required.
    :vartype content: list[~openai.models.ItemContent]
    """

    __mapping__: dict[str, _Model] = {}
    role: Literal[ResponsesMessageRole.ASSISTANT] = rest_discriminator(name="role", visibility=["read", "create", "update", "delete", "query"])  # type: ignore
    """The role of the message, which is always ``assistant``. Required."""
    content: list["_models.ItemContent"] = rest_field(visibility=["read", "create", "update", "delete", "query"])
    """The content associated with the message. Required."""

    @overload
    def __init__(
        self,
        *,
        id: str,  # pylint: disable=redefined-builtin
        status: Literal["in_progress", "completed", "incomplete"],
        content: list["_models.ItemContent"],
    ) -> None: ...

    @overload
    def __init__(self, mapping: Mapping[str, Any]) -> None:
        """
        :param mapping: raw JSON to initialize the model.
        :type mapping: Mapping[str, Any]
        """

    def __init__(self, *args: Any, **kwargs: Any) -> None:
        super().__init__(*args, **kwargs)
        self.role = ResponsesMessageRole.ASSISTANT  # type: ignore


class ResponsesDeveloperMessageItemParam(ResponsesMessageItemParam, discriminator="developer"):
    """A message parameter item with the ``developer`` role.

    :ivar type: The type of the responses item, which is always 'message'. Required.
    :vartype type: str or ~openai.models.MESSAGE
    :ivar role: The role of the message, which is always ``developer``. Required.
    :vartype role: str or ~openai.models.DEVELOPER
    :ivar content: The content associated with the message. Required. Is either a str type or a
     [ItemContent] type.
    :vartype content: str or list[~openai.models.ItemContent]
    """

    __mapping__: dict[str, _Model] = {}
    role: Literal[ResponsesMessageRole.DEVELOPER] = rest_discriminator(name="role", visibility=["read", "create", "update", "delete", "query"])  # type: ignore
    """The role of the message, which is always ``developer``. Required."""
    content: Union["str", list["_models.ItemContent"]] = rest_field(
        visibility=["read", "create", "update", "delete", "query"]
    )
    """The content associated with the message. Required. Is either a str type or a [ItemContent]
     type."""

    @overload
    def __init__(
        self,
        *,
        content: Union[str, list["_models.ItemContent"]],
    ) -> None: ...

    @overload
    def __init__(self, mapping: Mapping[str, Any]) -> None:
        """
        :param mapping: raw JSON to initialize the model.
        :type mapping: Mapping[str, Any]
        """

    def __init__(self, *args: Any, **kwargs: Any) -> None:
        super().__init__(*args, **kwargs)
        self.role = ResponsesMessageRole.DEVELOPER  # type: ignore


class ResponsesDeveloperMessageItemResource(ResponsesMessageItemResource, discriminator="developer"):
    """A message resource item with the ``developer`` role.

    :ivar id: Required.
    :vartype id: str
    :ivar type: The type of the responses item, which is always 'message'. Required.
    :vartype type: str or ~openai.models.MESSAGE
    :ivar status: The status of the item. One of ``in_progress``, ``completed``, or
     ``incomplete``. Populated when items are returned via API. Required. Is one of the following
     types: Literal["in_progress"], Literal["completed"], Literal["incomplete"]
    :vartype status: str or str or str
    :ivar role: The role of the message, which is always ``developer``. Required.
    :vartype role: str or ~openai.models.DEVELOPER
    :ivar content: The content associated with the message. Required.
    :vartype content: list[~openai.models.ItemContent]
    """

    __mapping__: dict[str, _Model] = {}
    role: Literal[ResponsesMessageRole.DEVELOPER] = rest_discriminator(name="role", visibility=["read", "create", "update", "delete", "query"])  # type: ignore
    """The role of the message, which is always ``developer``. Required."""
    content: list["_models.ItemContent"] = rest_field(visibility=["read", "create", "update", "delete", "query"])
    """The content associated with the message. Required."""

    @overload
    def __init__(
        self,
        *,
        id: str,  # pylint: disable=redefined-builtin
        status: Literal["in_progress", "completed", "incomplete"],
        content: list["_models.ItemContent"],
    ) -> None: ...

    @overload
    def __init__(self, mapping: Mapping[str, Any]) -> None:
        """
        :param mapping: raw JSON to initialize the model.
        :type mapping: Mapping[str, Any]
        """

    def __init__(self, *args: Any, **kwargs: Any) -> None:
        super().__init__(*args, **kwargs)
        self.role = ResponsesMessageRole.DEVELOPER  # type: ignore


class ResponsesSystemMessageItemParam(ResponsesMessageItemParam, discriminator="system"):
    """A message parameter item with the ``system`` role.

    :ivar type: The type of the responses item, which is always 'message'. Required.
    :vartype type: str or ~openai.models.MESSAGE
    :ivar role: The role of the message, which is always ``system``. Required.
    :vartype role: str or ~openai.models.SYSTEM
    :ivar content: The content associated with the message. Required. Is either a str type or a
     [ItemContent] type.
    :vartype content: str or list[~openai.models.ItemContent]
    """

    __mapping__: dict[str, _Model] = {}
    role: Literal[ResponsesMessageRole.SYSTEM] = rest_discriminator(name="role", visibility=["read", "create", "update", "delete", "query"])  # type: ignore
    """The role of the message, which is always ``system``. Required."""
    content: Union["str", list["_models.ItemContent"]] = rest_field(
        visibility=["read", "create", "update", "delete", "query"]
    )
    """The content associated with the message. Required. Is either a str type or a [ItemContent]
     type."""

    @overload
    def __init__(
        self,
        *,
        content: Union[str, list["_models.ItemContent"]],
    ) -> None: ...

    @overload
    def __init__(self, mapping: Mapping[str, Any]) -> None:
        """
        :param mapping: raw JSON to initialize the model.
        :type mapping: Mapping[str, Any]
        """

    def __init__(self, *args: Any, **kwargs: Any) -> None:
        super().__init__(*args, **kwargs)
        self.role = ResponsesMessageRole.SYSTEM  # type: ignore


class ResponsesSystemMessageItemResource(ResponsesMessageItemResource, discriminator="system"):
    """A message resource item with the ``system`` role.

    :ivar id: Required.
    :vartype id: str
    :ivar type: The type of the responses item, which is always 'message'. Required.
    :vartype type: str or ~openai.models.MESSAGE
    :ivar status: The status of the item. One of ``in_progress``, ``completed``, or
     ``incomplete``. Populated when items are returned via API. Required. Is one of the following
     types: Literal["in_progress"], Literal["completed"], Literal["incomplete"]
    :vartype status: str or str or str
    :ivar role: The role of the message, which is always ``system``. Required.
    :vartype role: str or ~openai.models.SYSTEM
    :ivar content: The content associated with the message. Required.
    :vartype content: list[~openai.models.ItemContent]
    """

    __mapping__: dict[str, _Model] = {}
    role: Literal[ResponsesMessageRole.SYSTEM] = rest_discriminator(name="role", visibility=["read", "create", "update", "delete", "query"])  # type: ignore
    """The role of the message, which is always ``system``. Required."""
    content: list["_models.ItemContent"] = rest_field(visibility=["read", "create", "update", "delete", "query"])
    """The content associated with the message. Required."""

    @overload
    def __init__(
        self,
        *,
        id: str,  # pylint: disable=redefined-builtin
        status: Literal["in_progress", "completed", "incomplete"],
        content: list["_models.ItemContent"],
    ) -> None: ...

    @overload
    def __init__(self, mapping: Mapping[str, Any]) -> None:
        """
        :param mapping: raw JSON to initialize the model.
        :type mapping: Mapping[str, Any]
        """

    def __init__(self, *args: Any, **kwargs: Any) -> None:
        super().__init__(*args, **kwargs)
        self.role = ResponsesMessageRole.SYSTEM  # type: ignore


class ResponsesUserMessageItemParam(ResponsesMessageItemParam, discriminator="user"):
    """A message parameter item with the ``user`` role.

    :ivar type: The type of the responses item, which is always 'message'. Required.
    :vartype type: str or ~openai.models.MESSAGE
    :ivar role: The role of the message, which is always ``user``. Required.
    :vartype role: str or ~openai.models.USER
    :ivar content: The content associated with the message. Required. Is either a str type or a
     [ItemContent] type.
    :vartype content: str or list[~openai.models.ItemContent]
    """

    __mapping__: dict[str, _Model] = {}
    role: Literal[ResponsesMessageRole.USER] = rest_discriminator(name="role", visibility=["read", "create", "update", "delete", "query"])  # type: ignore
    """The role of the message, which is always ``user``. Required."""
    content: Union["str", list["_models.ItemContent"]] = rest_field(
        visibility=["read", "create", "update", "delete", "query"]
    )
    """The content associated with the message. Required. Is either a str type or a [ItemContent]
     type."""

    @overload
    def __init__(
        self,
        *,
        content: Union[str, list["_models.ItemContent"]],
    ) -> None: ...

    @overload
    def __init__(self, mapping: Mapping[str, Any]) -> None:
        """
        :param mapping: raw JSON to initialize the model.
        :type mapping: Mapping[str, Any]
        """

    def __init__(self, *args: Any, **kwargs: Any) -> None:
        super().__init__(*args, **kwargs)
        self.role = ResponsesMessageRole.USER  # type: ignore


class ResponsesUserMessageItemResource(ResponsesMessageItemResource, discriminator="user"):
    """A message resource item with the ``user`` role.

    :ivar id: Required.
    :vartype id: str
    :ivar type: The type of the responses item, which is always 'message'. Required.
    :vartype type: str or ~openai.models.MESSAGE
    :ivar status: The status of the item. One of ``in_progress``, ``completed``, or
     ``incomplete``. Populated when items are returned via API. Required. Is one of the following
     types: Literal["in_progress"], Literal["completed"], Literal["incomplete"]
    :vartype status: str or str or str
    :ivar role: The role of the message, which is always ``user``. Required.
    :vartype role: str or ~openai.models.USER
    :ivar content: The content associated with the message. Required.
    :vartype content: list[~openai.models.ItemContent]
    """

    __mapping__: dict[str, _Model] = {}
    role: Literal[ResponsesMessageRole.USER] = rest_discriminator(name="role", visibility=["read", "create", "update", "delete", "query"])  # type: ignore
    """The role of the message, which is always ``user``. Required."""
    content: list["_models.ItemContent"] = rest_field(visibility=["read", "create", "update", "delete", "query"])
    """The content associated with the message. Required."""

    @overload
    def __init__(
        self,
        *,
        id: str,  # pylint: disable=redefined-builtin
        status: Literal["in_progress", "completed", "incomplete"],
        content: list["_models.ItemContent"],
    ) -> None: ...

    @overload
    def __init__(self, mapping: Mapping[str, Any]) -> None:
        """
        :param mapping: raw JSON to initialize the model.
        :type mapping: Mapping[str, Any]
        """

    def __init__(self, *args: Any, **kwargs: Any) -> None:
        super().__init__(*args, **kwargs)
        self.role = ResponsesMessageRole.USER  # type: ignore


class ResponseTextDeltaEvent(ResponseStreamEvent, discriminator="response.output_text.delta"):
    """Emitted when there is an additional text delta.

    :ivar sequence_number: The sequence number for this event. Required.
    :vartype sequence_number: int
    :ivar type: The type of the event. Always ``response.output_text.delta``. Required.
    :vartype type: str or ~openai.models.RESPONSE_OUTPUT_TEXT_DELTA
    :ivar item_id: The ID of the output item that the text delta was added to. Required.
    :vartype item_id: str
    :ivar output_index: The index of the output item that the text delta was added to. Required.
    :vartype output_index: int
    :ivar content_index: The index of the content part that the text delta was added to. Required.
    :vartype content_index: int
    :ivar delta: The text delta that was added. Required.
    :vartype delta: str
    """

    type: Literal[ResponseStreamEventType.RESPONSE_OUTPUT_TEXT_DELTA] = rest_discriminator(name="type", visibility=["read", "create", "update", "delete", "query"])  # type: ignore
    """The type of the event. Always ``response.output_text.delta``. Required."""
    item_id: str = rest_field(visibility=["read", "create", "update", "delete", "query"])
    """The ID of the output item that the text delta was added to. Required."""
    output_index: int = rest_field(visibility=["read", "create", "update", "delete", "query"])
    """The index of the output item that the text delta was added to. Required."""
    content_index: int = rest_field(visibility=["read", "create", "update", "delete", "query"])
    """The index of the content part that the text delta was added to. Required."""
    delta: str = rest_field(visibility=["read", "create", "update", "delete", "query"])
    """The text delta that was added. Required."""

    @overload
    def __init__(
        self,
        *,
        sequence_number: int,
        item_id: str,
        output_index: int,
        content_index: int,
        delta: str,
    ) -> None: ...

    @overload
    def __init__(self, mapping: Mapping[str, Any]) -> None:
        """
        :param mapping: raw JSON to initialize the model.
        :type mapping: Mapping[str, Any]
        """

    def __init__(self, *args: Any, **kwargs: Any) -> None:
        super().__init__(*args, **kwargs)
        self.type = ResponseStreamEventType.RESPONSE_OUTPUT_TEXT_DELTA  # type: ignore


class ResponseTextDoneEvent(ResponseStreamEvent, discriminator="response.output_text.done"):
    """Emitted when text content is finalized.

    :ivar sequence_number: The sequence number for this event. Required.
    :vartype sequence_number: int
    :ivar type: The type of the event. Always ``response.output_text.done``. Required.
    :vartype type: str or ~openai.models.RESPONSE_OUTPUT_TEXT_DONE
    :ivar item_id: The ID of the output item that the text content is finalized. Required.
    :vartype item_id: str
    :ivar output_index: The index of the output item that the text content is finalized. Required.
    :vartype output_index: int
    :ivar content_index: The index of the content part that the text content is finalized.
     Required.
    :vartype content_index: int
    :ivar text: The text content that is finalized. Required.
    :vartype text: str
    """

    type: Literal[ResponseStreamEventType.RESPONSE_OUTPUT_TEXT_DONE] = rest_discriminator(name="type", visibility=["read", "create", "update", "delete", "query"])  # type: ignore
    """The type of the event. Always ``response.output_text.done``. Required."""
    item_id: str = rest_field(visibility=["read", "create", "update", "delete", "query"])
    """The ID of the output item that the text content is finalized. Required."""
    output_index: int = rest_field(visibility=["read", "create", "update", "delete", "query"])
    """The index of the output item that the text content is finalized. Required."""
    content_index: int = rest_field(visibility=["read", "create", "update", "delete", "query"])
    """The index of the content part that the text content is finalized. Required."""
    text: str = rest_field(visibility=["read", "create", "update", "delete", "query"])
    """The text content that is finalized. Required."""

    @overload
    def __init__(
        self,
        *,
        sequence_number: int,
        item_id: str,
        output_index: int,
        content_index: int,
        text: str,
    ) -> None: ...

    @overload
    def __init__(self, mapping: Mapping[str, Any]) -> None:
        """
        :param mapping: raw JSON to initialize the model.
        :type mapping: Mapping[str, Any]
        """

    def __init__(self, *args: Any, **kwargs: Any) -> None:
        super().__init__(*args, **kwargs)
        self.type = ResponseStreamEventType.RESPONSE_OUTPUT_TEXT_DONE  # type: ignore


class ResponseTextFormatConfiguration(_Model):
    """ResponseTextFormatConfiguration.

    You probably want to use the sub-classes and not this class directly. Known sub-classes are:
    ResponseTextFormatConfigurationJsonObject, ResponseTextFormatConfigurationJsonSchema,
    ResponseTextFormatConfigurationText

    :ivar type: Required. Known values are: "text", "json_schema", and "json_object".
    :vartype type: str or ~openai.models.ResponseTextFormatConfigurationType
    """

    __mapping__: dict[str, _Model] = {}
    type: str = rest_discriminator(name="type", visibility=["read", "create", "update", "delete", "query"])
    """Required. Known values are: \"text\", \"json_schema\", and \"json_object\"."""

    @overload
    def __init__(
        self,
        *,
        type: str,
    ) -> None: ...

    @overload
    def __init__(self, mapping: Mapping[str, Any]) -> None:
        """
        :param mapping: raw JSON to initialize the model.
        :type mapping: Mapping[str, Any]
        """

    def __init__(self, *args: Any, **kwargs: Any) -> None:
        super().__init__(*args, **kwargs)


class ResponseTextFormatConfigurationJsonObject(
    ResponseTextFormatConfiguration, discriminator="json_object"
):  # pylint: disable=name-too-long
    """ResponseTextFormatConfigurationJsonObject.

    :ivar type: Required.
    :vartype type: str or ~openai.models.JSON_OBJECT
    """

    type: Literal[ResponseTextFormatConfigurationType.JSON_OBJECT] = rest_discriminator(name="type", visibility=["read", "create", "update", "delete", "query"])  # type: ignore
    """Required."""

    @overload
    def __init__(
        self,
    ) -> None: ...

    @overload
    def __init__(self, mapping: Mapping[str, Any]) -> None:
        """
        :param mapping: raw JSON to initialize the model.
        :type mapping: Mapping[str, Any]
        """

    def __init__(self, *args: Any, **kwargs: Any) -> None:
        super().__init__(*args, **kwargs)
        self.type = ResponseTextFormatConfigurationType.JSON_OBJECT  # type: ignore


class ResponseTextFormatConfigurationJsonSchema(
    ResponseTextFormatConfiguration, discriminator="json_schema"
):  # pylint: disable=name-too-long
    """JSON Schema response format. Used to generate structured JSON responses.
    Learn more about `Structured Outputs </docs/guides/structured-outputs>`_.

    :ivar type: The type of response format being defined. Always ``json_schema``. Required.
    :vartype type: str or ~openai.models.JSON_SCHEMA
    :ivar description: A description of what the response format is for, used by the model to
     determine how to respond in the format.
    :vartype description: str
    :ivar name: The name of the response format. Must be a-z, A-Z, 0-9, or contain
     underscores and dashes, with a maximum length of 64. Required.
    :vartype name: str
    :ivar schema: Required.
    :vartype schema: ~openai.models.ResponseFormatJsonSchemaSchema
    :ivar strict: Whether to enable strict schema adherence when generating the output.
     If set to true, the model will always follow the exact schema defined
     in the ``schema`` field. Only a subset of JSON Schema is supported when
     ``strict`` is ``true``. To learn more, read the `Structured Outputs
     guide </docs/guides/structured-outputs>`_.
    :vartype strict: bool
    """

    type: Literal[ResponseTextFormatConfigurationType.JSON_SCHEMA] = rest_discriminator(name="type", visibility=["read", "create", "update", "delete", "query"])  # type: ignore
    """The type of response format being defined. Always ``json_schema``. Required."""
    description: Optional[str] = rest_field(visibility=["read", "create", "update", "delete", "query"])
    """A description of what the response format is for, used by the model to
     determine how to respond in the format."""
    name: str = rest_field(visibility=["read", "create", "update", "delete", "query"])
    """The name of the response format. Must be a-z, A-Z, 0-9, or contain
     underscores and dashes, with a maximum length of 64. Required."""
    schema: "_models.ResponseFormatJsonSchemaSchema" = rest_field(
        visibility=["read", "create", "update", "delete", "query"]
    )
    """Required."""
    strict: Optional[bool] = rest_field(visibility=["read", "create", "update", "delete", "query"])
    """Whether to enable strict schema adherence when generating the output.
     If set to true, the model will always follow the exact schema defined
     in the ``schema`` field. Only a subset of JSON Schema is supported when
     ``strict`` is ``true``. To learn more, read the `Structured Outputs
     guide </docs/guides/structured-outputs>`_."""

    @overload
    def __init__(
        self,
        *,
        name: str,
        schema: "_models.ResponseFormatJsonSchemaSchema",
        description: Optional[str] = None,
        strict: Optional[bool] = None,
    ) -> None: ...

    @overload
    def __init__(self, mapping: Mapping[str, Any]) -> None:
        """
        :param mapping: raw JSON to initialize the model.
        :type mapping: Mapping[str, Any]
        """

    def __init__(self, *args: Any, **kwargs: Any) -> None:
        super().__init__(*args, **kwargs)
        self.type = ResponseTextFormatConfigurationType.JSON_SCHEMA  # type: ignore


class ResponseTextFormatConfigurationText(ResponseTextFormatConfiguration, discriminator="text"):
    """ResponseTextFormatConfigurationText.

    :ivar type: Required.
    :vartype type: str or ~openai.models.TEXT
    """

    type: Literal[ResponseTextFormatConfigurationType.TEXT] = rest_discriminator(name="type", visibility=["read", "create", "update", "delete", "query"])  # type: ignore
    """Required."""

    @overload
    def __init__(
        self,
    ) -> None: ...

    @overload
    def __init__(self, mapping: Mapping[str, Any]) -> None:
        """
        :param mapping: raw JSON to initialize the model.
        :type mapping: Mapping[str, Any]
        """

    def __init__(self, *args: Any, **kwargs: Any) -> None:
        super().__init__(*args, **kwargs)
        self.type = ResponseTextFormatConfigurationType.TEXT  # type: ignore


class ResponseUsage(_Model):
    """Represents token usage details including input tokens, output tokens,
    a breakdown of output tokens, and the total tokens used.

    :ivar input_tokens: The number of input tokens. Required.
    :vartype input_tokens: int
    :ivar input_tokens_details: A detailed breakdown of the input tokens. Required.
    :vartype input_tokens_details: ~openai.models.ResponseUsageInputTokensDetails
    :ivar output_tokens: The number of output tokens. Required.
    :vartype output_tokens: int
    :ivar output_tokens_details: A detailed breakdown of the output tokens. Required.
    :vartype output_tokens_details: ~openai.models.ResponseUsageOutputTokensDetails
    :ivar total_tokens: The total number of tokens used. Required.
    :vartype total_tokens: int
    """

    input_tokens: int = rest_field(visibility=["read", "create", "update", "delete", "query"])
    """The number of input tokens. Required."""
    input_tokens_details: "_models.ResponseUsageInputTokensDetails" = rest_field(
        visibility=["read", "create", "update", "delete", "query"]
    )
    """A detailed breakdown of the input tokens. Required."""
    output_tokens: int = rest_field(visibility=["read", "create", "update", "delete", "query"])
    """The number of output tokens. Required."""
    output_tokens_details: "_models.ResponseUsageOutputTokensDetails" = rest_field(
        visibility=["read", "create", "update", "delete", "query"]
    )
    """A detailed breakdown of the output tokens. Required."""
    total_tokens: int = rest_field(visibility=["read", "create", "update", "delete", "query"])
    """The total number of tokens used. Required."""

    @overload
    def __init__(
        self,
        *,
        input_tokens: int,
        input_tokens_details: "_models.ResponseUsageInputTokensDetails",
        output_tokens: int,
        output_tokens_details: "_models.ResponseUsageOutputTokensDetails",
        total_tokens: int,
    ) -> None: ...

    @overload
    def __init__(self, mapping: Mapping[str, Any]) -> None:
        """
        :param mapping: raw JSON to initialize the model.
        :type mapping: Mapping[str, Any]
        """

    def __init__(self, *args: Any, **kwargs: Any) -> None:
        super().__init__(*args, **kwargs)


class ResponseUsageInputTokensDetails(_Model):
    """ResponseUsageInputTokensDetails.

    :ivar cached_tokens: The number of tokens that were retrieved from the cache.
     `More on prompt caching </docs/guides/prompt-caching>`_. Required.
    :vartype cached_tokens: int
    """

    cached_tokens: int = rest_field(visibility=["read", "create", "update", "delete", "query"])
    """The number of tokens that were retrieved from the cache.
     `More on prompt caching </docs/guides/prompt-caching>`_. Required."""

    @overload
    def __init__(
        self,
        *,
        cached_tokens: int,
    ) -> None: ...

    @overload
    def __init__(self, mapping: Mapping[str, Any]) -> None:
        """
        :param mapping: raw JSON to initialize the model.
        :type mapping: Mapping[str, Any]
        """

    def __init__(self, *args: Any, **kwargs: Any) -> None:
        super().__init__(*args, **kwargs)


class ResponseUsageOutputTokensDetails(_Model):
    """ResponseUsageOutputTokensDetails.

    :ivar reasoning_tokens: The number of reasoning tokens. Required.
    :vartype reasoning_tokens: int
    """

    reasoning_tokens: int = rest_field(visibility=["read", "create", "update", "delete", "query"])
    """The number of reasoning tokens. Required."""

    @overload
    def __init__(
        self,
        *,
        reasoning_tokens: int,
    ) -> None: ...

    @overload
    def __init__(self, mapping: Mapping[str, Any]) -> None:
        """
        :param mapping: raw JSON to initialize the model.
        :type mapping: Mapping[str, Any]
        """

    def __init__(self, *args: Any, **kwargs: Any) -> None:
        super().__init__(*args, **kwargs)


class ResponseWebSearchCallCompletedEvent(ResponseStreamEvent, discriminator="response.web_search_call.completed"):
    """Note: web_search is not yet available via Azure OpenAI.

    :ivar sequence_number: The sequence number for this event. Required.
    :vartype sequence_number: int
    :ivar type: The type of the event. Always ``response.web_search_call.completed``. Required.
    :vartype type: str or ~openai.models.RESPONSE_WEB_SEARCH_CALL_COMPLETED
    :ivar output_index: The index of the output item that the web search call is associated with.
     Required.
    :vartype output_index: int
    :ivar item_id: Unique ID for the output item associated with the web search call. Required.
    :vartype item_id: str
    """

    type: Literal[ResponseStreamEventType.RESPONSE_WEB_SEARCH_CALL_COMPLETED] = rest_discriminator(name="type", visibility=["read", "create", "update", "delete", "query"])  # type: ignore
    """The type of the event. Always ``response.web_search_call.completed``. Required."""
    output_index: int = rest_field(visibility=["read", "create", "update", "delete", "query"])
    """The index of the output item that the web search call is associated with. Required."""
    item_id: str = rest_field(visibility=["read", "create", "update", "delete", "query"])
    """Unique ID for the output item associated with the web search call. Required."""

    @overload
    def __init__(
        self,
        *,
        sequence_number: int,
        output_index: int,
        item_id: str,
    ) -> None: ...

    @overload
    def __init__(self, mapping: Mapping[str, Any]) -> None:
        """
        :param mapping: raw JSON to initialize the model.
        :type mapping: Mapping[str, Any]
        """

    def __init__(self, *args: Any, **kwargs: Any) -> None:
        super().__init__(*args, **kwargs)
        self.type = ResponseStreamEventType.RESPONSE_WEB_SEARCH_CALL_COMPLETED  # type: ignore


class ResponseWebSearchCallInProgressEvent(ResponseStreamEvent, discriminator="response.web_search_call.in_progress"):
    """Note: web_search is not yet available via Azure OpenAI.

    :ivar sequence_number: The sequence number for this event. Required.
    :vartype sequence_number: int
    :ivar type: The type of the event. Always ``response.web_search_call.in_progress``. Required.
    :vartype type: str or ~openai.models.RESPONSE_WEB_SEARCH_CALL_IN_PROGRESS
    :ivar output_index: The index of the output item that the web search call is associated with.
     Required.
    :vartype output_index: int
    :ivar item_id: Unique ID for the output item associated with the web search call. Required.
    :vartype item_id: str
    """

    type: Literal[ResponseStreamEventType.RESPONSE_WEB_SEARCH_CALL_IN_PROGRESS] = rest_discriminator(name="type", visibility=["read", "create", "update", "delete", "query"])  # type: ignore
    """The type of the event. Always ``response.web_search_call.in_progress``. Required."""
    output_index: int = rest_field(visibility=["read", "create", "update", "delete", "query"])
    """The index of the output item that the web search call is associated with. Required."""
    item_id: str = rest_field(visibility=["read", "create", "update", "delete", "query"])
    """Unique ID for the output item associated with the web search call. Required."""

    @overload
    def __init__(
        self,
        *,
        sequence_number: int,
        output_index: int,
        item_id: str,
    ) -> None: ...

    @overload
    def __init__(self, mapping: Mapping[str, Any]) -> None:
        """
        :param mapping: raw JSON to initialize the model.
        :type mapping: Mapping[str, Any]
        """

    def __init__(self, *args: Any, **kwargs: Any) -> None:
        super().__init__(*args, **kwargs)
        self.type = ResponseStreamEventType.RESPONSE_WEB_SEARCH_CALL_IN_PROGRESS  # type: ignore


class ResponseWebSearchCallSearchingEvent(ResponseStreamEvent, discriminator="response.web_search_call.searching"):
    """Note: web_search is not yet available via Azure OpenAI.

    :ivar sequence_number: The sequence number for this event. Required.
    :vartype sequence_number: int
    :ivar type: The type of the event. Always ``response.web_search_call.searching``. Required.
    :vartype type: str or ~openai.models.RESPONSE_WEB_SEARCH_CALL_SEARCHING
    :ivar output_index: The index of the output item that the web search call is associated with.
     Required.
    :vartype output_index: int
    :ivar item_id: Unique ID for the output item associated with the web search call. Required.
    :vartype item_id: str
    """

    type: Literal[ResponseStreamEventType.RESPONSE_WEB_SEARCH_CALL_SEARCHING] = rest_discriminator(name="type", visibility=["read", "create", "update", "delete", "query"])  # type: ignore
    """The type of the event. Always ``response.web_search_call.searching``. Required."""
    output_index: int = rest_field(visibility=["read", "create", "update", "delete", "query"])
    """The index of the output item that the web search call is associated with. Required."""
    item_id: str = rest_field(visibility=["read", "create", "update", "delete", "query"])
    """Unique ID for the output item associated with the web search call. Required."""

    @overload
    def __init__(
        self,
        *,
        sequence_number: int,
        output_index: int,
        item_id: str,
    ) -> None: ...

    @overload
    def __init__(self, mapping: Mapping[str, Any]) -> None:
        """
        :param mapping: raw JSON to initialize the model.
        :type mapping: Mapping[str, Any]
        """

    def __init__(self, *args: Any, **kwargs: Any) -> None:
        super().__init__(*args, **kwargs)
        self.type = ResponseStreamEventType.RESPONSE_WEB_SEARCH_CALL_SEARCHING  # type: ignore


class ToolChoiceObject(_Model):
    """ToolChoiceObject.

    You probably want to use the sub-classes and not this class directly. Known sub-classes are:
    ToolChoiceObjectCodeInterpreter, ToolChoiceObjectComputer, ToolChoiceObjectFileSearch,
    ToolChoiceObjectFunction, ToolChoiceObjectImageGen, ToolChoiceObjectMCP,
    ToolChoiceObjectWebSearch

    :ivar type: Required. Known values are: "file_search", "function", "computer_use_preview",
     "web_search_preview", "image_generation", "code_interpreter", and "mcp".
    :vartype type: str or ~openai.models.ToolChoiceObjectType
    """

    __mapping__: dict[str, _Model] = {}
    type: str = rest_discriminator(name="type", visibility=["read", "create", "update", "delete", "query"])
    """Required. Known values are: \"file_search\", \"function\", \"computer_use_preview\",
     \"web_search_preview\", \"image_generation\", \"code_interpreter\", and \"mcp\"."""

    @overload
    def __init__(
        self,
        *,
        type: str,
    ) -> None: ...

    @overload
    def __init__(self, mapping: Mapping[str, Any]) -> None:
        """
        :param mapping: raw JSON to initialize the model.
        :type mapping: Mapping[str, Any]
        """

    def __init__(self, *args: Any, **kwargs: Any) -> None:
        super().__init__(*args, **kwargs)


class ToolChoiceObjectCodeInterpreter(ToolChoiceObject, discriminator="code_interpreter"):
    """ToolChoiceObjectCodeInterpreter.

    :ivar type: Required.
    :vartype type: str or ~openai.models.CODE_INTERPRETER
    """

    type: Literal[ToolChoiceObjectType.CODE_INTERPRETER] = rest_discriminator(name="type", visibility=["read", "create", "update", "delete", "query"])  # type: ignore
    """Required."""

    @overload
    def __init__(
        self,
    ) -> None: ...

    @overload
    def __init__(self, mapping: Mapping[str, Any]) -> None:
        """
        :param mapping: raw JSON to initialize the model.
        :type mapping: Mapping[str, Any]
        """

    def __init__(self, *args: Any, **kwargs: Any) -> None:
        super().__init__(*args, **kwargs)
        self.type = ToolChoiceObjectType.CODE_INTERPRETER  # type: ignore


class ToolChoiceObjectComputer(ToolChoiceObject, discriminator="computer_use_preview"):
    """ToolChoiceObjectComputer.

    :ivar type: Required.
    :vartype type: str or ~openai.models.COMPUTER
    """

    type: Literal[ToolChoiceObjectType.COMPUTER] = rest_discriminator(name="type", visibility=["read", "create", "update", "delete", "query"])  # type: ignore
    """Required."""

    @overload
    def __init__(
        self,
    ) -> None: ...

    @overload
    def __init__(self, mapping: Mapping[str, Any]) -> None:
        """
        :param mapping: raw JSON to initialize the model.
        :type mapping: Mapping[str, Any]
        """

    def __init__(self, *args: Any, **kwargs: Any) -> None:
        super().__init__(*args, **kwargs)
        self.type = ToolChoiceObjectType.COMPUTER  # type: ignore


class ToolChoiceObjectFileSearch(ToolChoiceObject, discriminator="file_search"):
    """ToolChoiceObjectFileSearch.

    :ivar type: Required.
    :vartype type: str or ~openai.models.FILE_SEARCH
    """

    type: Literal[ToolChoiceObjectType.FILE_SEARCH] = rest_discriminator(name="type", visibility=["read", "create", "update", "delete", "query"])  # type: ignore
    """Required."""

    @overload
    def __init__(
        self,
    ) -> None: ...

    @overload
    def __init__(self, mapping: Mapping[str, Any]) -> None:
        """
        :param mapping: raw JSON to initialize the model.
        :type mapping: Mapping[str, Any]
        """

    def __init__(self, *args: Any, **kwargs: Any) -> None:
        super().__init__(*args, **kwargs)
        self.type = ToolChoiceObjectType.FILE_SEARCH  # type: ignore


class ToolChoiceObjectFunction(ToolChoiceObject, discriminator="function"):
    """Use this option to force the model to call a specific function.

    :ivar type: For function calling, the type is always ``function``. Required.
    :vartype type: str or ~openai.models.FUNCTION
    :ivar name: The name of the function to call. Required.
    :vartype name: str
    """

    type: Literal[ToolChoiceObjectType.FUNCTION] = rest_discriminator(name="type", visibility=["read", "create", "update", "delete", "query"])  # type: ignore
    """For function calling, the type is always ``function``. Required."""
    name: str = rest_field(visibility=["read", "create", "update", "delete", "query"])
    """The name of the function to call. Required."""

    @overload
    def __init__(
        self,
        *,
        name: str,
    ) -> None: ...

    @overload
    def __init__(self, mapping: Mapping[str, Any]) -> None:
        """
        :param mapping: raw JSON to initialize the model.
        :type mapping: Mapping[str, Any]
        """

    def __init__(self, *args: Any, **kwargs: Any) -> None:
        super().__init__(*args, **kwargs)
        self.type = ToolChoiceObjectType.FUNCTION  # type: ignore


class ToolChoiceObjectImageGen(ToolChoiceObject, discriminator="image_generation"):
    """ToolChoiceObjectImageGen.

    :ivar type: Required.
    :vartype type: str or ~openai.models.IMAGE_GENERATION
    """

    type: Literal[ToolChoiceObjectType.IMAGE_GENERATION] = rest_discriminator(name="type", visibility=["read", "create", "update", "delete", "query"])  # type: ignore
    """Required."""

    @overload
    def __init__(
        self,
    ) -> None: ...

    @overload
    def __init__(self, mapping: Mapping[str, Any]) -> None:
        """
        :param mapping: raw JSON to initialize the model.
        :type mapping: Mapping[str, Any]
        """

    def __init__(self, *args: Any, **kwargs: Any) -> None:
        super().__init__(*args, **kwargs)
        self.type = ToolChoiceObjectType.IMAGE_GENERATION  # type: ignore


class ToolChoiceObjectMCP(ToolChoiceObject, discriminator="mcp"):
    """Use this option to force the model to call a specific tool on a remote MCP server.

    :ivar type: For MCP tools, the type is always ``mcp``. Required.
    :vartype type: str or ~openai.models.MCP
    :ivar server_label: The label of the MCP server to use. Required.
    :vartype server_label: str
    :ivar name: The name of the tool to call on the server.
    :vartype name: str
    """

    type: Literal[ToolChoiceObjectType.MCP] = rest_discriminator(name="type", visibility=["read", "create", "update", "delete", "query"])  # type: ignore
    """For MCP tools, the type is always ``mcp``. Required."""
    server_label: str = rest_field(visibility=["read", "create", "update", "delete", "query"])
    """The label of the MCP server to use. Required."""
    name: Optional[str] = rest_field(visibility=["read", "create", "update", "delete", "query"])
    """The name of the tool to call on the server."""

    @overload
    def __init__(
        self,
        *,
        server_label: str,
        name: Optional[str] = None,
    ) -> None: ...

    @overload
    def __init__(self, mapping: Mapping[str, Any]) -> None:
        """
        :param mapping: raw JSON to initialize the model.
        :type mapping: Mapping[str, Any]
        """

    def __init__(self, *args: Any, **kwargs: Any) -> None:
        super().__init__(*args, **kwargs)
        self.type = ToolChoiceObjectType.MCP  # type: ignore


class ToolChoiceObjectWebSearch(ToolChoiceObject, discriminator="web_search_preview"):
    """Note: web_search is not yet available via Azure OpenAI.

    :ivar type: Required.
    :vartype type: str or ~openai.models.WEB_SEARCH
    """

    type: Literal[ToolChoiceObjectType.WEB_SEARCH] = rest_discriminator(name="type", visibility=["read", "create", "update", "delete", "query"])  # type: ignore
    """Required."""

    @overload
    def __init__(
        self,
    ) -> None: ...

    @overload
    def __init__(self, mapping: Mapping[str, Any]) -> None:
        """
        :param mapping: raw JSON to initialize the model.
        :type mapping: Mapping[str, Any]
        """

    def __init__(self, *args: Any, **kwargs: Any) -> None:
        super().__init__(*args, **kwargs)
        self.type = ToolChoiceObjectType.WEB_SEARCH  # type: ignore


class TopLogProb(_Model):
    """The top log probability of a token.

    :ivar token: Required.
    :vartype token: str
    :ivar logprob: Required.
    :vartype logprob: float
    :ivar bytes: Required.
    :vartype bytes: list[int]
    """

    token: str = rest_field(visibility=["read", "create", "update", "delete", "query"])
    """Required."""
    logprob: float = rest_field(visibility=["read", "create", "update", "delete", "query"])
    """Required."""
    bytes: list[int] = rest_field(visibility=["read", "create", "update", "delete", "query"])
    """Required."""

    @overload
    def __init__(
        self,
        *,
        token: str,
        logprob: float,
        bytes: list[int],
    ) -> None: ...

    @overload
    def __init__(self, mapping: Mapping[str, Any]) -> None:
        """
        :param mapping: raw JSON to initialize the model.
        :type mapping: Mapping[str, Any]
        """

    def __init__(self, *args: Any, **kwargs: Any) -> None:
        super().__init__(*args, **kwargs)


class UpdateConversationRequest(_Model):
    """Update a conversation.

    :ivar metadata: Set of 16 key-value pairs that can be attached to an object. This can be
     useful for storing additional information about the object in a structured
     format, and querying for objects via API or the dashboard.

     Keys are strings with a maximum length of 64 characters. Values are strings
     with a maximum length of 512 characters.
    :vartype metadata: dict[str, str]
    """

    metadata: Optional[dict[str, str]] = rest_field(visibility=["read", "create", "update", "delete", "query"])
    """Set of 16 key-value pairs that can be attached to an object. This can be
     useful for storing additional information about the object in a structured
     format, and querying for objects via API or the dashboard.
     
     Keys are strings with a maximum length of 64 characters. Values are strings
     with a maximum length of 512 characters."""

    @overload
    def __init__(
        self,
        *,
        metadata: Optional[dict[str, str]] = None,
    ) -> None: ...

    @overload
    def __init__(self, mapping: Mapping[str, Any]) -> None:
        """
        :param mapping: raw JSON to initialize the model.
        :type mapping: Mapping[str, Any]
        """

    def __init__(self, *args: Any, **kwargs: Any) -> None:
        super().__init__(*args, **kwargs)


class VectorStoreFileAttributes(_Model):
    """Set of 16 key-value pairs that can be attached to an object. This can be
    useful for storing additional information about the object in a structured
    format, and querying for objects via API or the dashboard. Keys are strings
    with a maximum length of 64 characters. Values are strings with a maximum
    length of 512 characters, booleans, or numbers.

    """


class WebSearchAction(_Model):
    """WebSearchAction.

    You probably want to use the sub-classes and not this class directly. Known sub-classes are:
    WebSearchActionFind, WebSearchActionOpenPage, WebSearchActionSearch

    :ivar type: Required. Known values are: "search", "open_page", and "find".
    :vartype type: str or ~openai.models.WebSearchActionType
    """

    __mapping__: dict[str, _Model] = {}
    type: str = rest_discriminator(name="type", visibility=["read", "create", "update", "delete", "query"])
    """Required. Known values are: \"search\", \"open_page\", and \"find\"."""

    @overload
    def __init__(
        self,
        *,
        type: str,
    ) -> None: ...

    @overload
    def __init__(self, mapping: Mapping[str, Any]) -> None:
        """
        :param mapping: raw JSON to initialize the model.
        :type mapping: Mapping[str, Any]
        """

    def __init__(self, *args: Any, **kwargs: Any) -> None:
        super().__init__(*args, **kwargs)


class WebSearchActionFind(WebSearchAction, discriminator="find"):
    """Action type "find": Searches for a pattern within a loaded page.

    :ivar type: The action type. Required.
    :vartype type: str or ~openai.models.FIND
    :ivar url: The URL of the page searched for the pattern. Required.
    :vartype url: str
    :ivar pattern: The pattern or text to search for within the page. Required.
    :vartype pattern: str
    """

    type: Literal[WebSearchActionType.FIND] = rest_discriminator(name="type", visibility=["read", "create", "update", "delete", "query"])  # type: ignore
    """The action type. Required."""
    url: str = rest_field(visibility=["read", "create", "update", "delete", "query"])
    """The URL of the page searched for the pattern. Required."""
    pattern: str = rest_field(visibility=["read", "create", "update", "delete", "query"])
    """The pattern or text to search for within the page. Required."""

    @overload
    def __init__(
        self,
        *,
        url: str,
        pattern: str,
    ) -> None: ...

    @overload
    def __init__(self, mapping: Mapping[str, Any]) -> None:
        """
        :param mapping: raw JSON to initialize the model.
        :type mapping: Mapping[str, Any]
        """

    def __init__(self, *args: Any, **kwargs: Any) -> None:
        super().__init__(*args, **kwargs)
        self.type = WebSearchActionType.FIND  # type: ignore


class WebSearchActionOpenPage(WebSearchAction, discriminator="open_page"):
    """Action type "open_page" - Opens a specific URL from search results.

    :ivar type: The action type. Required.
    :vartype type: str or ~openai.models.OPEN_PAGE
    :ivar url: The URL opened by the model. Required.
    :vartype url: str
    """

    type: Literal[WebSearchActionType.OPEN_PAGE] = rest_discriminator(name="type", visibility=["read", "create", "update", "delete", "query"])  # type: ignore
    """The action type. Required."""
    url: str = rest_field(visibility=["read", "create", "update", "delete", "query"])
    """The URL opened by the model. Required."""

    @overload
    def __init__(
        self,
        *,
        url: str,
    ) -> None: ...

    @overload
    def __init__(self, mapping: Mapping[str, Any]) -> None:
        """
        :param mapping: raw JSON to initialize the model.
        :type mapping: Mapping[str, Any]
        """

    def __init__(self, *args: Any, **kwargs: Any) -> None:
        super().__init__(*args, **kwargs)
        self.type = WebSearchActionType.OPEN_PAGE  # type: ignore


class WebSearchActionSearch(WebSearchAction, discriminator="search"):
    """Action type "search" - Performs a web search query.

    :ivar type: The action type. Required.
    :vartype type: str or ~openai.models.SEARCH
    :ivar query: The search query. Required.
    :vartype query: str
    """

    type: Literal[WebSearchActionType.SEARCH] = rest_discriminator(name="type", visibility=["read", "create", "update", "delete", "query"])  # type: ignore
    """The action type. Required."""
    query: str = rest_field(visibility=["read", "create", "update", "delete", "query"])
    """The search query. Required."""

    @overload
    def __init__(
        self,
        *,
        query: str,
    ) -> None: ...

    @overload
    def __init__(self, mapping: Mapping[str, Any]) -> None:
        """
        :param mapping: raw JSON to initialize the model.
        :type mapping: Mapping[str, Any]
        """

    def __init__(self, *args: Any, **kwargs: Any) -> None:
        super().__init__(*args, **kwargs)
        self.type = WebSearchActionType.SEARCH  # type: ignore


class WebSearchPreviewTool(Tool, discriminator="web_search_preview"):
    """Note: web_search is not yet available via Azure OpenAI.

    :ivar type: The type of the web search tool. One of ``web_search_preview`` or
     ``web_search_preview_2025_03_11``. Required.
    :vartype type: str or ~openai.models.WEB_SEARCH_PREVIEW
    :ivar user_location: The user's location.
    :vartype user_location: ~openai.models.Location
    :ivar search_context_size: High level guidance for the amount of context window space to use
     for the search. One of ``low``, ``medium``, or ``high``. ``medium`` is the default. Is one of
     the following types: Literal["low"], Literal["medium"], Literal["high"]
    :vartype search_context_size: str or str or str
    """

    type: Literal[ToolType.WEB_SEARCH_PREVIEW] = rest_discriminator(name="type", visibility=["read", "create", "update", "delete", "query"])  # type: ignore
    """The type of the web search tool. One of ``web_search_preview`` or
     ``web_search_preview_2025_03_11``. Required."""
    user_location: Optional["_models.Location"] = rest_field(visibility=["read", "create", "update", "delete", "query"])
    """The user's location."""
    search_context_size: Optional[Literal["low", "medium", "high"]] = rest_field(
        visibility=["read", "create", "update", "delete", "query"]
    )
    """High level guidance for the amount of context window space to use for the search. One of
     ``low``, ``medium``, or ``high``. ``medium`` is the default. Is one of the following types:
     Literal[\"low\"], Literal[\"medium\"], Literal[\"high\"]"""

    @overload
    def __init__(
        self,
        *,
        user_location: Optional["_models.Location"] = None,
        search_context_size: Optional[Literal["low", "medium", "high"]] = None,
    ) -> None: ...

    @overload
    def __init__(self, mapping: Mapping[str, Any]) -> None:
        """
        :param mapping: raw JSON to initialize the model.
        :type mapping: Mapping[str, Any]
        """

    def __init__(self, *args: Any, **kwargs: Any) -> None:
        super().__init__(*args, **kwargs)
        self.type = ToolType.WEB_SEARCH_PREVIEW  # type: ignore


class WebSearchToolCallItemParam(ItemParam, discriminator="web_search_call"):
    """The results of a web search tool call. See the
    `web search guide </docs/guides/tools-web-search>`_ for more information.

    :ivar type: Required.
    :vartype type: str or ~openai.models.WEB_SEARCH_CALL
    :ivar action: An object describing the specific action taken in this web search call.
     Includes details on how the model used the web (search, open_page, find). Required.
    :vartype action: ~openai.models.WebSearchAction
    """

    type: Literal[ItemType.WEB_SEARCH_CALL] = rest_discriminator(name="type", visibility=["read", "create", "update", "delete", "query"])  # type: ignore
    """Required."""
    action: "_models.WebSearchAction" = rest_field(visibility=["read", "create", "update", "delete", "query"])
    """An object describing the specific action taken in this web search call.
     Includes details on how the model used the web (search, open_page, find). Required."""

    @overload
    def __init__(
        self,
        *,
        action: "_models.WebSearchAction",
    ) -> None: ...

    @overload
    def __init__(self, mapping: Mapping[str, Any]) -> None:
        """
        :param mapping: raw JSON to initialize the model.
        :type mapping: Mapping[str, Any]
        """

    def __init__(self, *args: Any, **kwargs: Any) -> None:
        super().__init__(*args, **kwargs)
        self.type = ItemType.WEB_SEARCH_CALL  # type: ignore


class WebSearchToolCallItemResource(ItemResource, discriminator="web_search_call"):
    """The results of a web search tool call. See the
    `web search guide </docs/guides/tools-web-search>`_ for more information.

    :ivar id: Required.
    :vartype id: str
    :ivar type: Required.
    :vartype type: str or ~openai.models.WEB_SEARCH_CALL
    :ivar status: The status of the web search tool call. Required. Is one of the following types:
     Literal["in_progress"], Literal["searching"], Literal["completed"], Literal["failed"]
    :vartype status: str or str or str or str
    :ivar action: An object describing the specific action taken in this web search call.
     Includes details on how the model used the web (search, open_page, find). Required.
    :vartype action: ~openai.models.WebSearchAction
    """

    type: Literal[ItemType.WEB_SEARCH_CALL] = rest_discriminator(name="type", visibility=["read", "create", "update", "delete", "query"])  # type: ignore
    """Required."""
    status: Literal["in_progress", "searching", "completed", "failed"] = rest_field(
        visibility=["read", "create", "update", "delete", "query"]
    )
    """The status of the web search tool call. Required. Is one of the following types:
     Literal[\"in_progress\"], Literal[\"searching\"], Literal[\"completed\"], Literal[\"failed\"]"""
    action: "_models.WebSearchAction" = rest_field(visibility=["read", "create", "update", "delete", "query"])
    """An object describing the specific action taken in this web search call.
     Includes details on how the model used the web (search, open_page, find). Required."""

    @overload
    def __init__(
        self,
        *,
        id: str,  # pylint: disable=redefined-builtin
        status: Literal["in_progress", "searching", "completed", "failed"],
        action: "_models.WebSearchAction",
    ) -> None: ...

    @overload
    def __init__(self, mapping: Mapping[str, Any]) -> None:
        """
        :param mapping: raw JSON to initialize the model.
        :type mapping: Mapping[str, Any]
        """

    def __init__(self, *args: Any, **kwargs: Any) -> None:
        super().__init__(*args, **kwargs)
        self.type = ItemType.WEB_SEARCH_CALL  # type: ignore
