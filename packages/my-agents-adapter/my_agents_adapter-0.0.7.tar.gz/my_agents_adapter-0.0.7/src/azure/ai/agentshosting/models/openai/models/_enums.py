# coding=utf-8
# --------------------------------------------------------------------------
# Copyright (c) Microsoft Corporation. All rights reserved.
# Licensed under the MIT License. See License.txt in the project root for license information.
# Code generated by Microsoft (R) Python Code Generator.
# Changes may cause incorrect behavior and will be lost if the code is regenerated.
# --------------------------------------------------------------------------

from enum import Enum
from azure.core import CaseInsensitiveEnumMeta


class AnnotationType(str, Enum, metaclass=CaseInsensitiveEnumMeta):
    """Type of AnnotationType."""

    FILE_CITATION = "file_citation"
    URL_CITATION = "url_citation"
    FILE_PATH = "file_path"
    CONTAINER_FILE_CITATION = "container_file_citation"


class CodeInterpreterOutputType(str, Enum, metaclass=CaseInsensitiveEnumMeta):
    """Type of CodeInterpreterOutputType."""

    LOGS = "logs"
    IMAGE = "image"


class ComputerActionType(str, Enum, metaclass=CaseInsensitiveEnumMeta):
    """Type of ComputerActionType."""

    SCREENSHOT = "screenshot"
    CLICK = "click"
    DOUBLE_CLICK = "double_click"
    SCROLL = "scroll"
    TYPE = "type"
    WAIT = "wait"
    KEYPRESS = "keypress"
    DRAG = "drag"
    MOVE = "move"


class ComputerToolCallOutputItemOutputType(str, Enum, metaclass=CaseInsensitiveEnumMeta):
    """A computer screenshot image used with the computer use tool."""

    SCREENSHOT = "computer_screenshot"


class Includable(str, Enum, metaclass=CaseInsensitiveEnumMeta):
    """Specify additional output data to include in the model response. Currently
    supported values are:

    * `code_interpreter_call.outputs`: Includes the outputs of python code execution
    in code interpreter tool call items.
    * `computer_call_output.output.image_url`: Include image urls from the computer call output.
    * `file_search_call.results`: Include the search results of
    the file search tool call.
    * `message.input_image.image_url`: Include image urls from the input message.
    * `message.output_text.logprobs`: Include logprobs with assistant messages.
    * `reasoning.encrypted_content`: Includes an encrypted version of reasoning
    tokens in reasoning item outputs. This enables reasoning items to be used in
    multi-turn conversations when using the Responses API statelessly (like
    when the `store` parameter is set to `false`, or when an organization is
    enrolled in the zero data retention program).
    """

    CODE_INTERPRETER_CALL_OUTPUTS = "code_interpreter_call.outputs"
    COMPUTER_CALL_OUTPUT_OUTPUT_IMAGE_URL = "computer_call_output.output.image_url"
    FILE_SEARCH_CALL_RESULTS = "file_search_call.results"
    MESSAGE_INPUT_IMAGE_IMAGE_URL = "message.input_image.image_url"
    MESSAGE_OUTPUT_TEXT_LOGPROBS = "message.output_text.logprobs"
    REASONING_ENCRYPTED_CONTENT = "reasoning.encrypted_content"


class ItemContentType(str, Enum, metaclass=CaseInsensitiveEnumMeta):
    """Multi-modal input and output contents."""

    INPUT_TEXT = "input_text"
    INPUT_AUDIO = "input_audio"
    INPUT_IMAGE = "input_image"
    INPUT_FILE = "input_file"
    OUTPUT_TEXT = "output_text"
    OUTPUT_AUDIO = "output_audio"
    REFUSAL = "refusal"


class ItemType(str, Enum, metaclass=CaseInsensitiveEnumMeta):
    """Type of ItemType."""

    MESSAGE = "message"
    FILE_SEARCH_CALL = "file_search_call"
    FUNCTION_CALL = "function_call"
    FUNCTION_CALL_OUTPUT = "function_call_output"
    COMPUTER_CALL = "computer_call"
    COMPUTER_CALL_OUTPUT = "computer_call_output"
    WEB_SEARCH_CALL = "web_search_call"
    REASONING = "reasoning"
    ITEM_REFERENCE = "item_reference"
    IMAGE_GENERATION_CALL = "image_generation_call"
    CODE_INTERPRETER_CALL = "code_interpreter_call"
    LOCAL_SHELL_CALL = "local_shell_call"
    LOCAL_SHELL_CALL_OUTPUT = "local_shell_call_output"
    MCP_LIST_TOOLS = "mcp_list_tools"
    MCP_APPROVAL_REQUEST = "mcp_approval_request"
    MCP_APPROVAL_RESPONSE = "mcp_approval_response"
    MCP_CALL = "mcp_call"
    STRUCTURED_INPUTS = "structured_inputs"
    STRUCTURED_OUTPUTS = "structured_outputs"
    SEMANTIC_EVENT = "semantic_event"
    WORKFLOW_ACTION = "workflow_action"


class LocationType(str, Enum, metaclass=CaseInsensitiveEnumMeta):
    """Type of LocationType."""

    APPROXIMATE = "approximate"


class ReasoningEffort(str, Enum, metaclass=CaseInsensitiveEnumMeta):
    """**o-series models only**

    Constrains effort on reasoning for
    `reasoning models <https://platform.openai.com/docs/guides/reasoning>`_.
    Currently supported values are ``low``, ``medium``, and ``high``. Reducing
    reasoning effort can result in faster responses and fewer tokens used
    on reasoning in a response.
    """

    LOW = "low"
    MEDIUM = "medium"
    HIGH = "high"


class ReasoningItemSummaryPartType(str, Enum, metaclass=CaseInsensitiveEnumMeta):
    """Type of ReasoningItemSummaryPartType."""

    SUMMARY_TEXT = "summary_text"


class ResponseErrorCode(str, Enum, metaclass=CaseInsensitiveEnumMeta):
    """The error code for the response."""

    SERVER_ERROR = "server_error"
    RATE_LIMIT_EXCEEDED = "rate_limit_exceeded"
    INVALID_PROMPT = "invalid_prompt"
    VECTOR_STORE_TIMEOUT = "vector_store_timeout"
    INVALID_IMAGE = "invalid_image"
    INVALID_IMAGE_FORMAT = "invalid_image_format"
    INVALID_BASE64_IMAGE = "invalid_base64_image"
    INVALID_IMAGE_URL = "invalid_image_url"
    IMAGE_TOO_LARGE = "image_too_large"
    IMAGE_TOO_SMALL = "image_too_small"
    IMAGE_PARSE_ERROR = "image_parse_error"
    IMAGE_CONTENT_POLICY_VIOLATION = "image_content_policy_violation"
    INVALID_IMAGE_MODE = "invalid_image_mode"
    IMAGE_FILE_TOO_LARGE = "image_file_too_large"
    UNSUPPORTED_IMAGE_MEDIA_TYPE = "unsupported_image_media_type"
    EMPTY_IMAGE_FILE = "empty_image_file"
    FAILED_TO_DOWNLOAD_IMAGE = "failed_to_download_image"
    IMAGE_FILE_NOT_FOUND = "image_file_not_found"


class ResponsesMessageRole(str, Enum, metaclass=CaseInsensitiveEnumMeta):
    """The collection of valid roles for responses message items."""

    SYSTEM = "system"
    DEVELOPER = "developer"
    USER = "user"
    ASSISTANT = "assistant"


class ResponseStreamEventType(str, Enum, metaclass=CaseInsensitiveEnumMeta):
    """Type of ResponseStreamEventType."""

    RESPONSE_AUDIO_DELTA = "response.audio.delta"
    RESPONSE_AUDIO_DONE = "response.audio.done"
    RESPONSE_AUDIO_TRANSCRIPT_DELTA = "response.audio_transcript.delta"
    RESPONSE_AUDIO_TRANSCRIPT_DONE = "response.audio_transcript.done"
    RESPONSE_CODE_INTERPRETER_CALL_CODE_DELTA = "response.code_interpreter_call_code.delta"
    RESPONSE_CODE_INTERPRETER_CALL_CODE_DONE = "response.code_interpreter_call_code.done"
    RESPONSE_CODE_INTERPRETER_CALL_COMPLETED = "response.code_interpreter_call.completed"
    RESPONSE_CODE_INTERPRETER_CALL_IN_PROGRESS = "response.code_interpreter_call.in_progress"
    RESPONSE_CODE_INTERPRETER_CALL_INTERPRETING = "response.code_interpreter_call.interpreting"
    RESPONSE_COMPLETED = "response.completed"
    RESPONSE_CONTENT_PART_ADDED = "response.content_part.added"
    RESPONSE_CONTENT_PART_DONE = "response.content_part.done"
    RESPONSE_CREATED = "response.created"
    ERROR = "error"
    RESPONSE_FILE_SEARCH_CALL_COMPLETED = "response.file_search_call.completed"
    RESPONSE_FILE_SEARCH_CALL_IN_PROGRESS = "response.file_search_call.in_progress"
    RESPONSE_FILE_SEARCH_CALL_SEARCHING = "response.file_search_call.searching"
    RESPONSE_FUNCTION_CALL_ARGUMENTS_DELTA = "response.function_call_arguments.delta"
    RESPONSE_FUNCTION_CALL_ARGUMENTS_DONE = "response.function_call_arguments.done"
    RESPONSE_IN_PROGRESS = "response.in_progress"
    RESPONSE_FAILED = "response.failed"
    RESPONSE_INCOMPLETE = "response.incomplete"
    RESPONSE_OUTPUT_ITEM_ADDED = "response.output_item.added"
    RESPONSE_OUTPUT_ITEM_DONE = "response.output_item.done"
    RESPONSE_REFUSAL_DELTA = "response.refusal.delta"
    RESPONSE_REFUSAL_DONE = "response.refusal.done"
    RESPONSE_OUTPUT_TEXT_ANNOTATION_ADDED = "response.output_text.annotation.added"
    RESPONSE_OUTPUT_TEXT_DELTA = "response.output_text.delta"
    RESPONSE_OUTPUT_TEXT_DONE = "response.output_text.done"
    RESPONSE_REASONING_SUMMARY_PART_ADDED = "response.reasoning_summary_part.added"
    RESPONSE_REASONING_SUMMARY_PART_DONE = "response.reasoning_summary_part.done"
    RESPONSE_REASONING_SUMMARY_TEXT_DELTA = "response.reasoning_summary_text.delta"
    RESPONSE_REASONING_SUMMARY_TEXT_DONE = "response.reasoning_summary_text.done"
    RESPONSE_WEB_SEARCH_CALL_COMPLETED = "response.web_search_call.completed"
    RESPONSE_WEB_SEARCH_CALL_IN_PROGRESS = "response.web_search_call.in_progress"
    RESPONSE_WEB_SEARCH_CALL_SEARCHING = "response.web_search_call.searching"
    RESPONSE_IMAGE_GENERATION_CALL_COMPLETED = "response.image_generation_call.completed"
    RESPONSE_IMAGE_GENERATION_CALL_GENERATING = "response.image_generation_call.generating"
    RESPONSE_IMAGE_GENERATION_CALL_IN_PROGRESS = "response.image_generation_call.in_progress"
    RESPONSE_IMAGE_GENERATION_CALL_PARTIAL_IMAGE = "response.image_generation_call.partial_image"
    RESPONSE_MCP_CALL_ARGUMENTS_DELTA = "response.mcp_call.arguments_delta"
    RESPONSE_MCP_CALL_ARGUMENTS_DONE = "response.mcp_call.arguments_done"
    RESPONSE_MCP_CALL_COMPLETED = "response.mcp_call.completed"
    RESPONSE_MCP_CALL_FAILED = "response.mcp_call.failed"
    RESPONSE_MCP_CALL_IN_PROGRESS = "response.mcp_call.in_progress"
    RESPONSE_MCP_LIST_TOOLS_COMPLETED = "response.mcp_list_tools.completed"
    RESPONSE_MCP_LIST_TOOLS_FAILED = "response.mcp_list_tools.failed"
    RESPONSE_MCP_LIST_TOOLS_IN_PROGRESS = "response.mcp_list_tools.in_progress"
    RESPONSE_QUEUED = "response.queued"
    RESPONSE_REASONING_DELTA = "response.reasoning.delta"
    RESPONSE_REASONING_DONE = "response.reasoning.done"
    RESPONSE_REASONING_SUMMARY_DELTA = "response.reasoning_summary.delta"
    RESPONSE_REASONING_SUMMARY_DONE = "response.reasoning_summary.done"


class ResponseTextFormatConfigurationType(str, Enum, metaclass=CaseInsensitiveEnumMeta):
    """An object specifying the format that the model must output.

    Configuring ``{ "type": "json_schema" }`` enables Structured Outputs,
    which ensures the model will match your supplied JSON schema. Learn more in the
    `Structured Outputs guide </docs/guides/structured-outputs>`_.

    The default format is ``{ "type": "text" }`` with no additional options.

    **Not recommended for gpt-4o and newer models:**

    Setting to ``{ "type": "json_object" }`` enables the older JSON mode, which
    ensures the message the model generates is valid JSON. Using ``json_schema``
    is preferred for models that support it.
    """

    TEXT = "text"
    JSON_SCHEMA = "json_schema"
    JSON_OBJECT = "json_object"


class ServiceTier(str, Enum, metaclass=CaseInsensitiveEnumMeta):
    """Specifies the processing type used for serving the request.

    * If set to 'auto', then the request will be processed with the service tier configured in the
    Project settings. Unless otherwise configured, the Project will use 'default'.
    * If set to 'default', then the request will be processed with the standard pricing and
    performance for the selected model.
    * If set to '[flex](/docs/guides/flex-processing)' or 'priority', then the request will be
    processed with the corresponding service tier. [Contact
    sales](https://openai.com/contact-sales) to learn more about Priority processing.
    * When not set, the default behavior is 'auto'.

      When the ``service_tier`` parameter is set, the response body will include the
    ``service_tier`` value based on the processing mode actually used to serve the request. This
    response value may be different from the value set in the parameter.
    """

    AUTO = "auto"
    DEFAULT = "default"
    FLEX = "flex"
    SCALE = "scale"
    PRIORITY = "priority"


class ToolChoiceObjectType(str, Enum, metaclass=CaseInsensitiveEnumMeta):
    """Indicates that the model should use a built-in tool to generate a response.
    `Learn more about built-in tools </docs/guides/tools>`_.
    """

    FILE_SEARCH = "file_search"
    FUNCTION = "function"
    COMPUTER = "computer_use_preview"
    WEB_SEARCH = "web_search_preview"
    IMAGE_GENERATION = "image_generation"
    CODE_INTERPRETER = "code_interpreter"
    MCP = "mcp"


class ToolChoiceOptions(str, Enum, metaclass=CaseInsensitiveEnumMeta):
    """Controls which (if any) tool is called by the model.

    ``none`` means the model will not call any tool and instead generates a message.

    ``auto`` means the model can pick between generating a message or calling one or
    more tools.

    ``required`` means the model must call one or more tools.
    """

    NONE = "none"
    AUTO = "auto"
    REQUIRED = "required"


class ToolType(str, Enum, metaclass=CaseInsensitiveEnumMeta):
    """A tool that can be used to generate a response."""

    FILE_SEARCH = "file_search"
    FUNCTION = "function"
    COMPUTER_USE_PREVIEW = "computer_use_preview"
    WEB_SEARCH_PREVIEW = "web_search_preview"
    MCP = "mcp"
    CODE_INTERPRETER = "code_interpreter"
    IMAGE_GENERATION = "image_generation"
    LOCAL_SHELL = "local_shell"
    BING_GROUNDING = "bing_grounding"
    BROWSER_AUTOMATION = "browser_automation"
    FABRIC_DATAAGENT = "fabric_dataagent"
    SHAREPOINT_GROUNDING = "sharepoint_grounding"
    AZURE_AI_SEARCH = "azure_ai_search"
    OPENAPI = "openapi"
    BING_CUSTOM_SEARCH = "bing_custom_search"
    CONNECTED_AGENT = "connected_agent"
    CAPTURE_STRUCTURED_OUTPUTS = "capture_structured_outputs"
    CAPTURE_SEMANTIC_EVENTS = "capture_semantic_events"
    A2_A = "a2a"


class WebSearchActionType(str, Enum, metaclass=CaseInsensitiveEnumMeta):
    """Type of WebSearchActionType."""

    SEARCH = "search"
    OPEN_PAGE = "open_page"
    FIND = "find"
