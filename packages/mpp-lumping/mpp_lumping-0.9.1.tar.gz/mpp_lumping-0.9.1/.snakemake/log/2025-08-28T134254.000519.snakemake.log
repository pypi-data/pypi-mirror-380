Assuming unrestricted shared filesystem usage.
None
host: bmdiota
Building DAG of jobs...
Using shell: /usr/bin/bash
Provided cores: 32
Rules claiming more threads will be scaled down.
Job stats:
job      count
-----  -------
gen_Z        1
plot         1
total        2

Select jobs to execute...
Execute 1 jobs...
[Thu Aug 28 13:42:54 2025]
localrule gen_Z:
    input: data/HP35_macro/input/config.yml
    output: data/HP35_macro/results/t/Z.npy
    jobid: 1
    reason: Updated input files: data/HP35_macro/input/config.yml
    wildcards: system=HP35_macro, lumping=t
    resources: tmpdir=/tmp
Shell command: python -m MPP.run data/HP35_macro/input/config.yml T none -Z data/HP35_macro/results/t/Z.npy
Activating conda environment: mpp
Moving output file data/HP35_macro/results/t/Z.npy to cache.
Symlinking output file data/HP35_macro/results/t/Z.npy from cache.
[Thu Aug 28 13:43:02 2025]
Finished jobid: 1 (Rule: gen_Z)
1 of 2 steps (50%) done
Select jobs to execute...
Execute 1 jobs...
[Thu Aug 28 13:43:02 2025]
localrule plot:
    input: data/HP35_macro/input/config.yml, data/HP35_macro/results/t/Z.npy
    output: data/HP35_macro/results/t/dendrogram.pdf
    jobid: 0
    reason: Input files updated by another job: data/HP35_macro/results/t/Z.npy
    wildcards: system=HP35_macro, lumping=t, plot=dendrogram, extension=pdf
    resources: tmpdir=/tmp
Shell command: python -m MPP.run data/HP35_macro/input/config.yml T none -Z data/HP35_macro/results/t/Z.npy -p dendrogram -o data/HP35_macro/results/t/dendrogram.pdf
Activating conda environment: mpp
[Thu Aug 28 13:43:10 2025]
Finished jobid: 0 (Rule: plot)
2 of 2 steps (100%) done
Complete log(s): /data/evaluation/MPP/stochastic_MPP_Felix/tools/MPP/.snakemake/log/2025-08-28T134254.000519.snakemake.log
