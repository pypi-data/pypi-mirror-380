"""Plan execution engine for the AI terminal."""

from __future__ import annotations

import subprocess
import sys
from dataclasses import dataclass
from typing import Callable, List, Optional

from .llm_client import LLMClient, PlanStep


@dataclass
class StepResult:
    """Outcome of executing a single step."""

    step: PlanStep
    success: bool
    stdout: str
    stderr: str


class PlanExecutor:
    """Executes plans generated by the LLM client with recovery support."""

    def __init__(
        self,
        llm_client: LLMClient,
        *,
        confirm_callback: Optional[Callable[[PlanStep], bool]] = None,
        output_callback: Optional[Callable[[StepResult], None]] = None,
        auto_fix: bool = True,
        max_fix_attempts: int = 3,
    ) -> None:
        self.llm = llm_client
        self.confirm_callback = confirm_callback
        self.output_callback = output_callback
        self.auto_fix = auto_fix
        self.max_fix_attempts = max_fix_attempts

    def execute_request(self, request: str) -> List[StepResult]:
        plan = self.llm.generate_plan(request)
        if not plan:
            print("⚠️  Unable to generate plan for the request.")
            return []

        print("📋 Planned steps:")
        for step in plan:
            print(f"  {step.step}. {step.description or step.command}")

        executed_results: List[StepResult] = []

        for step in plan:
            if self.confirm_callback and not self.confirm_callback(step):
                print(f"⏭️  Skipping step {step.step} per user choice.")
                continue

            result = self._run_command(step)
            executed_results.append(result)

            if self.output_callback:
                self.output_callback(result)

            if not result.success and self.auto_fix:
                print(f"⚠️  Step {step.step} failed. Attempting recovery...")
                recovered = self._attempt_recovery(
                    failed_step=step,
                    error_output=result.stderr,
                    executed_steps=[r.step for r in executed_results if r.success],
                )
                if recovered:
                    print("✅ Recovery succeeded. Resuming plan.")
                    executed_results.extend(recovered)
                    continue

                print("❌ Recovery failed. Aborting remaining steps.")
                break

        return executed_results

    # ------------------------------------------------------------------
    # Internal helpers
    # ------------------------------------------------------------------
    def _run_command(self, step: PlanStep) -> StepResult:
        print(f"🔧 Running step {step.step}: {step.command}")
        try:
            process = subprocess.run(
                step.command,
                shell=True,
                check=False,
                stdout=subprocess.PIPE,
                stderr=subprocess.PIPE,
                text=True,
            )
        except Exception as exc:  # noqa: BLE001
            stderr = f"Command execution failed: {exc}"
            return StepResult(step=step, success=False, stdout="", stderr=stderr)

        stdout = process.stdout.strip()
        stderr = process.stderr.strip()
        success = process.returncode == 0

        if success:
            print(f"✅ Step {step.step} completed successfully.")
        else:
            print(f"❌ Step {step.step} failed with code {process.returncode}.")
        if stdout:
            print(f"📄 STDOUT:\n{stdout}")
        if stderr:
            print(f"⚠️  STDERR:\n{stderr}")

        return StepResult(step=step, success=success, stdout=stdout, stderr=stderr)

    def _attempt_recovery(
        self,
        *,
        failed_step: PlanStep,
        error_output: str,
        executed_steps: List[PlanStep],
    ) -> List[StepResult]:
        fix_attempt = 0
        recovery_results: List[StepResult] = []

        while fix_attempt < self.max_fix_attempts:
            fix_attempt += 1
            print(f"🔁 Fix attempt {fix_attempt}...")
            fixes = self.llm.suggest_fix(
                failed_step=failed_step,
                error_output=error_output,
                executed_steps=executed_steps,
            )

            if not fixes:
                print("⚠️  LLM did not provide recovery steps.")
                break

            for fix_step in fixes:
                if self.confirm_callback and not self.confirm_callback(fix_step):
                    print(f"⏭️  Skipping fix step {fix_step.step} per user choice.")
                    continue

                result = self._run_command(fix_step)
                recovery_results.append(result)
                if self.output_callback:
                    self.output_callback(result)

                if not result.success:
                    print("⚠️  Fix step failed; requesting another attempt.")
                    break
            else:
                # all fix steps succeeded
                retry_result = self._run_command(failed_step)
                recovery_results.append(retry_result)
                if self.output_callback:
                    self.output_callback(retry_result)
                if retry_result.success:
                    return recovery_results
                error_output = retry_result.stderr
                print("⚠️  Retry failed; will ask for another fix plan.")
                continue

            # If we exited the for-loop due to failure, loop to ask LLM again

        return recovery_results

