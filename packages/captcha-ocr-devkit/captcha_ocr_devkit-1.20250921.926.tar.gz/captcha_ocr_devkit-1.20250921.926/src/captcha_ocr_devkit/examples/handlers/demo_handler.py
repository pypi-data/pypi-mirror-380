"""
Demo Handler ç¯„ä¾‹

ç´” random å¯¦ä½œï¼Œå®Œå…¨ä¸ä¾è³´ç¬¬ä¸‰æ–¹åº«ï¼Œé©åˆï¼š
- å¿«é€Ÿç†è§£ Handler æ¦‚å¿µ
- æ•™å­¸å’Œæ¼”ç¤ºç”¨é€”
- ç³»çµ±åŠŸèƒ½æ¸¬è©¦
- æ–°æ‰‹å…¥é–€ç¯„ä¾‹

é€™å€‹ç¯„ä¾‹å±•ç¤ºäº†å¦‚ä½•ç”¨æœ€ç°¡å–®çš„æ–¹å¼å¯¦ä½œæ‰€æœ‰å››ç¨® Handler
"""

import json
import time
import random
import string
from pathlib import Path
from typing import Any, List, Union

from captcha_ocr_devkit.core.handlers.base import (
    BasePreprocessHandler,
    BaseTrainHandler,
    BaseEvaluateHandler,
    BaseOCRHandler,
    HandlerResult,
    TrainingConfig,
    EvaluationResult
)


class DemoPreprocessHandler(BasePreprocessHandler):
    HANDLER_ID = "demo_preprocess"
    """
    Demo åœ–ç‰‡é è™•ç† Handler

    ç”¨ random æ¨¡æ“¬åœ–ç‰‡è™•ç†æ•ˆæœ
    """

    def process(self, image_data: Union[bytes, str, Path]) -> HandlerResult:
        """æ¨¡æ“¬åœ–ç‰‡é è™•ç†"""
        start_time = time.time()

        # æ¨¡æ“¬è™•ç†æ™‚é–“
        processing_delay = random.uniform(0.01, 0.05)
        time.sleep(processing_delay)

        # æ¨¡æ“¬è™•ç†æ•ˆæœ
        original_size = (random.randint(100, 200), random.randint(50, 100))
        processed_size = (128, 64)  # æ¨™æº–åŒ–å°ºå¯¸

        # æ¨¡æ“¬è™•ç†æ­¥é©Ÿ
        processing_steps = []
        if random.random() > 0.5:
            processing_steps.append("noise_reduction")
        if random.random() > 0.5:
            processing_steps.append("contrast_enhancement")
        if random.random() > 0.3:
            processing_steps.append("resized")

        processing_time = time.time() - start_time

        return HandlerResult(
            success=True,
            data=f"processed_image_data_{random.randint(1000, 9999)}",
            metadata={
                "original_size": f"{original_size[0]}x{original_size[1]}",
                "processed_size": f"{processed_size[0]}x{processed_size[1]}",
                "processing_steps": processing_steps,
                "processing_time": processing_time,
                "demo_mode": True
            }
        )

    def get_supported_formats(self) -> List[str]:
        return [".png", ".jpg", ".jpeg", ".bmp", ".gif", ".webp"]

    def get_info(self):
        return {
            "name": self.name,
            "handler_id": self.HANDLER_ID,
            "version": "1.0.0",
            "description": "Demo åœ–ç‰‡é è™•ç†ï¼Œç´” random æ¨¡æ“¬",
            "dependencies": [],
            "demo_mode": True
        }


class DemoTrainHandler(BaseTrainHandler):
    HANDLER_ID = "demo_train"
    """
    Demo è¨“ç·´ Handler

    ç”¨ random æ¨¡æ“¬è¨“ç·´éç¨‹å’Œçµæœ
    """

    def train(self, config: TrainingConfig) -> HandlerResult:
        """æ¨¡æ“¬è¨“ç·´éç¨‹"""
        print(f"ğŸ¯ Demo è¨“ç·´é–‹å§‹ï¼")
        print(f"ğŸ“‚ è¼¸å…¥ç›®éŒ„: {config.input_dir}")
        print(f"ğŸ’¾ è¼¸å‡ºè·¯å¾‘: {config.output_path}")
        print(f"ğŸ² Demo æ¨¡å¼: ç´” random æ¨¡æ“¬")

        start_time = time.time()

        # æª¢æŸ¥è¼¸å…¥ç›®éŒ„
        if not config.input_dir.exists():
            return HandlerResult(
                success=False,
                error=f"è¼¸å…¥ç›®éŒ„ä¸å­˜åœ¨: {config.input_dir}"
            )

        # æ¨¡æ“¬å°‹æ‰¾åœ–ç‰‡
        image_files = list(config.input_dir.glob("*.png")) + list(config.input_dir.glob("*.jpg"))
        total_images = len(image_files) if image_files else random.randint(50, 500)

        print(f"ğŸ–¼ï¸  æ¨¡æ“¬è™•ç† {total_images} å¼µåœ–ç‰‡")

        # è§£ææ¨™ç±¤ï¼ˆå¦‚æœæœ‰å¯¦éš›æª”æ¡ˆï¼‰
        if image_files:
            labels = self.parse_labels_from_filenames(image_files)
            unique_labels = set(labels)
        else:
            # æ¨¡æ“¬æ¨™ç±¤
            unique_labels = set()
            for _ in range(random.randint(10, 50)):
                label_length = random.randint(3, 6)
                label = ''.join(random.choices(string.ascii_lowercase + string.digits, k=label_length))
                unique_labels.add(label)

        print(f"ğŸ·ï¸  ç™¼ç¾ {len(unique_labels)} å€‹ä¸åŒæ¨™ç±¤")

        # æ¨¡æ“¬è¨“ç·´é€²åº¦
        total_epochs = min(config.epochs, 10)  # æœ€å¤šé¡¯ç¤º 10 å€‹ epochs
        for epoch in range(total_epochs):
            # æ¨¡æ“¬è¨“ç·´æ™‚é–“
            time.sleep(random.uniform(0.05, 0.15))

            # æ¨¡æ“¬ loss ä¸‹é™
            loss = max(0.01, 1.0 - (epoch / total_epochs) + random.uniform(-0.1, 0.1))

            if epoch % max(1, total_epochs // 5) == 0:
                print(f"  Epoch {epoch + 1}/{config.epochs} - Loss: {loss:.4f} (æ¨¡æ“¬)")

        # å‰µå»ºæ¨¡æ“¬æ¨¡å‹è³‡æ–™
        model_data = {
            "model_type": "demo_random",
            "demo_mode": True,
            "training_config": {
                "epochs": config.epochs,
                "batch_size": config.batch_size,
                "learning_rate": config.learning_rate,
                "validation_split": config.validation_split
            },
            "dataset_info": {
                "total_images": total_images,
                "unique_labels": len(unique_labels),
                "sample_labels": list(unique_labels)[:10],  # ä¿å­˜å‰ 10 å€‹ä½œç‚ºç¤ºä¾‹
                "alphabet": string.ascii_lowercase + string.digits
            },
            "model_performance": {
                "final_loss": random.uniform(0.01, 0.1),
                "validation_accuracy": random.uniform(0.85, 0.98),
                "training_accuracy": random.uniform(0.90, 0.99)
            },
            "training_time": time.time() - start_time,
            "timestamp": time.time()
        }

        # ä¿å­˜æ¨¡å‹
        success = self.save_model(model_data, config.output_path)
        if not success:
            return HandlerResult(
                success=False,
                error="æ¨¡å‹ä¿å­˜å¤±æ•—"
            )

        training_time = time.time() - start_time
        print(f"âœ… Demo è¨“ç·´å®Œæˆ! è€—æ™‚: {training_time:.2f}s")
        print(f"ğŸ² æ¨¡æ“¬æº–ç¢ºç‡: {model_data['model_performance']['validation_accuracy']:.4f}")

        return HandlerResult(
            success=True,
            data={
                "model_path": str(config.output_path),
                "total_images": total_images,
                "unique_labels": len(unique_labels),
                "demo_mode": True
            },
            metadata={
                "training_time": training_time,
                "epochs_completed": config.epochs,
                "dataset_size": total_images,
                "model_performance": model_data["model_performance"]
            }
        )

    def save_model(self, model_data: Any, output_path: Path) -> bool:
        """ä¿å­˜æ¨¡æ“¬æ¨¡å‹åˆ° JSON æª”æ¡ˆ"""
        try:
            output_path.parent.mkdir(parents=True, exist_ok=True)

            # å¦‚æœæ²’æœ‰å‰¯æª”åï¼ŒåŠ ä¸Š .json
            if not output_path.suffix:
                output_path = output_path.with_suffix('.json')

            with open(output_path, 'w', encoding='utf-8') as f:
                json.dump(model_data, f, indent=2, ensure_ascii=False, default=str)

            return True
        except Exception as e:
            print(f"ä¿å­˜æ¨¡å‹å¤±æ•—: {e}")
            return False

    def load_model(self, model_path: Path) -> Any:
        """è¼‰å…¥æ¨¡æ“¬æ¨¡å‹"""
        try:
            with open(model_path, 'r', encoding='utf-8') as f:
                return json.load(f)
        except Exception as e:
            print(f"è¼‰å…¥æ¨¡å‹å¤±æ•—: {e}")
            return None

    def get_info(self):
        return {
            "name": self.name,
            "handler_id": self.HANDLER_ID,
            "version": "1.0.0",
            "description": "Demo è¨“ç·´ï¼Œç´” random æ¨¡æ“¬è¨“ç·´éç¨‹",
            "dependencies": [],
            "demo_mode": True
        }


class DemoEvaluateHandler(BaseEvaluateHandler):
    HANDLER_ID = "demo_evaluate"
    """
    Demo è©•ä¼° Handler

    ç”¨ random æ¨¡æ“¬è©•ä¼°éç¨‹å’Œçµæœ
    """

    def evaluate(self, model_path: Path, test_data_path: Path) -> HandlerResult:
        """æ¨¡æ“¬è©•ä¼°éç¨‹"""
        print(f"ğŸ“Š Demo è©•ä¼°é–‹å§‹ï¼")
        print(f"ğŸ¤– æ¨¡å‹: {model_path}")
        print(f"ğŸ“‚ æ¸¬è©¦è³‡æ–™: {test_data_path}")
        print(f"ğŸ² Demo æ¨¡å¼: ç´” random æ¨¡æ“¬")

        start_time = time.time()

        # æª¢æŸ¥æª”æ¡ˆå­˜åœ¨
        if not model_path.exists():
            return HandlerResult(
                success=False,
                error=f"æ¨¡å‹æª”æ¡ˆä¸å­˜åœ¨: {model_path}"
            )

        if not test_data_path.exists():
            return HandlerResult(
                success=False,
                error=f"æ¸¬è©¦è³‡æ–™ç›®éŒ„ä¸å­˜åœ¨: {test_data_path}"
            )

        # è¼‰å…¥æ¨¡å‹
        model_data = self.load_model(model_path)
        if model_data is None:
            return HandlerResult(
                success=False,
                error="æ¨¡å‹è¼‰å…¥å¤±æ•—"
            )

        # æª¢æŸ¥æ¸¬è©¦åœ–ç‰‡
        test_images = list(test_data_path.glob("*.png")) + list(test_data_path.glob("*.jpg"))
        total_samples = len(test_images) if test_images else random.randint(20, 200)

        print(f"ğŸ–¼ï¸  æ¨¡æ“¬è©•ä¼° {total_samples} å¼µåœ–ç‰‡")

        # è§£ææ¨™ç±¤
        if test_images:
            labels = self.parse_labels_from_filenames(test_images)
        else:
            # æ¨¡æ“¬æ¨™ç±¤
            alphabet = model_data.get("dataset_info", {}).get("alphabet", string.ascii_lowercase + string.digits)
            labels = []
            for _ in range(total_samples):
                label_length = random.randint(3, 6)
                label = ''.join(random.choices(alphabet, k=label_length))
                labels.append(label)

        # æ¨¡æ“¬é æ¸¬çµæœ
        predictions = []
        base_accuracy = model_data.get("model_performance", {}).get("validation_accuracy", 0.85)

        for label in labels:
            # æ¨¡æ“¬è©•ä¼°æ™‚é–“
            if len(predictions) % 10 == 0:
                time.sleep(0.01)

            # æ ¹æ“šæ¨¡å‹æ€§èƒ½æ¨¡æ“¬é æ¸¬æº–ç¢ºç‡
            if random.random() < base_accuracy:
                predictions.append(label)  # æ­£ç¢ºé æ¸¬
            else:
                # éš¨æ©ŸéŒ¯èª¤é æ¸¬
                alphabet = string.ascii_lowercase + string.digits
                wrong_pred = ''.join(random.choices(alphabet, k=len(label)))
                predictions.append(wrong_pred)

        # è¨ˆç®—æŒ‡æ¨™
        eval_result = self.calculate_metrics(predictions, labels)

        evaluation_time = time.time() - start_time
        print(f"âœ… Demo è©•ä¼°å®Œæˆ! è€—æ™‚: {evaluation_time:.2f}s")
        print(f"ğŸ¯ æ¨¡æ“¬æº–ç¢ºç‡: {eval_result.accuracy:.4f}")
        print(f"ğŸ”¤ å­—å…ƒæº–ç¢ºç‡: {eval_result.character_accuracy:.4f}")

        return HandlerResult(
            success=True,
            data=eval_result,
            metadata={
                "evaluation_time": evaluation_time,
                "model_info": model_data.get("model_type", "unknown"),
                "demo_mode": True
            }
        )

    def calculate_metrics(self, predictions: List[str], ground_truth: List[str]) -> EvaluationResult:
        """è¨ˆç®—è©•ä¼°æŒ‡æ¨™"""
        total = len(predictions)
        if total == 0:
            return EvaluationResult(
                accuracy=0.0,
                total_samples=0,
                correct_predictions=0,
                character_accuracy=0.0
            )

        # å®Œæ•´åŒ¹é…æº–ç¢ºç‡
        correct = sum(1 for p, g in zip(predictions, ground_truth) if p == g)
        accuracy = correct / total

        # å­—å…ƒç´šæº–ç¢ºç‡
        total_chars = 0
        correct_chars = 0

        for pred, true in zip(predictions, ground_truth):
            min_len = min(len(pred), len(true))
            max_len = max(len(pred), len(true))
            total_chars += max_len

            # è¨ˆç®—æ­£ç¢ºçš„å­—å…ƒæ•¸
            for i in range(min_len):
                if pred[i] == true[i]:
                    correct_chars += 1

        char_accuracy = correct_chars / total_chars if total_chars > 0 else 0.0

        return EvaluationResult(
            accuracy=accuracy,
            total_samples=total,
            correct_predictions=correct,
            character_accuracy=char_accuracy
        )

    def load_model(self, model_path: Path) -> Any:
        """è¼‰å…¥æ¨¡å‹"""
        try:
            with open(model_path, 'r', encoding='utf-8') as f:
                return json.load(f)
        except Exception as e:
            print(f"è¼‰å…¥æ¨¡å‹å¤±æ•—: {e}")
            return None

    def parse_labels_from_filenames(self, image_paths: List[Path]) -> List[str]:
        """å¾æª”åè§£ææ¨™ç±¤"""
        labels = []
        for path in image_paths:
            filename = path.stem  # ç§»é™¤å‰¯æª”å
            label = filename.split('_')[0]  # ä»¥åº•ç·šåˆ†å‰²ï¼Œå–ç¬¬ä¸€éƒ¨åˆ†
            labels.append(label)
        return labels

    def get_info(self):
        return {
            "name": self.name,
            "handler_id": self.HANDLER_ID,
            "version": "1.0.0",
            "description": "Demo è©•ä¼°ï¼Œç´” random æ¨¡æ“¬è©•ä¼°éç¨‹",
            "dependencies": [],
            "demo_mode": True
        }


class DemoOCRHandler(BaseOCRHandler):
    HANDLER_ID = "demo_ocr"
    """
    Demo OCR Handler

    ç”¨ random æ¨¡æ“¬ OCR è­˜åˆ¥
    """

    def __init__(self, name: str, config=None):
        super().__init__(name, config)
        self.model_data = None
        self.alphabet = string.ascii_lowercase + string.digits

    def predict(self, processed_image: Any) -> HandlerResult:
        """æ¨¡æ“¬ OCR é æ¸¬"""
        start_time = time.time()

        # æ¨¡æ“¬è™•ç†æ™‚é–“
        processing_delay = random.uniform(0.02, 0.08)
        time.sleep(processing_delay)

        # æ ¹æ“šè¼‰å…¥çš„æ¨¡å‹æ±ºå®šé æ¸¬ç­–ç•¥
        if self.model_data:
            # ä½¿ç”¨æ¨¡å‹ä¸­çš„å­—æ¯è¡¨
            alphabet = self.model_data.get("dataset_info", {}).get("alphabet", self.alphabet)
            base_accuracy = self.model_data.get("model_performance", {}).get("validation_accuracy", 0.85)

            # å¾æ¨£æœ¬æ¨™ç±¤ä¸­éš¨æ©Ÿé¸æ“‡ä¸€å€‹ä½œç‚º"è­˜åˆ¥çµæœ"
            sample_labels = self.model_data.get("dataset_info", {}).get("sample_labels", [])
            if sample_labels and random.random() < base_accuracy:
                # é«˜æ©Ÿç‡è¿”å›è¨“ç·´éçš„æ¨™ç±¤
                predicted_text = random.choice(sample_labels)
            else:
                # éš¨æ©Ÿç”Ÿæˆ
                text_length = random.randint(3, 6)
                predicted_text = ''.join(random.choices(alphabet, k=text_length))
        else:
            # æ²’æœ‰æ¨¡å‹æ™‚ç´”éš¨æ©Ÿ
            text_length = random.randint(3, 6)
            predicted_text = ''.join(random.choices(self.alphabet, k=text_length))
            base_accuracy = 0.5

        # æ¨¡æ“¬ä¿¡å¿ƒåº¦ï¼ˆåŸºæ–¼æ¨¡å‹æ€§èƒ½ï¼‰
        confidence = min(0.99, max(0.1, base_accuracy + random.uniform(-0.15, 0.15)))

        processing_time = time.time() - start_time

        return HandlerResult(
            success=True,
            data=predicted_text,
            metadata={
                "confidence": confidence,
                "processing_time": processing_time,
                "model_type": "demo_random",
                "demo_mode": True,
                "alphabet_used": len(self.alphabet),
                "text_length": len(predicted_text)
            }
        )

    def load_model(self, model_path: Path) -> bool:
        """è¼‰å…¥ Demo æ¨¡å‹"""
        try:
            print(f"ğŸ¤– è¼‰å…¥ Demo æ¨¡å‹: {model_path}")

            if not model_path.exists():
                print(f"âš ï¸  æ¨¡å‹æª”æ¡ˆä¸å­˜åœ¨: {model_path}")
                return False

            # è¼‰å…¥æ¨¡å‹è³‡æ–™
            with open(model_path, 'r', encoding='utf-8') as f:
                self.model_data = json.load(f)

            # æ›´æ–°å­—æ¯è¡¨
            if "dataset_info" in self.model_data and "alphabet" in self.model_data["dataset_info"]:
                self.alphabet = self.model_data["dataset_info"]["alphabet"]

            print(f"âœ… Demo æ¨¡å‹è¼‰å…¥æˆåŠŸ")
            if self.model_data and "model_performance" in self.model_data:
                performance = self.model_data["model_performance"]
                print(f"ğŸ“Š æ¨¡å‹æ€§èƒ½: {performance.get('validation_accuracy', 0):.4f}")

            return True

        except Exception as e:
            print(f"âŒ Demo æ¨¡å‹è¼‰å…¥å¤±æ•—: {e}")
            return False

    def get_info(self):
        info = {
            "name": self.name,
            "handler_id": self.HANDLER_ID,
            "version": "1.0.0",
            "description": "Demo OCRï¼Œç´” random æ¨¡æ“¬è­˜åˆ¥",
            "dependencies": [],
            "demo_mode": True,
            "model_loaded": self.model_data is not None,
            "alphabet_size": len(self.alphabet)
        }

        if self.model_data:
            info["model_info"] = {
                "type": self.model_data.get("model_type", "unknown"),
                "training_time": self.model_data.get("training_time", 0),
                "sample_count": self.model_data.get("dataset_info", {}).get("total_images", 0)
            }

        return info


# ä¾¿åˆ©å‡½æ•¸ï¼šæª¢æŸ¥ Demo Handler å¯ç”¨æ€§
def check_demo_handlers():
    """æª¢æŸ¥ Demo Handlers å¯ç”¨æ€§"""
    print("ğŸ¯ Demo Handlers ç‹€æ…‹æª¢æŸ¥")
    print("âœ… demo_preprocess (DemoPreprocessHandler) - ç´” Pythonï¼Œç„¡ä¾è³´")
    print("âœ… demo_train (DemoTrainHandler) - ç´” Pythonï¼Œç„¡ä¾è³´")
    print("âœ… demo_evaluate (DemoEvaluateHandler) - ç´” Pythonï¼Œç„¡ä¾è³´")
    print("âœ… demo_ocr (DemoOCRHandler) - ç´” Pythonï¼Œç„¡ä¾è³´")
    print("ğŸ² æ‰€æœ‰åŠŸèƒ½éƒ½æ˜¯ random æ¨¡æ“¬ï¼Œé©åˆæ•™å­¸å’Œæ¸¬è©¦")
    return True


if __name__ == '__main__':
    # ç°¡å–®æ¸¬è©¦
    check_demo_handlers()

    # æ¸¬è©¦å‰µå»º handlers
    try:
        preprocess = DemoPreprocessHandler('demo_preprocess')
        train = DemoTrainHandler('demo_train')
        evaluate = DemoEvaluateHandler('demo_evaluate')
        ocr = DemoOCRHandler('demo_ocr')

        print("\nğŸ‰ æ‰€æœ‰ Demo Handlers å‰µå»ºæˆåŠŸï¼")
        print(f"ğŸ“ Preprocess: {preprocess.get_info()['description']}")
        print(f"ğŸ‹ï¸  Train: {train.get_info()['description']}")
        print(f"ğŸ“Š Evaluate: {evaluate.get_info()['description']}")
        print(f"ğŸ‘ï¸  OCR: {ocr.get_info()['description']}")

    except Exception as e:
        print(f"âŒ æ¸¬è©¦å¤±æ•—: {e}")
