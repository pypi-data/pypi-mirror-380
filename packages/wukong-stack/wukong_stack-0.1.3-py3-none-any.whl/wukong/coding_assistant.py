import os
import re
from typing import List, TypedDict, Annotated
from langchain_core.messages import AnyMessage, SystemMessage, HumanMessage, ToolMessage
from langchain_core.prompts import ChatPromptTemplate
from langchain_community.tools.tavily_search import TavilySearchResults
from langchain_openai import ChatOpenAI
from langgraph.graph import StateGraph, END
from langgraph.checkpoint.sqlite import SqliteSaver
from dotenv import load_dotenv

# Load environment variables from .env file
load_dotenv()

# --- 1. Define Tools and State ---

# Initialize the web search tool
web_search_tool = TavilySearchResults(max_results=3)
tools = [web_search_tool]

# The State class defines the structure of data that flows through the graph
class AgentState(TypedDict):
    messages: Annotated[list[AnyMessage], lambda x, y: x + y]
    code_snippet: str
    file_path: str

# --- 2. Setup Local LLM Connection ---

# Point to the local server from LM Studio
local_llm = ChatOpenAI(
    base_url="http://localhost:1234/v1",
    api_key="not-needed", # API key is not needed for local server
    temperature=0.2,
    model_name="local-model" # Model name can be anything
)

# Bind the tools to the LLM so it knows when to use them
llm_with_tools = local_llm.bind_tools(tools)

# --- 3. Define Agent Nodes ---

def coder_agent(state: AgentState):
    """
    The primary agent that generates or refines code based on the current state.
    It can decide to use the web search tool if it lacks information.
    """
    print("--- ðŸ‘¨â€ðŸ’» CALLING CODER AGENT ---")
    
    # Create a prompt that includes system instructions and the current conversation history
    prompt = ChatPromptTemplate.from_messages([
        ("system", "You are a senior software engineer. Your task is to write clean, efficient Python code based on the user's request. "
                   "If you don't know how to solve a problem or need examples, use the 'tavily_search_results_json' tool to search the web. "
                   "Generate only the code block in your response, without any introductory text."),
        ("placeholder", "{messages}")
    ])
    
    chain = prompt | llm_with_tools
    response = chain.invoke({"messages": state["messages"]})
    
    # Check if the LLM decided to use a tool
    if response.tool_calls:
        print("Coder decided to search the web.")
        return {"messages": [response]}
        
    # Extract the code from the LLM's response
    code = ""
    if response.content and "```" in response.content:
        code_match = re.search(r'```(?:python\n)?(.*?)```', response.content, re.DOTALL)
        if code_match:
            code = code_match.group(1).strip()
    
    print("Coder generated code snippet.")
    return {"messages": [response], "code_snippet": code}

def reviewer_agent(state: AgentState):
    """
    This agent reviews the code generated by the coder_agent for quality and correctness.
    It provides feedback for revision or approves the code.
    """
    print("--- ðŸ•µï¸ CALLING REVIEWER AGENT ---")
    review_prompt = ChatPromptTemplate.from_messages([
        ("system", "You are a code reviewer. Your task is to analyze the provided Python code snippet. "
                   "Check for bugs, style errors, and adherence to the original request. "
                   "If the code is good, respond with ONLY the word 'APPROVED'. "
                   "If it needs changes, respond with 'REJECTED' followed by a colon and concise, actionable feedback."),
        ("human", f"Original Request: {state['messages'][0].content}\n\nCode to Review:\n```python\n{state['code_snippet']}```")
    ])
    
    chain = review_prompt | local_llm
    review_response = chain.invoke({})
    
    print(f"Reviewer Feedback: {review_response.content}")
    return {"messages": [review_response]}

def web_search_agent(state: AgentState):
    """

    This agent executes the web search tool call initiated by the coder_agent.
    """
    print("--- ðŸŒ CALLING WEB SEARCH AGENT ---")
    tool_messages = []
    # The last message should be the tool call from the coder
    last_message = state["messages"][-1]
    
    for tool_call in last_message.tool_calls:
        # Execute the tool and get the result
        result = web_search_tool.invoke(tool_call["args"])
        tool_messages.append(ToolMessage(content=str(result), tool_call_id=tool_call["id"]))
        
    return {"messages": tool_messages}

def file_saver_agent(state: AgentState):
    """
    This agent saves the approved code to a file.
    """
    print("--- ðŸ’¾ CALLING FILE SAVER AGENT ---")
    file_path = state.get("file_path")
    if not file_path:
        return {"messages": [SystemMessage(content="Error: File path not provided.")]}
    
    try:
        with open(file_path, "w") as f:
            f.write(state["code_snippet"])
        success_message = f"Success! Code saved to '{file_path}'"
        print(success_message)
        return {"messages": [SystemMessage(content=success_message)]}
    except Exception as e:
        error_message = f"Error: Failed to save file. {str(e)}"
        print(error_message)
        return {"messages": [SystemMessage(content=error_message)]}

# --- 4. Define Graph Logic (Conditional Edges) ---

def should_continue_from_coder(state: AgentState) -> str:
    """
    Determines the next step after the coder agent runs.
    - If tool call exists: go to web_search_agent.
    - If code is generated: go to reviewer_agent.
    - Otherwise: end the process.
    """
    if state["messages"][-1].tool_calls:
        return "web_search"
    elif state.get("code_snippet"):
        return "review"
    else:
        return END

def should_continue_from_review(state: AgentState) -> str:
    """
    Determines the next step after the review.
    - If 'APPROVED': the code is good, present to user (end this run).
    - If 'REJECTED': go back to the coder for revisions.
    """
    last_message_content = state["messages"][-1].content
    if last_message_content.strip().upper().startswith("APPROVED"):
        print("âœ… Code Approved!")
        return END
    else:
        print("âŒ Code Rejected. Returning to Coder for revision.")
        return "coder"

# --- 5. Build the Graph ---

# Using an in-memory checkpoint saver for simplicity
memory = SqliteSaver.from_conn_string(":memory:")

workflow = StateGraph(AgentState)

# Add the nodes to the graph
workflow.add_node("coder", coder_agent)
workflow.add_node("review", reviewer_agent)
workflow.add_node("web_search", web_search_agent)
workflow.add_node("file_saver", file_saver_agent)

# Set the entry point
workflow.set_entry_point("coder")

# Add edges connecting the nodes
workflow.add_edge("web_search", "coder")
workflow.add_conditional_edges("coder", should_continue_from_coder, {"review": "review", "web_search": "web_search"})
workflow.add_conditional_edges("review", should_continue_from_review, {"coder": "coder", END: END})
workflow.add_edge("file_saver", END) # The file saver is a terminal node for its specific task

# Compile the graph into a runnable app
app = workflow.compile(checkpointer=memory)

# --- 6. Main Interaction Loop ---

def main():
    """The main loop to interact with the user."""
    config = {"configurable": {"thread_id": "coding-assistant-thread"}}
    
    while True:
        user_input = input("\nðŸ‘¤ You: ")
        if user_input.lower() in ["quit", "exit"]:
            print("ðŸ¤– Assistant: Goodbye!")
            break
            
        # Check for the "save" command
        if user_input.lower().startswith("save"):
            current_state = app.get_state(config)
            if not current_state or not current_state.values.get("code_snippet"):
                print("ðŸ¤– Assistant: There is no code to save yet. Please generate some code first.")
                continue

            parts = user_input.split(maxsplit=1)
            file_path = ""
            if len(parts) > 1:
                file_path = parts[1]
            else:
                while not file_path:
                    file_path = input("ðŸ¤– Assistant: Please provide a file path and name (e.g., 'app/main.py'): ")
            
            # Run the file saver agent directly
            app.invoke({"messages": [], "file_path": file_path}, config=config, tool_choice="file_saver")
            continue

        # Invoke the main coding/review workflow
        events = app.stream({"messages": [HumanMessage(content=user_input)]}, config=config, stream_mode="values")
        
        final_state = None
        for event in events:
            final_state = event

        if final_state and final_state.get("code_snippet"):
            print("\n--- âœ… Final Approved Code ---")
            print(final_state["code_snippet"])
            print("--------------------------")
            print("ðŸ¤– Assistant: What would you like to do next? You can ask for a revision or type 'save <filename.py>' to save the code.")

if __name__ == "__main__":
    main()