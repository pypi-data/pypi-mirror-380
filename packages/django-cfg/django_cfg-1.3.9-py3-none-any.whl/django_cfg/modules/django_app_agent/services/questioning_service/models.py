"""
Data Models for Intelligent Questioning Service.

This module defines the data structures used by the questioning service
for managing context-aware question generation and user interactions.
"""

from typing import List, Dict, Any, Optional
from pathlib import Path
from datetime import datetime, timezone

from pydantic import BaseModel, Field, ConfigDict

from ...models.requests import AppGenerationRequest
from ...models.context import ProjectContext


class QuestioningRequest(BaseModel):
    """Request for intelligent questioning session."""
    
    model_config = ConfigDict(extra='forbid', validate_assignment=True)
    
    user_intent: str = Field(description="User's stated intent or requirement")
    project_root: Path = Field(description="Root directory of the project")
    generation_request: Optional[AppGenerationRequest] = Field(default=None, description="Initial generation request")
    max_questions: int = Field(default=20, ge=1, le=30, description="Maximum number of questions to ask")
    focus_areas: List[str] = Field(default_factory=list, description="Areas to focus questioning on")


class ContextualQuestion(BaseModel):
    """Represents a context-aware question generated by AI agents."""
    
    model_config = ConfigDict(extra='forbid', validate_assignment=True)
    
    id: str = Field(description="Unique question identifier")
    text: str = Field(description="The question text")
    question_type: str = Field(description="Type of question (yes_no, choice, text, etc.)")
    priority: int = Field(ge=1, le=10, description="Question priority (1=highest, 10=lowest)")
    impact_level: str = Field(description="Impact level (low, medium, high, critical)")
    
    # Context information
    context_evidence: List[str] = Field(default_factory=list, description="Evidence from project analysis")
    architectural_implications: List[str] = Field(default_factory=list, description="Architectural implications")
    
    # Question options (for choice questions)
    options: Optional[List[str]] = Field(default=None, description="Available options for choice questions")
    default_value: Optional[str] = Field(default=None, description="Default/suggested value")
    
    # Metadata
    generated_by: str = Field(description="AI agent that generated this question")
    generation_reasoning: str = Field(description="Reasoning behind question generation")


class QuestionResponse(BaseModel):
    """User's response to a contextual question."""
    
    model_config = ConfigDict(extra='forbid', validate_assignment=True)
    
    question_id: str = Field(description="ID of the question being answered")
    answer: str = Field(description="User's answer")
    confidence: float = Field(ge=0.0, le=1.0, description="User's confidence in their answer")
    timestamp: datetime = Field(default_factory=lambda: datetime.now(timezone.utc))


class QuestioningSession(BaseModel):
    """Represents an active questioning session."""
    
    model_config = ConfigDict(extra='forbid', validate_assignment=True)
    
    session_id: str = Field(description="Unique session identifier")
    questions: List[ContextualQuestion] = Field(description="Generated questions")
    responses: List[QuestionResponse] = Field(default_factory=list, description="User responses")
    project_context: ProjectContext = Field(description="Project analysis context")
    
    # Session metadata
    created_at: datetime = Field(default_factory=lambda: datetime.now(timezone.utc))
    completed_at: Optional[datetime] = Field(default=None)
    user_intent: str = Field(description="Original user intent")
    
    # Progress tracking
    current_question_index: int = Field(default=0, description="Index of current question")
    is_completed: bool = Field(default=False, description="Whether session is completed")
    
    @property
    def completion_percentage(self) -> float:
        """Calculate completion percentage."""
        if not self.questions:
            return 0.0
        return len(self.responses) / len(self.questions) * 100
    
    @property
    def answered_questions(self) -> int:
        """Count of answered questions."""
        return len(self.responses)
    
    @property
    def remaining_questions(self) -> int:
        """Count of remaining questions."""
        return len(self.questions) - len(self.responses)


class QuestioningResult(BaseModel):
    """Result of intelligent questioning process."""
    
    model_config = ConfigDict(extra='forbid', validate_assignment=True)
    
    session: QuestioningSession = Field(description="Completed questioning session")
    refined_request: AppGenerationRequest = Field(description="Refined generation request based on answers")
    confidence_score: float = Field(ge=0.0, le=1.0, description="Confidence in the refined request")
    insights: Dict[str, Any] = Field(default_factory=dict, description="AI-generated insights from responses")
    recommendations: List[str] = Field(default_factory=list, description="Development recommendations")
