numpy
torch>2.6.0
transformers>=4.55.0
accelerate
flash-attn
