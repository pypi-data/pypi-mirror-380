Metadata-Version: 2.4
Name: nemo-curator
Version: 1.0.0
Summary: Scalable Data Preprocessing Tool for Training Large Language Models
Author-email: Ayush Dattagupta <adattagupta@nvidia.com>, Abhinav Garg <abhgarg@nvidia.com>, Praateek Mahajan <praateekm@nvidia.com>, Sarah Yurick <syurick@nvidia.com>, Vibhu Jawa <vjawa@nvidia.com>
Requires-Python: <3.13,>=3.10
Description-Content-Type: text/markdown
License-File: LICENSE
Requires-Dist: absl-py<3.0.0,>=2.0.0
Requires-Dist: comment_parser
Requires-Dist: cosmos-xenna==0.1.2
Requires-Dist: fsspec
Requires-Dist: jieba==0.42.1
Requires-Dist: loguru
Requires-Dist: mecab-python3
Requires-Dist: pandas>=2.1.0
Requires-Dist: pyarrow
Requires-Dist: ray[data,default]>=2.49
Requires-Dist: torch
Requires-Dist: transformers==4.55.2
Provides-Extra: cuda12
Requires-Dist: gpustat; extra == "cuda12"
Requires-Dist: pynvml; extra == "cuda12"
Provides-Extra: deduplication-cuda12
Requires-Dist: cudf-cu12==25.6.*; extra == "deduplication-cuda12"
Requires-Dist: cugraph-cu12==25.6.*; extra == "deduplication-cuda12"
Requires-Dist: cuml-cu12==25.6.*; extra == "deduplication-cuda12"
Requires-Dist: nx-cugraph-cu12==25.6.*; extra == "deduplication-cuda12"
Requires-Dist: pylibraft-cu12==25.6.*; extra == "deduplication-cuda12"
Requires-Dist: raft-dask-cu12==25.6.*; extra == "deduplication-cuda12"
Requires-Dist: rapidsmpf-cu12==25.6.*; extra == "deduplication-cuda12"
Provides-Extra: audio-cpu
Requires-Dist: nemo_toolkit[asr]==2.4.0; extra == "audio-cpu"
Provides-Extra: audio-cuda12
Requires-Dist: nemo_curator[audio_cpu]; extra == "audio-cuda12"
Requires-Dist: nemo_curator[cuda12]; extra == "audio-cuda12"
Provides-Extra: image-cpu
Requires-Dist: torchvision; extra == "image-cpu"
Provides-Extra: image-cuda12
Requires-Dist: nemo_curator[image_cpu]; extra == "image-cuda12"
Requires-Dist: nemo_curator[cuda12]; extra == "image-cuda12"
Requires-Dist: nemo_curator[deduplication_cuda12]; extra == "image-cuda12"
Requires-Dist: nvidia-dali-cuda120; extra == "image-cuda12"
Provides-Extra: text-cpu
Requires-Dist: beautifulsoup4; extra == "text-cpu"
Requires-Dist: justext; extra == "text-cpu"
Requires-Dist: lxml; extra == "text-cpu"
Requires-Dist: pycld2; extra == "text-cpu"
Requires-Dist: resiliparse; extra == "text-cpu"
Requires-Dist: s5cmd; extra == "text-cpu"
Requires-Dist: trafilatura==2.0.0; extra == "text-cpu"
Requires-Dist: warcio; extra == "text-cpu"
Requires-Dist: fasttext==0.9.3; extra == "text-cpu"
Requires-Dist: sentencepiece; extra == "text-cpu"
Requires-Dist: mwparserfromhell==0.6.5; extra == "text-cpu"
Requires-Dist: peft; extra == "text-cpu"
Requires-Dist: ftfy==6.1.1; extra == "text-cpu"
Provides-Extra: text-cuda12
Requires-Dist: nemo_curator[cuda12]; extra == "text-cuda12"
Requires-Dist: nemo_curator[deduplication_cuda12]; extra == "text-cuda12"
Requires-Dist: nemo_curator[text_cpu]; extra == "text-cuda12"
Provides-Extra: video-cpu
Requires-Dist: av==13.1.0; extra == "video-cpu"
Requires-Dist: opencv-python; extra == "video-cpu"
Requires-Dist: torchvision; extra == "video-cpu"
Requires-Dist: einops; extra == "video-cpu"
Requires-Dist: easydict; extra == "video-cpu"
Provides-Extra: video-cuda12
Requires-Dist: nemo_curator[video_cpu]; extra == "video-cuda12"
Requires-Dist: nemo_curator[cuda12]; extra == "video-cuda12"
Requires-Dist: cvcuda_cu12; extra == "video-cuda12"
Requires-Dist: flash-attn<=2.8.3; (platform_machine == "x86_64" and platform_system != "Darwin") and extra == "video-cuda12"
Requires-Dist: pycuda; extra == "video-cuda12"
Requires-Dist: PyNvVideoCodec==2.0.2; (platform_machine == "x86_64" and platform_system != "Darwin") and extra == "video-cuda12"
Requires-Dist: torch<=2.8.0; extra == "video-cuda12"
Requires-Dist: torchaudio; extra == "video-cuda12"
Requires-Dist: vllm==0.10.2; (platform_machine == "x86_64" and platform_system != "Darwin") and extra == "video-cuda12"
Provides-Extra: all
Requires-Dist: nemo_curator[audio_cuda12]; extra == "all"
Requires-Dist: nemo_curator[image_cuda12]; extra == "all"
Requires-Dist: nemo_curator[text_cuda12]; extra == "all"
Requires-Dist: nemo_curator[video_cuda12]; extra == "all"
Dynamic: license-file

<div align="center">

  <a href="https://github.com/NVIDIA-NeMo/Curator/blob/main/LICENSE">![https://pypi.org/project/nemo-curator](https://img.shields.io/github/license/NVIDIA-NeMo/Curator)</a>
  <a href="https://pypi.org/project/nemo-curator/">![https://pypi.org/project/nemo-curator/](https://img.shields.io/pypi/pyversions/nemo-curator.svg)</a>
  <a href="https://github.com/NVIDIA-NeMo/Curator/graphs/contributors">![NVIDIA-NeMo/Curator](https://img.shields.io/github/contributors/NVIDIA-NeMo/Curator)</a>
  <a href="https://github.com/NVIDIA-NeMo/Curator/releases">![https://github.com/NVIDIA-NeMo/Curator/releases](https://img.shields.io/github/release/NVIDIA-NeMo/Curator)</a>
  <a href="https://pypi.org/project/nemo-curator/">![https://github.com/Naereen/badges/](https://badgen.net/badge/open%20source/❤/blue?icon=github)</a>

</div>

# Accelerate Data Processing and Streamline Synthetic Data Generation with NVIDIA NeMo Curator

NeMo Curator, part of the NVIDIA NeMo software suite for managing the AI agent lifecycle, is a Python library specifically designed for fast and scalable data processing and curation for generative AI use cases such as foundation language model pretraining, text-to-image model training, domain-adaptive pretraining (DAPT), supervised fine-tuning (SFT) and parameter-efficient fine-tuning (PEFT).

It greatly accelerates data processing and curation by leveraging GPUs with [Dask](https://www.dask.org/) and [RAPIDS](https://developer.nvidia.com/rapids), resulting in significant time savings. The library provides a customizable and modular interface, simplifying pipeline expansion and accelerating model convergence through the preparation of high-quality tokens.

NeMo Curator also provides pre-built pipelines for synthetic data generation for customization and evaluation of generative AI systems. You can use any OpenAI API compatible model and plug it in NeMo Curator's synthetic data generation pipelines to process and curate high-quality synthetic data for various use cases.

## Getting Started

New to NeMo Curator? Start with our quickstart guides for hands-on experience:

- **[Text Curation Quickstart](https://docs.nvidia.com/nemo/curator/latest/get-started/text.html)** - Set up your environment and run your first text curation pipeline in under 30 minutes
- **[Image Curation Quickstart](https://docs.nvidia.com/nemo/curator/latest/get-started/image.html)** - Learn to curate large-scale image-text datasets for generative model training

For production deployments and advanced configurations, see our [Setup & Deployment documentation](https://docs.nvidia.com/nemo/curator/latest/admin/index.html).

---

## Key Features

With NeMo Curator, you can process raw data and curate high-quality data for training and customizing generative AI models such as LLMs, VLMs and WFMs. NeMo Curator provides a collection of scalable data processing modules for text and image curation.

### Text Curation
All of our text pipelines have great multilingual support. With NeMo Curator, you can pick and choose the features you want and build your data curation pipelines. Text curation follows a three-stage workflow: **Load** → **Process** → **Generate**. A typical pipeline starts by downloading raw data from public resources, then applies cleaning and filtering steps, and optionally generates synthetic data for training enhancement.

#### Load Data
- **[Download and Extraction](https://docs.nvidia.com/nemo/curator/latest/curate-text/load-data/index.html)** - Default implementations for Common Crawl, Wikipedia, and ArXiv sources with easy customization for other sources

#### Process Data  
- **Quality Assessment & Filtering**
  - [Heuristic Filtering](https://docs.nvidia.com/nemo/curator/latest/curate-text/process-data/quality-assessment/heuristic.html) - 30+ heuristic filters for punctuation density, length, and repetition analysis
  - [fastText Classification](https://docs.nvidia.com/nemo/curator/latest/curate-text/process-data/quality-assessment/classifier.html) - Fast language and quality classification
  - [GPU-Accelerated Classification](https://docs.nvidia.com/nemo/curator/latest/curate-text/process-data/quality-assessment/distributed-classifier.html) - Domain, Quality, Safety, Educational Content, Content Type, and Prompt Task/Complexity Classification

- **Deduplication**
  - [Exact Deduplication](https://docs.nvidia.com/nemo/curator/latest/curate-text/process-data/deduplication/gpudedup.html) - Remove identical documents efficiently
  - [Fuzzy Deduplication](https://docs.nvidia.com/nemo/curator/latest/curate-text/process-data/deduplication/gpudedup.html) - MinHash Locality Sensitive Hashing with optional False Positive Check
  - [Semantic Deduplication](https://docs.nvidia.com/nemo/curator/latest/curate-text/process-data/deduplication/semdedup.html) - GPU-accelerated semantic deduplication using RAPIDS cuML, cuDF, and PyTorch

- **Content Processing & Cleaning**
  - [Text Cleaning](https://docs.nvidia.com/nemo/curator/latest/curate-text/process-data/content-processing/text-cleaning.html) - Remove improperly decoded Unicode characters, inconsistent line spacing, and excessive URLs
  - [PII Redaction](https://docs.nvidia.com/nemo/curator/latest/curate-text/process-data/content-processing/pii.html) - Identify and remove personally identifiable information from training datasets

- **Specialized Processing**
  - [Language Identification](https://docs.nvidia.com/nemo/curator/latest/curate-text/process-data/language-management/index.html) - Accurate language detection using fastText
  - [Task Decontamination](https://docs.nvidia.com/nemo/curator/latest/curate-text/process-data/specialized-processing/task-decontamination.html) - Remove potential evaluation data leakage from training datasets

#### Generate Data
- **[Synthetic Data Pipelines](https://docs.nvidia.com/nemo/curator/latest/curate-text/generate-data/pipelines/index.html)** - Pre-built pipelines for generating high-quality synthetic training data:
  - [Open Q&A Generation](https://docs.nvidia.com/nemo/curator/latest/curate-text/generate-data/pipelines/open-qa.html) - Create question-answer pairs for instruction tuning
  - [Math Problem Generation](https://docs.nvidia.com/nemo/curator/latest/curate-text/generate-data/pipelines/math.html) - Generate mathematical problems for educational content
  - [Coding Tasks](https://docs.nvidia.com/nemo/curator/latest/curate-text/generate-data/pipelines/python.html) - Create programming challenges and code examples
  - [Writing Prompts](https://docs.nvidia.com/nemo/curator/latest/curate-text/generate-data/pipelines/writing-task.html) - Generate creative writing and content creation tasks
  - [Dialogue Generation](https://docs.nvidia.com/nemo/curator/latest/curate-text/generate-data/pipelines/dialogue.html) - Create conversational data for chat models
  - [Nemotron Pipelines](https://docs.nvidia.com/nemo/curator/latest/curate-text/generate-data/pipelines/wikipedia.html) - Wikipedia-style rewriting and knowledge distillation

---

### Image Curation

NeMo Curator provides powerful image curation features to curate high-quality image data for training generative AI models such as LLMs, VLMs, and WFMs. Image curation follows a **Load** → **Process** workflow: download datasets in WebDataset format, create embeddings, apply quality filters (NSFW and Aesthetic), and remove duplicates using semantic deduplication.

#### Load Data
- **[WebDataset Loading](https://docs.nvidia.com/nemo/curator/latest/curate-images/load-data/index.html)** - Load large-scale image-text datasets in WebDataset format

#### Process Data
- **Embeddings & Feature Extraction**
  - [Image Embedding Creation](https://docs.nvidia.com/nemo/curator/latest/curate-images/process-data/embeddings/index.html) - Generate CLIP embeddings for image analysis

- **Quality Assessment & Filtering**
  - [Aesthetic Classification](https://docs.nvidia.com/nemo/curator/latest/curate-images/process-data/classifiers/index.html) - Filter images based on aesthetic quality
  - [NSFW Classification](https://docs.nvidia.com/nemo/curator/latest/curate-images/process-data/classifiers/index.html) - Remove inappropriate content from datasets

- **Deduplication**
  - [Semantic Deduplication](https://docs.nvidia.com/nemo/curator/latest/curate-text/process-data/deduplication/semdedup.html) - Remove visually similar images using embedding-based clustering

---

## Module Ablation and Compute Performance

The modules within NeMo Curator were primarily designed to process and curate high-quality documents at scale.  To evaluate the quality of the data, we curated Common Crawl documents and conducted a series of ablation experiments. In these experiments, we trained a 357M-parameter GPT-style model using datasets generated at various stages of our data curation pipeline, which was implemented in NeMo Curator.

The following figure shows that the use of different data curation modules implemented in NeMo Curator led to improved model zero-shot downstream task performance.

<p align="center">
  <img src="./docs/_images/ablation.png" alt="drawing" width="700"/>
</p>

NeMo Curator leverages NVIDIA RAPIDS™ libraries like cuDF, cuML, and cuGraph along with Dask to scale workloads across multi-node, multi-GPU environments, significantly reducing data processing time. With NeMo Curator, developers achieve approximately 16× faster fuzzy‑deduplication on an 8 TB RedPajama‑v2 subset, with ~40% lower TCO and near‑linear scaling on 1–4 H100 80 GB nodes. Refer to the chart below to learn more details.

<p align="center">
  <img src="./docs/_images/text-benchmarks.png" alt="drawing" width="700"/>
</p>

NeMo Curator exhibits near‑linear scaling for fuzzy deduplication. On an 8 TB RedPajama‑v2 subset (~1.78 trillion tokens), processing time drops from 2.05 hours on one H100 80 GB node to 0.50 hours on four nodes. Refer to the scaling chart below to learn more:

<p align="center">
  <img src="./docs/_images/scaling.png" alt="drawing" width="700"/>
</p>

## Contribute to NeMo Curator

We welcome community contributions! Please refer to [CONTRIBUTING.md](https://github.com/NVIDIA/NeMo/blob/stable/CONTRIBUTING.md) for the process.
