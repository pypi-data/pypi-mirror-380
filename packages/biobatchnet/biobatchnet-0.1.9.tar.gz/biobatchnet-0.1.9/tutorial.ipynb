{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# BioBatchNet Tutorial\n",
    "\n",
    "**BioBatchNet** is a deep learning framework for batch effect correction in biological data, supporting both:\n",
    "- **Imaging Mass Cytometry (IMC)** data\n",
    "- **Single-cell RNA-seq (scRNA-seq)** data\n",
    "\n",
    "This tutorial demonstrates three usage patterns:\n",
    "1. **Quick Start** - Using the simple API with default parameters\n",
    "2. **Custom Loss Weights** - Fine-tuning training objectives\n",
    "3. **Direct Model Access** - Full control over architecture and training\n",
    "\n",
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1. Installation and Setup"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Install BioBatchNet (uncomment if needed)\n",
    "# !pip install biobatchnet\n",
    "\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import torch\n",
    "import scanpy as sc\n",
    "import anndata as ad\n",
    "import matplotlib.pyplot as plt\n",
    "import os\n",
    "\n",
    "from biobatchnet import correct_batch_effects, IMCVAE\n",
    "\n",
    "print(f\"PyTorch version: {torch.__version__}\")\n",
    "print(f\"Device: {'CUDA' if torch.cuda.is_available() else 'CPU'}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2. Load Example Data\n",
    "\n",
    "We'll use the **IMMUcan IMC dataset** as an example. The data will be downloaded from Google Drive."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import gdown\n",
    "\n",
    "# Download data from Google Drive\n",
    "FILE_ID = \"1S0AgcT0J7tnRtnnshRzAkECwhse0mTrK\"\n",
    "FILENAME = \"IMMUcan_batch.h5ad\"\n",
    "\n",
    "if not os.path.exists(FILENAME):\n",
    "    print(\"Downloading IMMUcan dataset...\")\n",
    "    gdown.download(id=FILE_ID, output=FILENAME, quiet=False)\n",
    "else:\n",
    "    print(f\"{FILENAME} already exists.\")\n",
    "\n",
    "# Load data\n",
    "adata = ad.read_h5ad(FILENAME)\n",
    "X = adata.X.toarray() if hasattr(adata.X, 'toarray') else adata.X\n",
    "\n",
    "# Extract batch labels\n",
    "unique_batches = np.unique(adata.obs['BATCH'].values)\n",
    "batch_to_int = {batch: i for i, batch in enumerate(unique_batches)}\n",
    "batch_labels = np.array([batch_to_int[b] for b in adata.obs['BATCH'].values])\n",
    "\n",
    "print(f\"✓ Data loaded: {X.shape[0]:,} cells, {X.shape[1]} features, {len(unique_batches)} batches\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def plot_umap(adata, use_rep=\"X\", title=None, color_by=['BATCH', 'celltype']):\n",
    "    \"\"\"Plot UMAP visualization colored by batch and cell type\"\"\"\n",
    "    adata_vis = adata.copy()\n",
    "    adata_vis.obs['BATCH'] = adata_vis.obs['BATCH'].astype(\"category\")\n",
    "    sc.pp.neighbors(adata_vis, use_rep=use_rep)\n",
    "    sc.tl.umap(adata_vis)\n",
    "    sc.pl.umap(adata_vis, color=color_by, title=title, frameon=False, wspace=0.5)\n",
    "\n",
    "# Visualize original data\n",
    "plot_umap(adata, title=\"Original Data (with batch effects)\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "\n",
    "## 3. Method 1: Quick Start with Simple API\n",
    "\n",
    "The easiest way to use BioBatchNet - just provide your data and batch labels."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Run batch correction with default parameters\n",
    "bio_embeddings, batch_embeddings = correct_batch_effects(\n",
    "    data=pd.DataFrame(X),\n",
    "    batch_info=pd.DataFrame({'BATCH': batch_labels}),\n",
    "    batch_key='BATCH',\n",
    "    data_type='imc',        # 'imc' or 'scrna'\n",
    "    latent_dim=20,          # Latent space dimension\n",
    "    epochs=100,             # Training epochs\n",
    "    device='cuda' if torch.cuda.is_available() else 'cpu'\n",
    ")\n",
    "\n",
    "print(f\"✓ Biological embeddings: {bio_embeddings.shape}\")\n",
    "print(f\"✓ Batch embeddings: {batch_embeddings.shape}\")\n",
    "\n",
    "# Add corrected embeddings to AnnData and visualize\n",
    "adata.obsm['X_biobatchnet'] = bio_embeddings\n",
    "plot_umap(adata, use_rep=\"X_biobatchnet\", title=\"After BioBatchNet Correction\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "\n",
    "## 4. Method 2: Custom Loss Weights\n",
    "\n",
    "Fine-tune the training objectives by adjusting loss weights."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define custom loss weights\n",
    "custom_loss_weights = {\n",
    "    'recon_loss': 10,       # Reconstruction loss (default: 10)\n",
    "    'discriminator': 0.1,   # Batch mixing (default: 0.3, lower = more mixing)\n",
    "    'classifier': 1。0,      # Batch retention (default: 1)\n",
    "    'kl_loss_1': 0.005,     # KL divergence for bio encoder (default: 0.005)\n",
    "    'kl_loss_2': 0.1,       # KL divergence for batch encoder (default: 0.1)\n",
    "    'ortho_loss': 0.01     # Orthogonality constraint (default: 0.01)\n",
    "}\n",
    "\n",
    "# Run with custom weights\n",
    "bio_embeddings_custom, _ = correct_batch_effects(\n",
    "    data=pd.DataFrame(X),\n",
    "    batch_info=pd.DataFrame({'BATCH': batch_labels}),\n",
    "    batch_key='BATCH',\n",
    "    data_type='imc',\n",
    "    latent_dim=20,\n",
    "    epochs=100,\n",
    "    loss_weights=custom_loss_weights,\n",
    "    device='cuda' if torch.cuda.is_available() else 'cpu'\n",
    ")\n",
    "\n",
    "print(\"✓ Training complete with custom loss weights\")\n",
    "\n",
    "# Visualize\n",
    "adata.obsm['X_custom'] = bio_embeddings_custom\n",
    "plot_umap(adata, use_rep=\"X_custom\", title=\"Custom Loss Weights\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "\n",
    "## 5. Method 3: Direct Model Usage (Advanced)\n",
    "\n",
    "For full control, use the model classes directly to customize architecture."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create IMCVAE model with custom architecture\n",
    "n_cells, n_features = X.shape\n",
    "n_batches = len(unique_batches)\n",
    "\n",
    "model = IMCVAE(\n",
    "    in_sz=n_features,\n",
    "    out_sz=n_features,\n",
    "    latent_sz=20,\n",
    "    num_batch=n_batches,\n",
    "    bio_encoder_hidden_layers=[256, 512, 512],        # Custom bio encoder\n",
    "    batch_encoder_hidden_layers=[128, 256],           # Custom batch encoder\n",
    "    decoder_hidden_layers=[512, 512, 256],            # Custom decoder\n",
    "    batch_classifier_layers_power=[500, 2000, 2000],  # Discriminator\n",
    "    batch_classifier_layers_weak=[128]                # Batch classifier\n",
    ")\n",
    "\n",
    "# Train model with custom loss weights\n",
    "custom_loss = {\n",
    "    'recon_loss': 10,\n",
    "    'discriminator': 0.1,\n",
    "    'classifier': 1.0,\n",
    "    'kl_loss_1': 0.005,\n",
    "    'kl_loss_2': 0.1,\n",
    "    'ortho_loss': 0.01\n",
    "}\n",
    "\n",
    "model.fit(\n",
    "    data=X,\n",
    "    batch_info=batch_labels,\n",
    "    epochs=100,\n",
    "    lr=1e-4,\n",
    "    batch_size=256,\n",
    "    loss_weights=custom_loss,\n",
    "    device='cuda' if torch.cuda.is_available() else 'cpu'\n",
    ")\n",
    "\n",
    "print(\"✓ Training complete\")\n",
    "\n",
    "# Extract embeddings and visualize\n",
    "bio_embeddings_direct = model.get_bio_embeddings(X)\n",
    "print(f\"✓ Bio embeddings: {bio_embeddings_direct.shape}\")\n",
    "\n",
    "adata.obsm['X_direct'] = bio_embeddings_direct\n",
    "plot_umap(adata, use_rep=\"X_direct\", title=\"Direct Model Usage\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "\n",
    "## 6. Summary and Tips\n",
    "\n",
    "### Three Usage Patterns\n",
    "\n",
    "| Method | Use Case | Complexity |\n",
    "|--------|----------|------------|\n",
    "| **Simple API** | Quick batch correction with defaults | Low |\n",
    "| **Custom Loss** | Fine-tune training objectives | Medium |\n",
    "| **Direct Model** | Full control over architecture | High |\n",
    "\n",
    "### Parameter Tuning Tips\n",
    "\n",
    "**Loss Weights:**\n",
    "- `recon_loss` (10): Higher = better reconstruction quality\n",
    "- `discriminator` (0.3): Lower = stronger batch mixing (use 0.1 for many batches)\n",
    "- `classifier` (1): Ensures batch information is preserved\n",
    "- `kl_loss_1` (0.005): Regularization for bio encoder\n",
    "- `kl_loss_2` (0.1): Regularization for batch encoder\n",
    "- `ortho_loss` (0.01): Encourages orthogonal bio/batch representations\n",
    "\n",
    "**Architecture:**\n",
    "- `latent_dim`: 20 for IMC\n",
    "- Increase hidden layers for complex datasets\n",
    "- Reduce model size if memory is limited\n",
    "\n",
    "**Training:**\n",
    "- Start with 100 epochs, increase if needed\n",
    "- Use GPU if available for faster training\n",
    "- Reduce `batch_size` if out of memory\n",
    "\n",
    "### Resources\n",
    "\n",
    "- **GitHub**: [https://github.com/Manchester-HealthAI/BioBatchNet](https://github.com/Manchester-HealthAI/BioBatchNet)\n",
    "- **Documentation**: See `README.md` and `USAGE.md`\n",
    "- **Paper**: [Link to paper when published]\n",
    "\n",
    "---\n",
    "\n",
    "**Questions or issues?** Please open an issue on GitHub!"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
