audio:
  chunk_size: 661500
  dim_f: 1024
  dim_t: 1101
  hop_length: 882
  n_fft: 4096
  num_channels: 2
  sample_rate: 44100
  min_mean_abs: 0.0001

model:
  dim: 512
  depth: 12
  stereo: true
  num_stems: 4
  linear_transformer_depth: 0
  time_transformer_depth: 1
  freq_transformer_depth: 1
  num_bands: 60
  dim_head: 64
  heads: 8
  attn_dropout: 0.0
  ff_dropout: 0.0
  flash_attn: true
  dim_freqs_in: 2049
  sample_rate: 44100  # needed for mel filter bank from librosa
  stft_n_fft: 4096
  stft_hop_length: 882
  stft_win_length: 4096
  stft_normalized: False
  mask_estimator_depth: 2
  multi_stft_resolution_loss_weight: 1.0
  multi_stft_resolutions_window_sizes: !!python/tuple
  - 4096
  - 2048
  - 1024
  - 512
  - 256
  multi_stft_hop_size: 147
  multi_stft_normalized: False
  mlp_expansion_factor: 4
  use_torch_checkpoint: False # it allows to greatly reduce GPU memory consumption during training (not fully tested)
  skip_connection: True # Enable skip connection between transformer blocks - can solve problem with gradients and probably faster training

training:
  batch_size: 1
  gradient_accumulation_steps: 4
  grad_clip: 0
  instruments: ['drums', 'bass', 'other', 'vocals']
  lr: 2.0e-05
  patience: 2
  reduce_factor: 0.95
  target_instrument: null
  num_epochs: 1000
  num_steps: 300
  q: 0.95
  coarse_loss_clip: false
  ema_momentum: 0.999
  optimizer: adamw
  read_metadata_procs: 8 # Number of processes to use during metadata reading for dataset. Can speed up metadata generation
  normalize: false
  other_fix: false # it's needed for checking on multisong dataset if other is actually instrumental
  use_amp: true # enable or disable usage of mixed precision (float16) - usually it must be true

augmentations:
  enable: false # enable or disable all augmentations (to fast disable if needed)
  loudness: false # randomly change loudness of each stem on the range (loudness_min; loudness_max)
  loudness_min: 0.5
  loudness_max: 1.5
  mixup: true # mix several stems of same type with some probability (only works for dataset types: 1, 2, 3)
  mixup_probs: !!python/tuple # 2 additional stems of the same type (1st with prob 0.2, 2nd with prob 0.02)
    - 0.2
    - 0.02
    - 0.002
  mixup_loudness_min: 0.5
  mixup_loudness_max: 1.5

  # apply mp3 compression to mixture only (emulate downloading mp3 from internet)
  mp3_compression_on_mixture: 0.01
  mp3_compression_on_mixture_bitrate_min: 32
  mp3_compression_on_mixture_bitrate_max: 320
  mp3_compression_on_mixture_backend: "lameenc"

  all:
    channel_shuffle: 0.5 # Set 0 or lower to disable
    random_inverse: 0.01 # inverse track (better lower probability)
    random_polarity: 0.5 # polarity change (multiply waveform to -1)

  vocals:
      pitch_shift: 1.0
      pitch_shift_min_semitones: -12
      pitch_shift_max_semitones: 12
      seven_band_parametric_eq: 0.5
      seven_band_parametric_eq_min_gain_db: -80
      seven_band_parametric_eq_max_gain_db: 9
      tanh_distortion: 0.5
      tanh_distortion_min: 0.1
      tanh_distortion_max: 1
      time_stretch: 1.0
      time_stretch_min_rate: 0.5
      time_stretch_max_rate: 2
  bass:
    pitch_shift: 1.0
    pitch_shift_min_semitones: -6
    pitch_shift_max_semitones: 6
    seven_band_parametric_eq: 0.4
    seven_band_parametric_eq_min_gain_db: -32
    seven_band_parametric_eq_max_gain_db: 6
    tanh_distortion: 1.0
    tanh_distortion_min: 0.1
    tanh_distortion_max: 0.5
    time_stretch: 1.0
    time_stretch_min_rate: 0.5
    time_stretch_max_rate: 1.5
  drums:
    pitch_shift: 0.1
    pitch_shift_min_semitones: -6
    pitch_shift_max_semitones: 6
    seven_band_parametric_eq: 0.5
    seven_band_parametric_eq_min_gain_db: -24
    seven_band_parametric_eq_max_gain_db: 12
    tanh_distortion: 0.3
    tanh_distortion_min: 0.1
    tanh_distortion_max: 0.6
    time_stretch: 1.0
    time_stretch_min_rate: 0.333
    time_stretch_max_rate: 1.5
  other:
    pitch_shift: 1.0
    pitch_shift_min_semitones: -12
    pitch_shift_max_semitones: 12
    gaussian_noise: 0.4
    gaussian_noise_min_amplitude: 0.001
    gaussian_noise_max_amplitude: 0.15
    time_stretch: 0.01
    time_stretch_min_rate: 0.25
    time_stretch_max_rate: 1.5

inference:
  batch_size: 1
  dim_t: 256
  num_overlap: 4
  normalize: false

loss_multistft:
  fft_sizes:
  - 1024
  - 2048
  - 4096
  hop_sizes:
  - 147
  - 256
  - 512
  win_lengths:
  - 1024
  - 2048
  - 4096
  window: "hann_window"
  scale: "mel"
  n_bins: 128
  sample_rate: 44100
  perceptual_weighting: true
  w_sc: 16.0
  w_log_mag: 16.0
  w_lin_mag: 16.0
  w_phs: 0.0
  mag_distance: "L1"
