litellm:
  - type: litellm
    model: openai/gpt-4o
    task: generation
    modality: text
    params:
      temperature: 0.3

  - type: litellm
    model: openai/gpt-4o-2024-08-06
    task: generation
    modality: text
    params:
      temperature: 0.3

  - type: litellm
    model: openai/gpt-4o-2024-05-13
    task: generation
    modality: text
    params:
      temperature: 0.3

  - type: litellm
    model: openai/gpt-4-turbo
    task: generation
    modality: text
    params:
      temperature: 0.3

  - type: litellm
    model: openai/gpt-4-turbo-preview
    task: generation
    modality: text
    params:
      temperature: 0.3

  - type: litellm
    model: openai/gpt-4-0125-preview
    task: generation
    modality: text
    params:
      temperature: 0.3

  - type: litellm
    model: openai/gpt-4-1106-preview
    task: generation
    modality: text
    params:
      temperature: 0.3

  - type: litellm
    model: openai/gpt-3.5-turbo
    task: generation
    modality: text
    params:
      temperature: 0.5

  - type: litellm
    model: openai/gpt-3.5-turbo-1106
    task: generation
    modality: text
    params:
      temperature: 0.5

  - type: litellm
    model: openai/gpt-3.5-turbo-0613
    task: generation
    modality: text
    params:
      temperature: 0.5

  - type: litellm
    model: openai/gpt-3.5-turbo-16k
    task: generation
    modality: text
    params:
      temperature: 0.5

  - type: litellm
    model: openai/gpt-3.5-turbo-16k-0613
    task: generation
    modality: text
    params:
      temperature: 0.5

  - type: litellm
    model: openai/gpt-4
    task: generation
    modality: text
    params:
      temperature: 0.2

  - type: litellm
    model: openai/gpt-4-0613
    task: generation
    modality: text
    params:
      temperature: 0.2

  - type: litellm
    model: openai/gpt-4-0314
    task: generation
    modality: text
    params:
      temperature: 0.2

  - type: litellm
    model: openai/gpt-4-32k
    task: generation
    modality: text
    params:
      temperature: 0.2

  - type: litellm
    model: openai/gpt-4-32k-0314
    task: generation
    modality: text
    params:
      temperature: 0.2

  - type: litellm
    model: openai/gpt-4-32k-0613
    task: generation
    modality: text
    params:
      temperature: 0.2

  - type: litellm
    model: openai/gpt-4-vision-preview
    task: generation
    modality: image
    params:
      temperature: 0.3

  - type: litellm
    model: openai/whisper-1
    task: transcription
    modality: audio
    params:
      temperature: 0.0

  - type: litellm
    model: openai/gpt-4o-transcribe
    task: transcription
    modality: audio
    params:
      temperature: 0.0

  - type: litellm
    model: openai/gpt-4o-mini-transcribe
    task: transcription
    modality: audio
    params:
      temperature: 0.0

  - type: litellm
    model: openai/tts-1
    task: text_to_speech
    modality: text
    params:
      temperature: 0.5

  - type: litellm
    model: openai/tts-1-hd
    task: text_to_speech
    modality: text
    params:
      temperature: 0.5

  - type: litellm
    model: openai/gpt-4o-mini-tts
    task: text_to_speech
    modality: text
    params:
      temperature: 0.5

  - type: litellm
    model: groq/distil-whisper-large-v3-en
    task: transcription
    modality: audio
    params:
      temperature: 0.0


  # --- Mistral Premier Models ---
  - type: litellm
    model: mistral/mistral-medium-2505
    task: generation
    modality: text
    context_window: 128000
    params:
      temperature: 0.5

  - type: litellm
    model: mistral/magistral-medium-2506
    task: generation
    modality: text
    context_window: 40000
    params:
      temperature: 0.5

  - type: litellm
    model: mistral/codestral-2501
    task: generation
    modality: code
    context_window: 256000
    params:
      temperature: 0.5

  - type: litellm
    model: mistral/mistral-ocr-2505
    task: transcription
    modality: document
    params:
      temperature: 0.0

  - type: litellm
    model: mistral/ministral-3b-2410
    task: generation
    modality: text
    context_window: 128000
    params:
      temperature: 0.5

  - type: litellm
    model: mistral/ministral-8b-2410
    task: generation
    modality: text
    context_window: 128000
    params:
      temperature: 0.5

  - type: litellm
    model: mistral/mistral-large-2407
    task: generation
    modality: text
    context_window: 128000
    params:
      temperature: 0.5

  - type: litellm
    model: mistral/pixtral-large-2411
    task: generation
    modality: multimodal
    context_window: 124000
    params:
      temperature: 0.5

  # --- Mistral Free/Open Models ---
  - type: litellm
    model: mistral/mistral-small-3.1
    task: generation
    modality: text
    context_window: 128000
    params:
      temperature: 0.5

  - type: litellm
    model: mistral/devstral-small-2505
    task: generation
    modality: code
    params:
      temperature: 0.5

  - type: litellm
    model: mistral/pixtral-12b-2409
    task: generation
    modality: multimodal
    params:
      temperature: 0.5

  - type: litellm
    model: mistral/mistral-nemo-2407
    task: generation
    modality: text
    params:
      temperature: 0.5

  - type: litellm
    model: mistral/codestral-mamba-7b-2407
    task: generation
    modality: code
    params:
      temperature: 0.5

  - type: litellm
    model: mistral/mathstral-7b-2407
    task: generation
    modality: text
    context_window: 32768
    params:
      temperature: 0.5

  - type: litellm
    model: mistral/mixtral-8x22b-2404
    task: generation
    modality: text
    context_window: 128000
    params:
      temperature: 0.5

  - type: litellm
    model: mistral/mistral-7b-2309
    task: generation
    modality: text
    params:
      temperature: 0.5
