huggingface:
  - model: google/flan-t5-small
    task: text2text-generation
    support_multi_turn: false
    supported_input_format: text
    params:
      max_new_tokens: 256
      temperature: 0.5
      top_k: 50

  - model: jc-detoxio/dtx-guard-mjb-large-v1
    task: text-classification
    support_multi_turn: false
    supported_input_format: text
    classification_model_scope: prompt
    params:
      max_new_tokens: 8192
    preferred_evaluator:
      evaluation_method:
        eval_model_type: "JSON_EXPRESSION"
        eval_model_name: "ANY_JSONPATH_EXP"
        scope: "scores"
        expressions:
          - ".scores.unsafe | select(. > 0.8)"

  - model: dcarpintero/pangolin-guard-base
    task: text-classification
    support_multi_turn: false
    supported_input_format: text
    classification_model_scope: prompt
    params:
      max_new_tokens: 8192
    preferred_evaluator:
      evaluation_method:
        eval_model_type: "JSON_EXPRESSION"
        eval_model_name: "ANY_JSONPATH_EXP"
        scope: "scores"
        expressions:
          - ".scores.unsafe | select(. > 0.8)"
  
  - model: meta-llama/Prompt-Guard-86M
    task: text-classification
    support_multi_turn: false
    supported_input_format: text
    classification_model_scope: prompt
    params:
      max_new_tokens: 512
    preferred_evaluator:
      evaluation_method:
        eval_model_type: "JSON_EXPRESSION"
        eval_model_name: "ANY_JSONPATH_EXP"
        scope: "scores"
        expressions:
          - ".scores.JAILBREAK | select(. > 0.8)"
    
  - model: meta-llama/Llama-Prompt-Guard-2-86M
    task: text-classification
    support_multi_turn: false
    supported_input_format: text
    classification_model_scope: prompt
    params:
      max_new_tokens: 512
    preferred_evaluator:
      evaluation_method:
        eval_model_type: "JSON_EXPRESSION"
        eval_model_name: "ANY_JSONPATH_EXP"
        scope: "scores"
        expressions:
          - ".scores.LABEL_1 | select(. > 0.8)"

  - model: meta-llama/Llama-Prompt-Guard-2-22M
    task: text-classification
    support_multi_turn: false
    supported_input_format: text
    classification_model_scope: prompt
    params:
      max_new_tokens: 512
    preferred_evaluator:
      evaluation_method:
        eval_model_type: "JSON_EXPRESSION"
        eval_model_name: "ANY_JSONPATH_EXP"
        scope: "scores"
        expressions:
          - ".scores.LABEL_1 | select(. > 0.8)"

  - model: unitary/toxic-bert
    task: text-classification
    support_multi_turn: false
    supported_input_format: text
    params:
      max_new_tokens: 512
    preferred_evaluator:
      evaluation_method:
        eval_model_type: "JSON_EXPRESSION"
        eval_model_name: "ANY_JSONPATH_EXP"
        scope: "response"
        expressions:
          - "any(.scores | to_entries[]; .value > 0.8)"

  - model: ibm-granite/granite-guardian-hap-38m
    task: text-classification
    support_multi_turn: false
    supported_input_format: text
    params:
      max_new_tokens: 512
    preferred_evaluator:
      evaluation_method:
        eval_model_type: "JSON_EXPRESSION"
        eval_model_name: "ANY_JSONPATH_EXP"
        scope: "scores"
        expressions:
          - ".scores.LABEL_1 | select(. > 0.8)"

  - model: ibm-granite/granite-guardian-hap-125m
    task: text-classification
    support_multi_turn: false
    supported_input_format: text
    params:
      max_new_tokens: 512
    preferred_evaluator:
      evaluation_method:
        eval_model_type: "JSON_EXPRESSION"
        eval_model_name: "ANY_JSONPATH_EXP"
        scope: "scores"
        expressions:
          - ".scores.LABEL_1 | select(. > 0.8)"

  - model: unitary/unbiased-toxic-roberta
    task: text-classification
    support_multi_turn: false
    supported_input_format: text
    params:
      max_new_tokens: 512
    preferred_evaluator:
      evaluation_method:
        eval_model_type: "JSON_EXPRESSION"
        eval_model_name: "ANY_JSONPATH_EXP"
        scope: "response"
        expressions:
          - "any(.scores | to_entries[]; .value > 0.8)"

  - model: gpt2
    task: text-generation
    support_multi_turn: true
    supported_input_format: text
    params:
      max_new_tokens: 256
      temperature: 0.7
      top_p: 0.9

  - model: arnir0/Tiny-LLM
    task: text-generation
    support_multi_turn: false
    supported_input_format: text
    params:
      max_new_tokens: 256
      temperature: 0.7
      top_p: 0.9

  - model: HuggingFaceTB/SmolLM2-135M
    task: text-generation
    support_multi_turn: false
    supported_input_format: text
    params:
      max_new_tokens: 256
      temperature: 0.6
      top_p: 0.85
      do_sample: True

  - model: HuggingFaceTB/SmolLM2-135M-Instruct
    task: text-generation
    support_multi_turn: true
    supported_input_format: openai
    params:
      max_new_tokens: 256
      temperature: 0.6
      top_p: 0.85
      do_sample: True

  - model: HuggingFaceTB/SmolLM2-360M
    task: text-generation
    support_multi_turn: false
    supported_input_format: text
    params:
      max_new_tokens: 256
      temperature: 0.6
      top_p: 0.85

  - model: HuggingFaceTB/SmolLM2-360M-Instruct
    task: text-generation
    support_multi_turn: true
    supported_input_format: openai
    params:
      max_new_tokens: 256
      temperature: 0.6
      top_p: 0.85
      do_sample: True

  - model: HuggingFaceTB/SmolLM2-1.7B
    task: text-generation
    support_multi_turn: false
    supported_input_format: text
    params:
      max_new_tokens: 512
      temperature: 0.5
      top_p: 0.9

  - model: HuggingFaceTB/SmolLM2-1.7B-Instruct
    task: text-generation
    support_multi_turn: true
    supported_input_format: openai
    params:
      max_new_tokens: 512
      temperature: 0.5
      top_p: 0.9

