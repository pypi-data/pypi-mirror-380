"""
Tests for the main AIPR functionality
"""

from unittest.mock import MagicMock, Mock, call, patch

import pytest
from git import Repo
from git.exc import InvalidGitRepositoryError

from aipr.main import (
    ENDC,
    YELLOW,
    compare_vulnerabilities,
    detect_provider_and_model,
    main,
    run_trivy_scan,
)
from aipr.prompts import PromptManager
from aipr.providers import generate_with_anthropic, generate_with_azure_openai, generate_with_openai


# Helper to clear all provider keys except the specified one
def clear_other_provider_keys(keep_provider=None):
    """Clear all provider API keys except the one specified."""
    env_dict = {
        "AZURE_API_KEY": "",
        "AZURE_OPENAI_ENDPOINT": "",
        "ANTHROPIC_API_KEY": "",
        "OPENAI_API_KEY": "",
        "GEMINI_API_KEY": "",
        "XAI_API_KEY": "",
    }

    if keep_provider == "anthropic":
        env_dict["ANTHROPIC_API_KEY"] = "test-key"
    elif keep_provider == "azure":
        env_dict["AZURE_API_KEY"] = "test-key"
        env_dict["AZURE_OPENAI_ENDPOINT"] = "https://test.openai.azure.com"
    elif keep_provider == "openai":
        env_dict["OPENAI_API_KEY"] = "test-key"
    elif keep_provider == "gemini":
        env_dict["GEMINI_API_KEY"] = "test-key"
    elif keep_provider == "xai":
        env_dict["XAI_API_KEY"] = "test-key"

    return env_dict


def test_version():
    """Test that version is properly set"""
    from aipr import __version__

    assert isinstance(__version__, str)
    assert len(__version__.split(".")) == 3


# Model Detection Tests
def test_detect_provider_and_model_defaults():
    """Test default model detection"""
    # Test with Azure key first (highest priority as default)
    with patch.dict(
        "os.environ",
        {"AZURE_API_KEY": "test-key", "AZURE_OPENAI_ENDPOINT": "https://test.openai.azure.com"},
        clear=True,
    ):
        provider, model = detect_provider_and_model(None)
        assert provider == "azure"
        assert model == "gpt-5-nano"

    # Test with Anthropic key
    with patch.dict("os.environ", {"ANTHROPIC_API_KEY": "test-key"}, clear=True):
        provider, model = detect_provider_and_model(None)
        assert provider == "anthropic"
        assert model == "claude-sonnet-4-5-20250929"

    # Test with OpenAI key
    with patch.dict("os.environ", {"OPENAI_API_KEY": "test-key"}, clear=True):
        provider, model = detect_provider_and_model(None)
        assert provider == "openai"
        assert model == "gpt-5"

    # Test with Gemini key
    with patch.dict("os.environ", {"GEMINI_API_KEY": "test-key"}, clear=True):
        provider, model = detect_provider_and_model(None)
        assert provider == "gemini"
        assert model == "gemini-2.5-flash"

    # Test with XAI key (lowest priority)
    with patch.dict("os.environ", {"XAI_API_KEY": "test-key"}, clear=True):
        provider, model = detect_provider_and_model(None)
        assert provider == "xai"
        assert model == "grok-code-fast-1"


def test_detect_provider_and_model_aliases():
    """Test all documented model aliases"""
    test_cases = [
        # Simple provider aliases
        ("claude", ("anthropic", "claude-sonnet-4-5-20250929")),
        ("opus", ("anthropic", "claude-opus-4-1-20250805")),
        ("claude-opus", ("anthropic", "claude-opus-4-1-20250805")),
        ("azure", ("azure", "gpt-5-nano")),  # Updated default
        ("openai", ("openai", "gpt-5")),  # Updated default
        ("gemini", ("gemini", "gemini-2.5-flash")),  # Updated default
        ("grok", ("xai", "grok-code-fast-1")),  # New provider
        ("xai", ("xai", "grok-code-fast-1")),  # New provider
        # Azure model aliases - only new models
        ("azure/gpt-4.1-nano", ("azure", "gpt-4.1-nano")),
        ("azure/gpt-5-chat", ("azure", "gpt-5-chat")),
        ("azure/gpt-5-mini", ("azure", "gpt-5-mini")),
        ("azure/gpt-5-nano", ("azure", "gpt-5-nano")),
        # OpenAI model aliases - only GPT-5 series
        ("gpt-5", ("openai", "gpt-5")),
        ("gpt-5-mini", ("openai", "gpt-5-mini")),
        ("gpt-5-nano", ("openai", "gpt-5-nano")),
        # Anthropic models - direct names only
        ("claude-sonnet-4-5-20250929", ("anthropic", "claude-sonnet-4-5-20250929")),
        ("claude-sonnet-4-20250514", ("anthropic", "claude-sonnet-4-20250514")),
        ("claude-opus-4-1-20250805", ("anthropic", "claude-opus-4-1-20250805")),
        # Gemini model aliases - only 2.5 series
        ("gemini-2.5-pro", ("gemini", "gemini-2.5-pro")),
        ("gemini-2.5-flash", ("gemini", "gemini-2.5-flash")),
        ("gemini-2.5-flash-lite", ("gemini", "gemini-2.5-flash-lite")),
        # xAI models
        ("grok-code-fast-1", ("xai", "grok-code-fast-1")),
    ]

    for input_model, expected in test_cases:
        provider, model = detect_provider_and_model(input_model)
        assert (provider, model) == expected, f"Failed for input model: {input_model}"


def test_detect_provider_and_model_azure():
    """Test Azure model detection"""
    test_cases = [
        ("azure/gpt-4.1-nano", ("azure", "gpt-4.1-nano")),
        ("azure/gpt-5-chat", ("azure", "gpt-5-chat")),
        ("azure/gpt-5-mini", ("azure", "gpt-5-mini")),
        ("azure/gpt-5-nano", ("azure", "gpt-5-nano")),
    ]
    for input_model, expected in test_cases:
        provider, model = detect_provider_and_model(input_model)
        assert (provider, model) == expected


def test_detect_provider_and_model_openai():
    """Test OpenAI model detection"""
    test_cases = [
        ("gpt-5", ("openai", "gpt-5")),
        ("gpt-5-mini", ("openai", "gpt-5-mini")),
        ("gpt-5-nano", ("openai", "gpt-5-nano")),
    ]
    for input_model, expected in test_cases:
        provider, model = detect_provider_and_model(input_model)
        assert (provider, model) == expected


def test_detect_provider_and_model_gemini():
    """Test Gemini model detection"""
    test_cases = [
        ("gemini-2.5-pro", ("gemini", "gemini-2.5-pro")),
        ("gemini-2.5-flash", ("gemini", "gemini-2.5-flash")),
        ("gemini-2.5-flash-lite", ("gemini", "gemini-2.5-flash-lite")),
        ("gemini", ("gemini", "gemini-2.5-flash")),  # Alias test
    ]
    for input_model, expected in test_cases:
        provider, model = detect_provider_and_model(input_model)
        assert (provider, model) == expected


def test_detect_provider_and_model_anthropic():
    """Test Anthropic model detection"""
    test_cases = [
        ("claude", ("anthropic", "claude-sonnet-4-5-20250929")),
        ("opus", ("anthropic", "claude-opus-4-1-20250805")),
        ("claude-opus", ("anthropic", "claude-opus-4-1-20250805")),
        ("claude-sonnet-4-5-20250929", ("anthropic", "claude-sonnet-4-5-20250929")),
        ("claude-sonnet-4-20250514", ("anthropic", "claude-sonnet-4-20250514")),
        ("claude-opus-4-1-20250805", ("anthropic", "claude-opus-4-1-20250805")),
    ]
    for input_model, expected in test_cases:
        provider, model = detect_provider_and_model(input_model)
        assert (provider, model) == expected


# Trivy Scanning Tests
@patch("subprocess.run")
def test_run_trivy_scan_python_poetry(mock_run, tmp_path):
    """Test Trivy scanning with Poetry project"""
    # Create mock Python project with Poetry
    poetry_lock = tmp_path / "poetry.lock"
    pyproject_toml = tmp_path / "pyproject.toml"
    poetry_lock.touch()
    pyproject_toml.touch()

    mock_run.return_value.stdout = '{"Results": []}'
    mock_run.return_value.returncode = 0

    result = run_trivy_scan(str(tmp_path), silent=True)

    assert mock_run.called
    args = mock_run.call_args[0][0]
    assert "--dependency-tree" in args
    assert str(tmp_path) in args


@patch("subprocess.run")
def test_run_trivy_scan_python_pip(mock_run, tmp_path):
    """Test Trivy scanning with pip requirements"""
    requirements = tmp_path / "requirements.txt"
    requirements.touch()

    mock_run.return_value.stdout = '{"Results": []}'
    mock_run.return_value.returncode = 0

    result = run_trivy_scan(str(tmp_path), silent=True)

    assert mock_run.called
    args = mock_run.call_args[0][0]
    assert "--dependency-tree" in args
    assert str(tmp_path) in args


# Vulnerability Comparison Tests
def test_compare_vulnerabilities_empty():
    """Test vulnerability comparison with empty scans"""
    report, analysis = compare_vulnerabilities({}, {})
    assert "Error: Unable to generate vulnerability comparison" in report
    assert analysis == ""


def test_compare_vulnerabilities_no_changes():
    """Test vulnerability comparison with no changes"""
    current_scan = {"Results": []}
    target_scan = {"Results": []}

    report, analysis = compare_vulnerabilities(current_scan, target_scan)
    assert "No vulnerability changes detected" in report
    assert "No security changes to analyze" in analysis


def test_compare_vulnerabilities_new_vulns():
    """Test vulnerability comparison with new vulnerabilities"""
    current_scan = {
        "Results": [
            {
                "Target": "requirements.txt",
                "Type": "pip",
                "Vulnerabilities": [
                    {
                        "VulnerabilityID": "CVE-2024-0001",
                        "PkgName": "requests",
                        "InstalledVersion": "2.25.0",
                        "Severity": "HIGH",
                        "Description": "Test vulnerability",
                        "Title": "Test Title",
                    }
                ],
            }
        ]
    }
    target_scan = {"Results": []}

    report, analysis = compare_vulnerabilities(current_scan, target_scan)
    assert "New Vulnerabilities" in report
    assert "HIGH" in report
    assert "CVE-2024-0001" in report
    assert "requests" in report


# Prompt Generation Tests
def test_prompt_generation():
    """Test prompt generation with and without vulnerabilities"""
    manager = PromptManager()

    # Test without vulnerabilities
    diff = "test diff content"
    prompt = manager.get_user_prompt(diff)
    assert "Git Diff:" in prompt
    assert diff in prompt
    assert "Vulnerability Analysis:" not in prompt

    # Test with vulnerabilities
    vuln_data = "test vulnerability data"
    prompt = manager.get_user_prompt(diff, vuln_data)
    assert "Git Diff:" in prompt
    assert diff in prompt
    assert "Vulnerability Analysis:" in prompt
    assert vuln_data in prompt


# Main Function Integration Tests
@patch("aipr.main.generate_with_anthropic")
@patch("aipr.main.git.Repo")
def test_main_with_changes(mock_repo_class, mock_generate, capsys):
    """Test main function with changes"""
    # Setup mock repo
    mock_repo = MagicMock()
    mock_repo_class.return_value = mock_repo
    mock_repo.is_dirty.return_value = True
    mock_repo.git.diff.return_value = "test diff"

    # Setup mock generate
    mock_generate.return_value = "test response"

    # Run with environment variable set - clear other provider keys
    with patch.dict("os.environ", clear_other_provider_keys("anthropic")):
        try:
            main([])
        except SystemExit:
            pass

    # Verify the response
    mock_generate.assert_called_once()
    captured = capsys.readouterr()
    assert "test response" in captured.out


@patch("aipr.main.generate_with_anthropic")
@patch("aipr.main.git.Repo")
def test_main_clean_branch(mock_repo_class, mock_generate, capsys):
    """Test main function with clean branch"""
    # Setup mock repo
    mock_repo = MagicMock()
    mock_repo_class.return_value = mock_repo
    mock_repo.is_dirty.return_value = False
    mock_repo.git.diff.return_value = "test diff"
    mock_repo.active_branch.name = "feature"
    mock_repo.heads = [MagicMock(name="main")]
    for head in mock_repo.heads:
        head.name = head._mock_name

    # Setup mock generate
    mock_generate.return_value = "test response"

    # Run with environment variable set - clear other provider keys
    with patch.dict("os.environ", clear_other_provider_keys("anthropic")):
        try:
            main(["-t", "main"])
        except SystemExit:
            pass

    # Verify the response
    mock_generate.assert_called_once()
    captured = capsys.readouterr()
    assert "test response" in captured.out


@patch("aipr.main.generate_with_anthropic")
@patch("aipr.main.git.Repo")
def test_main_explicit_working_tree(mock_repo_class, mock_generate, capsys):
    """Test main function with explicit working tree flag"""
    # Setup mock repo
    mock_repo = MagicMock()
    mock_repo_class.return_value = mock_repo
    mock_repo.git.diff.return_value = "test diff"

    # Setup mock generate
    mock_generate.return_value = "test response"

    # Run with environment variable set
    with patch.dict("os.environ", clear_other_provider_keys("anthropic")):
        try:
            main(["--working-tree"])
        except SystemExit:
            pass

    # Verify the response
    mock_generate.assert_called_once()
    captured = capsys.readouterr()
    assert "test response" in captured.out


@patch("aipr.main.git.Repo")
def test_main_invalid_repo(mock_repo_class, capsys):
    """Test main function with invalid repository"""
    mock_repo_class.side_effect = InvalidGitRepositoryError()

    with pytest.raises(SystemExit) as exc_info:
        main([])

    assert exc_info.value.code == 1
    captured = capsys.readouterr()
    assert "Directory is not a valid Git repository" in captured.err


@patch("aipr.main.generate_with_anthropic")
@patch("aipr.main.git.Repo")
def test_main_no_changes(mock_repo_class, mock_generate, mock_repo, capsys):
    """Test main function with no changes"""
    mock_repo.git.diff.return_value = ""
    mock_repo_class.return_value = mock_repo

    try:
        main(["--silent"])
    except SystemExit:
        pass

    # Verify no AI generation was attempted
    mock_generate.assert_not_called()
    captured = capsys.readouterr()
    assert "No changes found" in captured.err


def test_help(capsys):
    """Test help output"""
    try:
        main(["--help"])
    except SystemExit:
        pass

    # Verify help content
    captured = capsys.readouterr()
    assert "usage:" in captured.out
    # Help shows available subcommands
    assert "pr" in captured.out


@patch("aipr.main.run_trivy_scan")
@patch("aipr.main.generate_with_anthropic")
@patch("aipr.main.git.Repo")
def test_main_with_vulnerability_workflow(
    mock_repo_class, mock_generate, mock_trivy_run, mock_repo, capsys
):
    """Test main function with vulnerability scanning workflow"""
    # Set up mock repository
    mock_repo_class.return_value = mock_repo
    mock_repo.active_branch.name = "feature-branch"
    mock_repo.git.diff.return_value = "test diff content"

    # Mock Trivy scan results
    mock_trivy_run.return_value = {
        "Results": [
            {
                "Target": "requirements.txt",
                "Type": "pip",
                "Vulnerabilities": [
                    {
                        "VulnerabilityID": "CVE-2024-0001",
                        "PkgName": "requests",
                        "InstalledVersion": "2.25.0",
                        "FixedVersion": "2.31.0",
                        "Severity": "HIGH",
                        "Description": "Test vulnerability",
                        "Title": "Test Title",
                    }
                ],
            }
        ]
    }

    # Mock AI responses with correct format
    mock_generate.side_effect = [
        """### Merge Request

Initial description of changes""",
        """### Merge Request

Updated description with security context

## Vulnerability Scan

### HIGH Severity
- CVE-2024-0001 in requests 2.25.0 (requirements.txt)""",
    ]

    # Run main with vulnerability scanning
    with patch.dict("os.environ", clear_other_provider_keys("anthropic")):
        try:
            main(["--silent", "--vulns"])
        except SystemExit:
            pass

    # Verify Trivy scan was performed
    assert mock_trivy_run.called
    assert mock_generate.called

    # Verify output format
    captured = capsys.readouterr()
    output = captured.out
    assert "### Merge Request" in output
    assert "Initial description of changes" in output


@patch("aipr.main.generate_with_anthropic")
@patch("aipr.main.git.Repo")
def test_main_target_branch_fallback(mock_repo_class, mock_generate, mock_repo, capsys):
    """Test main function with target branch fallback logic"""
    mock_repo_class.return_value = mock_repo
    mock_repo.active_branch.name = "feature-branch"
    mock_repo.git.diff.return_value = "test diff content"
    mock_repo.is_dirty.return_value = False
    mock_generate.return_value = "Test PR description"

    # Set up mock branches with main as default
    mock_repo.heads = [MagicMock(name="main"), MagicMock(name="feature-branch")]
    for head in mock_repo.heads:
        head.name = head._mock_name

    # Run main without specifying target branch
    with patch.dict("os.environ", clear_other_provider_keys("anthropic")):
        try:
            main([])  # No target specified, should fall back to main
        except SystemExit:
            pass

    # Verify fallback to 'main'
    mock_repo.git.diff.assert_any_call("main...feature-branch")

    # Verify output
    captured = capsys.readouterr()
    assert "Test PR description" in captured.out


@patch("aipr.main.generate_with_anthropic")
@patch("aipr.main.git.Repo")
def test_main_pr_output_format(mock_repo_class, mock_generate, mock_repo, capsys):
    """Test main function output format verification"""
    mock_repo_class.return_value = mock_repo
    mock_repo.active_branch.name = "feature-branch"
    mock_repo.git.diff.return_value = """
diff --git a/test.py b/test.py
index 1234567..89abcdef 100644
--- a/test.py
+++ b/test.py
@@ -1,3 +1,4 @@
+import os
 def test_function():
-    return False
+    return True
"""

    # Mock a detailed PR description
    mock_generate.return_value = """
### Merge Request

**Branch:** feature-branch

**Changes:**
- Added import os
- Modified test_function return value

**Impact:**
Low impact change to test functionality.

**Testing:**
- Unit tests updated
- All tests passing
"""

    # Clear other provider keys to ensure Anthropic (which is mocked) is selected
    with patch.dict("os.environ", clear_other_provider_keys("anthropic")):
        try:
            main(["--silent"])
        except SystemExit:
            pass

    # Verify output format
    captured = capsys.readouterr()
    output = captured.out

    # Check for required sections
    assert "### Merge Request" in output
    assert "**Branch:**" in output
    assert "**Changes:**" in output
    assert "**Impact:**" in output
    assert "**Testing:**" in output

    # Check content details
    assert "feature-branch" in output
    assert "Added import os" in output
    assert "Modified test_function" in output


@patch("aipr.main.run_trivy_scan")
@patch("aipr.main.generate_with_anthropic")
@patch("aipr.main.git.Repo")
def test_main_working_tree_with_vulns(
    mock_repo_class, mock_generate, mock_trivy, mock_repo, capsys
):
    """Test main function with working tree (-t "-") and vulnerability scanning"""
    # Set up mock repository
    mock_repo_class.return_value = mock_repo
    mock_repo.active_branch.name = "feature-branch"
    mock_repo.git.diff.return_value = "test diff content"

    # Mock vulnerability scan results for single branch scan
    mock_trivy.return_value = {
        "Results": [
            {
                "Target": "requirements.txt",
                "Type": "pip",
                "Vulnerabilities": [
                    {
                        "VulnerabilityID": "CVE-2024-0001",
                        "PkgName": "requests",
                        "InstalledVersion": "2.25.0",
                        "Severity": "HIGH",
                    }
                ],
            }
        ]
    }

    mock_generate.return_value = "Test PR description with vulnerabilities"

    # Run main with both working tree and vulnerability scanning
    # Clear other provider keys to ensure Anthropic (which is mocked) is selected
    with patch.dict("os.environ", clear_other_provider_keys("anthropic")):
        try:
            main(["--silent", "-t", "-", "--vulns"])
        except SystemExit:
            pass

    # Verify only one Trivy scan was performed (no temp repo clone)
    mock_trivy.assert_called_once()

    # Verify git operations were for working tree
    mock_repo.git.diff.assert_has_calls([call("HEAD", "--cached"), call()])

    # Verify output
    captured = capsys.readouterr()
    assert "Test PR description with vulnerabilities" in captured.out


@patch("aipr.main.run_trivy_scan")
@patch("aipr.main.generate_with_anthropic")
@patch("aipr.main.git.Repo")
def test_main_single_branch_vuln_scan(
    mock_repo_class, mock_generate, mock_trivy, mock_repo, capsys
):
    """Test main function with vulnerability scanning on a single branch (no target comparison)"""
    # Set up mock repository with no target branch
    mock_repo_class.return_value = mock_repo
    mock_repo.active_branch.name = "feature-branch"
    mock_repo.git.diff.return_value = "test diff content"
    mock_repo.heads = [MagicMock(name="feature-branch")]  # Only current branch exists
    for head in mock_repo.heads:
        head.name = head._mock_name

    # Simulate working tree changes to ensure we take the working tree path
    mock_repo.index.diff.return_value = ["some_change"]  # Simulate staged changes
    mock_repo.untracked_files = ["untracked_file"]  # Simulate untracked files

    # Mock vulnerability scan results
    mock_trivy.return_value = {
        "Results": [
            {
                "Target": "requirements.txt",
                "Type": "pip",
                "Vulnerabilities": [
                    {
                        "VulnerabilityID": "CVE-2024-0001",
                        "PkgName": "requests",
                        "InstalledVersion": "2.25.0",
                        "Severity": "HIGH",
                    }
                ],
            }
        ]
    }

    mock_generate.return_value = "Test PR description with single branch vulnerabilities"

    # Run main with vulnerability scanning but no valid target branch
    # Clear other provider keys to ensure Anthropic (which is mocked) is selected
    with patch.dict("os.environ", clear_other_provider_keys("anthropic")):
        try:
            main(["--silent", "--vulns"])
        except SystemExit:
            pass

    # Verify only one Trivy scan was performed (no comparison scan)
    mock_trivy.assert_called_once()

    # Verify git operations were for working tree changes (staged and unstaged)
    mock_repo.git.diff.assert_has_calls([call("HEAD", "--cached"), call()])
    assert mock_repo.git.diff.call_count == 2  # Called for both staged and unstaged changes

    # Verify output
    captured = capsys.readouterr()
    assert "Test PR description with single branch vulnerabilities" in captured.out


@pytest.fixture
def mock_repo():
    with patch("git.Repo") as mock:
        repo = MagicMock()
        repo.is_dirty.return_value = True
        repo.git.diff.return_value = "test diff"
        repo.working_dir = "/test/dir"
        mock.return_value = repo
        yield mock


@pytest.fixture
def mock_anthropic():
    with patch("aipr.main.generate_with_anthropic") as mock:
        mock.return_value = "Test description"
        yield mock


@pytest.fixture
def mock_azure():
    with patch("aipr.main.generate_with_azure_openai") as mock:
        mock.return_value = "Test description"
        yield mock


@pytest.fixture
def mock_openai():
    with patch("aipr.main.generate_with_openai") as mock:
        mock.return_value = "Test description"
        yield mock


@pytest.fixture
def mock_trivy():
    with patch("aipr.main.run_trivy_scan") as mock:
        mock.return_value = {"vulnerabilities": []}
        yield mock


def test_main_anthropic(mock_repo, mock_anthropic):
    args = Mock(
        model="claude-opus-4-1-20250805",
        target="-",
        vulns=False,
        silent=True,
        verbose=False,
        prompt=None,
    )

    with patch("aipr.main.parse_args", return_value=args):
        try:
            result = main(args)
            assert result == "Test description"
            mock_anthropic.assert_called_once()
        except SystemExit:
            pass


@patch("aipr.main.generate_with_anthropic")
@patch("aipr.main.generate_with_azure_openai")
@patch("aipr.main.generate_with_openai")
def test_main_openai(mock_openai_gen, mock_azure_gen, mock_anthropic_gen, mock_repo):
    """Test main function with OpenAI"""
    args = Mock(model="gpt-5", target="-", vulns=False, silent=True, verbose=False, prompt=None)
    mock_openai_gen.return_value = "Test description"

    with patch("aipr.main.parse_args", return_value=args):
        with patch.dict("os.environ", {"OPENAI_API_KEY": "test-key"}):
            try:
                result = main(args)
                assert result == "Test description"
                mock_openai_gen.assert_called_once()
                mock_azure_gen.assert_not_called()
                mock_anthropic_gen.assert_not_called()
            except SystemExit:
                pass


@patch("aipr.main.generate_with_anthropic")
@patch("aipr.main.generate_with_azure_openai")
@patch("aipr.main.generate_with_openai")
def test_main_azure(mock_openai_gen, mock_azure_gen, mock_anthropic_gen, mock_repo):
    """Test main function with Azure OpenAI"""
    args = Mock(
        model="azure/gpt-5-mini",
        target="-",
        vulns=False,
        silent=True,
        verbose=False,
        prompt=None,
    )
    mock_azure_gen.return_value = "Test description"

    with patch("aipr.main.parse_args", return_value=args):
        with patch.dict(
            "os.environ",
            {
                "AZURE_API_KEY": "test-key",
                "AZURE_API_BASE": "test-base",
                "AZURE_OPENAI_ENDPOINT": "https://test.openai.azure.com",
            },
        ):
            try:
                result = main(args)
                assert result == "Test description"
                mock_azure_gen.assert_called_once()
                mock_openai_gen.assert_not_called()
                mock_anthropic_gen.assert_not_called()
            except SystemExit:
                pass


@patch("aipr.main.generate_with_anthropic")
@patch("aipr.main.generate_with_azure_openai")
@patch("aipr.main.generate_with_openai")
def test_main_with_vulns(
    mock_openai_gen, mock_azure_gen, mock_anthropic_gen, mock_repo, mock_trivy
):
    """Test main function with vulnerability scanning"""
    args = Mock(
        model="gpt-5",
        target="-",
        vulns=True,
        silent=True,
        verbose=False,
        prompt=None,
        debug=False,
        from_commit=None,
        to_commit=None,
        working_tree=False,
    )
    mock_openai_gen.return_value = "Test description"

    # Mock vulnerability scan results
    mock_trivy.return_value = {
        "Results": [
            {
                "Target": "requirements.txt",
                "Type": "pip",
                "Vulnerabilities": [
                    {
                        "VulnerabilityID": "CVE-2024-0001",
                        "PkgName": "requests",
                        "InstalledVersion": "2.25.0",
                        "FixedVersion": "2.31.0",
                        "Severity": "HIGH",
                        "Description": "Test vulnerability",
                        "Title": "Test Title",
                        "References": ["https://example.com/cve"],
                    }
                ],
            }
        ]
    }

    with patch("aipr.main.parse_args", return_value=args):
        with patch.dict("os.environ", {"OPENAI_API_KEY": "test-key"}):
            try:
                main(args)
            except SystemExit:
                pass

            # Verify the API calls and data
            mock_trivy.assert_called_once()
            mock_openai_gen.assert_called_once()
            mock_azure_gen.assert_not_called()
            mock_anthropic_gen.assert_not_called()

            # Verify vulnerability data was passed to the model
            vuln_data = mock_openai_gen.call_args[0][1]  # Get the vuln_data argument
            assert isinstance(vuln_data, dict)
            assert "Results" in vuln_data
            assert "CVE-2024-0001" in str(vuln_data)


def test_detect_provider_and_model():
    """Test provider and model detection"""
    # Test Anthropic models
    provider, model = detect_provider_and_model("claude-opus-4-1-20250805")
    assert provider == "anthropic"
    assert model == "claude-opus-4-1-20250805"

    # Test Azure OpenAI models with explicit azure/ prefix
    with patch.dict(
        "os.environ",
        {
            "AZURE_API_KEY": "test-key",
            "AZURE_API_BASE": "test-base",
            "AZURE_OPENAI_ENDPOINT": "https://test.openai.azure.com",
        },
    ):
        provider, model = detect_provider_and_model("azure/gpt-5-mini")
        assert provider == "azure"
        assert model == "gpt-5-mini"

    # Test OpenAI models
    with patch.dict("os.environ", {"OPENAI_API_KEY": "test-key"}):
        provider, model = detect_provider_and_model("gpt-5")
        assert provider == "openai"
        assert model == "gpt-5"


def test_prompt_manager():
    manager = PromptManager()

    # Test system prompt
    system_prompt = manager.get_system_prompt()
    assert isinstance(system_prompt, str)
    assert len(system_prompt) > 0

    # Test user prompt without vulnerabilities
    user_prompt = manager.get_user_prompt("test diff")
    assert isinstance(user_prompt, str)
    assert "test diff" in user_prompt

    # Test user prompt with vulnerabilities
    vuln_data = {
        "Results": [{"severity": "HIGH", "description": "Test vulnerability"}]
    }  # Updated structure
    user_prompt_with_vulns = manager.get_user_prompt("test diff", vuln_data)
    assert isinstance(user_prompt_with_vulns, str)
    assert "test diff" in user_prompt_with_vulns
    assert "Test vulnerability" in user_prompt_with_vulns


@patch("aipr.providers.OpenAI")
@patch("aipr.providers.AzureOpenAI")
@patch("aipr.providers.anthropic.Anthropic")
def test_provider_clients(mock_anthropic, mock_azure, mock_openai):
    """Test that provider clients are created correctly"""
    # Setup mock responses
    mock_anthropic_instance = mock_anthropic.return_value
    mock_anthropic_instance.messages.create.return_value = type(
        "Response", (), {"content": [type("Content", (), {"text": "Test response"})()]}
    )

    mock_azure.return_value.chat.completions.create.return_value.choices = [
        type(
            "Choice",
            (),
            {"message": type("Message", (), {"content": "Test response"})()},
        )()
    ]
    mock_openai.return_value.chat.completions.create.return_value.choices = [
        type(
            "Choice",
            (),
            {"message": type("Message", (), {"content": "Test response"})()},
        )()
    ]

    # Test Anthropic
    with patch.dict("os.environ", clear_other_provider_keys("anthropic")):
        result = generate_with_anthropic("test", None, "claude-3", "test prompt")
        assert result == "Test response"
        mock_anthropic.assert_called_once()
        mock_anthropic_instance.messages.create.assert_called_once()

    # Test Azure
    with patch.dict(
        "os.environ",
        {
            "AZURE_API_KEY": "test-key",
            "AZURE_API_BASE": "test-base",
            "AZURE_OPENAI_ENDPOINT": "https://test.openai.azure.com",
        },
    ):
        result = generate_with_azure_openai("test", None, "gpt-5-mini", "test prompt")
        assert result == "Test response"
        mock_azure.assert_called_once()

    # Test OpenAI
    with patch.dict("os.environ", {"OPENAI_API_KEY": "test-key"}):
        result = generate_with_openai("test", None, "gpt-5", "test prompt")
        assert result == "Test response"
        mock_openai.assert_called_once()


@patch("aipr.main.generate_with_anthropic")
@patch("aipr.main.generate_with_azure_openai")
@patch("aipr.main.generate_with_openai")
def test_main_azure_gpt5_mini(mock_openai_gen, mock_azure_gen, mock_anthropic_gen, mock_repo):
    """Test main function with Azure OpenAI GPT-5 Mini model"""
    args = Mock(
        model="azure/gpt-5-mini",
        target="-",
        vulns=False,
        silent=True,
        verbose=False,
        prompt=None,
        debug=False,
        from_commit=None,
        to_commit=None,
        working_tree=False,
    )
    mock_azure_gen.return_value = "Test description"

    # Mock repo with some diff content
    mock_repo = MagicMock()
    mock_repo.git.diff.return_value = "test diff"

    with patch("aipr.main.parse_args", return_value=args):
        with patch.dict(
            "os.environ",
            {
                "AZURE_API_KEY": "test-key",
                "AZURE_API_BASE": "test-base",
                "AZURE_OPENAI_ENDPOINT": "https://test.openai.azure.com",
            },
        ):
            try:
                main(args)
            except SystemExit:
                pass

            # Verify the correct provider was called
            mock_azure_gen.assert_called_once()
            mock_openai_gen.assert_not_called()
            mock_anthropic_gen.assert_not_called()

            # Verify the model name was passed correctly
            assert mock_azure_gen.call_args[0][2] == "gpt-5-mini"  # Check model parameter


# Commit Range Functionality Tests
class TestCommitRangeFunctionality:
    """Test the new commit range functionality for both pr and commit commands."""

    def test_get_commit_range_diff_valid_commits(self):
        """Test get_commit_range_diff with valid commit range."""
        from aipr.main import get_commit_range_diff

        mock_repo = MagicMock()
        mock_repo.git.cat_file.return_value = ""  # Valid commits
        mock_repo.git.diff.side_effect = [
            "test diff content",  # First call for diff content
            "A\ttest.py",  # Second call for name-status
        ]

        diff_content, file_stats = get_commit_range_diff(mock_repo, "abc123", "def456")

        assert diff_content == "test diff content"
        assert file_stats["total"] == 1
        assert file_stats["added"] == 1
        mock_repo.git.cat_file.assert_has_calls(
            [call("-e", "abc123^{commit}"), call("-e", "def456^{commit}")]
        )
        mock_repo.git.diff.assert_has_calls(
            [call("abc123..def456"), call("abc123..def456", "--name-status")]
        )

    def test_get_commit_range_diff_invalid_from_commit(self):
        """Test get_commit_range_diff with invalid from_commit."""
        import git

        from aipr.main import get_commit_range_diff

        mock_repo = MagicMock()
        mock_repo.git.cat_file.side_effect = git.exc.GitCommandError(
            "git cat-file", 1, stderr="does not exist"
        )

        with pytest.raises(ValueError, match="Invalid commit reference"):
            get_commit_range_diff(mock_repo, "abc123", "def456")

    def test_get_commit_range_diff_invalid_to_commit(self):
        """Test get_commit_range_diff with invalid to_commit."""
        import git

        from aipr.main import get_commit_range_diff

        mock_repo = MagicMock()
        mock_repo.git.diff.side_effect = git.exc.GitCommandError(
            "git diff", 1, stderr="bad revision"
        )

        with pytest.raises(ValueError, match="Invalid commit reference"):
            get_commit_range_diff(mock_repo, "abc123", "def456")

    def test_validate_commit_range_args_valid(self):
        """Test validate_commit_range_args with valid arguments."""
        from aipr.main import validate_commit_range_args

        args = MagicMock()
        args.from_commit = "abc123"
        args.to_commit = "def456"

        # Should not raise any exception
        validate_commit_range_args(args, "commit")

    def test_validate_commit_range_args_to_without_from(self):
        """Test validate_commit_range_args with --to but no --from."""
        from aipr.main import validate_commit_range_args

        args = MagicMock()
        args.from_commit = None
        args.to_commit = "def456"

        with pytest.raises(ValueError, match="--to can only be used together with --from"):
            validate_commit_range_args(args, "commit")

    def test_validate_commit_range_args_no_range(self):
        """Test validate_commit_range_args with no range specified."""
        from aipr.main import validate_commit_range_args

        args = MagicMock()
        args.from_commit = None
        args.to_commit = None

        # Should not raise any exception
        validate_commit_range_args(args, "commit")

    def test_determine_pr_mode_range(self):
        """Test determine_pr_mode with commit range."""
        from aipr.main import determine_pr_mode

        args = MagicMock()
        args.from_commit = "abc123"
        args.to_commit = None
        args.target = None
        args.working_tree = False

        mode = determine_pr_mode(args)
        assert mode == "range"

    def test_determine_pr_mode_working_tree(self):
        """Test determine_pr_mode with working_tree flag."""
        from aipr.main import determine_pr_mode

        args = MagicMock()
        args.from_commit = None
        args.to_commit = None
        args.target = None
        args.working_tree = True

        mode = determine_pr_mode(args)
        assert mode == "working_tree"

    def test_determine_pr_mode_target(self):
        """Test determine_pr_mode with target specified."""
        from aipr.main import determine_pr_mode

        args = MagicMock()
        args.from_commit = None
        args.to_commit = None
        args.target = "main"
        args.working_tree = False

        mode = determine_pr_mode(args)
        assert mode == "target"

    def test_determine_pr_mode_auto(self):
        """Test determine_pr_mode with auto detection."""
        from aipr.main import determine_pr_mode

        args = MagicMock()
        args.from_commit = None
        args.to_commit = None
        args.target = None
        args.working_tree = False

        mode = determine_pr_mode(args)
        assert mode == "auto"

    def test_validate_commit_range_args_pr_conflicts_with_target(self):
        """Test validate_commit_range_args with range conflicting with target for pr command."""
        from aipr.main import validate_commit_range_args

        args = MagicMock()
        args.from_commit = "abc123"
        args.to_commit = None
        args.target = "main"
        args.working_tree = False

        with pytest.raises(ValueError, match="--from/--to cannot be used with --target"):
            validate_commit_range_args(args, "pr")

    def test_validate_commit_range_args_pr_conflicts_with_working_tree(self):
        """Test validate_commit_range_args with range conflicting with working_tree for pr command."""
        from aipr.main import validate_commit_range_args

        args = MagicMock()
        args.from_commit = "abc123"
        args.to_commit = None
        args.target = None
        args.working_tree = True

        with pytest.raises(ValueError, match="--from/--to cannot be used with --working-tree"):
            validate_commit_range_args(args, "pr")

    def test_determine_commit_mode_range(self):
        """Test determine_commit_mode with commit range."""
        from aipr.main import determine_commit_mode

        args = MagicMock()
        args.from_commit = "abc123"
        args.to_commit = None

        mode = determine_commit_mode(args)
        assert mode == "range"

    def test_determine_commit_mode_staged(self):
        """Test determine_commit_mode with staged changes."""
        from aipr.main import determine_commit_mode

        args = MagicMock()
        args.from_commit = None
        args.to_commit = None

        mode = determine_commit_mode(args)
        assert mode == "staged"

    @patch("git.Repo")
    @patch("aipr.main.get_commit_range_diff")
    @patch("aipr.main.generate_commit_message")
    @patch("aipr.main.detect_provider_and_model")
    @patch("aipr.main.validate_commit_range_args")
    @patch("aipr.main.determine_commit_mode")
    def test_handle_commit_command_range_mode(
        self,
        mock_determine_mode,
        mock_validate,
        mock_detect,
        mock_generate,
        mock_get_diff,
        mock_repo_class,
    ):
        """Test handle_commit_command with commit range mode."""
        from aipr.main import handle_commit_command

        # Setup mocks
        mock_repo = MagicMock()
        mock_repo_class.return_value = mock_repo
        mock_determine_mode.return_value = "range"
        mock_detect.return_value = ("anthropic", "claude-sonnet-4-5-20250929")
        mock_get_diff.return_value = ("commit range diff content", {"total": 1, "files": []})
        mock_generate.return_value = "feat: add new feature from commit range"

        args = MagicMock()
        args.from_commit = "abc123"
        args.to_commit = "def456"
        args.debug = False
        args.silent = True
        args.verbose = False
        args.model = None
        args.context = ""

        with patch("sys.exit") as mock_exit:
            with patch("builtins.print") as mock_print:
                handle_commit_command(args)

                # Verify validations and mode detection
                mock_validate.assert_called_once_with(args, "commit")
                mock_determine_mode.assert_called_once_with(args)

                # Verify commit range diff was retrieved
                mock_get_diff.assert_called_once()

                # Verify AI generation was called with correct parameters
                mock_generate.assert_called_once()

                # Verify result was printed
                mock_print.assert_called_with("feat: add new feature from commit range")
                mock_exit.assert_not_called()

    @patch("aipr.main.get_commit_range_diff")
    @patch("aipr.main.generate_description")
    @patch("aipr.main.detect_provider_and_model")
    @patch("aipr.main.validate_commit_range_args")
    @patch("aipr.main.determine_pr_mode")
    def test_handle_pr_command_range_mode(
        self, mock_determine_mode, mock_validate, mock_detect, mock_generate, mock_get_diff
    ):
        """Test handle_pr_command with commit range mode."""
        from aipr.main import handle_pr_command

        # Setup mocks
        mock_determine_mode.return_value = "range"
        mock_detect.return_value = ("anthropic", "claude-sonnet-4-5-20250929")
        mock_get_diff.return_value = ("commit range diff content", {"files": [], "total": 0})
        mock_generate.return_value = "PR description from commit range"

        args = MagicMock()
        args.from_commit = "abc123"
        args.to_commit = "def456"
        args.debug = False
        args.silent = True
        args.verbose = False
        args.model = None
        args.vulns = False
        args.prompt = None

        with patch("sys.exit") as mock_exit:
            with patch("builtins.print") as mock_print:
                handle_pr_command(args)

                # Verify validations and mode detection
                mock_validate.assert_called_once_with(args, "pr")
                mock_determine_mode.assert_called_once_with(args)

                # Verify commit range diff was retrieved
                mock_get_diff.assert_called_once()

                # Verify AI generation was called
                mock_generate.assert_called_once()

                # Verify result was printed
                mock_print.assert_called_with("PR description from commit range")
                mock_exit.assert_not_called()

    @patch("git.Repo")
    @patch("aipr.main.get_commit_range_diff")
    def test_handle_commit_command_range_mode_debug(self, mock_get_diff, mock_repo_class):
        """Test handle_commit_command with commit range mode in debug mode."""
        from aipr.main import handle_commit_command

        # Setup repo mock
        mock_repo = MagicMock()
        mock_repo_class.return_value = mock_repo

        mock_get_diff.return_value = (
            "commit range diff content",
            {"total": 2, "added": 1, "modified": 1, "deleted": 0},
        )

        args = MagicMock()
        args.from_commit = "abc123"
        args.to_commit = "def456"
        args.debug = True
        args.model = None
        args.silent = True
        args.verbose = False
        args.context = ""
        args.working_tree = False
        args.target = None

        with patch("aipr.main.validate_commit_range_args"):
            with patch("aipr.main.determine_commit_mode", return_value="range"):
                with patch("sys.exit") as mock_exit:
                    with patch("builtins.print") as mock_print:
                        handle_commit_command(args)

                        # Verify debug mode exits without AI call - should exit with 0 eventually
                        # Check the last call to see if it's the debug exit
                        assert mock_exit.call_count >= 1
                        # The last call should be exit(0) for debug mode
                        last_call = mock_exit.call_args_list[-1]
                        if last_call == call(0):
                            # Good, debug mode worked
                            pass
                        else:
                            # Debug the calls to understand what happened
                            print(f"Exit calls: {mock_exit.call_args_list}")
                            # For now, just check that debug exit was called
                            assert any(
                                call_args == call(0) for call_args in mock_exit.call_args_list
                            )

                        # Verify debug output was printed
                        assert mock_print.call_count > 0
                        # Check that debug analysis was printed
                        debug_calls = [str(call) for call in mock_print.call_args_list]
                        debug_output = " ".join(debug_calls)
                        assert "Range:" in debug_output or "Files changed:" in debug_output

    def test_commit_range_cli_integration_pr_command(self):
        """Test CLI integration for pr command with commit range flags."""
        from aipr.main import parse_args

        # Test pr command with --from and --to
        args = parse_args(["pr", "--from", "abc123", "--to", "def456", "--silent"])

        assert args.from_commit == "abc123"
        assert args.to_commit == "def456"
        assert args.silent is True

    def test_commit_range_cli_integration_commit_command(self):
        """Test CLI integration for commit command with commit range flags."""
        from aipr.main import parse_args

        # Test commit command with --from only (--to defaults to HEAD)
        args = parse_args(["commit", "--from", "abc123", "--silent"])

        assert args.from_commit == "abc123"
        assert args.to_commit is None
        assert args.silent is True

    def test_commit_range_help_text_includes_range_info(self):
        """Test that help text includes information about commit range functionality."""
        from aipr.main import parse_args

        # Test that both commands include commit range help
        with patch("sys.exit"):
            with patch("sys.stdout.write") as mock_write:
                try:
                    parse_args(["pr", "--help"])
                except SystemExit:
                    pass

                help_output = " ".join([str(call) for call in mock_write.call_args_list])
                assert "--from" in help_output
                assert "--to" in help_output

    @patch("aipr.main.get_commit_range_diff")
    def test_handle_commit_command_range_error_handling(self, mock_get_diff):
        """Test error handling in commit range mode."""
        from aipr.main import handle_commit_command

        # Mock get_commit_range_diff to raise an error
        mock_get_diff.side_effect = ValueError("Invalid commit reference: abc123")

        args = MagicMock()
        args.from_commit = "abc123"
        args.to_commit = "def456"
        args.debug = False
        args.silent = True

        with patch("aipr.main.validate_commit_range_args"):
            with patch("aipr.main.determine_commit_mode", return_value="range"):
                with patch("sys.exit") as mock_exit:
                    with patch("builtins.print") as mock_print:
                        handle_commit_command(args)

                        # Verify error was printed and program exited
                        # Check that error message contains expected text (ignoring color codes)
                        print_calls = mock_print.call_args_list
                        assert any(
                            "Invalid commit reference: abc123" in str(call) for call in print_calls
                        )
                        mock_exit.assert_called_with(1)
