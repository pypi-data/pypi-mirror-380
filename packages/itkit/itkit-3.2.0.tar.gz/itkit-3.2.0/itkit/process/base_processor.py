import os, json, pdb
from abc import ABC, abstractmethod
from multiprocessing import Pool, cpu_count
from tqdm import tqdm
from enum import Enum


"""
Abstract base classes for creating data processing pipelines in ITK.

This module provides a framework for building reusable data processing tools
that operate on medical imaging datasets. It standardizes common tasks such
as file discovery, parallel processing, and metadata collection.

How to Choose a Processor:
- Use `DatasetProcessor`: If your data is structured with 'image' and 'label'
  subdirectories containing corresponding files.
    /path/to/data/
        ├── image/
        │   ├── case01.mha
        │   └── case02.mha
        └── label/
            ├── case01.mha
            └── case02.mha

- Use `SingleFolderProcessor`: If you are processing all files within a
  single directory (e.g., converting all images in a folder to a new
  orientation).
    /path/to/data/
        ├── case01.nii.gz
        ├── case02.mha
        └── ...

- Use `SeparateFoldersProcessor`: If your images and labels are in two
  completely separate directories but share the same filenames.
    /path/to/images/
        ├── case01.mha
        └── case02.mha
    /path/to/labels/
        ├── case01.mha
        └── case02.mha

How to Implement a New Processor:
1. Choose and inherit from one of the three processor classes above.
2. Implement the `process_one` method. This method contains the core logic
   for processing a single file or a pair of files. It should return a
   dictionary if you want to collect metadata, otherwise return `None`.
3. Call the `process()` method on an instance of your new processor to run
   the entire pipeline.
"""


class ProcessingMode(Enum):
    """Define different file processing modes"""
    DATASET_PAIRS = "dataset_pairs"      # image/label subfolders
    SINGLE_FOLDER = "single_folder"      # single folder with files
    SEPARATE_FOLDERS = "separate_folders"  # separate img and lbl folders
    

class BaseITKProcessor(ABC):
    """
    The abstract base class for all ITK processing pipelines.

    This class provides the core infrastructure for processing datasets, including:
    - A standardized `process()` entry point.
    - Multiprocessing support via `process_items`.
    - Utility methods for finding files (`find_files_recursive`, `find_files_flat`).
    - A mechanism for collecting and saving metadata.

    A subclass MUST implement two abstract methods:
    1. `get_items_to_process()`: Defines how to discover the files or file pairs
       that need to be processed.
    2. `process_one()`: Defines the actual operation to be performed on a single
       item from the list generated by `get_items_to_process`.
    """
    
    def __init__(self,
                 mp: bool = False,
                 workers: int | None = None,
                 extensions: tuple[str, ...] = ('.mha', '.mhd', '.nii', '.nii.gz')):
        """
        Initializes the base processor.

        Args:
            mp (bool): If True, enables multiprocessing. Defaults to False.
            workers (int | None): The number of worker processes to use. If None,
                it defaults to the number of CPU cores.
            extensions (tuple[str, ...]): A tuple of file extensions to look for.
        """
        self.mp = mp
        self.workers = workers or cpu_count()
        self.meta = {}
        self.extensions = extensions
        self.source_folder: str | None = None
        self.dest_folder: str | None = None
    
    def find_files_recursive(self, folder: str, extensions: tuple[str, ...] | None = None) -> list[str]:
        """
        Recursively finds all files in a directory matching the given extensions.

        Args:
            folder (str): The directory to search in.
            extensions (tuple[str, ...] | None): A tuple of file extensions.
                If None, uses the processor's default extensions.

        Returns:
            list[str]: A list of absolute paths to the found files.
        """
        if extensions is None:
            extensions = self.extensions
            
        files = []
        for root, dirs, filenames in os.walk(folder):
            for filename in filenames:
                if filename.endswith(extensions):
                    files.append(os.path.join(root, filename))
        return files
    
    def find_files_flat(self, folder: str, extensions: tuple[str, ...] | None = None) -> list[str]:
        """
        Finds all files in the top-level of a directory (non-recursive).

        Args:
            folder (str): The directory to search in.
            extensions (tuple[str, ...] | None): A tuple of file extensions.
                If None, uses the processor's default extensions.

        Returns:
            list[str]: A list of absolute paths to the found files.
        """
        if extensions is None:
            extensions = self.extensions
            
        files = []
        for f in os.listdir(folder):
            if f.endswith(extensions):
                files.append(os.path.join(folder, f))
        return files
    
    def find_pairs_dataset(self, source_folder: str, recursive: bool = False) -> list[tuple[str, str]]:
        """
        Finds matching image-label pairs for the 'dataset' structure.
        
        This expects `source_folder` to contain 'image' and 'label' subdirectories.

        Args:
            source_folder (str): The root directory containing 'image' and 'label' folders.
            recursive (bool): If True, searches subdirectories within 'image' and 'label'.

        Returns:
            list[tuple[str, str]]: A list of tuples, where each tuple is a pair of
            (image_path, label_path).
        """
        img_dir = os.path.join(source_folder, 'image')
        lbl_dir = os.path.join(source_folder, 'label')
        
        if not (os.path.isdir(img_dir) and os.path.isdir(lbl_dir)):
            raise ValueError(f"Missing 'image' or 'label' subfolders in {source_folder}")
        
        if recursive:
            # Get all image files with relative paths
            img_files = {}
            for img_path in self.find_files_recursive(img_dir):
                rel_path = os.path.relpath(img_path, img_dir)
                # Normalize extension for matching
                key = self._normalize_filename(rel_path)
                img_files[key] = img_path
            
            lbl_files = {}
            for lbl_path in self.find_files_recursive(lbl_dir):
                rel_path = os.path.relpath(lbl_path, lbl_dir)
                key = self._normalize_filename(rel_path)
                lbl_files[key] = lbl_path
        else:
            # Simple flat matching
            img_files = {self._normalize_filename(f): os.path.join(img_dir, f) for f in os.listdir(img_dir) if f.endswith(self.extensions)}
            lbl_files = {self._normalize_filename(f): os.path.join(lbl_dir, f) for f in os.listdir(lbl_dir) if f.endswith(self.extensions)}
        
        # Find intersection
        common_keys = set(img_files.keys()) & set(lbl_files.keys())
        pairs = [(img_files[key], lbl_files[key]) for key in common_keys]
        return pairs
    
    def find_pairs_separate(self, img_folder: str, lbl_folder: str) -> list[tuple[str, str]]:
        """
        Finds matching image-label pairs from two separate folders.

        Args:
            img_folder (str): The directory containing image files.
            lbl_folder (str): The directory containing label files.

        Returns:
            list[tuple[str, str]]: A list of tuples, where each tuple is a pair of
            (image_path, label_path).
        """
        img_files_paths = self.find_files_flat(img_folder)
        lbl_files_paths = self.find_files_flat(lbl_folder)

        img_files = {self._normalize_filename(os.path.basename(f)): f for f in img_files_paths}
        lbl_files = {self._normalize_filename(os.path.basename(f)): f for f in lbl_files_paths}
        
        common_files = set(img_files.keys()) & set(lbl_files.keys())
        pairs = [(img_files[f], lbl_files[f]) for f in common_files]
        return pairs
    
    def _normalize_filename(self, filepath: str) -> str:
        """
        Normalizes a filename for matching by removing common extensions.
        
        This is useful for matching files like 'case1.nii.gz' with 'case1.mha'.

        Args:
            filepath (str): The file path or name.

        Returns:
            str: The base name of the file without its final extension(s).
        """
        base = os.path.splitext(filepath)[0]
        # Handle double extensions like .nii.gz
        if base.endswith('.nii'):
            base = base[:-4]
        return base
    
    def process(self, desc: str = "Processing"):
        """
        The main entry point to run the processing pipeline.
        
        This method orchestrates the process: it calls `get_items_to_process`
        to discover items and then `process_items` to execute the processing.

        Args:
            desc (str): A description for the progress bar (e.g., "Resampling", "Patching").
        """
        items = self.get_items_to_process()
        self.process_items(items, desc)

    def process_items(self, items: list, desc: str = "Processing"):
        """
        Processes a list of items, with optional multiprocessing.

        This is the engine of the processor. It iterates over the items,
        calls `process_one` for each, and collects the results.

        Args:
            items (list): The list of items (e.g., file paths or pairs of paths) to process.
            desc (str): The description to show in the tqdm progress bar.

        Returns:
            list: A list of results returned by `process_one` for each item.
        """
        if not items:
            print(f"No items found for {desc.lower()}.")
            return []
        
        if self.mp:
            with Pool(self.workers) as pool:
                results = list(tqdm(pool.imap_unordered(self.process_one, items),
                                    total=len(items), desc=desc, dynamic_ncols=True))
        else:
            results = []
            for item in tqdm(items, desc=desc, dynamic_ncols=True):
                results.append(self.process_one(item))
        
        # Collect metadata from the results
        for res in results:
            if res:
                self.meta.update(res)
        
        return results
    
    @abstractmethod
    def get_items_to_process(self) -> list:
        """
        Abstract method to discover all items (files, pairs) to be processed.
        
        This is one of the two core methods a subclass must implement.

        Returns:
            list: A list of items to be processed. Each item will be passed as an
            argument to `process_one`.
        """
        pass

    @abstractmethod
    def process_one(self, args) -> dict | None:
        """
        Abstract method to process a single item.

        This is the other core method a subclass must implement. It contains the
        actual logic for transforming, analyzing, or otherwise processing a single
        data sample.

        Args:
            args: The item to process, as provided by `get_items_to_process`. This
                could be a single file path (str) or a tuple of paths.

        Returns:
            dict | None: A dictionary containing metadata for the processed item.
            The dictionary will be collected and can be saved with `save_meta`.
            Return `None` if no metadata should be recorded for this item.
        """
        pass
    
    def save_meta(self, meta_path: str | None = None):
        """
        Saves the collected metadata to a JSON file.

        Args:
            meta_path (str | None): The full path to save the metadata file.
                If None, it defaults to 'series_meta.json' inside the `dest_folder`.
        """
        if not meta_path and self.dest_folder:
            meta_path = os.path.join(self.dest_folder, 'series_meta.json')
        if meta_path:
            try:
                os.makedirs(os.path.dirname(meta_path), exist_ok=True)
                with open(meta_path, 'w') as f:
                    json.dump(self.meta, f, indent=4)
                print(f"Metadata saved to {meta_path}")
            except Exception as e:
                print(f"Warning: Could not save metadata: {e}")


class DatasetProcessor(BaseITKProcessor):
    """
    A processor for datasets with a specific 'image'/'label' directory structure.

    Use this class when your data is organized as follows:
    /path/to/data/
        ├── image/
        │   └── case01.mha
        └── label/
            └── case01.mha
    """
    
    def __init__(self, 
                 source_folder: str,
                 dest_folder: str | None = None,
                 mp: bool = False,
                 workers: int | None = None,
                 recursive: bool = False):
        """
        Initializes the DatasetProcessor.

        Args:
            source_folder (str): The root directory containing 'image' and 'label' subfolders.
            dest_folder (str | None): The root directory where results will be saved.
            mp (bool): Enable multiprocessing.
            workers (int | None): Number of worker processes.
            recursive (bool): If True, search for files recursively within the
                'image' and 'label' subdirectories.
        """
        super().__init__(mp, workers)
        self.source_folder = source_folder
        self.dest_folder = dest_folder
        self.recursive = recursive
    
    def get_items_to_process(self) -> list[tuple[str, str]]:
        """
        Finds all corresponding image-label pairs in the dataset.

        Returns:
            list[tuple[str, str]]: A list of (image_path, label_path) tuples.
        """
        return self.find_pairs_dataset(self.source_folder, self.recursive)


class SingleFolderProcessor(BaseITKProcessor):
    """
    A processor for handling all files within a single folder.

    Use this class for operations that apply to individual files, such as
    resampling or reorienting a collection of images that are not paired with labels.
    """
    
    def __init__(self,
                 source_folder: str,
                 dest_folder: str | None = None,
                 mp: bool = False,
                 workers: int | None = None,
                 recursive: bool = False):
        """
        Initializes the SingleFolderProcessor.

        Args:
            source_folder (str): The directory containing the files to process.
            dest_folder (str | None): The directory where results will be saved.
            mp (bool): Enable multiprocessing.
            workers (int | None): Number of worker processes.
            recursive (bool): If True, search for files recursively.
        """
        super().__init__(mp, workers)
        self.source_folder = source_folder
        self.dest_folder = dest_folder
        self.recursive = recursive
    
    def get_items_to_process(self) -> list[str]:
        """
        Finds all files in the source folder.

        Returns:
            list[str]: A list of file paths to be processed.
        """
        if self.recursive:
            return self.find_files_recursive(self.source_folder)
        else:
            return self.find_files_flat(self.source_folder)


class SeparateFoldersProcessor(BaseITKProcessor):
    """
    A processor for handling image and label files located in two separate folders.

    Use this class when your images and labels are not in the same parent directory,
    but can be matched by filename.
    """
    
    def __init__(self,
                 img_folder: str,
                 lbl_folder: str,
                 out_img_folder: str | None = None,
                 out_lbl_folder: str | None = None,
                 mp: bool = False,
                 workers: int | None = None):
        """
        Initializes the SeparateFoldersProcessor.

        Args:
            img_folder (str): The directory containing image files.
            lbl_folder (str): The directory containing label files.
            out_img_folder (str | None): Directory to save processed images.
            out_lbl_folder (str | None): Directory to save processed labels.
            mp (bool): Enable multiprocessing.
            workers (int | None): Number of worker processes.
        """
        super().__init__(mp, workers)
        self.img_folder = img_folder
        self.lbl_folder = lbl_folder
        self.out_img_folder = out_img_folder
        self.out_lbl_folder = out_lbl_folder
        # Set dest_folder for metadata saving purposes
        self.dest_folder = out_img_folder or out_lbl_folder
    
    def get_items_to_process(self) -> list[tuple[str, str]]:
        """
        Finds all corresponding image-label pairs from the two separate folders.

        Returns:
            list[tuple[str, str]]: A list of (image_path, label_path) tuples.
        """
        return self.find_pairs_separate(self.img_folder, self.lbl_folder)
